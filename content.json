{"meta":{"title":"荆文征","subtitle":"已識乾坤大，猶憐草木新。","description":"欲买桂花同载酒<br/>终不似 少年游","author":"小酒馆老板","url":"http://blog.msiter.com"},"pages":[{"title":"","date":"2018-08-29T10:33:16.494Z","updated":"2018-08-29T10:33:16.494Z","comments":true,"path":"404.html","permalink":"http://blog.msiter.com/404.html","excerpt":"","text":"404.html"},{"title":"","date":"2018-08-29T10:33:16.922Z","updated":"2018-08-29T10:33:16.922Z","comments":true,"path":"themes_config.json","permalink":"http://blog.msiter.com/themes_config.json","excerpt":"","text":"{\"override\":false,\"favicon\":{\"small\":\"favicon/favicon.png\",\"medium\":\"favicon/favicon.png\",\"apple_touch_icon\":\"favicon/favicon.png\",\"safari_pinned_tab\":\"favicon/favicon.png\"},\"keywords\":\"IOS,Swift,开发,技术,荆文征，博客,blog,msiter\",\"rss\":null,\"footer\":{\"icon\":\"user\",\"copyright\":false,\"powered\":false,\"theme\":{\"enable\":false,\"version\":false}},\"canonical\":true,\"seo\":true,\"index_with_subtitle\":true,\"menu\":{\"home\":\"/ || home\",\"tags\":\"/tags/ || tags\",\"categories\":\"/categories/ || th\",\"archives\":\"/archives/ || archive\"},\"menu_icons\":{\"enable\":true},\"scheme\":\"Pisces\",\"social_icons\":{\"enable\":true,\"icons_only\":false,\"transition\":false,\"GitHub\":\"github\",\"Twitter\":\"twitter\",\"Weibo\":\"weibo\"},\"links_icon\":\"link\",\"links_title\":\"Links\",\"links_layout\":\"block\",\"avatar\":\"favicon/avatar.jpg\",\"toc\":{\"enable\":true,\"number\":true,\"wrap\":false},\"sidebar\":{\"position\":\"left\",\"display\":\"post\",\"offset\":12,\"b2t\":true,\"scrollpercent\":false,\"onmobile\":false},\"scroll_to_more\":true,\"save_scroll\":false,\"excerpt_description\":true,\"auto_excerpt\":{\"enable\":false,\"length\":150},\"post_meta\":{\"item_text\":true,\"created_at\":true,\"updated_at\":false,\"categories\":true},\"post_wordcount\":{\"item_text\":true,\"wordcount\":false,\"min2read\":false,\"totalcount\":false,\"separated_meta\":true},\"post_copyright\":{\"enable\":false,\"license\":\"CC BY-NC-SA 3.0\",\"license_url\":\"https://creativecommons.org/licenses/by-nc-sa/3.0/\"},\"mobile_layout_economy\":false,\"android_chrome_color\":\"#222\",\"custom_logo\":{\"enabled\":false,\"image\":null},\"highlight_theme\":\"normal\",\"font\":{\"enable\":false,\"host\":null,\"global\":{\"external\":true,\"family\":\"Lato\",\"size\":null},\"headings\":{\"external\":true,\"family\":null,\"size\":null},\"posts\":{\"external\":true,\"family\":null},\"logo\":{\"external\":true,\"family\":null,\"size\":null},\"codes\":{\"external\":true,\"family\":null,\"size\":null}},\"mathjax\":{\"enable\":false,\"per_page\":false,\"cdn\":\"//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML\"},\"han\":false,\"baidu_analytics\":\"37f9fd734b75f078c1b06452e6c3ccfb\",\"disqus\":{\"enable\":false,\"shortname\":\"msiter\",\"count\":true},\"changyan\":{\"enable\":true,\"appid\":\"cytc1YTze\",\"appkey\":\"4df84c3a0a2bad896b42860f7ed0a300\"},\"valine\":{\"enable\":false,\"appid\":null,\"appkey\":null,\"notify\":false,\"verify\":false,\"placeholder\":\"Comment input placeholder\"},\"gitment\":{\"enable\":false,\"mint\":true,\"count\":true,\"lazy\":false,\"cleanly\":false,\"language\":null,\"github_user\":null,\"github_repo\":null,\"client_id\":null,\"client_secret\":null,\"proxy_gateway\":null,\"redirect_protocol\":null},\"needmoreshare2\":{\"enable\":false,\"postbottom\":{\"enable\":false,\"options\":{\"iconStyle\":\"box\",\"boxForm\":\"horizontal\",\"position\":\"bottomCenter\",\"networks\":\"Weibo,Wechat,Douban,QQZone,Twitter,Facebook\"}},\"float\":{\"enable\":false,\"options\":{\"iconStyle\":\"box\",\"boxForm\":\"horizontal\",\"position\":\"middleRight\",\"networks\":\"Weibo,Wechat,Douban,QQZone,Twitter,Facebook\"}}},\"duoshuo_info\":{\"ua_enable\":true,\"admin_enable\":false,\"user_id\":0},\"facebook_sdk\":{\"enable\":false,\"app_id\":null,\"fb_admin\":null,\"like_button\":null,\"webmaster\":null},\"facebook_comments_plugin\":{\"enable\":false,\"num_of_posts\":10,\"width\":\"100%\",\"scheme\":\"light\"},\"vkontakte_api\":{\"enable\":false,\"app_id\":null,\"like\":true,\"comments\":true,\"num_of_posts\":10},\"rating\":{\"enable\":false,\"id\":null,\"color\":\"fc6423\"},\"leancloud_visitors\":{\"enable\":false,\"app_id\":null,\"app_key\":null},\"busuanzi_count\":{\"enable\":false,\"site_uv\":true,\"site_uv_header\":\"\",\"site_uv_footer\":null,\"site_pv\":true,\"site_pv_header\":\"\",\"site_pv_footer\":null,\"page_pv\":true,\"page_pv_header\":\"\",\"page_pv_footer\":null},\"baidu_push\":false,\"calendar\":{\"enable\":false,\"calendar_id\":\"\",\"api_key\":\"\",\"orderBy\":\"startTime\",\"offsetMax\":24,\"offsetMin\":4,\"timeZone\":null,\"showDeleted\":false,\"singleEvents\":true,\"maxResults\":250},\"algolia_search\":{\"enable\":false,\"hits\":{\"per_page\":10},\"labels\":{\"input_placeholder\":\"Search for Posts\",\"hits_empty\":\"We didn't find any results for the search: ${query}\",\"hits_stats\":\"${hits} results found in ${time} ms\"}},\"local_search\":{\"enable\":true,\"trigger\":\"auto\",\"top_n_per_article\":1},\"exturl\":false,\"note\":{\"style\":\"simple\",\"icons\":false,\"border_radius\":3,\"light_bg_offset\":0},\"label\":true,\"tabs\":{\"enable\":true,\"transition\":{\"tabs\":false,\"labels\":true},\"border_radius\":0},\"motion\":{\"enable\":true,\"async\":false,\"transition\":{\"post_block\":\"fadeIn\",\"post_header\":\"slideDownIn\",\"post_body\":\"slideDownIn\",\"coll_header\":\"slideLeftIn\",\"sidebar\":\"slideUpIn\"}},\"fancybox\":true,\"pace\":false,\"pace_theme\":\"pace-theme-minimal\",\"canvas_nest\":false,\"three_waves\":false,\"canvas_lines\":false,\"canvas_sphere\":false,\"canvas_ribbon\":{\"enable\":false,\"size\":300,\"alpha\":0.6,\"zIndex\":-1},\"vendors\":{\"_internal\":\"lib\",\"jquery\":null,\"fancybox\":null,\"fancybox_css\":null,\"fastclick\":null,\"lazyload\":null,\"velocity\":null,\"velocity_ui\":null,\"ua_parser\":null,\"fontawesome\":null,\"algolia_instant_js\":null,\"algolia_instant_css\":null,\"pace\":null,\"pace_css\":null,\"canvas_nest\":null,\"three\":null,\"three_waves\":null,\"canvas_lines\":null,\"canvas_sphere\":null,\"canvas_ribbon\":null,\"han\":null,\"needMoreShare2\":null},\"css\":\"css\",\"js\":\"js\",\"images\":\"images\",\"version\":\"5.1.3\"} themes_config.yml"},{"title":"留言板","date":"2018-08-29T10:33:16.506Z","updated":"2018-08-29T10:33:16.506Z","comments":false,"path":"about/index.html","permalink":"http://blog.msiter.com/about/index.html","excerpt":"","text":"I heard, that your settled down. 已闻君，诸事安康。That you, found a girl and your married now.遇佳人，不久婚嫁。I heard that your dreams came true. 已闻君，得偿所想。Guess she gave you things, I didn’t give to you. 料得是，卿识君望。Old friend, why are you so shy?旧日知己，何故张惶？It ain’t like you to hold back or hide from the lie.遮遮掩掩，欲盖弥彰。I hate to turn up out of the blue uninvited.客有不速，实非我所想。ButI couldn’t stay away, I couldn’t fight it. 避之不得，遑论与相抗。I’d hoped you’d see my face&amp; that you’d be reminded, 异日偶遇，识得依稀颜。That for me, it isn’t over.再无所求，涕零而泪下。Never mind, I’ll find someone like you. 毋须烦恼，终有弱水替沧海。I wish nothing but the best, for you too. 抛却纠缠，再把相思寄巫山。Don’t forget me, I beg, I remember you said:勿忘昨日，亦存君言于肺腑。“Sometimes it lasts in love but sometimes it hurts instead” “情堪隽永，也善心潮掀狂澜。”Sometimes it lasts in love but sometimes it hurts instead, yeah. 情堪隽永，也善心潮掀狂澜，然。You’d know, how the time flies.光阴常无踪，词穷不敢道荏苒。Only yesterday, was the time of our lives. 欢笑仍如昨，今却孤影忆花繁。We were born and raised in a summery haze. 彼时初执手，夏雾郁郁湿衣衫。Bound by the surprise of our glory days. 自缚旧念中，诧喜荣光永不黯。I hate to turn up out of the blue uninvited.客有不速，实非我所想。ButI couldn’t stay away, I couldn’t fight it. 避之不得，遑论与相抗。I’d hoped you’d see my face&amp; that you’d be reminded, 异日偶遇，识得依稀颜。That for me, it isn’t over.再无所求，涕零而泪下。 Nothing compares, no worries or cares. 无可与之相提，切莫忧心同挂念。Regret’s and mistakes they’re memories made. 糊涂遗恨难免，白璧微瑕方可恋。Who would have known how bittersweet this would taste? 此中酸甜苦咸，世上谁人堪相言？ index.md"},{"title":"类别","date":"2018-08-29T10:33:16.506Z","updated":"2018-08-29T10:33:16.506Z","comments":false,"path":"categories/index.html","permalink":"http://blog.msiter.com/categories/index.html","excerpt":"","text":"index.md"},{"title":"resume","date":"2018-01-20T18:31:56.000Z","updated":"2018-08-29T10:33:16.922Z","comments":true,"path":"resume/index.html","permalink":"http://blog.msiter.com/resume/index.html","excerpt":"","text":"name index.md"},{"title":"标签","date":"2018-08-29T10:33:16.922Z","updated":"2018-08-29T10:33:16.922Z","comments":false,"path":"tags/index.html","permalink":"http://blog.msiter.com/tags/index.html","excerpt":"","text":"index.md"},{"title":"","date":"2018-08-29T10:33:16.910Z","updated":"2018-08-29T10:33:16.910Z","comments":true,"path":"publicFiles/images/隔离见证闪电网络/PPT 文稿.html","permalink":"http://blog.msiter.com/publicFiles/images/隔离见证闪电网络/PPT 文稿.html","excerpt":"","text":"MT.Gox 迈得嘎斯，以下简称MT H2 点最早是美国企业家 杰德 在 2010 年 7 月创办。杰德 想法很简单，当时一个比特币已经可兑换数美元，而且挖矿机正在源源不断地产出新的比特币，他想建立一个交易所可以连接买家和卖家。但是，很快，这个交易所花光了 杰德 所有的积蓄，于是出售给另一位比特币爱好者， H2 点也就是图片中的 马克2011 年，他将 MT.Gox 收购。马克 将网站的后端软件重写，改进了用户体验，加上他在比特币社区的活跃，越来越多的人在这里交易比特币，最终它变成了最流行的交易平台，承担着全球 70% 的交易。事实证明，马克 对于技术的精通在网站发展初期十分有效，但是在后期，马克 在商业管理的不足逐渐凸现出来，但 MT 并未因此做出改变。比特币价格的飞涨给参与进来的人巨大的回报，MT 处理的流水越来越多，通过手续费累积的比特币也越来越多，数量达到了 10 万级别，总价值数千万美元。马克 的身价也水涨船高。但这些光环却掩盖不了 MT 在业务上的问题，问题主要还是出在产品上，MT 很长一段时间都不使用控制软件来制定专业的开发环境，这意味着两个同事在同一个文件夹下工作，很有可能覆盖掉对方的代码。他们甚至把许多不经测试的软件推送到用户手机上，要知道他们是做金融服务的，这样做很容易引发问题。2011 年 6 月，MT 首次遭遇黑客攻击，当时受此影响，MT.Gox 比特币的价格暴跌，从 30 美元跌至 0.01 美元，比特币市场遭遇重创。 H2 点比特币爱好者 杰西 从旧金山赶过来与好友 罗杰 一起帮 MT 解决问题，他们还没来得及放下行李就去办公室工作。杰西 和 罗杰 工作了一整周来修复问题，但是直到周末，问题还没解决。杰西和罗杰 准备周末接着干， H2 点但意外的是，马克 却决定周末放假休息，让两个志愿者大跌眼镜，他们感到十分泄气。马克 并未真正重视这个问题，等到周一开工，他却花时间在整理信封，把问题丢在一边。随着 2014年2月份到来，危机终于降临，黑客利用比特币“交易可延展性”，将 MT 中的比特币洗劫一空2014年2月底，MT举行新闻发布会，会上承认丢失了 85 万个比特币，价值近 4.7 亿美元。在这 85 万个比特币中，75 万个属于客户，10 万个属于 Mt 自有资产。 H2 点比特币的延展性什么叫做 延展性，说是延展性，也可以理解为可塑性。举个例子来说《龙门镖局》中的白敬祺为了藏私房钱，将银锭打成了银夜壶，而银夜壶和银锭的价值是相当的，这就是金属“可锻性”的物理表现。比特币的一个“交易”是一段指令，这段指令告诉整个网络：我作为一些比特币的拥有者，要把他们的所有权转移到目标地址。这样，谁拥有目标地址，我就把钱打给谁了。这段指令本质上是一个hash字符串，就像这样： H2 点然后，你对这个字符串提取一个所谓的哈希，可以理解为用摘要的方式获得一个比较短的字符串，像这样的： H2 点这个东西就是咱们说的交易ID txid现在我们一步步的来看看这样到底如何完成交易延展性攻击的。首先我们来看一个交易的原始数据 H2 点在这里可以看到，input 和 out 都存在一个 script 字符串接下来，我们首先将 输入脚本进行格式化 H2 点这个就是原始的脚本，它主要包含的是，签名和公钥 H2 点输出脚本格式化之后我们可以看到，它存在很多脚本操作符。 在这里，扩展一下，比特币在交易中使用的脚本，比特币使用的脚本与FORTH(一种编译语言)一样，脚本是简单的、基于堆栈的、并且从左向右处理，它特意设计成非图灵完整，没有LOOP语句。它和逆波兰表达式类似，基于堆栈来执行。 接下来我们来演示下比特币是如何确认一次交易的。 H2 点####### 自己看着点首先执行的是『输入脚本』。因为脚本是从左向右执行的，那么先入栈的是『签名』，随后是『公钥』接着，执行的是『输出脚本』。从左向右执行，第一个指令是OP_DUP——复制栈顶元素OP_HASH160——推出并计算栈顶元素Hash，得到pubkeyhash，并将它放入栈顶将『输出脚本』中的『公钥哈希』入栈，为了和前面计算得到的哈希区别，称它为pubkeyhash’OP_EQUALVERIFY——检查栈顶前两元素是否相等，如果相等继续执行，否则中断执行，返回失败OP_CHECKSIG——使用栈顶前两元素执行签名校验操作，如果相等，返回成功，否则返回失败 当交易发送到比特币网络中后，网络中的各个结点会根据之前生成的签名来验证交易的真实性，这些做法都是很正确很理所当然的，MT就是这么做的，当你提现的时候，它就发出一个交易，然后记录下这个ID。当有人提现出问题要求重发时，他们就用这个ID去比特币网络检查这个ID有没有被确认，如果没有的话就重发。而问题就出现在签名算法中，由于现在大部分使用的签名算法都是基于OpenSSL的ECDSA（椭圆曲线数字签名），这个签名算法的一个问题就是，修改签名的某个字节能够使得签名依然校验成功，这样伪造签名之后交易依然能成功进行。如果单在比特币网络中这似乎没什么大不了的，顶多可以捣捣乱，因为你能使用的输出就那一个，你其中一笔交易使用了输出，第二笔自然就不会成功。但是对于第三方交易系统就不同了 记下来我们看看如何模拟一次攻击。 H2 点####### 自己看着点 大家还会有一个疑问，就是我们伪造的交易请求是在正常交易请求之后发出的，如果正常交易被采纳了，那我们伪造的交易如何能够奏效呢？这里就要说到比特币网络的一个特性，发出一个比特币交易请求后不会立刻返回交易成功与否，在比特币网络中会有一个处理延时，而比特币网络由于自身的特性，所有交易请求是以网状形式随机处理的，两次交易请求并不会以队列形式依次处理。这就给攻击者提供了可乘之机，专业的讲叫做时间条件竞争，通俗的讲就是拼人品。我们伪造的交易和正常的交易都在比特币网络中，如果伪造的交易先被处理，那么攻击成功。 隔离见证，就是把交易中见证脚本，提取出来，放到单独的数据结构里。这样子的话，交易变得安全，并且交易的大小会变小，因为在一笔交易中，见证脚本甚至可以占到75%。这样也在一定程度上实现了比特币的扩容。 为什么需要闪电网络 H2 点首先我们来说一下，现在比特币网络中存在的问题。 H2 点处理能力在最理想状态下，平均每笔交易225 字节。在1M区块限制下，一般平均10分钟可以打包大约 4400 笔交易。每秒大约7.3笔交易，实际交易平均大小是这个的一倍，那么容量减半，也就是每秒大约 3.6 笔交易。与当今的金融系统相比，Visa在标准的节假日每秒处理4.5万笔交易，通常的一个营业日则为数亿次交易。支付宝的每秒可以处理10万笔交易。而2017年的双11，支付峰值每秒25.6万笔。，然而比特币现在每秒约能支持7笔交易，同时还会受到区块链大小的限制。 H2 点时间延迟每一笔交易发起的时候，会出现10分钟的延迟，才会有可能被矿工确认。并且目前的交易量上升之后，你被确认的等待时间和你的手续费成反比，也就是说你的手续费越低，你被处理的顺序就越靠后。 H2 点交易最终性由于算哈希是随机的，加上网络有延迟，是有同时挖出两个区块的可能，然后不同的矿工根据他们收到的区块不同继续挖，然后还是有可能再出现分叉，但是几率会越来越小。一般认为一个区块在最长链上后面跟了五个区块，就不可能被分叉了。随着区块数量的增加，再次产生分叉的几率是呈指数下降的。到了6的区块的时候，就已经下降到不太可能分叉的情况 H2 点容量比特币，区块目前已经到51W多个区块。这么多的区块产生的容量是巨大的,而且以后只增不减 H2 点交易费中本聪最开始确定bitcoin一共有2100万个，当全部挖掘出来之后，矿工将不再获得奖励，到那个时候，矿工所有的收益都来自交易中的手续费。就目前为止，待确认交易堆积的这么多，也和交易费有关系，如果你想矿工早点确认你的交易，那么你就需要提高你的手续费，否则就没人处理。但是这个引起的来问题，也很明显，我就想买杯咖啡，就需要支付手续费吗？ 那么以后大概我们去买咖啡的时候，会遇到这种情况 H2 点你再付完钱后，不能立马走，你需要等待。 H2 点那到时候店规大概会是，顾客付比特币之后需要等至少一个小时才可以喝到咖啡，并且每杯咖啡会高于使用法币购买的，因为需要手续费。 这个时候我们就需要闪电网络了。 H2 点闪电网络 的基础基于 双向微支付通道，这里的微支付也说明，他尽可能的希望单次支付的金额足够小，即使一方违约另一方的损失也非常小，风险可以承受。因此使用时必须注意“微支付”这个前提。多少资金算“微”，显然应该根据业务而定。 H2 点而，我们要说的 RSMC 定义了该双向微支付通道的最基本工作方式 我们来模拟下这个过程是如何的 我们这里有两个好邻居，他们分别是花店老板娘和酒店老板，花店老板娘回去酒店买酒，而酒店老板也会去买花。如果他们每次都是用比特币的结账的话。相互找零和付钱很麻烦。 他们就决定各拿出来100块钱，放在另一个人哪里。 他们会创建一个账本来记录各自的消费记录，以及余额情况。 并且他们为了对方耍赖，每次更新账单的时候都会签字表示这个交易是自己承认的。 之后他们人手一份 并且记录当前的账单的详情，分别为100 花店老板娘区酒店买了瓶酒 花了 10 账单会发生如下更新，并且其中的时间格式也会发生变化。标志着之前的账单废除。 在之后，酒店老板在花店老板这里买了40 的花。 账单再次发生变化，并且时间也会发生变化 这样可以持续无限次 当然，如果某天酒店老板想拿回冻结的钱，他只只需要把账单给三方的人，这个人就会按照账单上的余额把钱发给各自的账户中。 当然，第三方发放余额的时候会有一段时间的缓冲时间，这主要是为了防止有人拿着坏账的情况。 酒点老板，在花费40之后出现了坏点子，他直接拿起了第二份账单去到了第三方。 在缓冲时间之内，花店老板拿出比酒店老板提取现金时间距离现在更近的账单的话，酒店老板不仅不会获得金币，反而会失去所有的金币。 通过构建适当的“举证”证据并结合罚没机制实现的。 为了鼓励双方尽可能久地利用通道进行交易，RSMC对主动终止通道方给予了一定的惩罚：主动提出方其资金到账将比对方晚，因此谁发起谁吃亏。这个设计虽然增加了技术复杂度，但应该说是合理的。 我们来用比特币中的经典人物， Alice 和 Bob 。 在这里，我们假设 Alice 拿出0.5个比特币，Bob也拿出0.5个比特币。 他们首先准备建立一个交易 Funding[分定]。 这个交易的输入是 Alice 的签名和Bob的签名，但是此时我们不签名，更不去广播这个交易。 我们再来看输出，输出为 Alice和Bob的 必须两个人都同意的多重签名。 接下来我们来看看 Alice构建它的第一个交易 C1a，他的输入本来应该是自己的签名以及Bob的签名，但是现在还没有签名。 记下来构建输出，输出有两个，第一个输出是 Alice的另一个把秘钥的 Alice2和Bob的多重签名。第二个输出为 Bob的0.5Btc。 接下来，来看看Alice构建的第二个交易 RD1a，这个交易的输入应该是 Alice2和Bob的签名，但是现在还没有 而它的输出呢是 Alice的0.5 个比特币，但是他和第一个交易不同的是，它的输出存在一个 sequence 1000.这个的作用时说，当前一笔交易确认到了1000个块的时候才会进入区块，才会被确认。 以当前值设为1000来计算的话，要接近一个星期才会被写入块… 这也是为了鼓励双方尽可能久地利用通道进行交易，主动提出方其资金到账将比对方晚，因此谁发起谁吃亏。 我们也为 Bob创建同样的交易。 在这个时候，我们的两笔交易已经创建完成了。我们将Alice 和 Bob的交易，进行交换的签名。 此时由于 Funding 交易并没有进行签名甚至说都没有广播，所以他们现在的交换是绝对安全的，任何一方都无法作恶，任何一方也不会吃亏。 双方都完成了交易之后，都各自对 Funding交易进行签名。此时 Funding 交易就已经是完整的交易了，广播它～ 至此一个 RSMC 通道就此建成。 Alice和Bob各自0.5BTC的余额，此时Alice从Bob处购买了一件商品，价格为0.1BTC，那么余额应该变为Alice 0.4BTC，Bob 0.6BTC。于是创建新的Commitment Tx，对于Alice来说是C2a 和RD2a，对于Bob来说是C2b和RD2b，过程与上面类似。 此时两个状态均是有效的，那么最核心的问题来了，如何才能彻底废弃掉C1a和C1b呢？RSMC采用了一个非常巧妙的方法，在C1a的第一个输出中，采用了Alice2和Bob的多重签名，Alice将Alice2的私钥交给Bob，即表示Alice放弃C1a，承认C2a Alice交出Alice2的私钥给Bob，那么Bob就可以修改RD1a的输出给他自己，形成新的交易BR1a。若Alice破坏合约存在C2a的情况下依然广播出C1a，那么Alice的惩罚就是失去她全部的币，这个Bob建立的简易叫做，作恶惩戒交易，就是用来惩戒不守规矩的一方。RD1a引入sequence的目的是，阻止后续交易进块（RD1a），给出一个实施惩罚窗口期，当发现对方破坏合约时，可以有1000个块确认的时间去实施惩罚交易，即广播BR1a代替RD1a。若错过1000个块时间窗口，则无法再实施惩罚了（RD1a进块了）。反之亦然。 正常情况下，Alice只要不在区块链上发布C1a，虽然Bob拥有输入解锁脚本完全就绪的BR1a，因为其父交易C1a并未发布，Bob也无法发布BR1a。这说明只要一方安分守己，就无需担心惩罚措施。 而交易关闭，咱们前面也说了，除了率先关闭交易的人会收到一些惩罚之外，其他没有任何影响，当然这一切都是没有人作弊的情况。 咱们再来看一下什么事 HTLC，HTLC简单来说就是为 RSMC提供了一个 有条件的资金支付方式。 具体是如何运作呢，我们还是来使用刚才的例子，花店老板，和酒店老板 在RSMC他们已经通过签名完成了，他们之前的快速交易了。但是，一笔还好，要是每一笔？都需要签名？ 在这个便捷的时代，绝对不与许这种行为啊。 所以，花店老板预先准备了一些钱，并且给这个锁加了一个钥匙，交给了第三方，告诉他，如果有人道你这里解开锁，拿钱就让他拿吧。 然后，花店老板去酒店老板哪里消费。消费完成之后，花店老板，直接丢给他一把钥匙。这样就不需要签名了，直接就可以不需要签名了。 而酒店老板只需要，拿着钥匙道第三方哪里，将锁解开。 就可以把钱拿到手了。 咱们再来看一下，HTCL的具体实现，在之前我们 看到了 RSMC的实现。 现在让我们来开始 HTCL的实现。 之前的交易展现方式不太适用现在了，我们调整为这个样子。 在这里，我们在 C2a交易增加一个新的输出，这个输出地址为为一段脚本，类似与这样子的脚本 在这个脚本里，我们可以看到它的流程处理，如下，首先，根据栈顶的元素的hash160和已经存在的hash值进行匹配，如果成功，继续匹配多重签名。否则，就调入下一个流程处理。 这里我们来模拟，Alice在Bob消费了0.1 bitCoin 的整个过程。 首先，Alice在Bob消费了0.1 bitCoin 给予R 之后，Bob 创建 HE1b交易，这里需要传递的输出分别为 Bob的一个签名 和 Alice的一个签名 以及一个 R值。如果传递成功之后，就可以输出一个交易，这个交易 的输出就是 Bob得到1个比特币。当然如果不符合规则的话，就会退回Alice的账户中。当然该操作符合闪电网络的先提出会收到惩罚的原则，我们的Bob需要交易确认1000个块，才可以提取到钱。 创建了这个交易之后，只要Bob 把 C2b D2b Rd2b 以及 He1b HERD1b 这个五个交易都发布出去就可以了，领取到0.6个bitCoin 而 Alice 会得到0.4个比特币，而整个交易通道到此也就关闭了。 那么我们如何，保持通道呢？很简单… 就是BOb离线告诉Alice他拥有适当R，且Alice和Bob都愿意达成新的余额划分，那么就新建一个 0.4 和 0.6 的新版本余额，并且废除旧版本，就可以了。好吧… 那既然如此 HTLC存在的意义在哪儿…. 在之后的 闪电网络，我们会知道为什么的 我们也可以看到 Alice这边也有一个交易，它的输出是 以 Alice获得 0.1bitcoin。但是前提是 LockTime &gt; 3 这就是给予 Bob获得R钥匙的3天时间，如果到了3天时间之后，Bob没有提供相对应的R值的话，Alice 可以构建该交易，并且需要构建另一个交易。Alice把 C2a RD2a D2a HT1a, HTRD1a 这五个交易来完成交易，倒是Alice和Bob都会获得0.5比特币。当然还是先发起申请的人还是会延迟1000个块确认时间才会入块。 建立新版本余额快照后，就应该作废旧版本。和之前作废旧版本的思路类似，在通道中还包含HTLC合约的情况下，依然靠新增若干作恶惩戒交易的方式作废旧版本。图中用红色虚线框出的部分就是新增的“作恶惩戒交易”。 假设HT1a交易已经超时，但以C2a为根的全部交易都已通过惩戒交易予以作废。如果此时Alice想作恶，她将C2a、RD2a、HT1a及HTRD1a区块链上公开。由于seq字段的限制，她不能立刻公开交易RD2a和HTRD1a，这样就使得Bob有机会发现Alice企图作恶并能够通过公布BR2a和HTBR1a交易的方式予以惩戒。发出这对交易后，通道中的全部资金将都归Bob所有。 虽然没有用上惩戒交易HBR1a，但该交易并不多余。理由是：如果Alice在区块链上公布了交易C2a但故意不公布交易HT1a，倘若Bob手头没有HBR1a，也不知道秘密R，Bob将无法获得这0.1 BTC。有了惩戒交易HBR1a之后，即使Alice不公布交易HT1a，只要C2a公布，Bob也可以通过HBR1a顺利提取这0.1 BTC。 只提供HBR1a、不提供HTBR1a也是不行的。因为万一Alice选择的是解锁并公布交易HT1a，并且抢在Bob之前消费了C2a的#2输出，Bob拥有的HBR1a交易就无法生效了，而此时虽然HTRD1a交易要等上1000个确认才能公布，Bob也没有任何手段来利用这1000个块的确认时间来阻止Alice提取这0.1 BTC。 闪电网络，简单来说就是中转交易，我们这里还是拿花店老板和酒店老板讲解，但是这个时候多了一个饭店老板 有一天，饭店老板 买酒10 元，临付账的时候，他和酒店老板并没有通道。所以没有办法直接交流。 但是饭店老板和花店老板有一个通道，那么这样子一个简单的网络就产生了。 这个时候饭店老板就私底下对酒店老板说“嘿，老酒，我要给你付笔钱”。 这个时候，老酒就生成了一个随机数，活着你可以理解为随便的一种密码，并且声称对应的一个Hash值，并把他交给饭店老板。 饭店老板，联系花店老板，说，老花，你只要给我一个密码，和我这边匹配了，我给你10.1。 花店老板虽然不知道密码，但是他还是答应了，他找到酒店老板，创建了一个新的交易粉配方案，并说，老酒，你只要给我密码，我就给我10 这个随机数本来就是老酒说的，自然知道就告诉老花。老花告诉老饭，老饭验证完成之后发现还真是这么回事儿，酒给了10。1 老花就给了老酒10. 至此交易完成。 当然我们来实际看一下。 Alice想给Dave发送0.05 BTC，但Alice和Dave之间并没有微支付通道。但这没关系，Alice找到了一条经过Bob、Carol到达Dave的支付路径，该路径由Alice/Bob, Bob/Carol和Carol/Dave这样三个微支付通道串接而成。 Dave生成一个秘密R并将Hash(R)发送给Alice，Alice不需要知道R。R和Hash(R)的作用就像是古代调兵用的一对虎符。 Alice和Bob商定一个HTLC合约：只要Bob能在3天内向Alice出示哈希正确的R，Alice会支付Bob 0.052 BTC；如果Bob做不到这点，这笔钱3天后自动退还Alice。 同样地，Bob和Carol商定一个HTLC合约：只要Carol能在2天内向Bob出示哈希正确的R，Bob会支付Carol 0.051 BTC；如果Carol做不到这点，这笔钱到期自动退还Bob。 最后，Carol和Dave商定一个HTLC合约：只要Dave能在1天内向Carol出示哈希正确的R，Carol会支付Dave 0.05 BTC；如果Dave做不到这点，这笔钱到期自动退还Carol。 一切就绪后，Dave及时向Carol披露R并拿到0.05 BTC；现在Carol知道了R，她可以向Bob出示密码R并拿到0.051 BTC（差额部分的0.001 BTC成了Carol的佣金）；Bob知道R后当然会向Alice出示并拿到他的那份0.052 BTC，差额部分的0.001 BTC成了Bob的佣金。 另外以太坊基于闪电网络完成它们的支付通道雷电网络。 原子跨链交易这里 我们假设。Alice 拥有1个比特币，Bob拥有10个比特币，他们都打算互相交易。 那么首先，我们来看第一步操作。 首先Alice ，生成一个只有自己知道的随机数X，并且生成一个 交易1，在这里面 输入的是 1个比特币，输出的是一段脚本，就是这样的一段脚本，我们查看这个脚本可以发现。 有两个条件满足该脚本运行。要么，拥有 随机值X的Hash符合条件并且拥有Bob的签名。要么 拥有 Alice 的签名和Bob的签名。 那么我们创建一个含有随机数值的交易，在这里我们可以看到，输入包含了一个随机数Hash以及Bob的签名。输出为 Bob立马得到1个bitCoin。 紧接着我们，创建一个赎回交易 Tx2，保证出现任何情况，Alice可以赎回自己的BitCoin. 在这里面，目前只包含了Alice的签名，以及一个输出，在输出里面，我们规定这个交易必须在48小时，之后才可以进块。也就是说该赎回交易会被锁定48小时。 之后我们将这个交易2 交给 Bob让他签名。签名完整之后，退回给Alice，这个时候，我们的交易2就是一个完整的交易了。 Alice把交易1发布出去。 这里Alice无需担心，Bob会取得这一个BitCoin ，在我们的设计中，取回这个交易的两个方式，Bob都不满足，首先他不知道X的值。其次他也不知道Alice的私钥，自然无法签名。所以这笔交易时安全的。及时出现Bob中途不打算交换也可以在48个小时后，赎回这一个比特币。 接下来，Bob也完成同样的操作。创建 交易3，书写脚本或者叫做智能合约。这里用脚本来表示。脚本中使用和 交易1 中一样的验证方式，也就是随机数hash确认，这个随机数就是Alice生成的随机数。 他会生成一个同样验证方式的随机数hash交易。 另外Bob也创建一个赎回交易4，该交易的Locktime为24个小时。可以保证，在Alice想要耍赖赎回交易1 24小时之前，Bob可以做出赎回操作。 之后，交给Alice签名。在签名之后，Alice 退回给 Bob。 这个时候，Bob将交易3发不出去。这个时候Let币会被锁定24个小时，在这24个小时之间 Alice可以通过自己创建的随机数X，去获取10个莱特币。 在Alice获取到莱特币的同时，Bob就知道了X的值，就可以使用同样的X值，去获取比特币。 当双方都确认完成之后，跨链交易完成，这就是原子交换。 PPT 文稿.md"}],"posts":[{"title":"Hashimoto I/O bound proof of work","slug":"Hashimoto IO bound proof of work","date":"2018-08-24T15:25:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Hashimoto IO bound proof of work-20180824.html","link":"","permalink":"http://blog.msiter.com/Hashimoto IO bound proof of work-20180824.html","excerpt":"Abstract: Using a cryptographic hash function not as a proof of work by itself, but rather as a generator of pointers to a shared data set, allows for an I/O bound proof of work. This method of proof of work is dif icult to optimize via ASIC design, and dif icult to outsource to nodes without the full data set. The name is based on the three operations which comprise the algorithm: hash, shift, and modulo.","text":"Abstract: Using a cryptographic hash function not as a proof of work by itself, but rather as a generator of pointers to a shared data set, allows for an I/O bound proof of work. This method of proof of work is dif icult to optimize via ASIC design, and dif icult to outsource to nodes without the full data set. The name is based on the three operations which comprise the algorithm: hash, shift, and modulo. H2 The need for proofs which are difficult to outsource and optimizeA common challenge in cryptocurrency development is maintaining decentralization of the network. The use of proof of work to achieve decentralized consensus has been most notably demonstrated by Bitcoin, which uses partial collisions with zero of sha256, similar to hashcash. As Bitcoin’s popularity has grown, dedicated hardware (currently application specific integrated circuits, or ASICs) has been produced to rapidly iterate the hash­based proof of work function. Newer projects similar to Bitcoin often use different algorithms for proof of work, and often with the goal of ASIC resistance. For algorithms such as Bitcoin’s, the improvement factor of ASICs means that commodity computer hardware can no longer be effectively used, potentially limiting adoption Proof of work can also be “outsourced”, or performed by a dedicated machine (a “miner”) without knowledge of what is being verified. This is often the case in Bitcoin’s “mining pools”. It is also beneficial for a proof of work algorithm to be difficult to outsource, in order to promote decentralization and encourage all nodes participating in the proof of work process to also verify transactions. With these goals in mind, we present Hashimoto, an I/O bound proof of work algorithm we believe to be resistant to both ASIC design and outsourcing. Initial attempts at “ASIC resistance” involved changing Bitcoin’s sha256 algorithm for a different, more memory intensive algorithm, Percival’s “scrypt” password based key derivation function . Many implementations set the scrypt arguments to low memory requirements, defeating much of the purpose of the key derivation algorithm. While changing to a new algorithm, coupled with the relative obscurity of the various scrypt­based cryptocurrencies allowed for a delay, scrypt optimized ASICs are now available. Similar attempts at variations or multiple heterogeneous hash functions can at best only delay ASIC implementations. H2 Leveraging shared data sets to create I/O bound proofs “A supercomputer is a device for turning compute-bound problems into I/O-bound problems.”-Ken Batcher Instead, an algorithm will have little room to be sped up by new hardware if it acts in a way that commodity computer systems are already optimized for. Since I/O bounds are what decades of computing research has gone towards solving, it’s unlikely that the relatively small motivation of mining a few coins would be able to advance the state of the art in cache hierarchies. In the case that advances are made, they will be likely to impact the entire industry of computer hardware. Fortuitously, all nodes participating in current implementations of cryptocurrency have a large set of mutually agreed upon data; indeed this “blockchain” is the foundation of the currency. Using this large data set can both limit the advantage of specialized hardware, and require working nodes to have the entire data set. Hashimoto is based off Bitcoin’s proof of work . In Bitcoin’s case, as in Hashimoto, a successful proof satisfies the following inequality: hash_output &lt; target For bitcoin, the hash_output is determined by hash_output = sha256(prev_hash, merkle_root, nonce) where prev_hash is the previous block’s hash and cannot be changed. The merkle_root is based on the transactions included in the block, and will be different for each individual node. The nonce is rapidly incremented as hash_outputs are calculated and do not satisfy the inequality. Thus the bottleneck of the proof is the sha256 function, and increasing the speed of sha256 or parallelizing it is something ASICs can do very effectively. Hashimoto uses this hash output as a starting point, which is used to generated inputs for a second hash function. We call the original hash hash_output_A, and the final result of the proof final_output. Hash_output_A can be used to select many transactions from the shared blockchain, which are then used as inputs to the second hash. Instead of organizing transactions into blocks, for this purpose it is simpler to organize all transactions sequentially. For example, the 47th transaction of the 815th block might be termed transaction 141,918. We will use 64 transactions, though higher and lower numbers could work, with different access properties. We define the following functions: nonce 64­bits. A new nonce is created for each attempt. get_txid(T) return the txid (a hash of a transaction) of transaction number T from block B. block_height the current height of the block chain, which increases at each new block Hashimoto chooses transactions by doing the following: hash_output_A = sha256(prev_hash, merkle_root, nonce) for i = 0 to 63 do shifted_A = hash_output_A &gt;&gt; i transaction = shifted_A mod total_transactions txid[i] = get_txid(transaction) &lt;&lt; i end for txid_mix = txid[0] ⊕ txid[1] … ⊕ txid[63] final_output = txid_mix ⊕ (nonce &lt;&lt; 192) The target is then compared with final_output, and smaller values are accepted as proofs. The initial hash output is used to independently and uniformly select 64 transactions from the blockchain. At each of the 64 steps, the hash_output­A is shifted right by one bit, to obtain a new number, shifted_A. A block is chosen by computing shifted_A modulo the total number of blocks, and a transaction chosen by computing shifted_A modulo the number of transactions within that block. These txids are also shifted by the same amount as the shifted_A which selected them. Once the 64 txids have been retrieved, they all XORed together and used as the input for the final hash function, along with the original nonce. The original nonce, shifted up into the most significant bits, is needed in the final XOR function because very small sets of transactions may not contain enough permutations of txids to satisfy the proof of work inequality. In fact, this algorithm only becomes I/O bound as the blockchain expands in size. In the extreme case of a blockchain with only 1 block and 1 transaction, the entire 64 iteration process can be omitted, and the nonce for final_output can be rapidly iterated as the txids will always be the same. With larger blockchains, inclusion of the nonce in the final hash may no longer be necessary but neither is it detrimental. H2 Analysis of bottlenecksThis method has an exponential tradeoff between hash operations and memory access. Given a blockchain of 100 blocks, if a mining node were to lack even one block, each initial hash would have a probability of 0.99^64 ≈ 0.5 of being able to retrieve the inputs for the second hash function. Thus a 1% reduction in I/O requires a 2X increase in hash power. A 2% reduction in I/O needs roughly a 4X increase in hash power, and so on. Holding half the blockchain will allow a miner to get to the second hash operation once for every 10^20 first hash operations. Clearly, miners need to have the entire blockchain to mine at all. Figure 1. Hashes needed vs proportion of blockchain held. Note the log scale This is also easy to verify for all nodes. Receiving nodes need only perform 1 sha256 operations, 128 shift operations, 64 XORs, and several hundred I/O operations. Verifying this proof of work is much less costly than the signature verification that is also needed during block verification. This method cannot be effectively outsourced. If a server were to host the blockchain for remote mining nodes, the network latency would completely overwhelm the time per hash operation. In this scenario, miners would hold a lookup table of the number of transactions in each block, so that they could compute the hash, shifts, modulo and find each transaction they need the txid of. Sending this to the blockchain host server would be at most a few kilobytes. The blockchain hosting servers response would also be 64 txids * 32 bytes each = 2Kbytes or slightly more. If these requests were serialized, the latency of each transfer is on the order of milliseconds, which would create a limit of under one thousand hashes per second. If instead, miners created large batches of txid requests, each possible hash would require 2Kbyte of data over the network. Running one billion sha256 operations per second, something easily achievable with current hardware, would require network throughput of several terabytes per second. For a blockchain smaller than a terabyte, the entire blockchain would need to be transferred multiple times per second. Clearly, it would be much faster for each mining node to maintain a local copy of all the data it needs to every possible the proof of work. Developing an ASIC for such an algorithm would be unlikely to lead to significant improvements over commodity computer hardware. As evidenced by the increase in the Bitcoin network’s difficulty, sha256 can be optimized through the use of dedicated hardware. However, Hashimoto uses only 1 sha256 operation per attempt, each of which takes on the order of microseconds for a current CPU. Though in customised hardware a shift can be had for zero time and transistor cost, the shift operation is also very rapid on general purpose CPUs and not a bottleneck. Similarly while modulo operations can also be optimized, the are very rapid on CPUs as well. The bottleneck for Hashimoto is the get_txid(T) function, which requires a read operation to disk or RAM. These I/O operations cannot be effectively cached, as each hash_output_A points to a completely different set of transactions. The most effective computers for this proof of work will have large amounts of high speed memory. As the hash, shift and modulo operations are fast, many (block, tx) pairs can be computed and queued, and retrieved either sequentially or in parallel. While the blockchain is small, CPUs will be able to cache the entire blockchain on­chip, but as it grows in size moving it DRAM will become necessary. Moving the txids onto a disk will be much slower, and would likely cause a miner to become uncompetitive with miners able to store the entire blockchain in DRAM. If the blockchain grows larger more quickly than DRAM storage, multiple servers using infiniband or another low­latency, high throughput networking system. This type of access pattern is commonly seen in many high performance computing applications, and decades of research has optimized computer hardware for this purpose. H2 ConclusionAn ASIC resistant, non­outsourceable proof of work can be created by leveraging the large shared data store inherent to cryptocurrencies ­­ the blockchain. Using a cryptographic hash algorithm to pseudo­randomly select elements from the large shared data set allows the proof of hashing capacity to become a proof of I/O capacity, something current computer hardware is already optimized for. This I/O bound algorithm also ensures that each node contains the entire data set, limiting centralized, outsourcing pools. Hashimoto can a new cryptocurrency to launch in a fair and decentralized way on commodity computer hardware. Hashimoto IO bound proof of work.md","categories":[{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/categories/共识算法/"}],"tags":[{"name":"hashimoto","slug":"hashimoto","permalink":"http://blog.msiter.com/tags/hashimoto/"},{"name":"论文","slug":"论文","permalink":"http://blog.msiter.com/tags/论文/"},{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/tags/共识算法/"}],"keywords":[{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/categories/共识算法/"}]},{"title":"Practical Byzantine Fault Tolerance","slug":"Practical Byzantine Fault Tolerance","date":"2018-08-03T14:22:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Practical Byzantine Fault Tolerance-20180803.html","link":"","permalink":"http://blog.msiter.com/Practical Byzantine Fault Tolerance-20180803.html","excerpt":"Abstract This paper describes a new replication algorithm that is able to tolerate Byzantine faults. We believe that Byzantinefault-tolerant algorithms will be increasingly important in the future because malicious attacks and software errors are increasingly common and can cause faulty nodes to exhibit arbitrary behavior. Whereas previous algorithms assumed a synchronous system or were too slow to be used in practice, the algorithm described in this paper is practical: it works in asynchronous environments like the Internet and incorporates several important optimizations that improve the response time of previous algorithms by more than an order of magnitude. We implemented a Byzantine-fault-tolerant NFS service using our algorithm and measured its performance. The results show that ourservice is only 3% slower than a standard unreplicated NFS.","text":"Abstract This paper describes a new replication algorithm that is able to tolerate Byzantine faults. We believe that Byzantinefault-tolerant algorithms will be increasingly important in the future because malicious attacks and software errors are increasingly common and can cause faulty nodes to exhibit arbitrary behavior. Whereas previous algorithms assumed a synchronous system or were too slow to be used in practice, the algorithm described in this paper is practical: it works in asynchronous environments like the Internet and incorporates several important optimizations that improve the response time of previous algorithms by more than an order of magnitude. We implemented a Byzantine-fault-tolerant NFS service using our algorithm and measured its performance. The results show that ourservice is only 3% slower than a standard unreplicated NFS. H1 1 IntroductionMalicious attacks and software errors are increasingly common. The growing reliance of industry and government on online information services makes malicious attacks more attractive and makes the consequences of successful attacks more serious. In addition, the number of software errors is increasing due to the growth in size and complexity of software. Since malicious attacks and software errors can cause faulty nodes to exhibit Byzantine (i.e., arbitrary) behavior, Byzantine-fault-tolerant algorithms are increasingly important. This paper presents a new, practical algorithm for state machine replication [17, 34] thattoleratesByzantine faults. The algorithm offers both liveness and safety provided at most [$\\dfrac {n-1}{3}$]out of a total of n replicas are simultaneously faulty. This means that clients eventually receive replies to their requests and those replies are correct according to linearizability [14, 4]. The algorithm works in asynchronous systems like the Internet and it incorporates important optimizations that enable it to perform efficiently. There is a significant body of work on agreement and replication techniques that tolerate Byzantine faults (starting with [19]). However, most earlier work (e.g., [3, 24, 10]) either concerns techniques designed to demonstrate theoretical feasibility that are too inefficient to be used in practice, or assumes synchrony, i.e., relies on known bounds on message delays and process speeds. The systems closest to ours, Rampart [30] and SecureRing [16], were designed to be practical, but they rely on the synchrony assumption for correctness, which is dangerous in the presence of malicious attacks. An attacker may compromise the safety of a service by delaying non-faulty nodes or the communication between them untilthey are tagged asfaulty and excluded from the replica group. Such a denial-of-service attack is generally easier than gaining control over a non-faulty node. Our algorithm is not vulnerable to this type of attack because it does not rely on synchrony for safety. In addition, it improves the performance of Rampart and SecureRing by more than an order of magnitude as explained in Section 7. It uses only one message round trip to execute read-only operations and two to execute read-write operations. Also, it uses an efficient authentication scheme based on message authentication codes during normal operation; public-key cryptography, which was cited as the major latency [29] and throughput [22] bottleneck in Rampart, is used only when there are faults. To evaluate our approach, we implemented a replication library and used it to implement a real service: a Byzantine-fault-tolerant distributed file system that supports the NFS protocol. We used the Andrew benchmark [15] to evaluate the performance of oursystem. The results show that our system is only 3% slower than the standard NFS daemon in the Digital Unix kernel during normal-case operation. Thus, the paper makes the following contributions: It describes the first state-machine replication protocol that correctly survives Byzantine faults in asynchronous networks. It describes a number of important optimizations that allow the algorithm to perform well so that it can be used in real systems. It describes the implementation of a Byzantine-faulttolerant distributed file system. It provides experimental results that quantify the cost of the replication technique. The remainder of the paper is organized as follows. We begin by describing our system model, including our failure assumptions. Section 3 describes the problem solved by the algorithm and states correctness conditions. The algorithm is described in Section 4 and some important optimizations are described in Section 5. Section 6 describes our replication library and how we used it to implement a Byzantine-fault-tolerant NFS. Section 7 presents the results of our experiments. Section 8 discusses related work. We conclude with a summary of what we have accomplished and a discussion of future research directions. H1 2 System ModelWe assume an asynchronous distributed system where nodes are connected by a network. The network may fail to deliver messages, delay them, duplicate them, or deliver them out of order. We use a Byzantine failure model, i.e., faulty nodes may behave arbitrarily, subject only to the restriction mentioned below. We assume independent node failures. Forthis assumption to be true in the presence of malicious attacks, some steps need to be taken, e.g., each node should run different implementations of the service code and operating system and should have a different root password and a different administrator. It is possible to obtain different implementations from the same code base [28] and for low degrees of replication one can buy operating systems from different vendors. N-version programming, i.e., different teams of programmers produce different implementations, is another option for some services. We use cryptographic techniques to prevent spoofing and replays and to detect corrupted messages. Our messages contain public-key signatures [33], message authentication codes [36], and message digests produced by collision-resistant hash functions [32]. We denote a message $m$ signed by node $i$ as $ \\langle m\\rangle_{\\sigma _{i}}$ and the digest of message $m$ by $D\\left( m\\right)$. We follow the common practice of signing a digest of a message and appending it to the plaintext of the message rather than signing the full message ($ \\langle m\\rangle_{\\sigma _{i}}$ should be interpreted in this way). All replicas know the others’ public keysto verify signatures. We allow for a very strong adversary that can coordinate faulty nodes, delay communication, or delay correct nodes in order to cause the most damage to the replicated service. We do assume that the adversary cannot delay correct nodes indefinitely. We also assume that the adversary (and the faulty nodes it controls) are computationally bound so that (with very high probability) it is unable to subvert the cryptographic techniques mentioned above. For example,the adversary cannot produce a valid signature of a non-faulty node, compute the information summarized by a digest from the digest, or find two messages with the same digest. The cryptographic techniques we use are thoughtto have these properties [33, 36, 32] H1 3 Service PropertiesOur algorithm can be used to implement any deterministic replicated service with a state and some operations. The operations are not restricted to simple reads or writes of portions of the service state; they can perform arbitrary deterministic computations using the state and operation arguments. Clientsissue requeststo the replicated service to invoke operations and block waiting for a reply. The replicated service is implemented by n replicas. Clients and replicas are non-faulty if they follow the algorithm in Section 4 and if no attacker can forge their signature. The algorithm provides both safety and liveness assuming no more than $\\dfrac {n-1}{3}$ replicas are faulty. Safety means that the replicated service satisfies linearizability [14] (modified to account for Byzantine-faulty clients [4]): it behaves like a centralized implementation that executes operations atomically one at a time. Safety requires the bound on the number of faulty replicas because a faulty replica can behave arbitrarily, e.g.,it can destroy its state. Safety is provided regardless of how many faulty clients are using the service (even if they collude with faulty replicas): all operations performed by faulty clients are observed in a consistent way by non-faulty clients. In particular, if the service operations are designed to preserve some invariants on the service state, faulty clients cannot break those invariants. The safety property is insufficient to guard against faulty clients, e.g., in a file system a faulty client can write garbage data to some shared file. However, we limit the amount of damage a faulty client can do by providing access control: we authenticate clients and deny access if the client issuing a request does not have the right to invoke the operation. Also, services may provide operations to change the access permissions for a client. Since the algorithm ensures that the effects of accessrevocation operations are observed consistently by all clients,this provides a powerful mechanism to recover from attacks by faulty clients. The algorithm does not rely on synchrony to provide safety. Therefore, it must rely on synchrony to provide liveness; otherwise it could be used to implement consensus in an asynchronous system, which is not possible [9]. We guarantee liveness, i.e., clients eventually receive replies to their requests, provided at most [$\\dfrac {n-1}{3}$ ] replicas are faulty and delay (t) does not grow faster than t indefinitely. Here, delay (t) is the time between the moment t when a message is sent for the first time and the moment when it is received by its destination (assuming the sender keepsretransmitting the message until it is received). (A more precise definition can be found in [4].) This is a rather weak synchrony assumption that is likely to be true in any real system provided network faults are eventually repaired, yet it enables us to circumvent the impossibility result in [9]. The resiliency of our algorithmis optimal: $3f+1$ is the minimum number of replicas that allow an asynchronous system to provide the safety and liveness properties when up to $f$ replicas are faulty (see [2] for a proof). This many replicas are needed because it must be possible to proceed after communicating with $n-f$ replicas, since $f$ replicas might be faulty and not responding. However, it is possible that the $f$ replicas that did not respond are not faulty and, therefore,$f$ of those that responded might be faulty. Even so, there must still be enough responses thatthose from non-faulty replicas outnumber those from faulty ones, i.e., $n-2f>f$ . Therefore $n>3f$ . The algorithm does not address the problem of faulttolerant privacy: a faulty replica may leak information to an attacker. Itis not feasible to offerfault-tolerant privacy in the general case because service operations may perform arbitrary computations using their arguments and the service state; replicas need this information in the clear to execute such operations efficiently. It is possible to use secret sharing schemes [35] to obtain privacy even in the presence of a threshold of malicious replicas [13] for the arguments and portions of the state that are opaque to the service operations. We plan to investigate these techniques in the future. H1 4 The AlgorithmOur algorithm is a form of state machine replication [17, 34]: the service is modeled as a state machine that is replicated across different nodes in a distributed system. Each state machine replica maintains the service state and implements the service operations. We denote the set of replicas by $R$ and identify each replica using an integer in $ \\left\\{ 0,\\ldots ,\\left| R\\right| -1\\right\\} $ . For simplicity, we assume $ \\left| R\\right| = 3f+1 $ where $f$ is the maximum number of replicas that may be faulty; although there could be more than $3f+1$ replicas,the additional replicas degrade performance (since more and bigger messages are being exchanged) without providing improved resiliency. The replicas move through a succession of configurations called views. In a view one replica is the primary and the others are backups. Views are numbered consecutively. The primary of a view is replica $p$ such that $ p=v \\ mod\\left| R\\right| $ , where $v$ is the view number. View changes are carried out when it appears that the primary hasfailed. Viewstamped Replication [26] andPaxos [18] used a similar approach to tolerate benign faults (as discussed in Section 8.) The algorithm works roughly as follows: A client sends a request to invoke a service operation to the primary The primary multicasts the request to the backups Replicas execute the request and send a reply to the client The client waits for $f+1$ replies from different replicas with the same result; this is the result of the operation. Like all state machine replication techniques [34], we impose two requirements on replicas: they must be deterministic (i.e., the execution of an operation in a given state and with a given set of arguments must always produce the same result) and they muststartin the same state. Given these two requirements, the algorithm ensures the safety property by guaranteeing that all nonfaulty replicas agree on a total order for the execution of requests despite failures. The remainder of this section describes a simplified version of the algorithm. We omit discussion of how nodes recover from faults due to lack of space. We also omit details related to message retransmissions. Furthermore, we assume that message authentication is achieved using digital signatures rather than the more efficient scheme based on message authentication codes; Section 5 discusses this issue further. A detailed formalization of the algorithm using the I/O automaton model [21] is presented in [4]. H2 4.1 The ClientA client $c$ requests the execution of state machine operation $o$ by sending a $ \\langle REQUEST,o,t,c\\rangle_{\\sigma _{c}}$ message to the primary. Timestamp $t$ is used to ensure exactlyonce semantics for the execution of client requests. Timestamps for $c$’s requests are totally ordered such that later requests have higher timestamps than earlier ones; for example, the timestamp could be the value of the client’s local clock when the request is issued. Each message sent by the replicasto the clientincludes the current view number, allowing the client to track the view and hence the current primary. A client sends a request to what it believes is the current primary using a point-to-point message. The primary atomically multicaststhe requestto allthe backups using the protocol described in the next section A replica sends the reply to the request directly to the client. The reply has the form $ \\langle REPLY,v,t,c,i,r\\rangle_{\\sigma _{i}}$ where $v$ is the current view number, is the timestamp of the corresponding request, $i$ is the replica number, and is the result of executing the requested operation. The client waits for $f+1$ replies with valid signatures from different replicas, and with the same $t$ and $r$, before accepting the result $r$. This ensuresthatthe resultis valid, since at most $f$ replicas can be faulty If the client does not receive replies soon enough, it broadcasts the request to all replicas. If the request has already been processed, the replicas simply re-send the reply; replicas remember the last reply message they sent to each client. Otherwise,if the replica is notthe primary, it relays the request to the primary. If the primary does not multicast the request to the group, it will eventually be suspected to be faulty by enough replicas to cause a view change. In this paper we assume that the client waits for one request to complete before sending the next one. But we can allow a client to make asynchronous requests, yet preserve ordering constraints on them. H2 4.2 Normal-Case OperationThe state of each replica includes the state of the service, a message log containing messages the replica has accepted, and an integer denoting the replica’s current view. We describe how to truncate the log in Section 4.3. When the primary, $p$ , receives a client request, $m$, it starts a three-phase protocol to atomically multicast the request to the replicas. The primary starts the protocol immediately unless the number of messages for which the protocol is in progress exceeds a given maximum. In this case, it buffers the request. Buffered requests are multicast later as a group to cut down on message traffic and CPUoverheads under heavy load;this optimization is similar to a group commitin transactional systems [11]. For simplicity, we ignore this optimization in the description below. The three phases are pre-prepare, prepare, and commit. The pre-prepare and prepare phases are used to totally order requests sent in the same view even when the primary, which proposes the ordering of requests, is faulty. The prepare and commit phases are used to ensure that requeststhat commit are totally ordered across views. In the pre-prepare phase, the primary assigns a sequence number, $n$ , to the request, multicasts a preprepare message with $m$ piggybacked to all the backups, and appends the message to its log. The message has the form $ \\langle\\langle PRE-PREPARE,v,n,d\\rangle_{\\sigma _{p}},m \\rangle $ , where $v$ indicates the view in which the message is being sent,$m$ is the client’s request message, and $d$ is $m$’s digest. Requests are not included in pre-prepare messages to keep them small. This is important because preprepare messages are used as a proof that the request was assigned sequence number $n$ in view $v$ in view changes. Additionally, it decouples the protocol to totally order requests from the protocol to transmit the request to the replicas; allowing us to use a transport optimized for small messages for protocol messages and a transport optimized for large messages for large requests. A backup accepts a pre-prepare message provided: the signatures in the request and the pre-prepare message are correct and $d$ is the digest for $m$ ; it is in view $v$ ; it has not accepted a pre-prepare message for view $v$ and sequence number $n$ containing a different digest; the sequence number in the pre-prepare message is between a low water mark, $h$ , and a high water mark, $H$ . The last condition prevents a faulty primary from exhausting the space of sequence numbers by selecting a very large one. We discuss how $H$ and $h$ advance in Section 4.3. If backup $i$ accepts the $ \\langle\\langle PRE-PREPARE,v,n,d\\rangle_{\\sigma _{p}},m \\rangle $ message, it enters the prepare phase by multicasting a $ \\langle PREPARE,v,n,d,i\\rangle_{\\sigma _{i}}$ message to all other replicas and adds both messagesto itslog. Otherwise,it does nothing. A replica (including the primary) accepts prepare messages and adds them to its log provided their signatures are correct, their view number equals the replica’s current view, and their sequence number is between $h$ and $H$. We define the predicate $prepared \\left(m,v,n,i \\right)$ to be true if and only if replica $i$ has inserted in its log: the request $m$, a pre-prepare for $m$ in view $v$ with sequence number $n$, and $2f$ prepares from different backups that match the pre-prepare. The replicas verify whether the prepares match the pre-prepare by checking that they have the same view, sequence number, and digest. The pre-prepare and prepare phases of the algorithm guarantee that non-faulty replicas agree on a total order for the requests within a view. More precisely, they ensure the following invariant: if $prepared \\left(m,v,n,i \\right)$ is true then $prepared \\left(m',v,n,i \\right)$ is false for any non-faulty replica j$ j \\left( including \\ i = j \\right)$ and any $m'$ such that $D\\left( m'\\right) \\neq D\\left( m\\right)$. This is true because $prepared \\left(m,v,n,i \\right)$ and $ \\left| R\\right| =3f+1 $ imply that at least $ f+1 $ non-faulty replicas have sent a pre-prepare or prepare for $ m $ in $ v $ view with sequence number $ n $. Thus, for $prepared \\left(m',v,n,i \\right)$ to be true at least one of these replicas needs to have sent two conflicting prepares (or pre-prepares if it is the primary for $v$), i.e., two prepares with the same view and sequence number and a different digest. But this is not possible because the replica is not faulty. Finally, our assumption aboutthe strength of message digests ensures that the probability that $ m \\neq m' $ and $D\\left( m'\\right) \\neq D\\left( m\\right)$ is negligible. Replica multicasts a $ \\langle COMMIT,v,n,D\\left( m \\right),i \\rangle_{\\sigma _{i}}$ to the other replicas when $prepared \\left(m,v,n,i \\right)$ becomes true. This starts the commit phase. Replicas accept commit messages and insert them in their log provided they are properly signed, the view number in the message is equal to the replica’s current view, and the sequence number is between $h$ and $H$ We define the committed and committed-local predicates as follows: $committed\\left(m,v,n\\right)$ is true if and only if $prepared\\left(m,v,n,i\\right)$ is true for all in some set of 1 non-faulty replicas; and$committed-local\\left(m,v,n,i\\right)$ is true if and only if $prepared\\left(m,v,n,i\\right)$ is true and has accepted $2f+1$ commits (possibly including its own) from different replicas that match the pre-prepare for $m$; a commit matches a pre-prepare if they have the same view, sequence number, and digest. The commit phase ensures the following invariant: if $committed-local\\left(m,v,n,i\\right)$ is true for some non-faulty $i$then $committed\\left(m,v,n\\right)$ is true. This invariant and the view-change protocol described inSection 4.4 ensure that non-faulty replicas agree on the sequence numbers of requests that commit locally even if they commit in different views at each replica. Furthermore, it ensures that any request that commits locally at a non-faulty replica will commit at $f+1$ or more non-faulty replicas eventually Each replica $i$ executes the operation requested by $m$ after $committed-local\\left(m,v,n,i\\right)$ is true and $i$’s state reflects the sequential execution of all requests with lower sequence numbers. This ensures that all nonfaulty replicas execute requests in the same order as required to provide the safety property. After executing the requested operation, replicassend a reply to the client. Replicas discard requests whose timestamp is lower than the timestamp in the last reply they sent to the client to guarantee exactly-once semantics. We do not rely on ordered message delivery, and therefore it is possible for a replica to commit requests out of order. This does not matter since it keeps the preprepare, prepare, and commit messages logged until the corresponding request can be executed. Figure 1 shows the operation of the algorithm in the normal case of no primary faults. Replica 0 isthe primary, replica 3 is faulty, and $C$ is the client. Figure 1: Normal Case Operation H2 4.3 Garbage CollectionThis section discusses the mechanism used to discard messages from the log. For the safety condition to hold, messagesmust be keptin a replica’slog untilit knowsthat the requests they concern have been executed by at least $f+1$ non-faulty replicas and it can prove this to others in view changes. In addition, if some replica misses messages that were discarded by all non-faulty replicas, it will need to be brought up to date by transferring all or a portion of the service state. Therefore, replicas also need some proof that the state is correct. Generating these proofs after executing every operation would be expensive. Instead, they are generated periodically, when a request with a sequence number divisible by some constant (e.g., 100) is executed. We will refer to the states produced by the execution of these requests as checkpoints and we will say that a checkpoint with a proof is a stable checkpoint. A replica maintainsseverallogical copies ofthe service state: the laststable checkpoint, zero or more checkpoints that are not stable, and a current state. Copy-on-write techniques can be used to reduce the space overhead to store the extra copies of the state, as discussed in Section 6.3. The proof of correctness for a checkpoint is generated as follows. When a replica $i$ produces a checkpoint, it multicasts a message $ \\langle CHECKPOINT,n,d,i\\rangle_{\\sigma _{i}}$ to the other replicas, where $n$ is the sequence number of the last request whose execution is reflected in the state and $d$ is the digest of the state. Each replica collects checkpoint messages in its log until it has $2f+1$ of them for sequence number $n$ with the same digest $d$ signed by different replicas (including possibly its own such message). These $2f+1$ messages are the proof of correctness for the checkpoint. A checkpoint with a proof becomes stable and the replica discards all pre-prepare, prepare, and commit messages with sequence number less than or equal to $n$ from its log; it also discards all earlier checkpoints and checkpoint messages. Computing the proofs is efficient because the digest can be computed using incremental cryptography [1] as discussed in Section 6.3, and proofs are generated rarely. The checkpoint protocol is used to advance the low and high water marks (which limit what messages will be accepted). The low-water mark $h$ is equal to the sequence number of the last stable checkpoint. The high water mark $ H = h+k $ , where $k$ is big enough so that replicas do not stall waiting for a checkpoint to become stable. For example, if checkpoints are taken every 100 requests,$k$ might be 200. H2 4.4 View ChangesThe view-change protocol provides liveness by allowing the system to make progress when the primary fails. View changes are triggered by timeouts that prevent backups from waiting indefinitely for requests to execute. A backup iswaitingfor a requestifitreceived a valid request and has not executed it. A backup starts a timer when it receives a request and the timer is not already running. It stops the timer when it is no longer waiting to execute the request, but restarts it if at that point it is waiting to execute some other request. If the timer of backup $i$ expires in view $v$, the backup starts a view change to move the system to view $v+1$. It stops accepting messages (other than checkpoint, view-change, and new-view messages) and multicasts a $ \\langle VIEW-CHANGE,v+1,n,C,P,i\\rangle_{\\sigma _{i}}$ message to all replicas. Here $n$ is the sequence number of the last stable checkpoint $s$ known to $i$,$C$ is a set of $2f+1$ valid checkpoint messages proving the correctness of $s$, and $P$ is a set containing a set $P_{m}$ for each request $m$ that prepared at $i$ with a sequence number higher than $n$ . Each set $P_{m}$ contains a valid pre-prepare message (withoutthe corresponding client message) and $2f$ matching, valid prepare messages signed by different backups with the same view, sequence number, and the digest of $m$ . When the primary $p$ of view $v+1$ receives $2f$ valid view-change messagesfor view $v+1$ from other replicas, it multicasts a $ \\langle NEW-VIEW,v+1,V,O\\rangle_{\\sigma _{p}}$ message to all other replicas, where is a set containing the valid viewchange messages received by the primary plus the viewchange message for $v+1$ the primary sent (or would have sent), and $O$ is a set of pre-prepare messages (withoutthe piggybacked request).$O$ is computed as follows: The primary determines the sequence number $min-s$ of the latest stable checkpoint in $V$ and the highest sequence number $max-s$ in a prepare message in $V$. The primary creates a new pre-prepare message for view $v+1$ for each sequence number $n$ between $min-s$ and $max-s$. There are two cases: (1) there is at least one set in the $P$ component of some view-change message in $V$ with sequence number $n$, or (2) there is no such set. In the first case, the primary creates a new message $ \\langle PRE-PREPARE,v+1,n,d\\rangle_{\\sigma _{p}}$ , where $d$ is the request digest in the pre-prepare message for sequence number $n$ with the highest view number in $V$. In the second case, it creates a new preprepare message $ \\langle PRE-PREPARE,v+1,n,d^{null}\\rangle_{\\sigma _{p}}$ , where $d^{null}$ is the digest of a special null request; a null request goes through the protocol like other requests, but its execution is a no-op. (Paxos [18] used a similar technique to fill in gaps.) Next the primary appends the messages in to $O$ its log. If $min-s$ is greater than the sequence number of its lateststable checkpoint,the primary also insertsthe proof of stability for the checkpoint with sequence number $min-s$ in its log, and discards information from the log as discussed in Section 4.3. Then it $enter$ view $v+1$: at this point it is able to accept messages for view $v+1$. A backup accepts a new-view message for view $v+1$ if it is signed properly, if the view-change messages it contains are valid for view $v+1$, and if the set $O$ is correct; it verifies the correctness of $O$ by performing a computation similar to the one used by the primary to create $O$. Then it adds the new information to its log as described for the primary, multicasts a prepare for each message in $O$ to allthe other replicas, addsthese prepares to its log, and enters view $v+1$. Thereafter, the protocol proceeds as described in Section 4.2. Replicas redo the protocol for messages between $min-s$ and $max-s$ but they avoid re-executing client requests (by using their stored information about the last reply sent to each client). A replica may be missing some request message $m$ or a stable checkpoint (since these are not sent in newview messages.) It can obtain missing information from another replica. For example, replica $i$ can obtain a missing checkpoint state $s$ from one of the replicas whose checkpoint messages certified its correctness in $V$ . Since $f+1$ of those replicas are correct, replica will always obtain $s$ or a later certified stable checkpoint. We can avoid sending the entire checkpoint by partitioning the state and stamping each partition with the sequence number of the last request that modified it. To bring a replica up to date, it is only necessary to send it the partitions where it is out of date, rather than the whole checkpoint. H2 4.5 CorrectnessThis section sketches the proof that the algorithm provides safety and liveness; details can be found in [4]. H3 4.5.1 SafetyAs discussed earlier, the algorithm provides safety if all non-faulty replicas agree on the sequence numbers of requests that commit locally. In Section 4.2, we showed that if $prepared \\left(m,v,n,i \\right)$ is true, $prepared \\left(m',v,n,i \\right)$ is false for any non-faulty replica j$ j \\left( including \\ i = j \\right)$ and $m'$ any such that $D\\left(m'\\right) \\neq D \\left(m\\right) $. This implies that two non-faulty replicas agree on the sequence number of requests that commit locally in the same view at the two replicas. The view-change protocol ensures that non-faulty replicas also agree on the sequence number of requests that commitlocally in different views at differentreplicas. A request $m$ commits locally at a non-faulty replica with sequence number $n$ in view $v$ only if $committed\\left(m,v,n\\right)$ istrue. This meansthatthere is a set $R_{1}$ containing atleast $f+1$ non-faulty replicas such that $prepared \\left(m,v,n,i \\right)$ is true for every replica $i$ in the set. Non-faulty replicas will not accept a pre-prepare for view $v' > v$ without having received a new-viewmessage for $v'$ (since only atthat point do they enter the view). But any correct new-view message for view $v' > v$ contains correct view-change messages from every replica $i$ in a set $R_{2}$ of $2f+1$ replicas. Since there are $3f+1$ replicas, $R_{1}$ and $R_{2}$ must intersect in at least one replica $k$ that is not faulty. $k$’s view-change message will ensure that the fact that $m$ prepared in a previous view is propagated to subsequent views, unless the new-view message contains a view-change message with a stable checkpoint with a sequence number higher than $n$ . In the first case, the algorithm redoes the three phases of the atomic multicast protocol for $m$ with the same sequence number $n$ and the new view number. This is important because it prevents any different request that was assigned the sequence number $n$ in a previous view from ever committing. In the second case no replica in the new view will accept any message with sequence number lower than $n$. In either case, the replicas will agree on the request that commits locally with sequence number $n$ . H3 4.5.2 LivenessTo provide liveness, replicas must move to a new view if they are unable to execute a request. But it is important to maximize the period of time when at least $2f+1$ non-faulty replicas are in the same view, and to ensure thatthis period of time increases exponentially untilsome requested operation executes. We achieve these goals by three means. First,to avoid starting a view change too soon, a replica that multicasts a view-change message for view $v+1$ waits for $2f+1$ view-change messages for view $v+1$ and then starts its timer to expire after some time $T$. If the timer expires before it receives a valid new-view message for $v+1$ or before it executes a request in the new view that it had not executed previously,it starts the view change for view $v+2$ but this time it will wait $2T$ before starting a view change for view $v+3$. Second, if a replica receives a set of $f+1$ valid viewchange messages from other replicas for views greater than its current view, it sends a view-change message for the smallest view in the set, even if its timer has not expired; this prevents it from starting the next view change too late Third, faulty replicas are unable to impede progress by forcing frequent view changes. A faulty replica cannot cause a view change by sending a view-change message, because a view change will happen only if at least $f+1$ replicas send view-change messages, but it can cause a view change when it is the primary (by not sending messages or sending bad messages). However, because the primary of view $v$ is the replica $p$ such that $ p=v \\ mod\\left| R\\right| $ , the primary cannot be faulty for more than $f$ consecutive views. These three techniques guarantee liveness unless message delays grow faster than the timeout period indefinitely, which is unlikely in a real system. H2 4.6 Non-DeterminismState machine replicas must be deterministic but many services involve some form of non-determinism. For example, the time-last-modified in NFS is set by reading the server’s local clock; if this were done independently at each replica, the states of non-faulty replicas would diverge. Therefore, some mechanism to ensure that all replicas select the same value is needed. In general, the client cannot select the value because it does not have enough information; for example, it does not know how its request will be ordered relative to concurrent requests by other clients. Instead, the primary needs to select the value either independently or based on values provided by the backups. If the primary selectsthe non-deterministic value independently, it concatenates the value with the associated request and executes the three phase protocol to ensure that non-faulty replicas agree on a sequence number for the request and value. This prevents a faulty primary from causing replica state to diverge by sending different valuesto differentreplicas. However, a faulty primary might send the same, incorrect, value to all replicas. Therefore, replicas must be able to decide deterministically whether the value is correct (and whatto do if it is not) based only on the service state. This protocol is adequate for most services (including NFS) but occasionally replicas must participate in selecting the value to satisfy a service’s specification. This can be accomplished by adding an extra phase to the protocol: the primary obtains authenticated values proposed by the backups, concatenates $2f+1$ of them with the associated request, and starts the three phase protocol for the concatenated message. Replicas choose the value by a deterministic computation on the $2f+1$ values and their state, e.g., taking the median. The extra phase can be optimized away in the common case. For example, if replicas need a value that is “close enough” to that of their local clock, the extra phase can be avoided when their clocks are synchronized within some delta. H1 5 OptimizationsThis section describes some optimizations that improve the performance of the algorithm during normal-case operation. All the optimizations preserve the liveness and safety properties. H2 5.1 Reducing CommunicationWe use three optimizations to reduce the cost of communication. The first avoids sending most large replies. A client request designates a replica to send the result; all other replicas send replies containing just the digest of the result. The digests allow the client to check the correctness ofthe result while reducing network bandwidth consumption and CPU overhead significantly for large replies. If the client does not receive a correct result from the designated replica, it retransmits the request as usual, requesting all replicas to send full replies. The second optimization reduces the number of message delays for an operation invocation from 5 to 4. Replicas execute a request tentatively as soon as the prepared predicate holds for the request, their state reflects the execution of all requests with lower sequence number, and these requests are all known to have committed. After executing the request,the replicas send tentative replies to the client. The client waits for $2f+1$ matching tentative replies. If it receives this many, the request is guaranteed to commit eventually. Otherwise, the client retransmits the request and waits for $f+1$ non-tentative replies. A request that has executed tentatively may abort if there is a view change and it is replaced by a null request. In this case the replica reverts its state to the last stable checkpoint in the new-view message or to its last checkpointed state (depending on which one has the higher sequence number). The third optimization improves the performance of read-only operations that do not modify the service state. A client multicasts a read-only request to all replicas. Replicas execute the request immediately in their tentative state after checking that the request is properly authenticated, that the client has access, and that the request is in fact read-only. They send the reply only after all requests reflected in the tentative state have committed; this is necessary to prevent the client from observing uncommitted state. The client waits for $2f+1$ replies from different replicas with the same result. The client may be unable to collect $2f+1$ such repliesif there are concurrent writes to data that affect the result; in this case, it retransmits the request as a regular read-write request after its retransmission timer expires. H2 5.2 CryptographyIn Section 4, we described an algorithm that uses digital signatures to authenticate all messages. However, we actually use digital signatures only for viewchange and new-view messages, which are sent rarely, and authenticate all other messages using message authentication codes (MACs). This eliminates the main performance bottleneck in previous systems [29, 22]. However, MACs have a fundamental limitation relative to digital signatures — the inability to prove that a message is authentic to a third party. The algorithm in Section 4 and previous Byzantine-fault-tolerant algorithms [31, 16] for state machine replication rely on the extra power of digital signatures. We modified our algorithm to circumvent the problem by taking advantage of specific invariants, e.g, the invariantthat no two different requests prepare with the same view and sequence number at two non-faulty replicas. The modified algorithm is described in [5]. Here we sketch the main implications of using MACs. MACs can be computed three orders of magnitude faster than digital signatures. For example, a 200MHz Pentium Pro takes 43ms to generate a 1024-bit modulus RSA signature of an MD5 digest and 0.6ms to verify the signature [37], whereas it takes only 10.3 s to compute the MAC of a 64-byte message on the same hardware in our implementation. There are other publickey cryptosystems that generate signatures faster, e.g., elliptic curve public-key cryptosystems, but signature verification is slower [37] and in our algorithm each signature is verified many times. Each node (including active clients) shares a 16-byte secret session key with each replica. We compute message authentication codes by applying MD5 to the concatenation of the message with the secret key. Rather than using the 16 bytes of the final MD5 digest, we use only the 10 least significant bytes. This truncation has the obvious advantage of reducing the size of MACs and it also improves their resilience to certain attacks [27]. This is a variant of the secret suffix method [36], which is secure as long as MD5 is collision resistant [27, 8]. The digitalsignature in a reply message isreplaced by a single MAC, which is sufficient because these messages have a single intended recipient. The signatures in all other messages (including client requests but excluding view changes) are replaced by vectors of MACs that we call authenticators. An authenticator has an entry for every replica other than the sender; each entry is the MAC computed with the key shared by the sender and the replica corresponding to the entry. The time to verify an authenticator is constant but the time to generate one grows linearly with the number of replicas. This is not a problem because we do not expect to have a large number of replicas and there is a huge performance gap between MAC and digital signature computation. Furthermore, we compute authenticators efficiently; MD5 is applied to the message once and the resulting context is used to compute each vector entry by applying MD5 to the corresponding session key. For example, in a system with 37 replicas (i.e., a system that can tolerate 12 simultaneous faults) an authenticator can still be computed much more than two orders of magnitude faster than a 1024-bit modulus RSA signature. The size of authenticators grows linearly with the number of replicas but it grows slowly: it is equal to $ 30\\times \\lfloor \\dfrac {n-1}{3}\\rfloor $bytes. An authenticator is smaller than an RSA signature with a 1024-bit modulus for $n\\leq 13$ (i.e., systems that can tolerate up to 4 simultaneous faults), which we expect to be true in most configurations. H1 6 ImplementationThis section describes our implementation. First we discuss the replication library, which can be used as a basis for any replicated service. In Section 6.2 we describe how we implemented a replicated NFS on top of the replication library. Then we describe how we maintain checkpoints and compute checkpoint digests efficiently. H2 6.1 The Replication LibraryThe client interface to the replication library consists of a single procedure, invoke, with one argument, an input buffer containing a request to invoke a state machine operation. The invoke procedure uses our protocol to execute the requested operation at the replicas and select the correct reply from among the replies of the individual replicas. It returns a pointer to a buffer containing the operation result. On the server side, the replication code makes a number of upcalls to procedures that the server part of the application must implement. There are procedures to execute requests (execute), to maintain checkpoints of the service state (make checkpoint, delete checkpoint),to obtain the digest of a specified checkpoint (get digest), and to obtain missing information (get checkpoint, set checkpoint). The execute procedure receives as input a buffer containing the requested operation, executes the operation, and places the result in an output buffer. The other procedures are discussed further in Sections 6.3 and 6.4. Point-to-point communication between nodesisimplemented using UDP, and multicastto the group of replicas is implemented using UDP over IP multicast [7]. There is a single IP multicast group for each service, which contains allthe replicas. These communication protocols are unreliable;they may duplicate or lose messages or deliver them out of order. The algorithm tolerates out-of-order delivery and rejects duplicates. View changes can be used to recover from lost messages, but this is expensive and therefore it is important to perform retransmissions. During normal operation recovery from lost messages is driven by the receiver: backups send negative acknowledgments to the primary when they are out of date and the primary retransmits pre-prepare messages after a long timeout. A reply to a negative acknowledgment may include both a portion of a stable checkpoint and missing messages. During view changes, replicas retransmit view-changemessages untilthey receive a matching newview message or they move on to a later view. The replication library does not implement view changes or retransmissions at present. This does not compromise the accuracy of the results given in Section 7 because the rest of the algorithm is completely implemented (including the manipulation of the timers that trigger view changes) and because we have formalized the complete algorithm and proved its correctness [4]. H2 6.2 BFS: A Byzantine-Fault-tolerant File SystemWe implemented BFS, a Byzantine-fault-tolerant NFS service, using the replication library. Figure 2 shows the architecture of BFS. We opted not to modify the kernel NFSclient and server because we did not have the sources for the Digital Unix kernel. A file systemexported by the fault-tolerant NFSservice is mounted on the client machine like any regular NFS file system. Application processes run unmodified and interact with the mounted file system through the NFS client in the kernel. We rely on user level relay processes to mediate communication between the standard NFS client and the replicas. A relay receives NFS protocol requests, calls the invoke procedure of our replication library, and sends the result back to the NFS client. Figure 2: Replicated File System Architecture. Each replica runs a user-level process with the replication library and our NFS V2 daemon, which we will refer to as snfsd (for simple nfsd). The replication library receives requests from the relay, interacts with snfsd by making upcalls, and packages NFS replies into replication protocol replies that it sends to the relay. We implemented snfsd using a fixed-size memorymapped file. All the file system data structures, e.g., inodes, blocks and their free lists, are in the mapped file. We rely on the operating system to manage the cache of memory-mapped file pages and to write modified pages to disk asynchronously. The current implementation uses 8KB blocks and inodes contain the NFS status information plus 256 bytes of data, which is used to store directory entries in directories, pointers to blocks in files, and text in symbolic links. Directories and files may also use indirect blocks in a way similar to Unix. Our implementation ensures that all state machine replicasstartin the same initialstate and are deterministic, which are necessary conditions for the correctness of a service implemented using our protocol. The primary proposes the values for time-last-modified and timelast-accessed, and replicas select the larger of the proposed value and one greater than the maximum of all values selected for earlier requests. We do not require synchronous writes to implement NFS V2 protocol semantics because BFS achieves stability of modified data and meta-data through replication [20]. H2 6.3 Maintaining CheckpointsThis section describes how snfsd maintains checkpoints of thefile system state. Recallthat each replica maintains severallogical copies of the state: the current state, some number of checkpointsthat are not yetstable, and the last stable checkpoint. snfsd executes file system operations directly in the memory mappedfile to preserve locality,and it uses copyon-write to reduce the space and time overhead associated with maintaining checkpoints. snfsd maintains a copyon-write bit for every 512-byte block in the memory mapped file. When the replication code invokes the make checkpoint upcall, snfsd sets all the copy-on-write bits and creates a (volatile) checkpoint record, containing the current sequence number, which it receives as an argument to the upcall, and a list of blocks. This list contains the copies of the blocks that were modified since the checkpoint was taken, and therefore, it is initially empty. The record also contains the digest of the current state; we discuss how the digest is computed in Section 6.4. When a block of the memory mapped file is modified while executing a client request, snfsd checks the copyon-write bit for the block and,if itisset,storesthe block’s current contents and itsidentifier in the checkpoint record for the last checkpoint. Then, it overwrites the block with its new value and resets its copy-on-write bit. snfsd retains a checkpoint record until told to discard it via a delete checkpoint upcall, which is made by the replication code when a later checkpoint becomes stable. If the replication code requires a checkpoint to send to another replica, it calls the get checkpoint upcall. To obtain the value for a block, snfsd first searches for the block in the checkpoint record of the stable checkpoint, and then searches the checkpoint records of any later checkpoints. If the block is not in any checkpoint record, it returns the value from the current state. The use of the copy-on-write technique and the fact that we keep at most 2 checkpoints ensure that the space and time overheads of keeping several logical copies of the state are low. For example, in the Andrew benchmark experiments described in Section 7, the average checkpoint record size is only 182 blocks with a maximum of 500. H2 6.4 Computing Checkpoint Digestssnfsd computes a digest of a checkpoint state as part of a make checkpoint upcall. Although checkpoints are only taken occasionally, it is important to compute the state digest incrementally because the state may be large. snfsd uses an incremental collision-resistant oneway hash function called AdHash [1]. This function divides the state into fixed-size blocks and uses some other hash function (e.g., MD5) to compute the digest of the string obtained by concatenating the block index with the block value for each block. The digest of the state is the sum of the digests of the blocks modulo some large integer. In our current implementation, we use the 512-byte blocks from the copy-on-write technique and compute their digest using MD5. To compute the digest for the state incrementally,snfsd maintains a table with a hash value for each 512-byte block. This hash value is obtained by applying MD5 to the block index concatenated with the block value at the time of the last checkpoint. When make checkpoint is called, snfsd obtains the digest $d$ for the previous checkpointstate (from the associated checkpoint record). It computes new hash values for each block whose copyon-write bit is reset by applying MD5 to the block index concatenated with the current block value. Then, it adds the new hash value to $d$, subtracts the old hash value from $d$, and updates the table to contain the new hash value. This process is efficient provided the number of modified blocksissmall; as mentioned above, on average 182 blocks are modified per checkpoint for the Andrew benchmark. H1 7 Performance EvaluationThis section evaluates the performance of our system using two benchmarks: a micro-benchmark and the Andrew benchmark [15]. The micro-benchmark provides a service-independent evaluation of the performance of the replication library; it measures the latency to invoke a null operation, i.e., an operation that does nothing. The Andrew benchmark is used to compare BFS with two otherfile systems: one isthe NFS V2 implementation in Digital Unix, and the other is identical to BFS except without replication. The first comparison demonstrates that our system is practical by showing that its latency is similar to the latency of a commercial system that is used daily by many users. The second comparison allows usto evaluate the overhead of our algorithm accurately within an implementation of a real service. H2 7.1 Experimental SetupThe experiments measure normal-case behavior (i.e., there are no view changes), because this is the behavior that determines the performance of the system. All experiments ran with one client running two relay processes, and four replicas. Four replicas can tolerate one Byzantine fault; we expect this reliability level to suffice for most applications. The replicas and the clientran on identical DEC3000/400 Alpha workstations. These workstations have a 133 MHz Alpha 21064 processor, 128 MB of memory, and run Digital Unix version 4.0. The file system was stored by each replica on a DEC RZ26 disk. All the workstations were connected by a 10Mbit/sswitched Ethernet and had DEC LANCE Ethernet interfaces. The switch was a DEC EtherWORKS 8T/TX. The experiments were run on an isolated network. The interval between checkpoints was 128 requests, which causes garbage collection to occur severaltimes in any of the experiments. The maximum sequence number accepted by replicas in pre-prepare messages was 256 plus the sequence number of the last stable checkpoint. H2 7.2 Micro-BenchmarkThe micro-benchmark measures the latency to invoke a null operation. It evaluates the performance of two implementations of a simple service with no state that implements null operations with arguments and results of different sizes. The first implementation is replicated using our library and the second is unreplicated and uses UDP directly. Table 1 reports the response times measured at the client for both read-only and readwrite operations. They were obtained by timing 10,000 operation invocationsin three separate runs and we report the median value of the three runs. The maximum deviation from the median was always below 0.3% of the reported value. We denote each operation by a/b, where a and b are the sizes of the operation argument and result in KBytes. Table 1: Micro-benchmark results (in milliseconds); the percentage overhead is relative to the unreplicated case.The overhead introduced by the replication library is due to extra computation and communication. For example, the computation overhead for the read-write 0/0 operation is approximately 1.06ms, which includes 0.55ms spent executing cryptographic operations. The remaining 1.47ms of overhead are due to extra communication; the replication library introduces an extra message roundtrip, it sends larger messages, and itincreases the number of messages received by each node relative to the service without replication. The overhead for read-only operations is significantly lower because the optimization discussed in Section 5.1 reduces both computation and communication overheads. For example,the computation overhead for the read-only 0/0 operation is approximately 0.43ms, which includes 0.23ms spent executing cryptographic operations, and the communication overhead is only 0.37ms because the protocol to execute read-only operations uses a single round-trip. Table 1 shows that the relative overhead is lower for the 4/0 and 0/4 operations. This is because a significant fraction of the overhead introduced by the replication library is independent of the size of operation arguments and results. For example, in the read-write 0/4 operation, the large message (the reply) goes over the network only once (as discussed in Section 5.1) and only the cryptographic overhead to process the reply message is increased. The overhead is higher for the read-write 4/0 operation because the large message (the request) goes over the network twice and increases the cryptographic overhead for processing both request and pre-prepare messages. It is important to note that this micro-benchmark represents the worst case overhead for our algorithm because the operations perform no work and the unreplicated server provides very weak guarantees. Most services will require stronger guarantees, e.g., authenticated connections, and the overhead introduced by our algorithmrelative to a serverthatimplementsthese guarantees will be lower. For example, the overhead of the replication library relative to a version of the unreplicated service that uses MACs for authentication is only 243% for the read-write 0/0 operation and 4% for the read-only 4/0 operation. We can estimate a rough lower bound on the performance gain afforded by our algorithm relative to Rampart [30]. Reiter reports that Rampart has a latency of 45ms for a multi-RPC of a null message in a 10 Mbit/s Ethernet network of 4 SparcStation 10s [30]. The multiRPCissufficientforthe primary to invoke a state machine operation but for an arbitrary clientto invoke an operation it would be necessary to add an extra message delay and an extra RSA signature and verification to authenticate the client; this would lead to a latency of at least 65ms (using the RSA timings reported in [29].) Even if we divide this latency by 1.7, the ratio of the SPECint92 ratings of the DEC 3000/400 and theSparcStation 10, our algorithm stillreducesthe latency to invoke the read-write and read-only 0/0 operations by factors of more than 10 and 20, respectively. Note thatthisscaling is conservative because the network accounts for a significant fraction of Rampart’s latency [29] and Rampart’s results were obtained using 300-bit modulus RSA signatures, which are not considered secure today unless the keys used to generate them are refreshed very frequently. There are no published performance numbers for SecureRing [16] but it would be slower than Rampart because its algorithm has more message delays and signature operations in the critical path. H2 7.3 Andrew BenchmarkThe Andrew benchmark [15] emulates a software development workload. It has five phases: (1) creates subdirectories recursively; (2) copies a source tree; (3) examines the status of all the files in the tree without examining their data; (4) examines every byte of data in all the files; and (5) compiles and links the files. We use the Andrew benchmark to compare BFS with two other file system configurations: NFS-std, which is the NFS V2 implementation in Digital Unix, and BFS-nr, which is identicalto BFSbut with no replication. BFS-nr ran two simple UDPrelays on the client, and on the server it ran a thin veneer linked with a version of snfsd from which allthe checkpoint management code wasremoved. This configuration does not write modified file system state to disk before replying to the client. Therefore, it does notimplement NFS V2 protocolsemantics, whereas both BFS and NFS-std do. Out of the 18 operations in the NFS V2 protocol only getattr is read-only because the time-last-accessed attribute of files and directories is set by operations that would otherwise be read-only, e.g., read and lookup. The result is that our optimization for readonly operations can rarely be used. To show the impact of this optimization, we also ran the Andrew benchmark on a second version of BFS that modifies the lookup operation to be read-only. This modification violates strict Unix file system semantics but is unlikely to have adverse effects in practice. For all configurations, the actual benchmark code ran at the client workstation using the standard NFS client implementation in the Digital Unix kernel with the same mount options. The most relevant of these options for the benchmark are: UDP transport, 4096-byte read and write buffers, allowing asynchronous client writes, and allowing attribute caching. We report the mean of 10 runs of the benchmark for each configuration. The sample standard deviation for the total time to run the benchmark was always below 2.6% of the reported value but it was as high as 14% for the individual times of the first four phases. This high variance was also present in the NFS-std configuration. The estimated error for the reported mean was below 4.5% for the individual phases and 0.8% for the total. Table 2 shows the results for BFS and BFS-nr. The comparison between BFS-strict and BFS-nr shows that the overhead of Byzantine fault tolerance for this service is low — BFS-strict takes only 26% more time to run Table 2: Andrew benchmark: BFS vs BFS-nr. The times are in seconds. the complete benchmark. The overhead is lower than what was observed for the micro-benchmarks because the clientspends a significant fraction of the elapsed time computing between operations, i.e., between receiving the reply to an operation and issuing the next request, and operations at the server perform some computation. But the overhead is not uniform across the benchmark phases. The main reason for this is a variation in the amount of time the client spends computing between operations; the first two phases have a higher relative overhead because the client spends approximately 40% of the total time computing between operations, whereas itspends approximately 70% during the lastthree phases. The table shows that applying the read-only optimization to lookup improves the performance of BFS significantly and reduces the overhead relative to BFS-nr to 20%. This optimization has a significant impact in the first four phases because the time spent waiting for lookup operations to complete in BFS-strict is at least 20% of the elapsed time for these phases, whereas it is less than 5% of the elapsed time for the last phase Table 3: Andrew benchmark: BFS vs NFS-std. The times are in seconds. Table 3 shows the results for BFS vs NFS-std. These results show that BFS can be used in practice — BFSstrict takes only 3% more time to run the complete benchmark. Thus, one could replace the NFS V2 implementation in Digital Unix, which is used daily by many users, by BFS without affecting the latency perceived by those users. Furthermore, BFS with the read-only optimization for the lookup operation is actually 2% faster than NFS-std. The overhead of BFS relative to NFS-std is not the same for all phases. Both versions of BFS are faster than NFS-std for phases 1, 2, and 5 but slower for the other phases. This is because during phases 1, 2, and 5 a large fraction (between 21% and 40%) of the operations issued by the client are synchronous, i.e., operations that require the NFS implementation to ensure stability of modified file system state before replying to the client. NFS-std achieves stability by writing modified state to disk whereas BFS achieves stability with lower latency using replication (as in Harp [20]). NFS-std is faster than BFS (and BFS-nr) in phases 3 and 4 because the client issues no synchronous operations during these phases. H1 8 Related WorkMost previous work on replication techniques ignored Byzantine faults or assumed a synchronous system model (e.g., [17, 26, 18, 34, 6, 10]). Viewstamped replication [26] and Paxos [18] use views with a primary and backups to tolerate benign faults in an asynchronous system. ToleratingByzantine faultsrequires a muchmore complex protocol with cryptographic authentication, an extra pre-prepare phase, and a different technique to trigger view changes and select primaries. Furthermore, oursystemuses view changes only to select a newprimary but never to select a different set of replicas to form the new view as in [26, 18]. Some agreement and consensus algorithms tolerate Byzantine faultsin asynchronoussystems(e.g,[2, 3, 24]). However, they do not provide a complete solution for state machine replication, and furthermore, most of them were designed to demonstrate theoretical feasibility and are too slow to be used in practice. Our algorithm during normal-case operation is similar to the Byzantine agreement algorithm in [2] but that algorithm is unable to survive primary failures. The two systems that are most closely related to our work are Rampart [29, 30, 31, 22] and SecureRing [16]. They implement state machine replication but are more than an order of magnitude slower than our system and, most importantly, they rely on synchrony assumptions. Both Rampart and SecureRing must exclude faulty replicasfrom the group to make progress(e.g., to remove a faulty primary and elect a new one), and to perform garbage collection. They rely on failure detectors to determine which replicas are faulty. However, failure detectors cannot be accurate in an asynchronous system [21], i.e.,they may misclassify a replica as faulty. Since correctness requires that fewer than 1 3 of group members be faulty, a misclassification can compromise correctness by removing a non-faulty replica from the group. This opens an avenue of attack: an attacker gains control over a single replica but does not change its behavior in any detectable way; then it slows correct replicas orthe communication between themuntil enough are excluded from the group. To reduce the probability of misclassification, failure detectors can be calibrated to delay classifying a replica as faulty. However, for the probability to be negligible the delay must be very large, which is undesirable. For example,if the primary has actually failed,the group will be unable to process client requests until the delay has expired. Our algorithm is not vulnerable to this problem because it never needsto exclude replicasfrom the group. Phalanx [23, 25] applies quorum replication techniques [12] to achieve Byzantine fault-tolerance in asynchronous systems. This work does not provide generic state machine replication; instead, it offers a data repository with operationsto read and write individual variables and to acquire locks. The semantics it provides for read and write operations are weaker than those offered by our algorithm; we can implement arbitrary operationsthat access any number of variables,whereasinPhalanx it would be necessary to acquire and release locks to execute such operations. There are no published performance numbers for Phalanx but we believe our algorithm is faster because it has fewer message delays in the critical path and because of our use of MACs rather than public key cryptography. The approach in Phalanx offers the potential for improved scalability; each operation is processed by only a subset of replicas. But this approach to scalability is expensive: it requires n >4f+1 to tolerate $f$ faults; each replica needs a copy of the state; and the load on each replica decreases slowly with $n$ (it is $O\\left( 1/\\sqrt {n}\\right)$ ). H1 9 ConclusionsThis paper has described a new state-machine replication algorithm that is able to tolerate Byzantine faults and can be used in practice: it is the first to work correctly in an asynchronous system like the Internet and it improves the performance of previous algorithms by more than an order of magnitude. The paper also described BFS, a Byzantine-faulttolerant implementation of NFS. BFS demonstrates that it is possible to use our algorithm to implement real services with performance close to that of an unreplicated service — the performance of BFSis only 3% worse than that of the standard NFSimplementation in Digital Unix. This good performance is due to a number of important optimizations, including replacing public-key signatures by vectors of message authentication codes, reducing the size and number of messages, and the incremental checkpoint-management techniques. One reason why Byzantine-fault-tolerant algorithms will be important in the future is that they can allow systems to continue to work correctly even when there are software errors. Not all errors are survivable; our approach cannot mask a software error that occurs at all replicas. However, it can mask errors that occur independently at different replicas, including nondeterministic software errors, which are the most problematic and persistent errors since they are the hardestto detect. In fact, we encountered such a software bug while running oursystem, and our algorithmwas able to continue running correctly in spite of it. There isstillmuch work to do on improving oursystem. One problem of special interest is reducing the amount of resources required to implement our algorithm. The number of replicas can be reduced by using $f$ replicas as witnesses that are involved in the protocol only when some full replica fails. We also believe that it is possible to reduce the number of copies of the state to $f+1$ but the details remain to be worked out. AcknowledgmentsWe would like to thank Atul Adya, Chandrasekhar Boyapati, Nancy Lynch,Sape Mullender, AndrewMyers, LiubaShrira, and the anonymousrefereesfortheir helpful comments on drafts of this paper. References [1] M. Bellare and D. Micciancio. A New Paradigm for Collisionfree Hashing: Incrementality at Reduced Cost. In Advances in Cryptology – Eurocrypt 97, 1997.[2] G. Bracha and S. Toueg. Asynchronous Consensus and Broadcast Protocols. Journal of the ACM, 32(4), 1995.[3] R. Canneti and T. Rabin. Optimal Asynchronous Byzantine Agreement. Technical Report #92-15, Computer Science Department, Hebrew University, 1992.[4] M. Castro and B. Liskov. A Correctness Proof for a Practical Byzantine-Fault-Tolerant Replication Algorithm. Technical Memo MIT/LCS/TM-590, MIT Laboratory for Computer Science, 1999.[5] M. Castro and B. Liskov. Authenticated Byzantine Fault Tolerance Without Public-Key Cryptography. Technical Memo MIT/LCS/TM-589, MIT Laboratory for Computer Science, 1999.[6] F. Cristian, H. Aghili, H. Strong, and D. Dolev. AtomicBroadcast: From Simple Message Diffusion to Byzantine Agreement. In International Conference on Fault Tolerant Computing, 1985.[7] S. Deering and D. Cheriton. Multicast Routing in Datagram Internetworks and Extended LANs. ACM Transactions on Computer Systems, 8(2), 1990.[8] H. Dobbertin. The Status of MD5 After a Recent Attack. RSA Laboratories’ CryptoBytes, 2(2), 1996.[9] M. Fischer, N. Lynch, and M. Paterson. Impossibility of Distributed Consensus With One Faulty Process. Journal of the ACM, 32(2), 1985.[10] J. Garay and Y. Moses. Fully Polynomial Byzantine Agreement for n 3t Processorsin t+1 Rounds. SIAM Journal of Computing, 27(1), 1998.[11] D. Gawlick and D. Kinkade. Varieties of Concurrency Control in IMS/VS Fast Path. Database Engineering, 8(2), 1985.[12] D. Gifford. Weighted Voting for Replicated Data. In Symposium on Operating Systems Principles, 1979.[13] M. Herlihy and J. Tygar. How to make replicated data secure. Advances in Cryptology (LNCS 293), 1988.[14] M. Herlihy and J. Wing. Axiomsfor Concurrent Objects. In ACM Symposium on Principles of Programming Languages, 1987.[15] J. Howard et al. Scale and performance in a distributed file system. ACM Transactions on Computer Systems, 6(1), 1988.[16] K. Kihlstrom, L. Moser, and P. Melliar-Smith. The SecureRing Protocols for Securing Group Communication. In Hawaii International Conference on System Sciences, 1998.[17] L. Lamport. Time, Clocks, and the Ordering of Events in a Distributed System. Commun. ACM, 21(7), 1978.[18] L. Lamport. The Part-Time Parliament. Technical Report 49, DEC Systems Research Center, 1989.[19] L. Lamport, R. Shostak, and M. Pease. The Byzantine Generals Problem. ACM Transactions on Programming Languages and Systems, 4(3), 1982.[20] B. Liskov et al. Replication in the Harp File System. In ACM Symposium on Operating System Principles, 1991.[21] N. Lynch. Distributed Algorithms. Morgan Kaufmann Publishers, 1996.[22] D. Malkhi and M. Reiter. A High-Throughput Secure Reliable Multicast Protocol. In Computer Security Foundations Workshop, 1996.[23] D. Malkhi and M. Reiter. Byzantine Quorum Systems. In ACM Symposium on Theory of Computing, 1997.[24] D. Malkhi and M. Reiter. Unreliable Intrusion Detection in Distributed Computations. In Computer Security Foundations Workshop, 1997.[25] D. Malkhi and M. Reiter. Secure and Scalable Replication in Phalanx. In IEEE Symposium on Reliable Distributed Systems, 1998.[26] B. Oki and B. Liskov. Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems. In ACM Symposium on Principles of Distributed Computing, 1988.[27] B. Preneel and P. Oorschot. MDx-MAC and Building Fast MACs from Hash Functions. In Crypto 95, 1995.[28] C. Pu, A. Black, C. Cowan, and J. Walpole. A Specialization Toolkit to Increase the Diversity of Operating Systems. In ICMAS Workshop on Immunity-Based Systems, 1996.[29] M. Reiter. Secure Agreement Protocols. In ACM Conference on Computer and Communication Security, 1994.[30] M. Reiter. The Rampart Toolkit for Building High-Integrity Services. Theory and Practice in Distributed Systems (LNCS 938), 1995.[31] M. Reiter. A Secure Group Membership Protocol. IEEE Transactions on Software Engineering, 22(1), 1996.[32] R. Rivest. The MD5 Message-Digest Algorithm. Internet RFC1321, 1992.[33] R. Rivest, A. Shamir, and L. Adleman. A Method for Obtaining Digital Signatures and Public-Key Cryptosystems. Communications of the ACM, 21(2), 1978.[34] F. Schneider. Implementing Fault-Tolerant Services Using The State Machine Approach: A Tutorial. ACM Computing Surveys, 22(4), 1990.[35] A. Shamir. How to share a secret. Communications of the ACM, 22(11), 1979.[36] G. Tsudik. Message Authentication with One-Way Hash Functions. ACM ComputerCommunicationsReview, 22(5), 1992.[37] M. Wiener. Performance Comparison of Public-Key Cryptosystems. RSA Laboratories’ CryptoBytes, 4(1), 1998. Practical Byzantine Fault Tolerance.md","categories":[{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/categories/共识算法/"}],"tags":[{"name":"论文","slug":"论文","permalink":"http://blog.msiter.com/tags/论文/"},{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/tags/共识算法/"},{"name":"paoxs","slug":"paoxs","permalink":"http://blog.msiter.com/tags/paoxs/"},{"name":"PBFT","slug":"PBFT","permalink":"http://blog.msiter.com/tags/PBFT/"}],"keywords":[{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/categories/共识算法/"}]},{"title":"Paxos Made Live - An Engineering Perspective","slug":"Paxos Made Live - An Engineering Perspective","date":"2018-07-31T15:05:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Paxos Made Live - An Engineering Perspective-20180731.html","link":"","permalink":"http://blog.msiter.com/Paxos Made Live - An Engineering Perspective-20180731.html","excerpt":"最近在学习 paxos。英文能力略残，所以把论文按照规则排版之后，在网页上进行 谷歌翻译。 IntroductionIt is well known that fault-tolerance on commodity hardware can be achieved through replication [17, 18]. A common approach is to use a consensus algorithm [7] to ensure that all replicas are mutually consistent [8, 14, 17]. By repeatedly applying such an algorithm on a sequence of input values, it is possible to build an identical log of values on each replica. If the values are operations on some data structure, application of the same log on all replicas may be used to arrive at mutually consistent data structures on all replicas. For instance, if the log contains a sequence of database operations, and if the same sequence of operations is applied to the (local) database on each replica, eventually all replicas will end up with the same database content (provided that they all started with the same initial database state).","text":"最近在学习 paxos。英文能力略残，所以把论文按照规则排版之后，在网页上进行 谷歌翻译。 H1 IntroductionIt is well known that fault-tolerance on commodity hardware can be achieved through replication [17, 18]. A common approach is to use a consensus algorithm [7] to ensure that all replicas are mutually consistent [8, 14, 17]. By repeatedly applying such an algorithm on a sequence of input values, it is possible to build an identical log of values on each replica. If the values are operations on some data structure, application of the same log on all replicas may be used to arrive at mutually consistent data structures on all replicas. For instance, if the log contains a sequence of database operations, and if the same sequence of operations is applied to the (local) database on each replica, eventually all replicas will end up with the same database content (provided that they all started with the same initial database state). This general approach can be used to implement a wide variety of fault-tolerant primitives, of which a fault-tolerant database is just an example. As a result, the consensus problem has been studied extensively over the past two decades. There are several well-known consensus algorithms that operate within a multitude of settings and which tolerate a variety of failures. The Paxos consensus algorithm [8] has been discussed in the theoretical [16] and applied community [10, 11, 12] for over a decade. We used the Paxos algorithm (“Paxos”) as the base for a framework that implements a fault-tolerant log. We then relied on that framework to build a fault-tolerant database. Despite the existing literature on the subject, building a production system turned out to be a non-trivial task for a variety of reasons: • While Paxos can be described with a page of pseudo-code, our complete implementation contains several thousand lines of C++ code. The blow-up is not due simply to the fact that we used C++ instead of pseudo notation, nor because our code style may have been verbose. Converting the algorithm into a practical, production-ready system involved implementing many features and optimizations – some published in the literature and some not.• The fault-tolerant algorithms community is accustomed to proving short algorithms (one page of pseudo code) correct. This approach does not scale to a system with thousands of lines of code. To gain confidence in the “correctness” of a real system, different methods had to be used.• Fault-tolerant algorithms tolerate a limited set of carefully selected faults. However, the real world exposes software to a wide variety of failure modes, including errors in the algorithm, bugs in its implementation, and operator error. We had to engineer the software and design operational procedures to robustly handle this wider set of failure modes.• A real system is rarely specified precisely. Even worse, the specification may change during the implementation phase. Consequently, an implementation should be malleable. Finally, a system might “fail” due to a misunderstanding that occurred during its specification phase. This paper discusses a selection of the algorithmic and engineering challenges we encountered in moving Paxos from theory to practice. This exercise took more R&amp;D efforts than a straightforward translation of pseudo-code to C++ might suggest. The rest of this paper is organized as follows. The next two sections expand on the motivation for this project and describe the general environment into which our system was built. We then provide a quick refresher on Paxos. We divide our experiences into three categories and discuss each in turn: algorithmic gaps in the literature, software engineering challenges, and unexpected failures. We conclude with measurements of our system, and some broader observations on the state of the art in our field. H1 BackgroundChubby [1] is a fault-tolerant system at Google that provides a distributed locking mechanism and stores small files. Typically there is one Chubby instance, or “cell”, per data center. Several Google systems – such as the Google Filesystem (GFS) [4] and Bigtable [2] – use Chubby for distributed coordination and to store a small amount of metadata. Chubby achieves fault-tolerance through replication. A typical Chubby cell consists of five replicas, running the same code, each running on a dedicated machine. Every Chubby object (e.g., a Chubby lock, or file) is stored as an entry in a database. It is this database that is replicated. At any one time, one of these replicas is considered to be the “master”. Chubby clients (such as GFS and Bigtable) contact a Chubby cell for service. The master replica serves all Chubby requests. If a Chubby client contacts a replica that is not the master, the replica replies with the master’s network address. The Chubby client may then contact the master. If the master fails, a new master is automatically elected, which will then continue to serve traffic based on the contents of its local copy of the replicated database. Thus, the replicated database ensures continuity of Chubby state across master failover. The first version of Chubby was based on a commercial, third-party, fault-tolerant database; we will refer to this database as “3DB” for the rest of this paper. This database had a history of bugs related to replication. In fact, as far as we know, the replication mechanism was not based on a proven replication algorithm and we do not know if it is correct. Given the history of problems associated with that product and the importance of Chubby, we eventually decided to replace 3DB with our own solution based on the Paxos algorithm. H1 Architecture outlineFigure 1 illustrates the architecture of a single Chubby replica. A fault-tolerant replicated log based on the Paxos algorithm sits at the bottom of the protocol stack. Each replica maintains a local copy of the log. The Paxos algorithm is run repeatedly as required to ensure that all replicas have identical sequences of entries in their local logs. Replicas communicate with each other through a Paxos-specific protocol. The next layer is a fault-tolerant replicated database which includes a local copy of the database at each replica. The database consists of a local snapshot and a replay-log of database operations. New database operations are submitted to the replicated log. When a database operation appears at a replica, it is applied on that replica’s local database copy. Finally, Chubby uses the fault-tolerant database to store its state. Chubby clients communicate with a single Chubby replica through a Chubby-specific protocol. Figure 1: A single Chubby replica. We devoted effort to designing clean interfaces separating the Paxos framework, the database, and Chubby. We did this partly for clarity while developing this system, but also with the intention of reusing the replicated log layer in other applications. We anticipate future systems at Google that seek fault-tolerance through replication. We believe that a fault-tolerant log is a powerful primitive on which to build such systems.Our fault-tolerant log’s API is depicted in Figure 2. It contains a call to submit a new value to the log. Once a submitted value enters the fault-tolerant log, our system invokes a callback to the client application at each replica and passes the submitted value.Our system is multi-threaded and multiple values can be submitted concurrently on different threads. The replicated log does not create its own threads but can be invoked concurrently by any number of threads. This approach to threading helps in testing the system, as we will show in more detail later in the paper. H1 On PaxosIn this section we give an informal overview of the basic Paxos algorithm and outline how to chain together multiple executions of it (Multi-Paxos). We refer the reader to the literature for more formal descriptions and correctness proofs [8, 9, 16]. Readers who are familiar with Paxos may skip directly to the next section. H2 Paxos BasicsPaxos is a consensus algorithm executed by a set of processes, termed replicas, to agree on a single value in the presence of failures. Replicas may crash and subseqently recover. The network may drop messages Figure 2: API for fault-tolerant log. between replicas. Replicas have access to persistent storage that survives crashes. Some replicas may submit values for consensus. If eventually a majority of the replicas run for long enough without crashing and there are no failures, all running replicas are guaranteed to agree on one of the values that was submitted. In our system, the value to be agreed upon is the next entry in a (replicated) log as described in the introduction.The algorithm consists of three phases, which may be repeated (because of failures): Elect a replica to be the coordinator. The coordinator selects a value and broadcasts it to all replicas in a message called the accept message. Other replicas either acknowledge this message or reject it. Once a majority of the replicas acknowledge the coordinator, consensus has been reached, and the coordinator broadcasts a commit message to notify replicas. To provide some intuition about how the algorithm works, consider first the case in which there is only a single coordinator and no failures. Consensus is reached once a majority of replicas receive the accept message from the coordinator and acknowledge it. Subsequently, if any minority of the replicas fail, we are still guaranteed that at least one replica will be alive that received the consensus value. In reality the coordinator may fail. Paxos does not require that only one replica act as coordinator at a time. Multiple replicas may decide to become coordinators and execute the algorithm at any time. Typically the system is engineered to limit coordinator turnover, as it can delay reaching consensus. This flexible election policy means there may be multiple replicas who simultaneously believe they are the coordinator. Further, these coordinators may select different values. Paxos ensures consensus can be reached on a single value (it can be from any coordinator) by introducing two extra mechanisms: 1) assigning an ordering to the successive coordinators; and 2) restricting each coordinator’s choice in selecting a value. Ordering the coordinators allows each replica to distinguish between the current coordinator and previous coordinators. In this way, replicas can reject messages from old coordinators and prevent them from disrupting consensus once it is reached. Paxos orders the coordinators by assigning them an increasing sequence number as follows. Each replica keeps track of the most recent sequence number it has seen so far. When a replica wants to become coordinator, it generates a unique1 sequence number higher than any it has seen,and broadcasts it to all replicas in a propose message. If a majority of replicas reply and indicate they have not seen a higher sequence number, then the replica acts as a coordinator. These replies are called promise messages since replicas promise henceforth to reject messages from old coordinators. This propose/promise message exchange constitutes step 1 listed above. Once consensus is reached on a value, Paxos must force future coordinators to select that same value in order to ensure continued agreement. To guarantee this, the promise messages from replicas include the most recent value they have heard, if any, along with the sequence number of the coordinator from whom they heard it. The new coordinator chooses the value from the most recent coordinator. If none of the promise messages contain a value, the coordinator is free to choose a submitted value. The reasoning why this works is subtle, but proceeds roughly as follows. The new coordinator requires a response to the propose message from a majority of replicas. Therefore, if consensus was achieved by a previous coordinator, the new coordinator is guaranteed to hear about the value decided upon from at least one replica. By induction, that value will have the highest sequence number of all responses received, and so will be selected by the new coordinator. H2 4.2 Multi-PaxosPractical systems use Paxos as a building block to achieve consensus on a sequence of values, such as in a replicated log. The simple way to implement this is to repeatedly execute the Paxos algorithm. We term each execution an instance of Paxos. We refer to submitting a value to Paxos (or equivalently, to the log) to mean executing an instance of Paxos while submitting that value. In Multi-Paxos some slow (lagging) replicas might not have participated in recent Paxos instances. We use a catch-up mechanism to enable lagging replicas to catch up with leading replicas. Each replica maintains a locally persistent log to record all Paxos actions. When a replica crashes and subsequently recovers, it replays the persistent log to reconstruct its state prior to crashing. Replicas also use this log when helping lagging replicas to catch up. The Paxos algorithm as described thus far requires all message senders to log their state before sending messages – thus the algorithm requires a sequence of five writes (for each of the propose, promise, accept, acknowledgment, and commit messages) to disk on its critical path. Note that all writes have to be flushed to disk immediately before the system can proceed any further. In a system where replicas are in close network proximity, disk flush time can dominate the overall latency of the implementation. There is a well-known optimization to reduce the number of messages involved by chaining together multiple Paxos instances [9]. Propose messages may be omitted if the coordinator identity does not change between instances. This does not interfere with the properties of Paxos because any replica at any time can still try to become coordinator by broadcasting a propose message with a higher sequence number. In order to avail itself of this optimization, a Multi-Paxos algorithm may be designed to pick a coordinator for long periods of time, trying not to let the coordinator change. We refer to this coordinator as the master. With this optimization, the Paxos algorithm only requires a single write to disk per Paxos instance on each replica, executed in parallel with each other. The master writes to disk immediately after sending its accept message and other replicas write to disk prior to sending their acknowledge message. In order to get additional throughput in a concurrent system, it is possible to batch a collection of values submitted by different application threads into a single Paxos instance H1 5 Algorithmic challengesWhile the core Paxos algorithm is well-described, implementing a fault-tolerant log based on it is a non-trivial endeavor. Some of the complications are due to imperfections found in the real world (such as hard disk failures, or finite resources), and some are due to additional requirements (for instance, “master leases”). Many of these challenges have algorithmic solutions that are intimately connected with the core Paxos algorithm. In the following we describe a number of mechanisms that we introduced. H2 5.1 Handling disk corruptionReplicas witness disk corruption from time to time. A disk may be corrupted due to a media failure or due to an operator error (an operator may accidentally erase critical data). When a replica’s disk is corrupted and it loses its persistent state, it may renege on promises it has made to other replicas in the past. This violates a key assumption in the Paxos algorithm. We use the following mechanism to address this problem [14]. Disk corruptions manifest themselves in two ways. Either file(s) contents may change or file(s) may become inaccessible. To detect the former, we store the checksum of the contents of each file in the file2. The latter may be indistinguishable from a new replica with an empty disk – we detect this case by having a new replica leave a marker in GFS after start-up. If this replica ever starts again with an empty disk, it will discover the GFS marker and indicate that it has a corrupted disk. A replica with a corrupted disk rebuilds its state as follows. It participates in Paxos as a non-voting member; meaning that it uses the catch-up mechanism to catch up but does not respond with promise or acknowledgment messages. It remains in this state until it observes one complete instance of Paxos that was started after the replica started rebuilding its state. By waiting for the extra instance of Paxos, we ensure that this replica could not have reneged on an earlier promise. This mechanism enables the following optimization to improve the latency of the system. Since the system can now deal with occasional disk corruption, under some circumstances it may be acceptable not to flush writes to disk immediately3 . While we have considered schemes to exploit this observation, we have not implemented them yet. H2 5.2 Master leasesWhen the basic Paxos algorithm is used to implement a replicated data structure, reads of the data structure require executing an instance of Paxos. This serializes the read with respect to updates and ensures that the current state is read. In particular, read operations cannot be served out of the master’s copy of the data structure because it is possible that other replicas have elected another master and modified the data structure without notifying the old master. In this case, the read operation at the master runs the risk of returning stale data. Since read operations usually comprise a large fraction of all operations, serializing reads through Paxos is expensive. The workaround is to implement master leases [5] with the following semantics: as long as the master has the lease, it is guaranteed that other replicas cannot successfully submit values to Paxos. Thus a master with the lease has up-to-date information in its local data structure which can be used to serve a read operation purely locally. By making the master attempt to renew its lease before it expires we can ensure that a master has a lease most of the time. With our system, masters successfully maintain leases for several days at a time. In our implementation, all replicas implicitly grant a lease to the master of the previous Paxos instance and refuse to process Paxos messages from any other replica while the lease is held. The master maintains a shorter timeout for the lease than the replicas – this protects the system against clock drift. The master periodically submits a dummy “heartbeat” value to Paxos to refresh its lease. The Multi-Paxos optimization exhibits the following stability problem when there are intermittent network outages. When a master temporarily disconnects, Paxos will elect a new master. The new master will maintain a fixed sequence number across instances of Paxos. In the mean time, when the disconnected old master tries to run the Paxos algorithm, if it manages to connect with another replica, it may increase its sequence number. When it reconnects, it may have a higher sequence number than the new master and be able to replace the new master. Later it may disconnect again, and the cycle can repeat itself. This behavior is undesirable as Chubby master changes have a negative impact on some of its users. Furthermore, this behavior can degenerate into rapid master changes in a network with poor connectivity.In our implementation the master periodically boosts its sequence number by running a full round of the Paxos algorithm, including sending propose messages4 . Boosting with the right frequency avoids this type of master churn in most cases. Note that it is possible to extend the concept of leases to all replicas. This will allow any replica witha lease to serve read requests from its local data structure. This extended lease mechanism is useful whenread traffic significantly exceeds write traffic. We have examined algorithms for replica leases, but have not implemented them yet. H2 5.3 Epoch numbersRequests (by a Chubby client) submitted to a Chubby cell are directed to the current Chubby master replica. From the time when the master replica receives the request to the moment the request causes an update of the underlying database, the replica may have lost its master status. It may even have lost master status and regained it again. Chubby requires an incoming request to be aborted if mastership is lost and/or re-acquired during the handling of the request. We needed a mechanism to reliably detect master turnover and abort operations if necessary. We solved this problem by introducing a global epoch number with the following semantics. Two requests for the epoch number at the master replica receive the same value iff that replica was master continuously for the time interval between the two requests. The epoch number is stored as an entry in the database, and all database operations are made conditional on the value of the epoch number. H2 5.4 Group membershipPractical systems must be able to handle changes in the set of replicas. This is referred to as the group membership problem in the literature [3]. Some Paxos papers point out that the Paxos algorithm itself can be used to implement group membership [8]. While group membership with the core Paxos algorithm is straightforward, the exact details are non-trivial when we introduce Multi-Paxos, disk corruptions, etc. Unfortunately the literature does not spell this out, nor does it contain a proof of correctness for algorithms related to group membership changes using Paxos. We had to fill in these gaps to make group membership work in our system. The details – though relatively minor – are subtle and beyond the scope of this paper. H2 5.5 SnapshotsAs described thus far, the repeated application of a consensus algorithm to create a replicated log will lead to an ever growing log. This has two problems: it requires unbounded amounts of disk space; and perhaps worse, it may result in unbounded recovery time since a recovering replica has to replay a potentially long log before it has fully caught up with other replicas. Since the log is typically a sequence of operations to be applied to some data structure, and thus implicitly (through replay) represents a persistent form of that data structure, the problem is to find an alternative persistent representation for the data structure at hand. An obvious mechanism is to persist – or snapshot – the data structure directly, at which point the log of operations leading to the current state of the data structure is no longer needed. For example, if the data structure is held in memory, we take a snapshot by serializing it on disk. If the data structure is kept on disk, a snapshot may just be an on-disk copy of it.By itself, the Paxos framework does not know anything about the data structure we are trying to replicate; its only concern is the consistency of the replicated log. It is the particular application using the Paxos framework that has all the knowledge about the replicated data structure. Thus the application must be responsible for taking snapshots. Our framework provides a mechanism that allows client applications, e.g. our fault-tolerant database, to inform the framework that a snapshot was taken; the client application is free to take a snapshot at any point. When the Paxos framework is informed about a snapshot, it will truncate its log by deleting log entries that precede the snapshot. Should the replica fail, during subsequent recoveryit will simply install the latest snapshot and then replay the truncated log to rebuild its state. Snapshotsare not synchronized across replicas; each replica independently decides when to create a snapshot.This mechanism appears straightforward at first and is mentioned briefly in the literature [8]. However, it introduces a fair amount of complexity into the system: the persistent state of a replica now comprises a log and a snapshot that have to be maintained consistently. The log is fully under the framework’s control, while the snapshot format is application-specific. Some aspects of the snapshot machinery are of particular interest: The snapshot and log need to be mutually consistent. Each snapshot needs to have information about its contents relative to the fault-tolerant log. In our framework we introduced the concept of a snapshot handle for this purpose. The snapshot handle contains all the Paxos-specific information related to a particular snapshot. When creating a snapshot (which is under control of the application) the corresponding snapshot handle (provided by the framework) needs to be stored by the application as well. When recovering a snapshot, the application must return the snapshot handle to the framework, which in turn will use the information in the handle to coordinate the snapshot with the log. Note that the handle is really a snapshot of the Paxos state itself. In our system, it contains the Paxos instance number corresponding to the (log) snapshot and the group membership at that point. Taking a snapshot takes time and in some situations we cannot afford to freeze a replica’s log while it is taking a snapshot. In our framework, taking a snapshot is split into three phases. First, when the client application decides to take a snapshot, it requests a snapshot handle. Next, the client application takes its snapshot. It may block the system while taking the snapshot, or – more likely – spawn a thread that takes a snapshot while the replica continues to participate in Paxos. The snapshot must correspond to the client state at the log position when the handle was obtained. Thus if the replica continues to participate in Paxos while taking a snapshot, special precautions may have to be taken to snapshot the client’s data structure while it is actively updated.5 Finally, when the snapshot has been taken, the client application informs the framework about the snapshot and passes the corresponding snapshot handle. The framework then truncates the log appropriately. Taking a snapshot may fail. Our framework only truncates the log when it is informed that a snapshot has been taken and has received the corresponding snapshot handle. Thus, as long as the client application does not inform the framework, from the framework’s viewpoint, no snapshot has been taken. This allows the client application to verify a snapshot’s integrity and discard it if necessary. If there is a problem with the snapshot, the client doesn’t ask the framework to truncate its log. A client application may even attempt to take several snapshots at the same time using this mechanism. While in catch-up, a replica will attempt to obtain missing log records. If it cannot obtain them (because no replica has old-enough log entries readily available), the replica will be told to obtain a snapshot from another replica. This snapshot’s handle contains information about the Paxos instance up to which the snapshot captured the state. Once the snapshot has been received and installed, under most circumstances the lagging replica will be close to the leading replica. In order to completely catchup, the lagging replica asks for and receives the remaining log records from the leading replica to bring it fully up-to-date Note that a leading replica may even create a new snapshot while a lagging replica is installing an older snapshot – in a fault-tolerant system this cannot be avoided. In this scenario, the lagging replica may not be able to obtain any outstanding log records because the snapshot provider (and any other replicas) may have moved ahead in the meantime. The lagging replica will need to obtain a more recent snapshot. Furthermore, the leading replica may fail after sending its snapshot. The catch-up mechanism must be able to recover from such problems by having the lagging replica contact another leading replica. We needed a mechanism to locate recent snapshots. Some applications may choose to transfer snapshots directly between leading and lagging replicas while others may ask a lagging replica to look up a snapshot on GFS. We implemented a general mechanism that allows an application to pass snapshot location information between leading and lagging replicas. H2 5.6 Database transactionsThe database requirements imposed by Chubby are simple: the database needs to store key-value pairs (with keys and values being arbitrary strings), and support common operations such as insert, delete, lookup, an atomic compare and swap (cas), and iteration over all entries. We implemented a log-structured design using a snapshot of the full database, and a log of database operations to be applied to that snapshot. The log of operations is the Paxos log. The implementation periodically takes a snapshot of the database state and truncates the log accordingly. The cas operation needed to be atomic with respect to other database operations (potentially issued by a different replica). This was easily achieved by submitting all cas-related data as a single “value” to Paxos. We realized that we could extend this mechanism to provide transaction-style support without having to implement true database transactions. We describe our solution in more detail because we believe it to be useful in other contexts. Our implementation hinges around a powerful primitive which we call MultiOp. All other database operations except for iteration are implemented as a single call to MultiOp. A MultiOp is applied atomically and consists of three components: A list of tests called guard. Each test in guard checks a single entry in the database. It may check for the absence or presence of a value, or compare with a given value. Two different tests in the guard may apply to the same or different entries in the database. All tests in the guard are applied and MultiOp returns the results. If all tests are true, MultiOp executes t op (see item 2 below), otherwise it executes f op (see item 3 below). A list of database operations called t op. Each operation in the list is either an insert, delete, or lookup operation, and applies to a single database entry. Two different operations in the list may apply to the same or different entries in the database. These operations are executed6 if guard evaluates to true. A list of database operations called f op. Like t op, but executed if guard evaluates to false. Late in our development (and after we had implemented the database and MultiOp), we realized that we also needed epoch numbers to implement database operations for Chubby. With this additional requirement, all Chubby operations became associated with an epoch number and were required to fail if the Paxos epoch number changed. MultiOp proved useful in accomodating this new requirement. After we incorporated the Paxos epoch as a database entry, we were able to modify all previous calls to our database to include an additional guard to check for the epoch number. H1 6 Software EngineeringFault-tolerant systems are expected to run continuously for long periods of time. Users are much less likely to tolerate bugs than in other systems. For instance, a layout bug exhibited by a document editor may be annoying to a user, but often it is possible to “work around” the issue, even though the bug is really at the core of what the software is supposed to do. A bug of similar gravity in a fault-tolerant system may makethe system unusable.We adopted several software engineering methods to give us confidence in the robustness of our implementation. We describe some of the methods we used in this section. H2 6.1 Expressing the algorithm effectivelyFault-tolerant algorithms are notoriously hard to express correctly, even as pseudo-code. This problem is worse when the code for such an algorithm is intermingled with all the other code that goes into building a complete system. It becomes harder to see the core algorithm, to reason about it, or to debug it when a bug is present. It also makes it difficult to change the core algorithm in response to a requirement change. We addressed this problem by coding the core algorithm as two explicit state machines. For that purpose, we designed a simple state machine specification language and built a compiler to translate such specifications into C++. The language was designed to be terse so that a full algorithm can be rendered on a single screen. As an additional benefit, the state machine compiler also automatically generates code to log state transitions and measure code coverage to assist in debugging and testing. We believe that choosing a specification language makes it easier to reason about and modify our state machines than an explicitly coded implementation that is intermingled with the rest of the system. This is illustrated by the following experience. Towards the end of our development of the fault-tolerant log, we had to make a fundamental change in our group membership algorithm. Prior to this change, a replica roughly went through three states. Initially it waited to join the group, then it joined the group, and finally it left the group. Once a replica left the group, it was not allowed to rejoin the group. We felt this approach was best because an intermittently failing replica would not be able to join the group and disrupt it for long. Intermittent failure turned out to be more common than originally anticipated because normal replicas exhibit intermittent failures from time to time. Thus, we needed to change the algorithm to have two states. Either a replica was in the group or it was out. A replica could switch between these two states often during the lifetime of the system. It took us about one hour to make this change and three days to modify our tests accordingly. Had we intermingled our state machines with the rest of the system, this change would have been more difficult to make. H2 6.2 Runtime consistency checkingThe chance for inconsistencies increases with the size of the code base, the duration of a project, and the number of people working simultaneously on the same code. We used various active self-checking mechanisms such as the liberal use of assert statements, and explicit verification code that tests data structures for consistency.For example, we used the following database consistency check. The master periodically submits a checksum request to the database log. On receipt of this request, each replica computes a checksum of its local database7 Since the Paxos log serializes all operations identically on all replicas, we expect all replicas to compute the same checksum. After the master completes a checksum computation, it sends its checksum to all replicas which compare the master’s checksum with their computed checksum. We have had three database inconsistency incidents thus far: The first incident was due to an operator error. We have not found an explanation for the second incident. On replaying the faulty replica’s log we found that it was consistent with the other replicas. Thus it is possible that this problem was caused by a random hardware memory corruption. We suspect the third was due to an illegal memory access from errant code in the included codebase (which is of considerable size). To protect against this possibility in the future, we maintain a second database of checksums and double-check every database access against the database of checksums. In all three cases manual intervention appeared to resolve the problem before it became visible to Chubby H2 6.3 TestingGiven the current state of the art, it is unrealistic to prove a real system such as ours correct. To achieve robustness, the best practical solution in addition to meticulous software engineering is to test a system thoroughly. Our system was designed to be testable from the onset and now contains an extensive suite of tests. In this section we describe two tests that take the system through a long sequence of random failures and verify that it behaves as expected. Both tests can run in one of two modes: Safety mode. In this mode, the test verifies that the system is consistent. However, the system is not required to make any progress. For example, it is acceptable for an operation to fail to complete or to report that the system is unavailable. Liveness mode. In this mode, the test verifies that the system is consistent and is making progress. All operations are expected to complete and the system is required to be consistent. Our tests start in safety mode and inject random failures into the system. After running for a predetermined period of time, we stop injecting failures and give the system time to fully recover. Then we switch the test to liveness mode. The purpose for the liveness test is to verify that the system does not deadlock after a sequence of failures. One of our tests verifies the fault-tolerant log. It simulates a distributed system consisting of a random number of replicas and takes our fault-tolerant log through a random sequence of network outages, message delays, timeouts, process crashes and recoveries, file corruptions, schedule interleavings, etc. We wanted this test to be repeatable to aid in debugging. To this end, we use a random number generator to determine the schedule of failures. The seed for the random number generator is given at the beginning of the test run. We ensure that two test runs with the same random number seed are identical by running the test in a single thread to remove unwanted non-determinism from multi-threading. This is possible because the fault-tolerant log does not create its own threads and can run in a single-threaded environment (even though it normally runs in a multi-threaded environment). Each test execution reports success or failure. If a test fails, we rerun that test with the failing random number seed and with detailed logging turned on in a debugger to determine what went wrong. This is possible because these tests are repeatable. This test proved useful in finding various subtle protocol errors, including errors in our group membership implementation, and our modifications to deal with corrupted disks. In order to measure the strength of this test, we left some protocol bugs found during code and design reviews in the system, and verified that our test system detected these bugs. After a number of bug fixes, the test became very stable. In order to improve its bug yield, we started running this test on a farm of several hundred Google machines at a time. We found additional bugs, some of which took weeks of simulated execution time (at extremely high failure rates) to find. Another test verifies robustness of the new Chubby system against lower-level system and hardware failures. We implemented several hooks in our fault-tolerant log to inject failures. The test randomly invokes these hooks and verifies that higher levels of the system can cope. Our hooks can be used to crash a replica, disconnect it from other replicas for a period of time or force a replica to pretend that it is no longer the master. This test found five subtle bugs in Chubby related to master failover in its first two weeks. In the same vein, we built a filesystem with hooks to programmatically inject failures and are using it to test our ability to deal with filesystem failures. In closing we point out a challenge that we faced in testing our system for which we have no systematic solution. By their very nature, fault-tolerant systems try to mask problems. Thus they can mask bugs or configuration problems while insidiously lowering their own fault-tolerance. For example, we have observed the following scenario. We once started a system with five replicas, but misspelled the name of one of the replicas in the initial group. The system appeared to run correctly as the four correctly configured replicas were able to make progress. Further, the fifth replica continunously ran in catch-up mode8 and therefore appeared to run correctly as well. However in this configuration the system only tolerates one faulty replica instead of the expected two. We now have processes in place to detect this particular type of problem. We have no way of knowing if there are other bugs/misconfigurations that are masked by fault-tolerance. 6.4 ConcurrencyAt the onset of the project we were concerned about the problem of testing concurrent fault-tolerant code. In particular, we wanted our tests to be repeatable. As described earlier, our fault-tolerant log doesn’t contain any of its own threads (even though it can handle concurrent requests on different threads). Threading is introduced at the edges of the code – where we receive calls from the networking layer. By making our tests repeatable, we were able to hunt down several obscure protocol errors during testing. As the project progressed, we had to make several subsystems more concurrent than we had intended and sacrifice repeatability. Chubby is multi-threaded at its core, thus we cannot run repeatable tests against the complete system. Next we had to make our database multi-threaded so it could take snapshots, compute checksums and process iterators while concurrently serving database requests. Finally, we were forced to make the code that handles the local copy of the log multi-threaded as well (the exact reason why is beyond the scope of this paper). In summary, we believe that we set ourselves the right goals for repeatability of executions by constraining concurrency. Unfortunately, as the product needs grew we were unable to adhere to these goals. 7 Unexpected failuresSo far, our system has logged well over 100 machine years of execution in production. In this period we have witnessed the following unexpected failure scenarios: Our first release shipped with ten times the number of worker threads as the original Chubby system. We hoped this change would enable us to handle more requests. Unfortunately, under load, the worker threads ended up starving some other key threads and caused our system to time out frequently. This resulted in rapid master failover, followed by en-masse migrations of large numbers of clients to the new master which caused the new master to be overwhelmed, followed by additional master failovers, and so on.When this problem first appeared, the precise cause was unknown and we had to protect ourselves from a potentially dangerous bug in our system. We decided to err on the side of caution and to rollback our system to the old version of Chubby (based on 3DB) in one of our data centers. At that point, the rollback mechanism was not properly documented (because we never expected to use it), its use was non-intuitive, the operator performing the roll-back had no experience with it, and when the rollback was performed, no member of the development team was present. As a result, an old snapshot was accidentally used for the rollback. By the time we discovered the error, we had lost 15 hours of data and several key datasets had to be rebuilt. When we tried to upgrade this Chubby cell again a few months later, our upgrade script failed because we had omitted to delete files generated by the failed upgrade from the past. The cell ended up running with a months-old snapshot for a few minutes before we discovered the problem. This caused us to lose about 30 minutes of data. Fortunately all of Chubby’s clients recovered from this outage. A few months after our initial release, we realized that the semantics provided by our database were different from what Chubby expected. If Chubby submitted an operation to the database, and the database lost its master status, Chubby expected the operation to fail. With our system, a replica could be re-installed as master during the database operation and the operation could succeed. The fix required a substantial rework of the integration layer between Chubby and our framework (we needed to implement epoch numbers). MultiOp proved to be helpful in solving this unexpected problem – an indication that MultiOp is a powerful primitive. As mentioned before, on three occasions we discovered that one of the database replicas was different from the others in that Chubby cell. We found this problem because our system periodically takes checksums of all replicas and then compares them. Our upgrade script which is responsible for migrating cells from the 3DB version of Chubby to the Paxos version has failed several times for a variety of reasons. For example, it once failed because a basic Google program was not installed on one of our cells. We have encountered failures due to bugs in the underlying operating system. For example in our version of the Linux 2.4 kernel, when we try to flush a small file to disk, the call can hang for a long time if there are a lot of buffered writes to other files. This happens immediately after we write a database snapshot to disk. In this case, we observed that it could take several seconds for the kernel to flush an unrelated small write to the Paxos log. Our workaround is to write all large files in small chunks, with a flush to disk after each small chunk. While this hurts the performance of the write slightly, it protects the more critical log writes from unexpected delays A small number of failures in 100 machine years would be considered excellent behavior for most production systems. However, we consider the current failure rate too high for Chubby and we have determined that we need to reduce it further. Three of the failures occurred during upgrade (or rollback). Every time we encountered a problem during upgrade, we updated our upgrade script accordingly. Once a cell is upgraded, this type of failure will disappear. Two of the failures were from bugs that have since been fixed. To reduce the probability of other bugs, we continue to improve and run the Chubby verification test outlined earlier. Two of our unexpected problems relate to operator error during rollout of a new release and caused us to lose data. At Google, the day-to-day monitoring and management of our systems is done by system operators. While they are very competent, they are usually not part of the development team that built the system, and therefore not familiar with its intricate details. This may lead to the occasional operator error in unforseen situations. We now rely on carefully written and well-tested scripts to automate rollout and minimize operator involvement. As a result our most recent major release of Chubby was rolled out across hundreds of machines without incident, while serving life traffic. One of the failures was due to memory corruption. Because our system is log-structured and maintains several days of log data and snapshots, it was possible to replay the database upto the exact point at which the problem appears. We were able to verify that our logs were correct and conclude that the memory corruption occurred from errant software or due to hardware problems. We added additional checksum data to detect this type of problem in the future and will crash a replica when it detects this problem. H1 8 MeasurementsThe initial goal of our system was to replace 3DB with our own database. Thus our system had to demonstrate equal or superior performance relative to 3DB. We measured the performance of a complete Chubby system (clients, server, including network latency) using our fault-tolerant replicated database. We also benchmarked this system against an identical system based on 3DB (see Table 1). For our tests, we ran two copies of Chubby on the same set of 5 servers (typical PentiumR-class machines). One copy of Chubby used our database while the other copy used 3DB. We ran Chubby clients on workstations to generate load on the servers. For our tests, we measured total system throughput. Each call includes the Chubby client, the network, the Chubby server and our fault-tolerant database. While this test underestimates the performance of our database, it gives a sense of the full system throughput of a system based on Paxos. Figure 1:Table 1: Comparing our system with 3DB (higher numbers are better). Even though read requests to Chubby dominate in practice, we designed our tests to be write intensive. This is because read requests are completely handled on the master, which typically has a lease, and do not exercise the Paxos algorithm. In our test, each worker repeatedly creates a file in Chubby and waits for Chubby to return before creating the file again. Thus each operation makes one write call to the underlying database. If the contents of the file are small and there is a single worker, the test measures the latency of the system. If the contents of the file are large, the test measures the throughput of the system in MB/s. By using multiple concurrent workers, we were also able to measure the throughput of the system in submissions/s. All tests with more than one worker show the effect of batching a collection of submitted values. It should be possible to achieve some speedup with 3DB by bundling a collection of updates in a database transaction. The last two throughput tests show the effect of taking snapshots. This system was configured to take a snapshot whenever the replicated log size exceeded 100 MB. In these two tests, the system takes snapshots roughly every 100 seconds. When taking a snapshot, the system makes another copy of the database and writes it to disk. As a result, its performance temporarily drops off. Our system is by no means optimized for performance, and we believe that there is a lot of room to make it faster. However, given the performance improvement over 3DB, further optimizations are not a priority at this time. H1 9 Summary and open problemsWe have described our implementation of a fault-tolerant database, based on the Paxos consensus algorithm. Despite the large body of literature in the field, algorithms dating back more then 15 years, and experience of our team (one of us has designed a similar system before and the others have built other types of complex systems in the past), it was significantly harder to build this system then originally anticipated. We attribute this to several shortcomings in the field: There are significant gaps between the description of the Paxos algorithm and the needs of a real-world system. In order to build a real-world system, an expert needs to use numerous ideas scattered in the literature and make several relatively small protocol extensions. The cumulative effort will be substantial and the final system will be based on an unproven protocol. The fault-tolerance computing community has not developed the tools to make it easy to implement their algorithms. The fault-tolerance computing community has not paid enough attention to testing, a key ingredient for building fault-tolerant systems. As a result, the core algorithms work remains relatively theoretical and is not as accessible to a larger computing community as it could be. We believe that in order to make a greater impact, researchers in the field should focus on addressing these shortcomings. In contrast, consider the field of compiler construction. Though concepts in that field are complex, they have been made accessible to a wide audience. Industrial-strength parsing tools such yacc [6] appeared not too long after the theory of parsing was well-understood. Not only are there now many front-end tools such as ANTLR [15] or CoCo/R [13]; but there are also tree-rewriting tools helping with optimizations and instruction selection, assemblers helping with binary code generation, and so forth. Thus, in this area of software engineering, an entire family of tools has emerged, making the construction of a compiler significantly easier or at least less error-prone. Disciplines within the field of compiler construction, such as parsing, which were once at the cutting edge of research, are now considered “solved” and are routinely taught at the undergraduate level in many schools. It appears that the fault-tolerant distributed computing community has not developed the tools and know-how to close the gaps between theory and practice with the same vigor as for instance the compiler community. Our experience suggests that these gaps are non-trivial and that they merit attention by the research community. H1 10 AcknowledgmentsMany people at Google helped us with this project. Mike Burrows who implemented Chubby suggested that we replace 3DB with a Paxos-based system. He and Sharon Perl reviewed our designs and provided excellent feedback. They introduced us to the mechanism for handling disk corruptions and suggested that we implement master leases. Michal Cierniak ported the original state machine compiler from Perl to C++ and made substantial modifications (it is now being used elsewhere at Google as well). Vadim Furman helped us write the Chubby verification test. Salim Virji and his team were responsible for the roll-out of our system across Google data centers. Mike Burrows, Bill Coughran, Gregory Eitzman, Peter Mckenzie, Sharon Perl, Rob Pike, David Presotto,Sean Quinlan, and Salim Virji reviewed earlier versions of this paper and provided valuable feedback. H1 References[1] Burrows, M. The Chubby lock service for loosely-coupled distributed systems. In Proceedings of the 7th USENIX Symposium on Operating Systems Design and Implementation, pp. 335-350[2] Chang, F., Dean, J., Ghemawat, S., Hsieh, W. C., Wallach, D. A., Burrows, M., Chandra, T., Fikes, A., and Gruber, R. E. Bigtable: A distributed storage system for structured data. In Proceedings of the 7th USENIX Symposium on Operating Systems Design and Implementation, pp. 205-218[3] Cristian, F. Reaching agreement on processor-group membership in synchronous distributed systems. Distributed Computing 4, 4 (1991), 175–188.[4] Ghemawat, S., Gobioff, H., and Leung, S.-T. The Google file system. In Proceedings of the 19th ACM Symposium on Operating Systems Principles (Dec. 2003), pp. 29–43.[5] Gray, C., Cheriton, D. Leases: An efficient fault-tolerant mechanism for distributed file cache consistency. In Proceedings of the 12th ACM Symposium on Operating Systems Principles (1989), pp. 202–210.[6] Johnson, S. C. Yacc: Yet another compiler-compiler.[7] Lamport, Shostak, and Pease. The byzantine generals problem. In Advances in Ultra-Dependable Distributed Systems, N. Suri, C. J. Walter, and M. M. Hugue (Eds.), IEEE Computer Society Press. 1995.[8] Lamport, L. The part-time parliament. ACM Transactions on Computer Systems 16, 2 (1998), 133–169.[9] Lamport, L. Paxos made simple. ACM SIGACT News 32, 4 (Dec. 2001), 18–25.[10] Lampson, B. W. How to build a highly available system using consensus. In 10th International Workshop on Distributed Algorithms (WDAG 96) (1996), Babaoglu and Marzullo, Eds., vol. 1151, Springer-Verlag, Berlin Germany, pp. 1–17.[11] Lee, E. K., and Thekkath, C. A. Petal: Distributed virtual disks. In Proceedings of the Seventh International Conference on Architectural Support for Programming Languages and Operating Systems (Cambridge, MA, 1996), pp. 84–92.[12] MacCormick, J., Murphy, N., Najork, M., Thekkath, C. A., and Zhou, L. Boxwood: Abstractions as the foundation for storage infrastructure. In Proceedings of the 6th Symposium on Operating Systems Design and Implementation (2004), pp. 105–120.[13] Moessenboeck, H. A generator for production quality compilers. In Proceedings of the 3rd International Workshop on Compiler Compilers - Lecture Notes in Computer Science 477 (Berlin, Heidelberg, New York,Tokyo, 1990), Springer-Verlag, pp. 42–55.[14] Oki, Brian M., and Liskov, Barbara H. Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems. In Proceedings of the 7th annual ACM Symposium on Principles of Distributed Computing (1988), pp. 8–17.[15] Parr, T. J., and QUONG, R. W. Antlr: A predicated-ll(k) parser generator. Software–Practice and Experience25, 7 (JULY 1995), 789–810.[16] Prisco, R. D., Lampson, B. W., and Lynch, N. A. Revisiting the paxos algorithm. In 11th International Workshop on Distributed Algorithms (WDAG 96) (1997), pp. 111–125.[17] Schneider, F. B. Implementing fault-tolerant services using the state machine approach: A tutorial. ACM Computing Surveys 22, 4 (1990), 299–319.[18] von Neumann, J. Probabilistic logics and synthesis of reliable organisms from unreliable components. Automata Studies (1956), 43–98. Paxos Made Live - An Engineering Perspective.md","categories":[{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/categories/共识算法/"}],"tags":[{"name":"论文","slug":"论文","permalink":"http://blog.msiter.com/tags/论文/"},{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/tags/共识算法/"},{"name":"paoxs","slug":"paoxs","permalink":"http://blog.msiter.com/tags/paoxs/"},{"name":"multi-paoxs","slug":"multi-paoxs","permalink":"http://blog.msiter.com/tags/multi-paoxs/"}],"keywords":[{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/categories/共识算法/"}]},{"title":"Paxos Made Simple - Leslie Lamport","slug":"paxos-simple","date":"2018-07-26T18:22:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"paxos-simple-20180726.html","link":"","permalink":"http://blog.msiter.com/paxos-simple-20180726.html","excerpt":"最近在学习 paxos。英文能力略残，所以把论文按照规则排版之后，在网页上进行 谷歌翻译。 IntroductionThe Paxos algorithm for implementing a fault-tolerant distributed system has been regarded as difficult to understand, perhaps because the original presentation was Greek to many readers [5]. In fact, it is among the simplest and most obvious of distributed algorithms. At its heart is a consensus algorithm—the “synod” algorithm of [5]. The next section shows that this consensus algorithm follows almost unavoidably from the properties we want it to satisfy. The last section explains the complete Paxos algorithm, which is obtained by the straightforward application of consensus to the state machine approach for building a distributed system—an approach that should be well-known, since it is the subject of what is probably the most often-cited article on the theory of distributed systems [4].","text":"最近在学习 paxos。英文能力略残，所以把论文按照规则排版之后，在网页上进行 谷歌翻译。 H2 IntroductionThe Paxos algorithm for implementing a fault-tolerant distributed system has been regarded as difficult to understand, perhaps because the original presentation was Greek to many readers [5]. In fact, it is among the simplest and most obvious of distributed algorithms. At its heart is a consensus algorithm—the “synod” algorithm of [5]. The next section shows that this consensus algorithm follows almost unavoidably from the properties we want it to satisfy. The last section explains the complete Paxos algorithm, which is obtained by the straightforward application of consensus to the state machine approach for building a distributed system—an approach that should be well-known, since it is the subject of what is probably the most often-cited article on the theory of distributed systems [4]. H2 The Consensus AlgorithmH3 The ProblemAssume a collection of processes that can propose values. A consensus algorithm ensures that a single one among the proposed values is chosen. If no value is proposed, then no value should be chosen. If a value has been chosen, then processes should be able to learn the chosen value. The safety requirements for consensus are: Only a value that has been proposed may be chosen, Only a single value is chosen, and A process never learns that a value has been chosen unless it actually has been.We won’t try to specify precise liveness requirements. However, the goal is to ensure that some proposed value is eventually chosen and, if a value has been chosen, then a process can eventually learn the value. We let the three roles in the consensus algorithm be performed by three classes of agents: proposers, acceptors, and learners. In an implementation, a single process may act as more than one agent, but the mapping from agents to processes does not concern us here. Assume that agents can communicate with one another by sending messages.We use the customary asynchronous, non-Byzantine model, in which: Agents operate at arbitrary speed, may fail by stopping, and may restart. Since all agents may fail after a value is chosen and then restart, a solution is impossible unless some information can be remembered by an agent that has failed and restarted. Messages can take arbitrarily long to be delivered, can be duplicated, and can be lost, but they are not corrupted. H3 Choosing a ValueThe easiest way to choose a value is to have a single acceptor agent. A proposer sends a proposal to the acceptor, who chooses the first proposed value that it receives. Although simple, this solution is unsatisfactory because the failure of the acceptor makes any further progress impossible. So, let’s try another way of choosing a value. Instead of a single acceptor, let’s use multiple acceptor agents. A proposer sends a proposed value to a set of acceptors. An acceptor may accept the proposed value. The value is chosen when a large enough set of acceptors have accepted it. How large is large enough? To ensure that only a single value is chosen, we can let a large enough set consist of any majority of the agents. Because any two majorities have at least one acceptor in common, this works if an acceptor can accept at most one value. (There is an obvious generalization of a majority that has been observed in numerous papers, apparently starting with [3].) In the absence of failure or message loss, we want a value to be chosen even if only one value is proposed by a single proposer. This suggests the requirement: P1. An acceptor must accept the first proposal that it receives. But this requirement raises a problem. Several values could be proposed by different proposers at about the same time, leading to a situation in which every acceptor has accepted a value, but no single value is accepted by a majority of them. Even with just two proposed values, if each is accepted by about half the acceptors, failure of a single acceptor could make it impossible to learn which of the values was chosen. P1 and the requirement that a value is chosen only when it is accepted by a majority of acceptors imply that an acceptor must be allowed to accept more than one proposal. We keep track of the different proposals that an acceptor may accept by assigning a (natural) number to each proposal, so a proposal consists of a proposal number and a value. To prevent confusion, we require that different proposals have different numbers. How this is achieved depends on the implementation, so for now we just assume it. A value is chosen when a single proposal with that value has been accepted by a majority of the acceptors. In that case, we say that the proposal (as well as its value) has been chosen. We can allow multiple proposals to be chosen, but we must guarantee that all chosen proposals have the same value. By induction on the proposal number, it suffices to guarantee: P2.If a proposal with value v is chosen, then every higher-numbered proposal that is chosen has value v. Since numbers are totally ordered, condition P2 guarantees the crucial safety property that only a single value is chosen. To be chosen, a proposal must be accepted by at least one acceptor. So, we can satisfy P2 by satisfying: P2a.If a proposal with value v is chosen, then every higher-numbered proposal accepted by any acceptor has value v. We still maintain P1 to ensure that some proposal is chosen. Because communication is asynchronous, a proposal could be chosen with some particular acceptor c never having received any proposal. Suppose a new proposer “wakes up” and issues a higher-numbered proposal with a different value. P1 requires c to accept this proposal, violating P2a . Maintaining both P1 and P2a requires strengthening P2a to:P2b.If a proposal with value v is chosen, then every higher-numbered proposal issued by any proposer has value v. Since a proposal must be issued by a proposer before it can be accepted by an acceptor, P2b implies P2a , which in turn implies P2. To discover how to satisfy P2b , let’s consider how we would prove that it holds. We would assume that some proposal with number m and value v is chosen and show that any proposal issued with number n &gt; m also has value v. We would make the proof easier by using induction on n, so we can prove that proposal number n has value v under the additional assumption that every proposal issued with a number in m . .(n − 1) has value v, where i . . j denotes the set of numbers from i through j. For the proposal numbered m to be chosen, there must be some set C consisting of a majority of acceptors such that every acceptor in C accepted it. Combining this with the induction assumption, the hypothesis that m is chosen implies: Every acceptor in C has accepted a proposal with number in m . .(n − 1), and every proposal with number in m . .(n − 1) accepted by any acceptor has value v. Since any set S consisting of a majority of acceptors contains at least one member of C , we can conclude that a proposal numbered n has value v by ensuring that the following invariant is maintained: P2c . For any v and n, if a proposal with value v and number n is issued, then there is a set S consisting of a majority of acceptors such that either (a) no acceptor in S has accepted any proposal numbered less than n, or (b) v is the value of the highest-numbered proposal among all proposals numbered less than n accepted by the acceptors in S. We can therefore satisfy P2b by maintaining the invariance of P2c To maintain the invariance of P2c , a proposer that wants to issue a proposal numbered n must learn the highest-numbered proposal with number less than n, if any, that has been or will be accepted by each acceptor in some majority of acceptors. Learning about proposals already accepted is easy enough; predicting future acceptances is hard. Instead of trying to predict the future, the proposer controls it by extracting a promise that there won’t be any such acceptances. In other words, the proposer requests that the acceptors not accept any more proposals numbered less than n. This leads to the following algorithm for issuing proposals. A proposer chooses a new proposal number n and sends a request to each member of some set of acceptors, asking it to respond with: (a) A promise never again to accept a proposal numbered less than n, and (b) The proposal with the highest number less than n that it has accepted, if any. I will call such a request a prepare request with number n. If the proposer receives the requested responses from a majority of the acceptors, then it can issue a proposal with number n and value v, where v is the value of the highest-numbered proposal among the responses, or is any value selected by the proposer if the responders reported no proposals. A proposer issues a proposal by sending, to some set of acceptors, a request that the proposal be accepted. (This need not be the same set of acceptors that responded to the initial requests.) Let’s call this an accept request. This describes a proposer’s algorithm. What about an acceptor? It can receive two kinds of requests from proposers: prepare requests and accept requests. An acceptor can ignore any request without compromising safety. So, we need to say only when it is allowed to respond to a request. It can always respond to a prepare request. It can respond to an accept request, accepting the proposal, iff it has not promised not to. In other words: P1a . An acceptor can accept a proposal numbered n iff it has not responded to a prepare request having a number greater than n. Observe that P1a subsumes P1. We now have a complete algorithm for choosing a value that satisfies the required safety properties—assuming unique proposal numbers. The final algorithm is obtained by making one small optimization. Suppose an acceptor receives a prepare request numbered n, but it has already responded to a prepare request numbered greater than n, thereby promising not to accept any new proposal numbered n. There is then no reason for the acceptor to respond to the new prepare request, since it will not accept the proposal numbered n that the proposer wants to issue. So we have the acceptor ignore such a prepare request. We also have it ignore a prepare request for a proposal it has already accepted. With this optimization, an acceptor needs to remember only the highestnumbered proposal that it has ever accepted and the number of the highestnumbered prepare request to which it has responded. Because P2c must be kept invariant regardless of failures, an acceptor must remember this information even if it fails and then restarts. Note that the proposer can always abandon a proposal and forget all about it—as long as it never tries to issue another proposal with the same number. Putting the actions of the proposer and acceptor together, we see that the algorithm operates in the following two phases. Phase 1. (a) A proposer selects a proposal number n and sends a prepare request with number n to a majority of acceptors. (b) If an acceptor receives a prepare request with number n greater than that of any prepare request to which it has already responded, hen it responds to the request with a promise not to accept any more roposals numbered less than n and with the highest-numbered proposal if any) that it has accepted. Phase 2. (a) If the proposer receives a response to its prepare requests (numbered n) from a majority of acceptors, then it sends an accept request to each of those acceptors for a proposal numbered n with a value v, where v is the value of the highest-numbered proposal among the responses, or is any value if the responses reported no proposals. (b) If an acceptor receives an accept request for a proposal numbered n, it accepts the proposal unless it has already responded to a prepare request having a number greater than n. A proposer can make multiple proposals, so long as it follows the algorithm for each one. It can abandon a proposal in the middle of the protocol at any time. (Correctness is maintained, even though requests and/or responses for the proposal may arrive at their destinations long after the proposal was abandoned.) It is probably a good idea to abandon a proposal if some proposer has begun trying to issue a higher-numbered one. Therefore, if an acceptor ignores a prepare or accept request because it has already received a prepare request with a higher number, then it should probably informthe proposer, who should then abandon its proposal. This is a performanceoptimization that does not affect correctness. H3 Learning a Chosen ValueTo learn that a value has been chosen, a learner must find out that a proposal has been accepted by a majority of acceptors. The obvious algorithm is to have each acceptor, whenever it accepts a proposal, respond to all learners, sending them the proposal. This allows learners to find out about a chosen value as soon as possible, but it requires each acceptor to respond to each learner—a number of responses equal to the product of the number of acceptors and the number of learners. The assumption of non-Byzantine failures makes it easy for one learner to find out from another learner that a value has been accepted. We can have the acceptors respond with their acceptances to a distinguished learner, which in turn informs the other learners when a value has been chosen. This approach requires an extra round for all the learners to discover the chosen value. It is also less reliable, since the distinguished learner could fail. But it requires a number of responses equal only to the sum of the number of acceptors and the number of learners. More generally, the acceptors could respond with their acceptances to some set of distinguished learners, each of which can then inform all the learners when a value has been chosen. Using a larger set of distinguished learners provides greater reliability at the cost of greater communication complexity. Because of message loss, a value could be chosen with no learner ever finding out. The learner could ask the acceptors what proposals they have accepted, but failure of an acceptor could make it impossible to know whether or not a majority had accepted a particular proposal. In that case, learners will find out what value is chosen only when a new proposal is chosen. If a learner needs to know whether a value has been chosen, it can have a proposer issue a proposal, using the algorithm described above. H3 ProgressIt’s easy to construct a scenario in which two proposers each keep issuing a sequence of proposals with increasing numbers, none of which are ever chosen. Proposer p completes phase 1 for a proposal number n1. Another proposer q then completes phase 1 for a proposal number n2 &gt; n1. Proposer p’s phase 2 accept requests for a proposal numbered n1 are ignored because the acceptors have all promised not to accept any new proposal numbered less than n2. So, proposer p then begins and completes phase 1 for a new proposal number n3 &gt; n2, causing the second phase 2 accept requests of proposer q to be ignored. And so on. To guarantee progress, a distinguished proposer must be selected as the only one to try issuing proposals. If the distinguished proposer can communicate successfully with a majority of acceptors, and if it uses a proposal with number greater than any already used, then it will succeed in issuing a proposal that is accepted. By abandoning a proposal and trying again if it learns about some request with a higher proposal number, the distinguished proposer will eventually choose a high enough proposal number. If enough of the system (proposer, acceptors, and communication network) is working properly, liveness can therefore be achieved by electing a single distinguished proposer. The famous result of Fischer, Lynch, and Patterson [1] implies that a reliable algorithm for electing a proposer must use either randomness or real time—for example, by using timeouts. However, safety is ensured regardless of the success or failure of the election. H3 The ImplementationThe Paxos algorithm [5] assumes a network of processes. In its consensus algorithm, each process plays the role of proposer, acceptor, and learner. The algorithm chooses a leader, which plays the roles of the distinguished proposer and the distinguished learner. The Paxos consensus algorithm is precisely the one described above, where requests and responses are sent as ordinary messages. (Response messages are tagged with the corresponding proposal number to prevent confusion.) Stable storage, preserved during failures, is used to maintain the information that the acceptor must remember. An acceptor records its intended response in stable storage before actually sending the response. All that remains is to describe the mechanism for guaranteeing that no two proposals are ever issued with the same number. Different proposers choose their numbers from disjoint sets of numbers, so two different proposers never issue a proposal with the same number. Each proposer remembers (in stable storage) the highest-numbered proposal it has tried to issue, and begins phase 1 with a higher proposal number than any it has already used. H2 Implementing a State MachineA simple way to implement a distributed system is as a collection of clients that issue commands to a central server. The server can be described as a deterministic state machine that performs client commands in some sequence. The state machine has a current state; it performs a step by taking as input a command and producing an output and a new state. For example, the clients of a distributed banking system might be tellers, and the state-machine state might consist of the account balances of all users. A withdrawal would be performed by executing a state machine command that decreases an account’s balance if and only if the balance is greater than the amount withdrawn, producing as output the old and new balances. An implementation that uses a single central server fails if that server fails. We therefore instead use a collection of servers, each one independently implementing the state machine. Because the state machine is deterministic, all the servers will produce the same sequences of states and outputs if they all execute the same sequence of commands. A client issuing a command can then use the output generated for it by any server. To guarantee that all servers execute the same sequence of state machine commands, we implement a sequence of separate instances of the Paxos consensus algorithm, the value chosen by the ith instance being the ith state machine command in the sequence. Each server plays all the roles (proposer, acceptor, and learner) in each instance of the algorithm. For now, I assume that the set of servers is fixed, so all instances of the consensus algorithm use the same sets of agents. In normal operation, a single server is elected to be the leader, which acts as the distinguished proposer (the only one that tries to issue proposals) in all instances of the consensus algorithm. Clients send commands to the leader, who decides where in the sequence each command should appear. If the leader decides that a certain client command should be the 135th command, it tries to have that command chosen as the value of the 135th instance of the consensus algorithm. It will usually succeed. It might fail because of failures, or because another server also believes itself to be the leader and has a different idea of what the 135th command should be. But the consensus algorithm ensures that at most one command can be chosen as the 135th one. Key to the efficiency of this approach is that, in the Paxos consensus algorithm, the value to be proposed is not chosen until phase 2. Recall that, after completing phase 1 of the proposer’s algorithm, either the value to be proposed is determined or else the proposer is free to propose any value. I will now describe how the Paxos state machine implementation works during normal operation. Later, I will discuss what can go wrong. I consider what happens when the previous leader has just failed and a new leader has been selected. (System startup is a special case in which no commands have yet been proposed.) The new leader, being a learner in all instances of the consensus algorithm, should know most of the commands that have already been chosen. Suppose it knows commands 1–134, 138, and 139—that is, the values chosen in instances 1–134, 138, and 139 of the consensus algorithm. (We will see later how such a gap in the command sequence could arise.) It then executes phase 1 of instances 135–137 and of all instances greater than 139. (I describe below how this is done.) Suppose that the outcome of these executions determine the value to be proposed in instances 135 and 140, but leaves the proposed value unconstrained in all other instances. The leader then executes phase 2 for instances 135 and 140, thereby choosing commands 135 and 140. The leader, as well as any other server that learns all the commands the leader knows, can now execute commands 1–135. However, it can’t execute commands 138–140, which it also knows, because commands 136 and 137 have yet to be chosen. The leader could take the next two commands requested by clients to be commands 136 and 137. Instead, we let it fill the gap immediately by proposing, as commands 136 and 137, a special “noop” command that leaves the state unchanged. (It does this by executing phase 2 of instances 136 and 137 of the consensus algorithm.) Once these no-op commands have been chosen, commands 138–140 can be executed. Commands 1–140 have now been chosen. The leader has also completed phase 1 for all instances greater than 140 of the consensus algorithm, and it is free to propose any value in phase 2 of those instances. It assigns command number 141 to the next command requested by a client, proposing it as the value in phase 2 of instance 141 of the consensus algorithm. It proposes the next client command it receives as command 142, and so on. The leader can propose command 142 before it learns that its proposed command 141 has been chosen. It’s possible for all the messages it sent in proposing command 141 to be lost, and for command 142 to be chosen before any other server has learned what the leader proposed as command 141. When the leader fails to receive the expected response to its phase 2 messages in instance 141, it will retransmit those messages. If all goes well, its proposed command will be chosen. However, it could fail first, leaving a gap in the sequence of chosen commands. In general, suppose a leader can get α commands ahead—that is, it can propose commands i + 1 through i +α after commands 1 through i are chosen. A gap of up to α−1 commands could then arise. A newly chosen leader executes phase 1 for infinitely many instances of the consensus algorithm—in the scenario above, for instances 135–137 and all instances greater than 139. Using the same proposal number for all instances, it can do this by sending a single reasonably short message to the other servers. In phase 1, an acceptor responds with more than a simple OK only if it has already received a phase 2 message from some proposer. (In the scenario, this was the case only for instances 135 and 140.) Thus, a server (acting as acceptor) can respond for all instances with a single reasonably short message. Executing these infinitely many instances of phase 1 therefore poses no problem. Since failure of the leader and election of a new one should be rare events, the effective cost of executing a state machine command—that is, of achieving consensus on the command/value—is the cost of executing only phase 2 of the consensus algorithm. It can be shown that phase 2 of the Paxos consensus algorithm has the minimum possible cost of any algorithm for reaching agreement in the presence of faults [2]. Hence, the Paxos algorithm is essentially optimal. This discussion of the normal operation of the system assumes that there is always a single leader, except for a brief period between the failure of the current leader and the election of a new one. In abnormal circumstances, the leader election might fail. If no server is acting as leader, then no new commands will be proposed. If multiple servers think they are leaders, then they can all propose values in the same instance of the consensus algorithm, which could prevent any value from being chosen. However, safety is preserved—two different servers will never disagree on the value chosen as the ith state machine command. Election of a single leader is needed only to ensure progress. If the set of servers can change, then there must be some way of determining what servers implement what instances of the consensus algorithm. The easiest way to do this is through the state machine itself. The current set of servers can be made part of the state and can be changed with ordinary state-machine commands. We can allow a leader to get α commands ahead by letting the set of servers that execute instance i + α of the consensus algorithm be specified by the state after execution of the ith state machine command. This permits a simple implementation of an arbitrarily sophisticated reconfiguration algorithm. References[1] Michael J. Fischer, Nancy Lynch, and Michael S. Paterson. Impossibility of distributed consensus with one faulty process. Journal of the ACM, 32(2):374–382, April 1985.[2] Idit Keidar and Sergio Rajsbaum. On the cost of fault-tolerant consensus when there are no faults—a tutorial. TechnicalReport MIT-LCS-TR-821, Laboratory for Computer Science, Massachusetts Institute Technology, Cambridge, MA, 02139, May 2001. also published in SIGACT News 32(2) (June 2001).[3] Leslie Lamport. The implementation of reliable distributed multiprocess systems. Computer Networks, 2:95–114, 1978.[4] Leslie Lamport. Time, clocks, and the ordering of events in a distributed system. Communications of the ACM, 21(7):558–565, July 1978.[5] Leslie Lamport. The part-time parliament. ACM Transactions on Computer Systems, 16(2):133–169, May 1998. paxos-simple.md","categories":[{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/categories/共识算法/"}],"tags":[{"name":"论文","slug":"论文","permalink":"http://blog.msiter.com/tags/论文/"},{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/tags/共识算法/"},{"name":"paoxs","slug":"paoxs","permalink":"http://blog.msiter.com/tags/paoxs/"}],"keywords":[{"name":"共识算法","slug":"共识算法","permalink":"http://blog.msiter.com/categories/共识算法/"}]},{"title":"分布网络-共识算法","slug":"分布网络-共识算法","date":"2018-07-20T18:25:43.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"fbwl-gs,zsf-20180720.html","link":"","permalink":"http://blog.msiter.com/fbwl-gs,zsf-20180720.html","excerpt":"分布式网络我们来大致的看一下网络的发展脚步 在1961年，麻省理工学院的L.克莱因罗克(L.Klenrock)博士发表论文《大型通讯网络的信息流》，第一次详细论述了分布式网络理论。 我们可以看到，从这个理论开始到现在也不过50多个年头，连一个世纪都没有，甚至说，L.克莱因罗克(L.Klenrock)博士(互联网的创始人之一)至今还在世。 不仅让我们感叹，人类的进步的速度… 之后60年代，美籍波兰人保罗·巴兰(Paul Baran)撰写多份报告，不仅系统地阐述了分布式网络理论而且提出后来网络传播的核心——“包切换”(Packet Switching)","text":"H2 分布式网络我们来大致的看一下网络的发展脚步 在1961年，麻省理工学院的L.克莱因罗克(L.Klenrock)博士发表论文《大型通讯网络的信息流》，第一次详细论述了分布式网络理论。 我们可以看到，从这个理论开始到现在也不过50多个年头，连一个世纪都没有，甚至说，L.克莱因罗克(L.Klenrock)博士(互联网的创始人之一)至今还在世。 不仅让我们感叹，人类的进步的速度… 之后60年代，美籍波兰人保罗·巴兰(Paul Baran)撰写多份报告，不仅系统地阐述了分布式网络理论而且提出后来网络传播的核心——“包切换”(Packet Switching) 与此同时，英国物理学家D.W.戴维斯也提出“分布式网络”理论，其原理同巴兰的构想如出一辙，唯一的区别在于命名。巴兰将拆分的、便于传送的数据称为“块”。而戴维斯经过深思熟虑，并请教语言学家后，选择了“包”(packet)这个术语，从此拆分传送数据的方式也就被称为“包切换”。另外，戴维斯构想包切换的初衷，也同巴兰为军方服务有所不同，他是想创建一个更加有效的网络系统，从而使更多的人可以利用网络进行交流。 1964年伊凡·沙日尔兰德（Ivan Sutherland）继任担任该处处长，两年后的鲍勃·泰勒（Bob Taylor）上任，他在任职期间萌发了新型计算机网络的想法，并筹集资金启动试验。在鲍勃·泰勒的一再邀请下，日后成为“阿帕网之父”的拉里·罗伯茨出任信息处理处处长。 1965年的时候，在兰德公司(Rand)的支持下，巴兰正式向美国空军提出创建分布式网络的计划。由于巴兰的想法适合军方的需要，因而受到美国国防部的高度重视。按照分布式网络的原理，由于单个节点的重要性大大降低，所以网络的任何节点遭到破坏，都不至于影响整个网络，而且节点越多，网络的安全性能就越高。 这个包切换，网络专家尼葛洛庞帝(Nicholas Negropoute)对包切换及网络传播原理做了如下解释： 一个个信息包各自独立，其中包含了大量讯息，每个信息包都可以经由不同的传输路径，从甲地传输到乙地。现在，假定我要从波士顿把这段文字传到旧金山给你。每个信息包……基本上都可以采取不同的路径，有的经由丹佛，有的经由芝加哥，有的经由达拉斯，等等。假设信息包在旧金山以此排序时，却发现6号信息包不见了。6号信息包究竟出了什么事？军方拨款资助阿帕网时,正值冷战高峰。核战的威胁让人忧心忡忡。因此，假设6号信息包经过明尼阿波利斯时,敌人的飞弹正好落在这个城市。6号信息包因此不见了。其他的信息包一确定它不见了，就会要求波士顿重新传输一次(这次不会再经过明尼阿波利斯了)。也就是说，因为我总是有办法可以找到可用的传输途径，假如要阻止我把讯息传输给你，敌人必须扫荡大半个美国。没错，在寻找可用的传输路径时(假如越来越多城市被敌人摧毁)，系统的速度就会减慢，但系统不会灭亡。了解这个道理非常重要，因为正是这种分布式体系结构令互联网能像今天这样三头六臂。无论是通过法律还是炸弹，政客都无法控制整个网络。讯息还是传提交去了，不是经由这条路，就是走另一条路出去。 有了这些理论的支持，以及政府的介入。 1967年，罗伯茨来到高级研究计划署ARPA，着手筹建“分布式网络”。人员调度和工程设计很顺利，不到一年，就提出阿帕网的构想。随着计划的不断改进和完善，罗伯茨在描图纸上陆续绘制了数以百计的网络连接设计图，使之结构日益成熟。 1968年，罗伯茨提交研究报告《资源共享的计算机网络》，其中着力阐发的就是让“阿帕”的电脑达到互相连接，从而使大家分享彼此的研究成果。根据这份报告组建的国防部“高级研究计划网”，就是著名的“阿帕网”，拉里·罗伯茨也就成为“阿帕网之父”。 1969年底，阿帕网正式投入运行。最初的“阿帕网”，由西海岸的4个节点构成。第一个节点选在加州大学洛杉矶分校（UCLA），因为罗伯茨过去的麻省理工学院同事L.克莱因罗克教授，正在该校主持网络研究。第二个节点选在斯坦福研究院（SRI），那里有道格拉斯·恩格巴特（D.Engelbart）等一批网络的先驱人物。此外，加州大学圣巴巴拉分校（UCSB）和犹他大学（UTAH）分别被选为三、四节点。这两所大学都有电脑绘图研究方面的专家，而泰勒之前的信息处理技术处处长伊凡·泽兰教授，此时也任教于犹他大学。 我们可以看到这就是最初的互联网的雏形，它本身就是 peer to peer的分布式网络。 ARPA网无法做到和个别计算机网络交流，这引发了研究者的思考。根据诺顿的看法，他的设计需要太多的控制和太多的网络中机器设备的标准化。因此，1973年春，文顿·瑟夫和鲍勃·康（Bob Kahn）开始思考如何将ARPA网和另外两个已有的网络相连接，尤其是连接卫星网络（SAT NET）和基于夏威夷的分组无线业务的ALOHA网（ALOHA NET）瑟夫设想了新的计算机交流协议，最后创造出传送控制协议／互联网协议（TCP/IP）。 1975年，ARPA网被转交到美国国防部通信处（Defense Department Communicationg Agence）。此后ARPA网不再是实验性和独一无二的了。大量新的网络在1970年代开始出现，包括计算机科学研究网络（CSNET，Computer Science Research Network），加拿大网络（CDnet，Canadian Network），因时网（BITNET，Because It’s Time Network）和美国国家自然科学基金网络（NSFnet，National Science Foundation Network）。最后一个网络最终将在它自身被商业网络取代前代替ARPA网作为互联网的高速链路。 1982年中期ARPA网被停用，原先的交流协议NCP被禁用，只允许使用Cern的TCP/IP语言的网站交流。1983年1月1日，NCP成为历史，TCP/IP开始成为通用协议。 1983年ARPA网被分成两部分，用于军事和国防部门的军事网（MILNET）和用于民间的ARPA网版本。 1985年成为TCP/IP协议突破的一年，当时它成为UNIX操作系统的组成部分。最终将它放进了Sun公司的微系统工作站。 当免费的在线服务和商业的在线服务兴起后，例如Prodigy、FidoNet、Usenet、Gopher等，当NSFNET成为互联网中枢后，ARPA网的重要性被大大减弱了。系统在1989年被关闭，1990年正式退役。 另外，咱们现在这种 服务端-客户端的方式是从80年代到90年代，开始流行的。当时大部分文件传输还是依靠电话线，使用FTP或者Usenet网络。90年代后，新的数据压缩技术出现，例如 MP3，MPEG。在此背景下，Napster 出现了。用户可以免费下载 Napster 客户端，然后从别人那里下载 MP3 文件，同时自己也作为一台服务器，供别人下载。Napster 有一台中心服务器，向所有用户提供文件目录服务，客户想下载音乐时，需要先到这台中心服务器上查询哪些客户端拥有这首音乐，然后直连到那台机器下载。不到一年时间，它的用户量达到100万，两年时间不到，金属乐队起诉这家公司。2001年七月，Napster 被关闭，此时距它成立还不到三年时间。 我们可以来看看虽然，Napster服务是以p2p网络以基础，但是它依靠中心节点来存储索引，所以这也是为什么 Napster 容易被关闭的原因。 在 2000年的时候，Gnutella出现，它向与自己直接连接的节点发起查询，被查询的结点再去查询与自己连接的节点，如此递归下去，直到查询到为止。尽管它没有直接查询中心节点有效率，但它不再依赖一个中心化的索引节点。 并且与此同时，Freenet在2000年也开启了。Freenet 是一个内容发布和沟通平台，专为抵御内容审查而设计。在 Freenet 网络中，任何人都可以在上面自由发表言论，做自己想做的网站，传自己想传的资源。Freenet 开启了暗网时代！ 在2001年，诸多肥宅的希望-Bittorrent!降世!! Bittorrent 是基于 TCP/IP 协议开发的。发布文件之前需要制作种子文件，种子是一个记录了下载文件的服务器信息的索引文件。BitTorrent 协议下载的特点是，下载的人越多，提供的带宽也越多，下载速度就越快。同时，拥有完整文件的用户也会越来越多，文件的“寿命”也就越长。BitTorrent 引入了分布式哈希技术（ DHT ），相比泛洪查询技术，DHT 效率显著提升。 2009年bitcoin出现，在此之前从未让这么多民众开始关心这些东西。它的出现，可以说是一场革命。 Namecoin，2011年。Namecoin 是一个去中心化的域名系统，功能和传统的域名供应商类似，用来解析域名。我们现在使用的域名系统是分布式而非去中心化的，所以理论上强权是可以做到控制整个域名系统，从而控制互联网的访问。而 Namecoin 是去中心化的，理论上是没有人可以关闭他的。Namecoin 提供的域名后缀是 .bit，目前主流浏览器都还不支持它，要想使用就需要安装插件。可以说 Namecoin 是第一个非货币的区块链应用。早期以太坊的创始人就提到了用区块链来做 DNS 系统的可能性。所以愣着干嘛，赶紧把 google.bit baidu.bit mi.bit 搞下来～ 等升值去吧 Diaspora，2012年。Diaspora 将自己定位为开源的个人 Web 服务器和去中心化的社交网络。2010年在 Kickstarter 上筹资20万美金后，项目正式成立，并迅速发布了一个测试版本，到了2012年，稳定的社区版才算正式发布。Diaspora 的目标之一就是替代Facebook。Facebook 是一个集中式的平台，用户使用它时，只需要一台 Web 浏览器即可，而 Diaspora 是需要专门下载自己的程序客户端的，这也使得推广起来比较难。另外，有的人其实根本不关心集中式平台带来的隐私问题。 DSNs, Descentralised Storage Networks。 去中心化存储网络的背后思想是将云存储转变成一种带有激励措施的去中心化存储系统，并向愿意提供存储空间的矿工节点发放代币。经济激励是关键，它是系统可持续运行的重要保障。目前代表作有 IPFS。在比特币这样的区块链上存储数据，效率非常低，并且成本高，而在 IPFS 上，我们可以很方便的存储例如 PDF、mp4 等文件。 以上就是P2P网络的发展历史，我们可以将它们分为4个阶段 依赖中心索引系统的 Napster 时代 使用泛洪查询，摆脱中心索引的 Gnutella 的时代 使用分布式哈希（DHT）的 BitTorrent 带激励的分布式存储 H2 共识问题区块链核心价值就在于实现了去中心化的价值传输。那么区块链是如何做到这种价值传输的呢，很显然共识机制起到了决定性作用，今天我们就来深入讲解共识机制背后的原理及其发展。 首先我们来看一个我们不能绕开的问题，“拜占庭将军问题”，这个问题，首次是由 Leslie Lamport等人在1982年在他的同名论文The Byzantine Generals Problem 中提到。Fischer, Lynch 和 Patterson在1985年发表的论文中提出了可以说是最重要的分布式系统定理：FLP不可能定理（在异步通信场景，即使只有一个进程失败，也没有任何算法能保证非失败进程达到一致性）；2000年，EricBrewer教授又进一步提出了CAP猜想：一致性、可用性和分区容错性三者无法在分布式系统中被同时满足，并且最多只能满足其中两个；2002年，Lynch与其他人证明了Brewer的猜想，从而把CAP上升为一个定理。这期间和之后，涌现了一些著名的分布式一致性算法，如LeslieLamport在1989年提出的Paxos算法，1999年Castro和Liskov提出的PBFT算法等。直到比特币采用POW进行记账后，共识算法才真正进入到了大众的视野里。 H3 共识资料H4 FLP不可能原理任何问题一般都存在一个理论上的下限（最坏的情况），那么对于分布式系统的共识问题，其理论上的解是什么呢？经过科学家的证明，异步分布式系统的共识问题的通用解决方法是：无解，也就是说即便是在网络通信可靠的情况下，可扩展的分布式系统的共识问题是无解的。这个定理由Fischer，Lynch和Patterson三位科学家于1985年发表的论文中给出了证明，也叫做FLP不可能原理。这个定理也告诉人们不要试图去设计一套在任意场景下都适用的共识算法，否则等同于浪费时间。 H4 CAP原理CAP定理（CAP theorem），又被称作布鲁尔定理（Brewer’s theorem），它指出对于一个分布式计算系统来说，不可能同时满足以下三点： 一致性（Consistence） （等同于所有节点访问同一份最新的数据副本） 可用性（Availability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据） 分区容错性（Partition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择[3]。） 根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项。 理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。 此定理也是由FLP定理证明的作者之一的Lynch给出证明。 H4 BASE原理BASE是对CAP原理中一致性和可用性权衡以后的结果： Base Available：基本可用性，是指在系统的部分节点出现故障以后，允许损失一部分可用性； Soft state：软状态，允许系统中的数据存在中间状态，允许不同节点之间的数据副本的同步过程存在延迟； Eventually consistent：最终一致性，是指系统中的数据，在经过一定的时间以后会最终达到一致状态，也就是降低一致性要求，不要求实时的强一致性。 比特币区块链就是一个很好的例子，在区块链延长的过程中，有可能会出现分叉，不同的节点上区块不一样（不一致），但是经过一定时间以后，随着所有节点都切换到最长的主链，分叉的情况就会消失（最终一致）。 H3 拜占庭容错我们现在来看一下，拜占庭容错，到底讲了什么？ 一组拜占庭将军分别各率领一支军队共同围困一座城市。为了简化问题，将各支军队的行动策略限定为进攻或撤离两种。因为部分军队进攻部分军队撤离可能会造成灾难性后果，因此各位将军必须通过投票来达成一致策略，即所有军队一起进攻或所有军队一起撤离。因为各位将军分处城市不同方向，他们只能通过信使互相联系。在投票过程中每位将军都将自己投票给进攻还是撤退的信息通过信使分别通知其他所有将军，这样一来每位将军根据自己的投票和其他所有将军送来的信息就可以知道共同的投票结果而决定行动策略。 要让这个问题有解，有一个十分重要的前提，那就是信道必须是可靠的。如果信道不能保证可靠，那么拜占庭问题无解。关于信道可靠问题，会引出两军问题。两军问题的结论是，在一个不可靠的通信链路上试图通过通信以达成一致是基本不可能或者十分困难的。 H4 两军问题 两军问题 白军驻扎在沟渠里，蓝军则分散在沟渠两边。白军比任何一支蓝军都更为强大，但是蓝军若能同时合力进攻则能够打败白军。他们不能够远程的沟通，只能派遣通信兵穿过沟渠去通知对方蓝军协商进攻时间。是否存在一个能使蓝军必胜的通信协议，这就是两军问题。 看到这里您可能发现两军问题和拜占庭将军问题有一定的相似性，但我们必须注意的是，通信兵得经过敌人的沟渠，在这过程中他可能被捕，也就是说，两军问题中信道是不可靠的，并且其中没有叛徒之说，这就是两军问题和拜占庭将军问题的根本性不同。 倘若1号蓝军（简称1）向2号蓝军（简称2）派出了通信兵，若1要知道2是否收到了自己的信息，1必须要求2给自己传输一个回执，说“你的信息我已经收到了，我同意你提议的明天早上10点9分准时进攻”。 然而，就算2已经送出了这条信息，2也不能确定1就一定会在这个时间进攻，因为2发出的回执1并不一定能够收到。所以，1必须再给2发出一个回执说“我收到了”，但是1也不会知道2是否收到了这样一个回执，所以1还会期待一个2的回执。 虽然看似很可笑，但在这个系统中永远需要存在一个回执，这对于两方来说都并不一定能够达成十足的确信。更要命的是，我们还没有考虑，通信兵的信息还有可能被篡改。由此可见，经典情形下两军问题是不可解的，并不存在一个能使蓝军一定胜利的通信协议。 不幸的是，两军问题作为现代通信系统中必须解决的问题，我们尚不能将之完全解决，这意味着你我传输信息时仍然可能出现丢失、监听或篡改的情况。但我们能不能通过一种相对可靠的方式来解决大部分情形呢？这需要谈到TCP协议。事实上，搜索“两军问题与三次握手”，您一定可以找到大量与TCP协议相关的内容 TCP 握手协议 TCP协议中，A先向B发出一个随机数x，B收到x了以后，发给A另一个随机数y以及x+1作为答复，这样A就知道B已经收到了，因为要破解随机数x可能性并不大；然后A再发回y+1给B，这样B就知道A已经收到了。这样，A和B之间就建立一个可靠的连接，彼此相信对方已经收到并确认了信息。 而事实上，A并不会知道B是否收到了y+1；并且，由于信道的不可靠性，x或者y都是可能被截获的，这些问题说明了即使是三次握手，也并不能够彻底解决两军问题，只是在现实成本可控的条件下，我们把TCP协议当作了两军问题的现实可解方法。 解决方法，可参考量子纏結,量子信道。 所以，在这种情况下，我们必须默认，信道是安全的，才可以继续去看待拜占庭容错这个问题。 H4 拜占庭容错问题回到刚才的问题，我们可以看出来，问题在于，将军中可能出现叛徒，他们不仅可能向较为糟糕的策略投票，还可能选择性地发送投票信息。假设有9位将军投票，其中1名叛徒。8名忠诚的将军中出现了4人投进攻，4人投撤离的情况。这时候叛徒可能故意给4名投进攻的将领送信表示投票进攻，而给4名投撤离的将领送信表示投撤离。这样一来在4名投进攻的将领看来，投票结果是5人投进攻，从而发起进攻；而在4名投撤离的将军看来则是5人投撤离。这样各支军队的一致协同就遭到了破坏。 由于将军之间需要通过信使通讯，叛变将军可能通过伪造信件来以其他将军的身份发送假投票。而即使在保证所有将军忠诚的情况下，也不能排除信使被敌人截杀，甚至被敌人间谍替换等情况。因此很难通过保证人员可靠性及通讯可靠性来解决问题。 假始那些忠诚（或是没有出错）的将军仍然能通过多数决定来决定他们的战略，便称达到了拜占庭容错。在此，票都会有一个默认值，若消息（票）没有被收到，则使用此默认值来投票。 上述的故事映射到计算机系统里，将军便成了计算机，而信差就是通信系统。虽然上述的问题涉及了电子化的决策支持与信息安全，却没办法单纯的用密码学与数字签名来解决。因为不正常的电压仍可能影响整个加密过程，这不是密码学与数字签名算法在解决的问题。因此计算机就有可能将错误的结果提交去，亦可能导致错误的决策。 H4 拜占庭容错论文证明Lamport在其论文中证明：假设将军总数为N，叛变的将军数为f，则在N &gt; 3f 时，上述的拜占庭将军问题可以解决，将军达成共识的时间复杂度为O(N^(f+1))，即指数级的复杂度。 接下来，让我们来推算下这个容错。 假设总共有3个将军A，B，C，其中1个将军叛变，按照上面的结论，因为不满足N &gt;= 3f + 1的条件，因此不可能达成一致： 假设A是叛变者同时也是提案者，他派出两名信使分别告诉B说进攻，告诉C说防守，结果最终C会得到两份矛盾的消息：A的信使告诉他说防守，但是B的信使又告诉他说进攻，无法形成共识； 假设叛变的将军是A，但提案者是B，B派出信使告诉A和C某日某时某刻发起进攻，但是A收到消息后可以篡改，他可以告诉C说收到的是防守的指令，同样无法达成共识； 如果加1名将军，总共A，B，C，D四名将军，同样只有1名将军叛变，此时满足N &gt;= 3f + 1的条件，我们再来验证看是否能达成一致： 假设A是提案者，同时也是叛徒，此时无论他怎么安排，剩余的3名将军中总会有至少2名的将军得到相同的指令，假设B和C得到的是A发出的进攻指令，而D得到的是A发出的防守的指令，根据少数服从多数的原则，最终B，C，D都会达成共识： D收到A的防守指令，但是收到B和C的进攻指令，少数服从多数，D认为要进攻； B收到A和C的进攻指令，收到D的防守指令，少数服从多数，B也选择进攻； C收到A和B的进攻指令，收到D的防守指令，同样C也决定进攻； 最终B，C，D都进攻，A的诡计无法得逞。 通过上面的简单验证，我们已经了解到N &gt;= 3f + 1确实能做到存在拜占庭节点的分布式系统的共识，换句话说PBFT算法最多可以容许不超过(N-1) / 3个问题节点。作者Lamport凭借他在分布式系统共识算法上的杰出成绩，获得了2013年的图灵奖。 H3 PAXOS 共识算法paxos算法是由Leslie Lamport于1990年提出的一种非拜占庭模型的分布式系统共识算法，对的就是提出拜占庭问题的大牛，自己提出的解答。 为了描述算法，Lamport虚拟了一个希腊城邦paxos（这也是算法名字的由来），这个岛按照议会民主制的政治模式制订法律，但是没有人愿意将自己的全部时间和精力放在这种事情上。所以无论是议员，议长或者传递纸条的服务员都不能承诺别人需要时一定会出现，也无法承诺批准决议或者传递消息的时间。但是这里假设没有拜占庭将军问题（Byzantine failure，即虽然有可能一个消息被传递了两次，但是绝对不会出现错误的消息）；只要等待足够的时间，消息就会被传到。另外，Paxos 岛上的议员是不会反对其他议员提出的决议。 paxos算法的推导过程理解起来有一定困难，但是从操作层面讲，paxos解决共识的思路其实并不难。 首先算法将网络中的节点划分为3种角色：提案者，接受者和学习者。 提案者：负责提出提案，这里提案可以是任何可以达成共识的东西，比如某个要写入DB的值，一条日志等等； 接受者：接收提案，确定接受还是拒绝提案； 学习者：获取并同步最终选择的提案； 提案是一个由提案编号和提案值组成的pair，即[proposalNo, proposalValue]，一个提案被半数以上的接受者接受即认为达成共识。提案编号是最终能达成共识的关键，每个接受者都会记录已响应过的提案的最大编号，并且承诺不会接受比此提案号小的提案。 具体操作时，paxos可以分为两个阶段： 第一阶段：准备阶段，提案者选择一个提案号，发送提案给接受者，试探能否得到半数以上接受者的响应；第二阶段：如果第一阶段收到超过半数的接受者的响应，则提交提案，如果能够得到半数以上接受者的响应，则共识完成； H4 paxos算法推导过程paxos算法最初的论文被公认为是晦涩难懂，后来作者Lamport又发布了《paxos made simple》，用更加容易理解的方式对paxos做了阐述。 论文中通过从简单到复杂逐步添加约束条件的方式来论证其共识算法。虽然作者已经做了简化，但毕竟还是比较学术化，理解论文中提出的几个约束条件还是有一定的困难，详细的过程读者可以自行阅读论文。 paxos算法的论证过程虽然比较难理解，但是实际的操作过程却比较简单，网上有人用一个形象的例子来说明paxos达成共识的过程： 假设有2个商人P1和P2想从政府买块地，商人想要最终拿下这块地，需要经过3个政府官员A1，A2和A3的审批，只有经过2个以上的官员同意，才能最终拿下地皮，现在的目标是：最终只能有一个商人拿到地。另外假设商人要想通过官员的审批，必须给一定数量的贿赂费。 我们看看这样一个场景下，如何达成共识（选定一个商人把地批给他）。 拿地是一件争分夺秒的事情，于是商人P1和P2开始准备了： 假设P1的行动快一些，他很快找到了官员A1和A2，告诉两人只要批了地就给100W的感谢费，两个官员很高兴，告诉P1回去拿钱吧；注：这一步实际上是P1在进行paxos算法中的准备阶段； 商人P2在P1之前先找了官员A3，告诉他只要批了地就给他200W，A3愉快的接受了； P2又跑到官员A1和A2那，承诺只要批地，就给200W，因为这份费用比此前P1承诺的高，于是贪财的官员A1和A2变卦了；注：以上两步是P2在进行paxos的准备阶段； 商人P1此前已经初步贿赂A1和A2成功，于是满心欢喜的拿着准备好的钱找到了A1和A2，结果却是A1和A2都告诉他：对不起，MrXX，就在刚刚有人承诺了200W，你是个聪明人，你懂得该怎么做的。商人P1很是郁闷，告诉A1和A2：容我想想再给答复；注：以上P1拿钱给A1和A2，对应与paxos算法的提交阶段，因为此前P1已经得到了3位官员中2位的同意； 就在P1还在犹豫要不要提高贿赂费的时候，商人P2按之前承诺的向A1和A2的账户分别打入200W，于是A1，A2拿钱办事，批准通过，因为超过半数的官员审批通过，于是在政府网站上向大众公布P2最终拿地成功，所有人都知道了这个结果。 注意上面的过程中的一个问题：假设上面第（4）步中P1被拒绝以后，立刻向官员承诺一个更高的费用，那么当商人P2拿着钱到A1和A2时，同样也会被拒绝，于是P2又可能会抬价，这样交替下去就可能造成死循环，这就是paxos算法中的活锁问题。 paxos 算法交互图 H4 paxos 算法优化paxos算法有很多变种和优化算法，这里只说一下multi paxos算法。 之前提到paxos算法存在活锁的问题：一个提案者提案被拒以后用更高的提案，另一个提案者发现被提案被拒以后也增加提案编号，从而形成死循环，造成活锁 multi paxos算法对paxos进行了优化，引入leader这个角色以避免活锁问题。首先选举出一个节点作为leader，之后所有的提案先提交给leder节点，因为通过leader可以控制提案提交进度，从而避免活锁发生。 考虑前面商人买地的那个例子：此时官员们不直接和商人碰面，而是由官员指定一个总代理，啥事情都先跟代理说，再由代理统一汇报。于是P1跑到代理那承诺说：只要能批，咱就给领导100W酬劳，但是代理可以选择不立刻就去把这事给官员汇报，他可以等一等，结果不久后P2来承诺说事成之后200W，代理就可以选择报价高的拿给官员审批。 可以参考paxos和multi paxos算法的流程图仔细体会一下： paxos 算法交互图 multi paxos 算法交互图 从图中可以看到最大的区别在于，multi paxos算法没有了第一阶段（prepare阶段），而是直接由leader发送提案（直接进行第二阶段），如果收到半数以上的acceptor的应答就达成共识。 引入leader节点虽然可以解决活锁问题，但是又引出其他一些问题：比如leader应该如何选举产生等等。 H4 paxos 算法总结paxos是CFT类共识算法，不考虑拜占庭错误即节点可能作恶的情况； paxos算法将节点分成三个角色：提案者（proposer），接受者（acceptor）和学习者（learner） paxos算法分成两个阶段来完成共识： 准备阶段：提案者发出提案，试探是否能得到半数以上acceptor的同意； 提交阶段：如果提案在准备阶段得到半数以上的支持，则尝试提交此提案，如果响应的acceptor超过半数以上，则此提案被选定，完成共识；否则提案者需要新选定一个提案编号重新进入准备阶段； 在这里，我们有必要解释一下 CFT类，其实分布式系统的共识算法主要分为： CFT算法（Crash falut）和BFT（Byzantine fault）算法。CFT算法主要解决网络中节点可能出错（比如宕机），但是节点不会作恶（比如伪造数据）的情况下节点之间如何达成共识，而BFT算法则针对网络中可能存在节点作恶的情况下节点间达成共识的方法。 H3 RAFT 共识算法结合咱们刚才学习的 paxos 共识算法，在后面我们提到的 multi paxos算法的leader选举问题，raft给出了答案。它是一种paxos改进算法。它有许多的开源参考实现，具有 GO,C++,Java和Sacle的完整规范实现。更多的实现可以查看The Raft Consensus Algorithm,具体的实现可以查阅 In Search of an Understandable Consensus Algorithm raft是 paxos 的改进方法，所以他是 CFT类，在他的算法中，他的容错率为 n &gt; 2f即可，也就是说，有超过一半的节点进行了统一，那么就说明完成了共识操作了。因为不存在做恶的节点。 在这里，我们就不想进行这个验证了。大家可以思考一下。 H4 角色划分raft 把节点分为三种角色， leader: 负责Client交互和log复制，同一时刻系统中最多存在1个 follower: 被动响应leader请求RPC，从不主动发起请求RPC candidate: 由Follower向Leader转换的中间状态 server states - 节点的状态 H4 Terms众所周知，在分布式环境中，“时间同步”本身是一个很大的难题，但是为了识别“过期信息”，时间信息又是必不可少的。Raft为了解决这个问题，将时间切分为一个个的Term，可以认为是一种“逻辑时间”。如下图所示： term 示意图 每个Term至多存在1个Leader 某些Term由于选举失败，不存在Leader 每个Server本地维护currentTerm H4 选举过程在开始启动之初，所有的节点都以 follower 角色启动，如果某个 follower 不想听从 领导者意见了，想起义。那么就把自己的状态修改为 candidate 状态，并且向其他的节点发起投票请求，我想当leader，其他的节点回复他的请求。如果大多数的节点都进行了投票，该 node 就会再次修改状态 从 candidate -&gt; leader. 以上的过程就被称为 选举过程。 接下来，我们来看一下实际中 raft 操作。 我们假设存在三个节点，Nodea，Nodeb，Nodec，raft 会给每一个节点都设置两个 timeout settings，也就是时间超时设置. 第一个时间的超时是 election timeout,也就是选举超时，如果达到这个时间，节点就会由follower转换为 candidate，也就是咱们之前说的起义。其中 在 raft中，这个选举超时的值设置为150ms和300ms之间的随机值。在达到时间超时之后，节点会转换身份为 candidate，并且将自己的 term 增加1，我们可以理解为 要换代了，进行国号的修改。另外，默认的 转换身份的节点会给自己投上一票～然后向其他的follwer节点发送所有选票的请求(大家支持支持我吧～)。此时我们假设NodeA时间超时了，成为了candidate，并且更改了 term为1，并且NodeA 给自己投上一票接下来，收到消息的 follower，也就是NodeB和NodeC，要确认国号，也就是 term 为 1 的这个朝代内，他没有投票过！之后他会针对为这个 candidate 即 Nodea 进行投票～并且在此之后，follower 节点即 Nodeb，Nodec重置自己的 election timeout.一旦 candidate即Nodea 获得了大多数的支持票之后，它就成为了 leader 起义完成。 随后的时间里，leader会对他的follower 通过心跳超时heartbeat timeout的方式发送互动消息。这里我们就接触到了第二个 时间超时。follower 会在接收到消息之后，重置他的选举超时时间，并进行回复。 这种情况会一直存在，直到 leader Nodea 死去（死机，宕机），接下来，选举超时的节点，有可能是 Nodeb，有可能是 Nodec，会重复以上选举超时，进行选举的操作。 要求，在一个term下只能存在一个 leader。 （一个国号下只能存在一个领导人） 那么如果出现了！两个follower 在同一个时刻成为了 candidate 那怎么办？ 这种情况我们称为 分裂投票，好的，我们接下来进行一次分裂投票吧。 在这个时候我们在加入的一个 Noded。假设此时。 Nodea 和 Noded，timeout settings 在同一个时刻进行了起义，他们都会成为 candidate，他们定国号都为 term 2. 他们向 node bc 发送所有选票请求。因为 时间先后的顺序，bc只能为同一个 term2 朝代内的一个节点投票，所有最后 a d 他们选票都是 2.所以进入第二次超时投票，因为超时时间是随机的额，所以肯定会最终出现一个领导。当然 term2 这个朝代内就不存在领导了～ H4 日志复制此时基本的流程就是， 客户端发送一个提案（值）给 leader ，leader 将提案追加到log中，将日志中的值广播给他的 follower，大于一半的 follower 给予肯定反馈，那么 leader 确认提案。接下来， leader 告诉会再次发送请求告诉所有的 follower ，刚才的提案已经提交了。所有的follower，此时该集群内就现在的系统状态达成了共识。这个过程叫做 日志复制 我们来看一下 raft内的日志复制的做法吧 还是 Node abc。三个节点，其中 Nodea为leader。 我们的客户端向 Nodea发送更改，例如为5。发送给leader nodea，nodea不会立马发布，他会把这个值放置在日志中。然后再下一次心跳超时消息时，把值带给他的follower。如果大多数的粉丝同意这个值，nodea就会把这个值，设置为提交，并修改 nodea节点值。并把这个响应结果返回给客户端。其中设置为提交的这个消息会在下一次的心跳超时消息时传递给 其他的 follower。 H4 raft 网络分区raft 可以在网络分区同样适用。假设我们此时有 5个节点 node abcde，其中 ab为一个分区(a为leader)，cde为一个分区(c为leader)。 我们添加使用两个客户端尝试更新这两个leader。 假如此时，我们向A发送一个 消息，A会向他的 follower B 发送消息，但是因为他的个数达不到满足，所以他的消息状态始终为 为提交。此时，我们向C发送一个消息，它最终会因为拥有两个 follower而达到消息最终确定。 此时我们来 治愈分区. NodeA 会看到的更高的 term，而停止。节点A和B都将回滚他们未提交条目并且匹配到最新的leader的条目。 这个时候整个 网络达成一致～ H4 raft 总结raft 算法的容错率为 2f &lt; n, 原因是 它并没有把做恶的节点这种情况算入，也就是他只针对 节点死机宕机的情况进行了处理。 其他的特性，我们在讲完 PBFT 之后，会与 PBFT 一起进行对比查看。 ！！！！！都是虚的！！！！！ raft 动画演示 H3 PBFT 算法PBFT是Practical Byzantine Fault Tolerance的缩写，意为实用拜占庭容错算法。该算法是Miguel Castro (卡斯特罗)和Barbara Liskov（利斯科夫）在1999年提出来的，解决了原始拜占庭容错算法效率不高的问题，将算法复杂度由指数级降低到多项式级，使得拜占庭容错算法在实际系统应用中变得可行。该论文发表在1999年的操作系统设计与实现国际会议上（OSDI99）。没错，这个Loskov就是提出著名的里氏替换原则（LSP）的人，2008年图灵奖得主。 PBFT算法目前在许多区块链项目中都有运用，例如国内的迅雷，腾讯等公司的区块链使用的就是PBFT算法（应该是对算法进行了优化），超级账本的Farbic v0.6版本也使用了PBFT作为其共识算法。 简单来说一下 PBEF，在网上看到一个故事可以概述这个算法。 PBFT算法要求至少要4个参与者，一个被选举为军长，3个师长。军长接到总司令命令：你们向前行军500公里。军长就会给3个师长发命令向前行军500公里。3个师长收到消息后会执行命令，并汇报结果。A师长说我在首都以东500公里，B师长说我在首都以东500公里，C师长说我在首都以东250公里。军长总结3个师长的汇报，发现首都以东500公里占多数（2票&gt;1票），所以就会忽略C师长的汇报结果，给总司令汇报说，好了，现在部队是在首都以东500公里了。这就是PBFT算法。 在可以理解为：对于每一个收到命令的将军，都要去询问其他人，他们收到的命令是什么。也就是说利用不断的信息交换让可行的节点确认哪一个记录选择是正确的，即发现其中的背叛者 采用PBFT方法，本质上就是利用通信次数换取信用。每个命令的执行都需要节点间两两交互去核验消息，通信代价是非常高的。通常采用PBFT算法，节点间的通信复杂度是节点数的平方级的 但是即使如此，也已经把之前的指数级 变成了现在的 多项式级 H4 PBFT 算法 3f+1 &lt;= n 的推论我们会在 下面和 raft 对比的时候进行详细说明。这里我们就知道这个就是如此就好了。 H4 PBFT 算法基本流程pbft算法的基本流程主要有以下四步： 客户端发送请求给主节点 主节点广播请求给其它节点，节点执行pbft算法的三阶段共识流程。 节点处理完三阶段流程后，返回消息给客户端。 客户端收到来自f+1个节点的相同消息后，代表共识已经正确完成。 为什么收到f+1个节点的相同消息后就代表共识已经正确完成？从上一小节的推导里可知，无论是最好的情况还是最坏的情况，如果客户端收到f+1个节点的相同消息，那么就代表有足够多的正确节点已全部达成共识并处理完毕了。 H4 算法核心三阶段流程 PBFT流程 算法的核心三个阶段分别是pre-prepare阶段（预准备阶段），prepare阶段（准备阶段），commit阶段（提交阶段）。图中的C代表客户端，0，1，2，3代表节点的编号，打叉的3代表可能是故障节点或者是问题节点，这里表现的行为就是对其它节点的请求无响应。0是主节点。整个过程大致是： 首先，客户端向主节点发起请求，主节点0收到客户端请求，会向其它节点发送pre-prepare消息，其它节点就收到了pre-prepare消息，就开始了这个核心三阶段共识过程了。 Pre-prepare阶段：节点收到pre-prepare消息后，会有两种选择，一种是接受，一种是不接受。什么时候才不接受主节点发来的pre-prepare消息呢？一种典型的情况就是如果一个节点接到了一条pre-pre消息，消息里的v和n在之前收到里的消息是曾经出现过的，但是d和m却和之前的消息不一致，或者请求编号不在高低水位之间（高低水位的概念在2.4节会进行解释），这时候就会拒绝请求。拒绝的逻辑就是主节点不会发送两条具有相同的v和n，但d和m却不同的消息。 Prepare阶段：节点同意请求后会向其它节点发送prepare消息。这里要注意一点，同一时刻不是只有一个节点在进行这个过程，可能有n个节点也在进行这个过程。因此节点是有可能收到其它节点发送的prepare消息的。在一定时间范围内，如果收到超过2f个不同节点的prepare消息，就代表prepare阶段已经完成。 Commit阶段：于是进入commit阶段。向其它节点广播commit消息，同理，这个过程可能是有n个节点也在进行的。因此可能会收到其它节点发过来的commit消息，当收到2f+1个commit消息后（包括自己），代表大多数节点已经进入commit阶段，这一阶段已经达成共识，于是节点就会执行请求，写入数据。 处理完毕后，节点会返回消息给客户端，这就是pbft算法的全部流程。 为了更清晰的展现这个过程和一些细节，下面以流程图来表示这个过程。 PBFT交互图 注解： V：当前视图的编号。视图的编号是什么意思呢？比如当前主节点为A，视图编号为1，如果主节点换成B，那么视图编号就为2.这个概念和raft的term任期是很类似的。N：当前请求的编号。主节点收到客户端的每个请求都以一个编号来标记。M：消息的内容d或D(m)：消息内容的摘要i： 节点的编号 H4 checkpoint、stable checkpoint和高低水位什么是checkpoint呢？checkpoint就是当前节点处理的最新请求序号。前文已经提到主节点收到请求是会给请求记录编号的。比如一个节点正在共识的一个请求编号是101，那么对于这个节点，它的checkpoint就是101. 那什么是stable checkpoint（稳定检查点）呢？stable checkpoint就是大部分节点（2f+1）已经共识完成的最大请求序号。比如系统有4个节点，三个节点都已经共识完了的请求编号是213.那么这个213就是stable checkpoint了。 那设置这个stable checkpoint有什么作用呢？最大的目的就是减少内存的占用。因为每个节点应该记录下之前曾经共识过什么请求，但如果一直记录下去，数据会越来越大，所以应该有一个机制来实现对数据的删除。那怎么删呢？很简单，比如现在的稳定检查点是213，那么代表213号之前的记录已经共识过的了，所以之前的记录就可以删掉了。 高低水位示意图 图中A节点的当前请求编号是1039，即checkpoint为1039，B节点的checkpoint为1133.当前系统stable checkpoint为1034.那么1034这个编号就是低水位，而高水位H=低水位h+L，其中L是可以设定的数值。因此图中系统的高水位为1034+100=1134。 举个例子：如果B当前的checkpoint已经为1034，而A的checkpoint还是1039，假如有新请求给B处理时，B会选择等待，等到A节点也处理到和B差不多的请求编号时，比如A也处理到1112了，这时会有一个机制更新所有节点的stabel checkpoint ，比如可以把stabel checkpoint设置成1100，于是B又可以处理新的请求了，如果L保持100不变，这时的高水位就会变成1100+100=1200了。 H4 ViewChange（视图更改）事件当主节点挂了（超时无响应）或者从节点集体认为主节点是问题节点时，就会触发ViewChange事件，ViewChange完成后，视图编号将会加1。 下图展示ViewChange的三个阶段流程。 View Change 流程 如图所示，viewchange会有三个阶段，分别是view-change，view-change-ack和new-view阶段。从节点认为主节点有问题时，会向其它节点发送view-change消息，当前存活的节点编号最小的节点将成为新的主节点。当新的主节点收到2f个其它节点的view-change消息，则证明有足够多人的节点认为主节点有问题，于是就会向其它节点广播 New-view消息。注意：从节点不会发起new-view事件。对于主节点，发送new-view消息后会继续执行上个视图未处理完的请求，从pre-prepare阶段开始。其它节点验证new-view消息通过后，就会处理主节点发来的pre-prepare消息，这时执行的过程就是前面描述的pbft过程。到这时，正式进入 v+1（视图编号加1）的时代了。 为了更清晰的展现ViewChange这个过程和一些细节，下面以流程图来表示这个过程。 View Change 交互图 上图里红色字体部分的O集合会包含哪些pre-prepare消息呢？假设O集合里消息的编号范围：（min～max），则Min为V集合最小的stable checkpoint，Max为V集合中最大序号的prepare消息。最后一步执行O集合里的pre-preapare消息，每条消息会有两种情况: 如果max-min&gt;0,则产生消息 ；如果max-min=0，则产生消息。 H4 从Fabric源码看出些东西在 fabric v0.6 将项目荡到本地之后，我们发现在consensus内的 pbft 就是整个 fabric 共识代码。 type pbftCore struct { // internal data internalLock sync.Mutex executing bool // signals that application is executing idleChan chan struct{} // Used to detect idleness for testing injectChan chan func() // Used as a hack to inject work onto the PBFT thread, to be removed eventually consumer innerStack // PBFT data activeView bool // view change happening byzantine bool // whether this node is intentionally acting as Byzantine; useful for debugging on the testnet f int // max. number of faults we can tolerate N int // max.number of validators in the network h uint64 // low watermark id uint64 // replica ID; PBFT `i` K uint64 // checkpoint period logMultiplier uint64 // use this value to calculate log size : k*logMultiplier L uint64 // log size lastExec uint64 // last request we executed replicaCount int // number of replicas; PBFT `|R|` seqNo uint64 // PBFT \"n\", strictly monotonic increasing sequence number view uint64 // current view chkpts map[uint64]string // state checkpoints; map lastExec to global hash pset map[uint64]*ViewChange_PQ //已经完成prepare阶段的请求 qset map[qidx]*ViewChange_PQ //已经完成pre-prepare阶段的请求 skipInProgress bool // Set when we have detected a fall behind scenario until we pick a new starting point stateTransferring bool // Set when state transfer is executing highStateTarget *stateUpdateTarget // Set to the highest weak checkpoint cert we have observed hChkpts map[uint64]uint64 // highest checkpoint sequence number observed for each replica currentExec *uint64 // currently executing request timerActive bool // is the timer running? vcResendTimer events.Timer // timer triggering resend of a view change newViewTimer events.Timer // timeout triggering a view change requestTimeout time.Duration // progress timeout for requests vcResendTimeout time.Duration // timeout before resending view change newViewTimeout time.Duration // progress timeout for new views newViewTimerReason string // what triggered the timer lastNewViewTimeout time.Duration // last timeout we used during this view change broadcastTimeout time.Duration // progress timeout for broadcast outstandingReqBatches map[string]*RequestBatch // track whether we are waiting for request batches to execute nullRequestTimer events.Timer // timeout triggering a null request nullRequestTimeout time.Duration // duration for this timeout viewChangePeriod uint64 // period between automatic view changes viewChangeSeqNo uint64 // next seqNo to perform view change missingReqBatches map[string]bool // for all the assigned, non-checkpointed request batches we might be missing during view-change // implementation of PBFT `in` reqBatchStore map[string]*RequestBatch // track request batches certStore map[msgID]*msgCert // track quorum certificates for requests checkpointStore map[Checkpoint]bool // track checkpoints as set viewChangeStore map[vcidx]*ViewChange // track view-change messages newViewStore map[uint64]*NewView // track last new-view we received or sent } 我们可以发现， bfpt中的view 就是一个 正整数。 其中我可以看到他的主节点,判断如下。 // Given a certain view n, what is the expected primary? func (instance *pbftCore) primary(n uint64) uint64 { return n % uint64(instance.replicaCount) } 主节点由公式p = v mod |R|计算得到，这里v是视图编号，p是副本编号，|R|是副本集合的个数。当主节点失效的时候就需要启动视图更换（view change）过程 H4 PBFT 算法总结PBFT 就属于 BFT 类的共识算法了，他可以解决分布式系统中存在做宕机的节点，也可以处理存在做坏事儿节点的问题。 pbft算法可以容忍不超过(N - 1) / 3个问题节点，共识算法的时间复杂度为O(n^2)； pbft算法完成共识需要经过三个阶段：pre-prepare、prepare和commit阶段； pbft算法需要一个主节点，每个主节点的任期就是一个view。当从节点发现主节点有问题（比如请求在规定时间内没有相应）时通过view change来请求更换主节点。 PBFT算法非常重要，很多大厂的区块链项目中都有运用，例如国内的迅雷、腾讯等公司的区块链项目，超级账本的fabric等，都使用了pbft或者优化后的pbft作为共识算法，理解pbft算法是区块链学习过程中非常重要的一环。 H3 PBFT 与 RAFT 对比 我就一展示数据的表格 对比点 RAFT PBFT 适用环境 私链 联盟链 算法通信复杂度 O(n) O(n^2) 最大故障合同错节点 2f+1&lt;=N 3f+1&lt;=N 流程对比 1. 初始化leader（谁快谁当）2. 共识过程3. 重选leader机制 1. 初始化leader选举(按编号依次轮流做主节点)2. 共识过程3. 重选leader机制 公链：公链不仅需要考虑网络中存在故障节点，还需要考虑作恶节点，这一点和联盟链是类似的。和联盟链最大的区别就是，公链中的节点可以很自由的加入或者退出，不需要严格的验证和审核。 H4 最大容错率首先我们先来思考一个问题，为什么pbft算法的最大容错节点数量是（n-1）/3，而raft算法的最大容错节点数量是（n-1）/2？ 对于raft算法，raft算法的的容错只支持容错故障节点，不支持容错作恶节点。什么是故障节点呢？就是节点因为系统繁忙、宕机或者网络问题等其它异常情况导致的无响应，出现这种情况的节点就是故障节点。那什么是作恶节点呢？作恶节点除了可以故意对集群的其它节点的请求无响应之外，还可以故意发送错误的数据，或者给不同的其它节点发送不同的数据，使整个集群的节点最终无法达成共识，这种节点就是作恶节点。 raft算法只支持容错故障节点，假设集群总节点数为n，故障节点为f，根据小数服从多数的原则，集群里正常节点只需要比f个节点再多一个节点，即f+1个节点，正确节点的数量就会比故障节点数量多，那么集群就能达成共识。因此raft算法支持的最大容错节点数量是（n-1）/2。 对于pbft算法，因为pbft算法的除了需要支持容错故障节点之外，还需要支持容错作恶节点。假设集群节点数为N，有问题的节点为f。有问题的节点中，可以既是故障节点，也可以是作恶节点，或者只是故障节点或者只是作恶节点。那么会产生以下两种极端情况： 第一种情况，f个有问题节点既是故障节点，又是作恶节点，那么根据小数服从多数的原则，集群里正常节点只需要比f个节点再多一个节点，即f+1个节点，确节点的数量就会比故障节点数量多，那么集群就能达成共识。也就是说这种情况支持的最大容错节点数量是（n-1）/2。 第二种情况，故障节点和作恶节点都是不同的节点。那么就会有f个问题节点和f个故障节点，当发现节点是问题节点后，会被集群排除在外，剩下f个故障节点，那么根据小数服从多数的原则，集群里正常节点只需要比f个节点再多一个节点，即f+1个节点，确节点的数量就会比故障节点数量多，那么集群就能达成共识。所以，所有类型的节点数量加起来就是f+1个正确节点，f个故障节点和f个问题节点，即3f+1=n。 结合上述两种情况，因此pbft算法支持的最大容错节点数量是（n-1）/3。下图展示了论文里证明pbft算法为什么3f+1&lt;=n的一段原文，以及根据原文提到的两种情况对应的示意图。 paxos主要用于解决非拜占庭模型的共识问题，一般适用于私链，因为私链仅在组织内部使用，因此可以不考虑集群中存在拜占庭节点问题，而公链或者联盟链则必须要考虑存在恶意节点的情况，因此不适合用paxos或者raft这类非拜占庭模型的共识算法。 H4 时间复杂度为什么raft是o（n），而pbft是o（n^2）呢？这里主要考虑算法的共识过程。 对于raft算法，核心共识过程是日志复制这个过程，这个过程分两个阶段，一个是日志记录，一个是提交数据。两个过程都只需要领导者发送消息给跟随者节点，跟随者节点返回消息给领导者节点即可完成，跟随者节点之间是无需沟通的。所以如果集群总节点数为 n，对于日志记录阶段，通信次数为n-1，对于提交数据阶段，通信次数也为n-1，总通信次数为2n-2，因此raft算法复杂度为O（n）。 对于pbft算法，核心过程有三个阶段，分别是pre-prepare（预准备）阶段，prepare（准备）阶段和commit（提交）阶段。对于pre-prepare阶段，主节点广播pre-prepare消息给其它节点即可，因此通信次数为n-1；对于prepare阶段，每个节点如果同意请求后，都需要向其它节点再 广播parepare消息，所以总的通信次数为n（n-1），即n^2-n；对于commit阶段，每个节点如果达到prepared状态后，都需要向其它节点广播commit消息，所以总的通信次数也为n（n-1），即n^2-n。所以总通信次数为（n-1）+（n^2-n）+（n^2-n），即2n^2-n-1，因此pbft算法复杂度为O（n^2）。 H4 流程对比上对于leader选举这块，raft算法本质是谁快谁当选，而pbft算法是按编号依次轮流做主节点。对于共识过程和重选leader机制这块，为了更形象的描述这两个算法，接下来会把raft和pbft的共识过程比喻成一个团队是如何执行命令的过程，从这个角度去理解raft算法和pbft的区别。 一个团队一定会有一个老大和普通成员。对于raft算法，共识过程就是：只要老大还没挂，老大说什么，我们（团队普通成员）就做什么，坚决执行。那什么时候重新老大呢？只有当老大挂了才重选老大，不然生是老大的人，死是老大的鬼。 对于pbft算法，共识过程就是：老大向我发送命令时，当我认为老大的命令是有问题时，我会拒绝执行。就算我认为老大的命令是对的，我还会问下团队的其它成员老大的命令是否是对的，只有大多数人（2f+1）都认为老大的命令是对的时候，我才会去执行命令。那什么时候重选老大呢？老大挂了当然要重选，如果大多数人都认为老大不称职或者有问题时，我们也会重新选择老大。 H4 结语raft算法和pbft算法是私链和联盟链中经典的共识算法，本文主要介绍了raft和pbft算法的流程和区别。raft和pbft算法有两点根本区别： raft算法从节点不会拒绝主节点的请求，而pbft算法从节点在某些情况下会拒绝主节点的请求 ; raft算法只能容错故障节点，并且最大容错节点数为（n-1）/2，而pbft算法能容错故障节点和作恶节点，最大容错节点数为（n-1）/3。 H3 Pow 工作证明Proof of Work，工作证明相关理念最早于1993年被Cynthia Dwork和Moni Naor提出，之后的几年，该概念在是否能有效对抗拒绝服务攻击的争论中不断被人们所知。PoW机制的核心在于强迫攻击者作出一定量的工作才能进行接下来的交互操作，这样无形中就给攻击者提高了攻击的成本。自然而然的，攻击者需要完成的工作可以按消耗的计算机资源种类分为以下三大类： 消耗CPU资源。例如，反垃圾邮件的Hashcash方案以及受此启发而诞生的比特币；消耗内存资源。例如，为了防止与比特币采用相同的共识机制所可能导致的51%攻击，以太坊目前就使用了一种需要占用大量内存资源的PoW算法；消耗网络资源。攻击者在进行拒绝服务攻击之前，必须要获取多个远程服务器发送的命令。POW作为数字货币的共识机制于 1998 年在 B-money 设计中提出。2008年中本聪发表比特币白皮书，比特币采用POW共识，通过计算来猜测一个数值（nonce），得以解决规定的 Hash 问题（两次SHA256）。保证在一段时间内，系统中只能出现少数合法提案。 同时，这些少量的合法提案会在网络中进行广播，收到的用户进行验证后会基于它认为的最长链上继续难题的计算。因此，系统中可能出现链的分叉（Fork），但最终会有一条链成为最长的链。 Hash 问题具有不可逆的特点，因此，目前除了暴力计算外，还没有有效的算法进行解决。反之，如果获得符合要求的 nonce，则说明在概率上是付出了对应的算力。谁的算力多，谁最先解决问题的概率就越大。 当掌握超过全网一半算力时，从概率上就能控制网络中链的走向。这也是所谓 51% 攻击的由来 H4 比特币POW算法的ASIC化问题由于比特币采用的是比较简单的SHA256哈希算法作为POW共识算法，这个算法只消耗CPU资源，对内存要求不高，所以可以很容易被制造出ASIC芯片。这是比特币挖矿芯片的更新换代图 比特币矿机芯片阶段 而现在，比特币的挖矿都变成了这样子：大量ASIC矿机组成的矿场。 大量ASIC矿机组成的矿场 这样算力就越来越集中到了大矿主手里，普通用户使用电脑根本不可能挖到矿，这与中本聪当年设想的人人都能公平记账的愿景相违背。为此，人们设计了各种反ASIC化的方案。主要思想就是将POW算法改的很复杂，需要大量的内存，这样ASIC芯片是不可能集成大量内存进去的，从而无法制造出专门的挖矿芯片。比较有代码的改进方案有： 莱特币：刚性内存哈希函数Scrypt取代SHA256 达世币：X11，11种哈希函数混合使用 以太坊：Ethash，大内存DAG搜索 但是实际上，只要利益足够大，人们总能够设计出专门POW挖矿的矿机，莱特币矿机和达世币矿机先后被制造了出来，以太坊之前也顶多是使用显卡挖矿，最近比特大陆也研发出了专门进行以太坊挖矿的专业矿机“蚂蚁矿机E3。具体可以参考这个新闻：http://t.cj.sina.com.cn/articles/view/1181714847/466f899f001007d4h 比特币的POW算法是没有任何实际意义的SHA256运算，那么有没有可能在挖矿的同时，把这些算力算出一些副产物？以下是几个比较有名的进行有效工作量证明的区块链： 质数币：Primecoin（质数币）发布于2013年7月。其最大的特点是将虚拟货币中浪费的算法资源利用起来。它的PoW可以搜索质数，从而计算孪生素数表。所以有一定的科学价值。 治疗币：Curecoin（治疗币）发布于2013年5月。治疗币最大的特点是将蛋白质褶皱结构的研究SHA256工作量证明算法进行了结合。因为蛋白质褶皱研究需要对蛋白质进行生化反应的模拟过程需要大量的计算资源，所以在“挖矿”的同时，还用于发现治愈疾病的新药，一举两得。 比原链：比原链重新设计一种不同于比特币的哈希运算PoW共识机制，引入了矩阵运算与卷积运算，这样就能让人工智能运算充分利用比原链的挖矿设备。在这个过程中，人工智能加入了新的硬件，其算法运行速度得到明显提高。同时，这样也能减少一定的资源浪费。在这种情况下，矿机市场巨大的经济利益能够极大地加速人工智能ASIC芯片的发展，加快人工智能的研究。反过来，人工智能的快速发展也产生了更多的ASIC矿机需求。因此，这是一种正向反馈良性发展的过程。 H3 Pos 权益证明PoS也称股权证明机制，其诞生的初衷是为了解决PoW带来的能耗问题。这种模式下持有币的数量越多、时间越长，记账成功率就越高（持有越多，获得越多），类似于利息制度。举例来说，PoS算法中有一个名词叫币龄，每个币每天产生1币龄，如果你持有100个币，总共持有了30天，那么此时你的币龄就为3000。这个时候如果你发现了一个PoS区块，你的币龄就会被清空为0。你每被清空365币龄，你将会从区块中获得0.05个币的奖励(相当于年利率5%)，在这个案例中，奖励 = 3000 * 5% / 365 = 0.41个币，即持币有利息。 PoS作为PoW的一种升级共识机制，根据每个节点所持有代币的数量和时间，等比例的降低挖矿难度，在一定程度上缩短了共识达成的时间，但最重要的是不再需要消耗大量能源进行挖矿。它的缺点在于：性能提升有限，持币吃息的模式会导致代币的大量集中，流动性变得匮乏起来。典型项目如以太坊，目前正在从PoW切换至PoS机制。 第一个POS虚拟货币——点点币Peercoin（点点币，PPC）于2012年8月发布，最大创新是其采矿方式混合了POW工作量证明及POS权益证明方式，其中POW主要用于发行货币，未来预计随着挖矿难度上升，产量降低，系统安全主要由POS维护。目前区块链中存在两种类型的区块，POW区块和POS区块。PPC的作者为同样不愿意公开身份的密码货币极客Sunny King，同时也是Primecoin的发明者。 第一个纯POS虚拟货币——未来币2013年9月，一个名为BCNext的用户在Bitcointalk论坛发起一个帖子，宣布将发行一种全新的纯POS币种，后来取名为Nextcoin，简称NXT。Nxt是且是第一个100%的股权证明(PoS)机制的电子货币，Nxt不再通过消耗大量的资源“挖矿”产生新货币，而是通过现有账户的余额去“锻造”区块，并给与成功“锻造”区块的账户交易费用奖励。NXT的POS实现方式与PPC完全不同，合格区块判定方法为： hit &lt; baseTarget effectiveBalance elapseTime hit是根据最新区块和用户的私钥生成的值，用户在挖一个区块时只需要计算一次即可。而右边的值跟账户余额成正比，跟流逝的时间成正比。也就意味着，用户账户余额越多，挖到矿的几率越高，随着时间的流逝越久，越容易找到新的区块。NXT区块的生成完全摒弃了竞争的理念，有点“上帝早已安排好一切”的味道，下一个区块由谁来生成冥冥中早就注定了，全网节点能做的就是静静等待那一刻的到来。 POS POS的本质就是比谁的钱多，钱越多越容易挖到区块，这将会造成富者越富，资源越来越集中，从而变得更中心化。 H3 DPOS 代理权益证明DPoS是权益证明的一种改进版本，共识过程不再需要所有参与节点进行验证，而是委托部分代表来进行，很大程度上提高了共识效率。BitShares社区首先提出了DPoS机制，并引入了见证人的概念。见证人可以生成区块（记账并获得奖励），每一个持有比特股的人都可以投票选举见证人。得票数前100名的候选者可以当选为见证人，见证人的候选名单每个维护周期更新一次。见证人通过随机排列后，依次轮流生成区块（限时2s内出块），若见证人在2s内未能出块，则自动跳到下一个见证人。由于持股人可以随时通过投票更换见证人，因此见证人为了获得奖励和避免损失保证金，就必须提供稳定高效的出块能力。 可以看出，DPoS实际上是对共识进行了分级，先通过投票选举达成见证人共识（选出极少数可信的见证人），然后见证人之间再达成交易验证共识，这样大大提高了整个系统的共识效率。从某种角度来看，DPoS与议会制度或人民代表大会制度有相似之处。如果代表不能履行他们的职责，例如未能按时出块，就会被网络选出的新见证节点所取代。DPoS算法从性能和能耗的角度来说完全可以满足商用，但也不可避免地带来了过于中心化的问题。比如现在很火的EOS超级节点竞选就变成了鲸鱼们的合纵游戏，甚至被质疑是伪区块链项目。当然这种看法笔者并不赞同，毕竟上期也讲到3类区块链，采用DPoS算法的项目应当算作联盟链，只不过有些联盟比较开放有了大量散户，从运营模式上看更像公链。 H4 EOS另外目前最火的区块链项目之一EOS也是采用了DPOS共识。EOS通过投票的方式选举出21个超级节点作为记账节点，每个节点有3秒的时间片，轮流记账。如果轮到某节点记账而没有出块，则该节点可能被投票出局，由其他备选节点顶替。出块速度是0.5秒！ EOS.IO软件允许区块精准的以每0.5秒产生一个区块，只有一个生产者被授权在任何给定的时间点生产一个区块。如果区块在预定的时间没有被生产出来，那么，那个时间的区块将被跳过。当一个或多个区块被跳过，将会有0.5秒或更多秒的区块间隔。使用EOS.IO软件，区块以126个区块为一轮（每个生产者可以生产6个，有21个生产者，二者相乘）。在每一轮的开始，21个区块生产者通过token持有者的投票被选中。选中的生产者依据商定好的顺序生产区块，这个顺序由15个或者更多的生产者商定。如果一个生产者错过了一个区块，并且在24小时内没有生产任何区块，他们将会被移除。直到这些“宕机”的生产者们及时通知区块链，他们将打算再次生产区块才被重新加入。通过不安排那些不够可靠的节点，尽可能的减少错过区块创建，来让整个网络运行得更平稳。 DPOS的特殊性，也是奠定拜占庭容错能力的基础框架，是它的算力节点是固定21个人，并且由大型的机构运营节点，其信息也相对透明，例如运营节点的地点、运营的情况等等。并且DPOS的算力节点是固定出块顺序的，固定地从A到B到C······。 传统DPOS中加入了拜占庭容错算法（BFT），只要没有生产者盖上相同的时间戳或相同区块高度的两个区块，便允许所有生产者签署所有区块。一旦15个生产者签署了一个区块，该区块就被认为是不可逆转的。在这种模式下，不可逆转的共识应该在1秒内完成。 在这种情况下，其实DPOS是拜占庭容错的特殊解，如何理解特殊解？原来的拜占庭容错（POW工作量证明），解决的是不限数量、随机广播同步的算力节点的容错能力，DPOS解决的拜占庭容错从两个维度降低了难度： 1、节点数量固定只有21个。并且节点信息透明。2、固定出块顺序。每个节点跟接力棒一样，一个个往下接力出块。每个节点不能还没轮到它出块的时候，就出块。都是必须轮到再出块。如果出现出块故障，会跳过这个节点。 在POW或者其他的POS共识里，节点不限、随机出块顺序的问题，就变成只要解决「固定数量和固定出块顺序情况下的拜占庭问题」，其难度就大大降低。 一直以来以太坊的创始人Vitalik和EOS创始人BM关于POW和DPOS谁更中心化进行互怼。Vitalik认为EOS的21个超级节点违反了区块链的去中心化原则，有失公平。而BM则认为几个几大矿池控制了比特币和以太坊的绝大部分算力，这相当于以太坊只有几个超级节点，比21个节点还要少，对手里拿着BTC和ETH的人他们对社区和整个生态，他们是没有确定的发言权的，在比特币的世界里算力就是王道，面对算力大量集中在部分矿场的现在，它真的实现了中本聪的本心了吗？同样需要挖矿POS也是一样，需要看概率来决定你能否发声，但是DPOS是有发言权的，不管持有多少，我都有发言权。这种看似由“直接民主”转为“间接民主”的机制，或许才是真正体现了去中心化精神。 H3 NEO的dBFTNEO采用的是 Delegated Byzantine Fault Tolerance (dBFT) 共识算法，由于它目前只有 7 个 代理节点，而代表节点则是通过用户投票选出。dBFT参与记账的是超级节点，普通节点可以看到共识过程，并同步账本信息，但不参与记账。总共n个超级节点分为一个议长和n-1个议员，议长会轮流当选。每次记账时，先有议长发起区块提案（拟记账的区块内容），一旦有至少（2n+1)/3个记账节点（议长加议员）同意了这个提案，那么这个提案就成为最终发布的区块，并且该区块是不可逆的，所有里面的交易都是百分之百确认的。 H3 以太坊的下一代POS共识：CasperCasper（投注共识）是一种以太坊下一代的共识机制，属于PoS。Casper的共识是按块达成的而不是像PoS那样按链达成的。 为了防止验证人在不同的世界中提供不同的投注，我们还有一个简单严格的条款：如果你有两次投注序号一样，或者说你提交了一个无法让Casper合约处理的投注，你将失去所有保证金。从这一点我们可以看出，Casper与传统的PoS不同的是Casper有惩罚机制，这样非法节点通过恶意攻击网络不仅得不到交易费，而且还面临着保证金被没收的风险。 Casper协议下的验证人需要完成出块和投注两个活动。具体如下： 出块是一个独立于其它所有事件而发生的过程：验证人收集交易，当轮到他们的出块时间时，他们就制造一个区块，签名，然后发送到网络上。投注的过程更为复杂一些。目前Casper默认的验证人策略被设计为模仿传统的拜占庭容错共识：观察其他的验证人如何投注，取33%处的值，向0或者1进一步移动。而客户端的确认当前状态的过程如下所示： 一开始先下载所有的区块和投注，然后用上面的算法来形成自己的意见，但是不公布意见。它只要简单的按顺序在每个高度进行观察，如果一个块的概率高于0.5就处理它，否则就跳过它。在处理所有的区块之后得到的状态就可以显示为区块链的“当前状态”。客户端还可以给出对于“最终确定”的主观看法：当高度k之前的每个块，意见要么高于99.999%或者低于0.001% H3 HyperLedger Fabric下一代共识：SBFTPBFT在Fabric0.6的时候被采用，但是由于一些说不清的原因，在Fabric1.0中并没有采用PBFT，而是使用Kafka进行排序，作为共识节点。在Fabric的提案中，打算会采用SBFT（Simple BFT），这种BFT算法会对PBFT进行简化，具体什么时候实现还没准呢。 H3 PalletOne的陪审团共识在英美，陪审团制度是一个使用了几百年的共识制度，关于一个案件中嫌疑人是否有罪，是由随机抽选的陪审员组成陪审团共同决定的。提到陪审团，就不得不提一部非常经典的电影《十二怒汉》： 十二怒汉》讲述的是一个在贫民窟长大的18岁少年因为涉嫌杀害自己的父亲被告上法庭，证人言之凿凿，各方面的证据都对他极为不利。十二个不同职业的人组成了这个案件的陪审团，他们要在休息室达成一致的意见，裁定少年是否有罪，如果罪名成立，少年将会被判处死刑。《十二怒汉》通过一场陪审团审判，生动演绎了美国的法律制度与文化，是美国宣传法律和法律制度的“银法槌奖”的首部获奖作品。同名电影在IMDB上排名第五，高于《阿甘正传》《辛德勒的名单》等，是一部超越时代的经典之作！其中的一段台词也很能体现陪审团制度的特点： “我们都肩负责任。我一直认为，这正是民主社会了不起的地方。我们接到邮件通知，大老远跑到这里，决定一个跟我们素昧平生的人到底有没有罪。不论作出什么样的裁决，我们都拿不到任何好处，也不会有任何损失。这正是我们国家强大的原因之一。我们不能把它当成个人的事” PalletOne提供了对各个底层链的抽象，用户使用常用的开发语言，基于对底层链的抽象接口进行操作。而合约的执行就是靠一个个的陪审团来完成的。 PalletOne 示意图 除了陪审团这个角色，在PalletOne中还有一个叫仲裁中介(Mediator)的角色，该角色是基于DPOS选举的，相当于现实生活中的法官的角色，在接到一个新的智能合约后，Mediator会随机选择陪审员组成陪审团，由该陪审团负责该智能合约的执行和共识。 仲裁中介(Mediator) 陪审团共识与传统POW、POS等共识的不同之处在于，陪审团共识是一个并行的共识机制，在同一个时刻，有多个陪审团同时在执行不同的合约。为了配合陪审团的并行共识，PalletOne采用了DAG作为分布式存储，合约的状态数据可以并行写入DAG中。所以PalletOne使用陪审团并行共识+DAG的并行写入，可以实现极高的TPS。 H2 总结共识算法的选择与应用场景高度相关，可信环境使用Paxos或者Raft，带许可的联盟可使用PBFT，非许可链可以是POW、POS、DPOS共识等。 现在区块链上数字资产的应用越来越多来源于真实世界或金融资产，对交易的最终确认有很高的要求，需要有不同的共识机制。共识机制是区块链的核心技术，现在各种区块链共识机制的选择是认为至今为止的相对的最优选择；当未来区块链技术越来越多应用于现实，未来将会不断有所改进，以切合实际的需要。 现在仍然有很多共识算法在不断的被研究出，被优化，这是一条不会终止的路。 分布网络-共识算法.md","categories":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/tags/区块链/"},{"name":"p2p","slug":"p2p","permalink":"http://blog.msiter.com/tags/p2p/"},{"name":"consensus","slug":"consensus","permalink":"http://blog.msiter.com/tags/consensus/"}],"keywords":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/categories/区块链/"}]},{"title":"区块链 P2P 认识","slug":"区块链 p2p认识","date":"2018-07-16T15:05:43.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"q,okl p2prs,z-20180716.html","link":"","permalink":"http://blog.msiter.com/q,okl p2prs,z-20180716.html","excerpt":"我们都知道，区块链的不同节点要互相交换数据，无论是交易的发布，以及挖矿成功的发布 我最开始学习这个时候就很疑惑，他是怎么知道我的呢？ 本次文章，我打算搞清楚四件事儿 我如何知道别人的 节点间的互相通讯 他是怎么知道我的 我们如何交换数据","text":"我们都知道，区块链的不同节点要互相交换数据，无论是交易的发布，以及挖矿成功的发布 我最开始学习这个时候就很疑惑，他是怎么知道我的呢？ 本次文章，我打算搞清楚四件事儿 我如何知道别人的 节点间的互相通讯 他是怎么知道我的 我们如何交换数据 H2 我如何知道别人的我们可以发现在，bitcoin的wiki上有以下方法 Nodes discover their own external address by various methods. 节点通过各种方法发现自己​​的外部地址。 Nodes receive the callback address of remote nodes that connect to them. 节点接收连接到它们的远程节点的回调地址。 Nodes makes DNS request to receive IP addresses. 节点使DNS请求接收IP地址。 Nodes can use addresses hard coded into the software. 节点可以使用硬编码到软件中的地址。 Nodes exchange addresses with other nodes. 节点与其他节点交换地址。 Nodes store addresses in a database and read that database on startup. 节点在数据库中存储地址并在启动时读取该数据库。 Nodes can be provided addresses as command line arguments 节点可以作为命令行参数提供地址 Nodes read addresses from a user provided text file on startup 节点在启动时从用户提供的文本文件中读取地址 我们分开来介绍一下。 H3 Nodes discover their own external address by various methods.大致的意思，就是让我们自己想办法，找到自己的外部ip地址。 客户端里有内置的方法，通过很多公共的服务，比如 checkip.dyndns.org，当然客户端有内置的一系列链接，来获取ip，如果失败，就一直请求下去。直到可以获取完成。 这个方法，目前已经被废除了 在#3088 提交中，建议不要使用该方法，具体原因可以自行查看。 目前的代码，我查找到一些位于net.cpp#L1499代码 ，好像是为了获取本机的外网的代码 char externalIPAddress[40]; r = UPNP_GetExternalIPAddress(urls.controlURL, data.first.servicetype, externalIPAddress); if(r != UPNPCOMMAND_SUCCESS) LogPrintf(\"UPnP: GetExternalIPAddress() returned %d\\n\", r); else { if(externalIPAddress[0]) { CNetAddr resolved; if(LookupHost(externalIPAddress, resolved, false)) { LogPrintf(\"UPnP: ExternalIPAddress = %s\\n\", resolved.ToString().c_str()); AddLocal(resolved, LOCAL_UPNP); } } else LogPrintf(\"UPnP: GetExternalIPAddress failed.\\n\"); } 使用了 miniupnpc 库，针对于 upnp的操作 UPNP_GetExternalIPAddress：根据指定设备获得外网ip地址 后面，我才知道这个东西…….庞大…. 后面会做介绍 H3 Nodes receive the callback address of remote nodes that connect to them.在版本 0.6.x开始，比特币客户端，默认不在使用IRC引导，并且从0.8.2版本开始，对IRC引导的支持完全删除。 这里，我们还是解释一下的他的工作原理。 在代码中,我们可以发现， 在我们的客户端初始化后，我们会默认的使用 CService addrConnect(\"92.243.23.21\", 6667); // irc.lfnet.org CService addrIRC(\"irc.lfnet.org\", 6667, true); if (addrIRC.IsValid()) addrConnect = addrIRC; SOCKET hSocket; if (!ConnectSocket(addrConnect, hSocket)) { printf(\"IRC connect failed\\n\"); nErrorWait = nErrorWait * 11 / 10; if (Wait(nErrorWait += 60)) continue; else return; } irc.lfnet.rog 的服务，随机的进入频道 #bitcoin00-#bitcoin99。 随后，发布 who 命令，之后线程会解析出现的打印，并且解析IP地址。这是一个循环，直到节点关闭 当我们发现了地址之后，会把当前的时间戳设置给这个地址，但是他会使用51分钟的惩罚,也就是把这个时间增加51分钟… 该代码位于 irc.cpp 348 行处 if (boost::algorithm::starts_with(strName, \"u\")) { CAddress addr; if (DecodeAddress(strName, addr)) { addr.nTime = GetAdjustedTime(); if (addrman.Add(addr, addrConnect, 51 * 60)) printf(\"IRC got new address: %s\\n\", addr.ToString().c_str()); nGotIRCAddresses++; } else { printf(\"IRC decode failed\\n\"); } } 为什么。。。我也不知道。。。。这看起来很奇怪，就像你发现这个地址是在51分钟之后…. H3 Nodes makes DNS request to receive IP addresses.在启动的时候，如果需要发现对等网络节点，客户端会发起DNS请求，来了解其他对等节点的地址。 客户端会请求DNS服务的主机名列表。 截止到 2018-7-12. l列表来自 chainparams.cpp，包括： seed.bitcoin.sipa.be dnsseed.bluematt.me dnsseed.bitcoin.dashjr.org seed.bitcoinstats.com seed.bitcoin.jonasschnelli.ch seed.btc.petertodd.org seed.bitcoin.sprovoost.nl 我们可以使用 dig 命令来测试一下 % dig dnsseed.bitcoin.dashjr.org ; &lt;&lt;>> DiG 9.10.6 &lt;&lt;>> dnsseed.bitcoin.dashjr.org ;; global options: +cmd ;; Got answer: ;; ->>HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 64930 ;; flags: qr rd ra; QUERY: 1, ANSWER: 24, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 4096 ;; QUESTION SECTION: ;dnsseed.bitcoin.dashjr.org. IN A ;; ANSWER SECTION: dnsseed.bitcoin.dashjr.org. 3262 IN A 94.102.220.92 dnsseed.bitcoin.dashjr.org. 3262 IN A 82.43.171.91 dnsseed.bitcoin.dashjr.org. 3262 IN A 18.216.38.201 dnsseed.bitcoin.dashjr.org. 3262 IN A 35.185.239.122 dnsseed.bitcoin.dashjr.org. 3262 IN A 213.239.201.46 dnsseed.bitcoin.dashjr.org. 3262 IN A 178.62.242.100 dnsseed.bitcoin.dashjr.org. 3262 IN A 109.197.127.221 dnsseed.bitcoin.dashjr.org. 3262 IN A 95.158.39.64 dnsseed.bitcoin.dashjr.org. 3262 IN A 67.193.68.147 dnsseed.bitcoin.dashjr.org. 3262 IN A 18.194.75.63 dnsseed.bitcoin.dashjr.org. 3262 IN A 24.233.245.188 dnsseed.bitcoin.dashjr.org. 3262 IN A 52.60.106.162 dnsseed.bitcoin.dashjr.org. 3262 IN A 14.2.124.84 dnsseed.bitcoin.dashjr.org. 3262 IN A 101.65.253.15 dnsseed.bitcoin.dashjr.org. 3262 IN A 75.109.56.138 dnsseed.bitcoin.dashjr.org. 3262 IN A 18.219.96.50 dnsseed.bitcoin.dashjr.org. 3262 IN A 82.213.234.197 dnsseed.bitcoin.dashjr.org. 3262 IN A 111.206.188.73 dnsseed.bitcoin.dashjr.org. 3262 IN A 117.62.107.81 dnsseed.bitcoin.dashjr.org. 3262 IN A 18.191.24.206 dnsseed.bitcoin.dashjr.org. 3262 IN A 76.89.163.33 dnsseed.bitcoin.dashjr.org. 3262 IN A 18.184.20.43 dnsseed.bitcoin.dashjr.org. 3262 IN A 18.197.78.199 dnsseed.bitcoin.dashjr.org. 3262 IN A 221.225.194.182 ;; Query time: 26 msec ;; SERVER: 114.114.114.114#53(114.114.114.114) ;; WHEN: Thu Jul 12 16:14:45 CST 2018 ;; MSG SIZE rcvd: 439 H3 Nodes can use addresses hard coded into the software.在chainparamsseeds.h本身存在一批种子节点，这些节点是硬编码在代码中的。 在这里就会获取到一批种子结果，当然，在有可能的情况下，代码会尽量的从种子节点转移到其他节点，避免种子节点过载。 一旦本地有了足够的地址（可以从种子节点获知），链接线程将关闭种子节点链接。 目前的地址为： #ifndef BITCOIN_CHAINPARAMSSEEDS_H #define BITCOIN_CHAINPARAMSSEEDS_H /** * List of fixed seed nodes for the bitcoin network * AUTOGENERATED by contrib/seeds/generate-seeds.py * * Each line contains a 16-byte IPv6 address and a port. * IPv4 as well as onion addresses are wrapped inside an IPv6 address accordingly. */ static SeedSpec6 pnSeed6_main[] = { {{0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0xff,0xff,0x05,0x13,0x05,0x7f}, 8333}, {{0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0xff,0xff,0x05,0x1d,0x8b,0x78}, 8333}, {{0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0xff,0xff,0x05,0x27,0x40,0x07}, 8333}, {{0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0xff,0xff,0x05,0x27,0xae,0x74}, 8333}, {{0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0xff,0xff,0x05,0x2d,0x45,0x0d}, 8333}, {{0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,0xff,0xff,0x05,0x2d,0x4b,0x0f}, 8333}, ...... more 但是，，表示看不懂… 怎么这么多位…. H3 Nodes exchange addresses with other nodes.和其他的节点交换地址～ bang bang bang！！！ 敲黑板了！ 重点了！ 重点了！！！ 这节，我们会单独到下一个章节，重起一章，进行讲解 H3 Nodes store addresses in a database and read that database on startup.在调用 AddAddress() 时，地址会存储在数据库中。 当 AppInit2() 调用位于 db.cpp的 LoanAddress() 时，会在启动时读取地址。 目前该方法，已经在版本删除，代码提交在 pull #545,具体的原因就是 没有人用这玩意。留着没意思…. H3 Nodes can be provided addresses as command line arguments可以使用命令行，指定要连接的节点 -addnode 可以指定多个节点。 命令行上提供的地址最初为0时间戳，因此不会相应 getaddr 请求而通告他们。用户还可以使用 -connect &lt;ip&gt; 指定要连接的地址。可以指定多个节点。 -connect 与 -addnode 参数的不同之处在于它并没有将地址添加到数据中，仅仅是使用这些地址 H3 Nodes read addresses from a user provided text file on startup客户端会自动读取比特币目录下的名为 addr.txt 的文件，并把在其中找到的任何地址添加为节点地址。这些节点没有特别优先于其他地址。 他们被添加时，将被赋予零时间戳，因此他们不会相应 getaddr 请求而被通告 H3 疑惑！！！在这里你肯定很疑惑！ 零时间戳！ 是什么鬼吧？ 或者，你也许压根没注意到这个东西… 好吧，接下来我们看看节点间是如何互相通讯的吧 H2 节点间的通讯在这里，我们介绍的事以bitcoin core客户端为例的。 节点必须连接到若干不同的对等节点才能在比特币网络中建立通向比特币网络的种类各异的路径（path）。 由于节点可以随时加入和离开，通讯路径是不可靠的。 因此，节点必须持续进行两项工作：在失去已有连接时发现新节点，并在其他节点启动时为其提供帮助。节点启动时只需要一个连接，因为第一个节点可以将它引荐给它的对等节点，而这些节点又会进一步提供引荐。一个节点，如果连接到大量的其他对等节点，这既没必要，也是对网络资源的浪费。在启动完成后，节点会记住它最近成功连接的对等节点；因此，当重新启动后它可以迅速与先前的对等节点网络重新建立连接。如果先前的网络的对等节点对连接请求无应答，该节点可以使用种子节点进行重启动。 如果已建立的连接没有数据通信，所在的节点会定期发送信息以维持连接。如果节点持续某个连接长达90分钟没有任何通信，它会被认为已经从网络中断开，网络将开始查找一个新的对等节点。因此，比特币网络会随时根据变化的节点及网络问题进行动态调整，不需经过中心化的控制即可进行规模增、减的有机调整。 H3 消息的结构在节点与对等节点交流中，会发送一段数据，这些数据的结构都是以下结构。 我就一展示数据的表格 Field Size Description Data type Comments 4 magic uint32_t Magic value indicating message origin network, and used to seek to next message when stream state is unknown 12 command char[12] ASCII string identifying the packet content, NULL padded (non-NULL padding results in packet rejected) 4 length uint32_t Length of payload in number of bytes 4 checksum uint32_t First 4 bytes of sha256(sha256(payload)) ? payload uchar[] The actual data H4 神奇数其中 magic 字段，是一个在bitcoin 硬性编码的值。其目的是作为两个消息间的间隔，其值会根据其所在的网络环境进行选择。其位于 chainparams.cpp /** * The message start string is designed to be unlikely to occur in normal data. * The characters are rarely used upper ASCII, not valid as UTF-8, and produce * a large 32-bit integer with any alignment. */ pchMessageStart[0] = 0xf9; pchMessageStart[1] = 0xbe; pchMessageStart[2] = 0xb4; pchMessageStart[3] = 0xd9; nDefaultPort = 8333; nPruneAfterHeight = 100000; 以上只是 主网的神奇数，其他的神奇数如下。 我就一展示数据的表格 Network Magic value Sent over wire as main 0xD9B4BEF9 F9 BE B4 D9 testnet 0xDAB5BFFA FA BF B5 DA testnet3 0x0709110B 0B 11 09 07 namecoin 0xFEB4BEF9 F9 BE B4 FE 其中在消息中会出现其他的数据结构，在这里也总结一下： H4 VarintVarint 是一个变长的参数。Variable length integer 我就一展示数据的表格 Value Storage length Format &lt; 0xFD 1 uint8_t &lt;= 0xFFFF 3 0xFD followed by the length as uint16_t &lt;= 0xFFFF FFFF 5 0xFE followed by the length as uint32_t - 9 0xFF followed by the length as uint64_t 解析的步骤如下: 读取第 1 个字节, 假设它的值为 v1 如果 v1 &lt; 0xF, 那么 v1 就是 In-counter 的值 如果 v1 == 0xFD, 那么再读取 2 个字节, 这 2 个字节以 little-endian 形式存储了 In-counter 值 如果 v1 == 0xFE, 那么再读取 4 个字节, 这 4 个字节以 little-endian 形式存储了 In-counter 值 如果 v1 == 0xFF, 那么再读取 8 个字节, 这 8 个字节以 little-endian 形式存储了 In-counter 值 H4 Variable length string可变长度字符串可以使用可变长度整数存储，后跟字符串本身。结构如下： 我就一展示数据的表格 Field Size Description Data type Comments ? length var_int Length of the string ? string char[] The string itself (can be empty) H4 Network address当某处需要网络地址时，使用此结构。网络地址不以版本消息中的时间戳为前缀。 我就一展示数据的表格 Field Size Description Data type Comments 4 time uint32 the Time (version &gt;= 31402). Not present in version message. 8 services uint64_t same service(s) listed in version 16 IPv6/4 char[16] IPv6 address. Network byte order. The original client only supported IPv4 and only read the last 4 bytes to get the IPv4 address. However, the IPv4 address is written into the message as a 16 byte IPv4-mapped IPv6 address (12 bytes 00 00 00 00 00 00 00 00 00 00 FF FF, followed by the 4 bytes of the IPv4 address). 2 port uint16_t port number, network byte order hexdump: 0000 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0010 00 00 FF FF 0A 00 00 01 20 8D ........ . Network address: 01 00 00 00 00 00 00 00 - 1 (NODE_NETWORK: see services listed under version command) 00 00 00 00 00 00 00 00 00 00 FF FF 0A 00 00 01 - IPv6: ::ffff:a00:1 or IPv4: 10.0.0.1 20 8D - Port 8333 H4 Inventory Vectors清单向量用于通知其他节点有关他们拥有的对象或正在请求的数据。 结构如下： 我就一展示数据的表格 Field Size Description Data type Comments 4 type uint32_t Identifies the object type linked to this inventory 32 hash char[32] Hash of the object 目前的type类型有可能是以下 我就一展示数据的表格 Value Name Description 0 ERROR Any data of with this number may be ignored 1 MSG_TX Hash is related to a transaction 2 MSG_BLOCK Hash is related to a data block 3 MSG_FILTERED_BLOCK Hash of a block header; identical to MSG_BLOCK. Only to be used in getdata message. Indicates the reply should be a merkleblock message rather than a block message; this only works if a bloom filter has been set. 4 MSG_CMPCT_BLOCK Hash of a block header; identical to MSG_BLOCK. Only to be used in getdata message. Indicates the reply should be a cmpctblock message. See BIP 152 for more info. H4 command我们可以看到 第二个参数为 command ，目前bitcoin的 command 列表如下。 version - Information about program version and block count. Exchanged when first connecting. verack - Sent in response to a version message to acknowledge that we are willing to connect. addr - List of one or more IP addresses and ports. inv - “I have these blocks/transactions: …” Normally sent only when a new block or transaction is being relayed. This is only a list, not the actual data. getdata - Request a single block or transaction by hash. getblocks - Request an inv of all blocks in a range. getheaders - Request a headers message containing all block headers in a range. tx - Send a transaction. This is sent only in response to a getdata request. block - Send a block. This is sent only in response to a getdata request. headers - Send up to 2,000 block headers. Non-generators can download the headers of blocks instead of entire blocks. getaddr - Request an addr message containing a bunch of known-active peers (for bootstrapping). submitorder, checkorder, and reply - Used when performing an IP transaction. alert - Send a network alert. ping - Does nothing. Used to check that the connection is still online. A TCP error will occur if the connection has died. 以上就是目前所有的消息类型。我们来看看这些命令的，数据结构 H3 version我们获取到了对等网络的地址之后，就需要进行握手协议了。也就是向目标地址发送一个 version的消息，其中 version 的消息数据结构包含。 我就一展示数据的表格 Field Size Description Data type Comments 4 version int32_t Identifies protocol version being used by the node 8 services uint64_t bitfield of features to be enabled for this connection 8 timestamp int64_t standard UNIX timestamp in seconds 26 addr_recv net_addr The network address of the node receiving this message Fields below require version ≥ 106 26 addr_from net_addr The network address of the node emitting this message 8 nonce uint64_t Node random nonce, randomly generated every time a version packet is sent. This nonce is used to detect connections to self. ? user_agent var_str User Agent (0x00 if string is 0 bytes long) 4 start_height int32_t The last block received by the emitting node Fields below require version ≥ 70001 1 relay bool Whether the remote peer should announce relayed transactions or not, see BIP 0037 对等节点收到version消息后，会回应verack进行确认并建立连接。有时候对等端可能需要互换连接并连回起始节点，此时对等端也会发送该节点的version消息。 参考下图: 握手协议示意图 其中具体的数据我们参考 Version 0.3.19 hexdump: 0000 F9 BE B4 D9 76 65 72 73 69 6F 6E 00 00 00 00 00 ....version..... 0010 55 00 00 00 9C 7C 00 00 01 00 00 00 00 00 00 00 U....|.......... 0020 E6 15 10 4D 00 00 00 00 01 00 00 00 00 00 00 00 ...M............ 0030 00 00 00 00 00 00 00 00 00 00 FF FF 0A 00 00 01 ................ 0040 20 8D 01 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0050 00 00 00 00 FF FF 0A 00 00 02 20 8D DD 9D 20 2C .......... ... , 0060 3A B4 57 13 00 55 81 01 00 :.W..U... Message header: F9 BE B4 D9 - Main network magic bytes 76 65 72 73 69 6F 6E 00 00 00 00 00 - &quot;version&quot; command 55 00 00 00 - Payload is 85 bytes long - No checksum in version message until 20 February 2012. See https://bitcointalk.org/index.php?topic=55852.0 Version message: 9C 7C 00 00 - 31900 (version 0.3.19) 01 00 00 00 00 00 00 00 - 1 (NODE_NETWORK services) E6 15 10 4D 00 00 00 00 - Mon Dec 20 21:50:14 EST 2010 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 FF FF 0A 00 00 01 20 8D - Recipient address info - see Network Address 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 FF FF 0A 00 00 02 20 8D - Sender address info - see Network Address DD 9D 20 2C 3A B4 57 13 - Node random unique ID 00 - &quot;&quot; sub-version string (string is 0 bytes long) 55 81 01 00 - Last block sending node has is block #98645 Version 60002 hexdump: 0000 f9 be b4 d9 76 65 72 73 69 6f 6e 00 00 00 00 00 ....version..... 0010 64 00 00 00 35 8d 49 32 62 ea 00 00 01 00 00 00 d...5.I2b....... 0020 00 00 00 00 11 b2 d0 50 00 00 00 00 01 00 00 00 .......P........ 0030 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ff ff ................ 0040 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0050 00 00 00 00 00 00 00 00 ff ff 00 00 00 00 00 00 ................ 0060 3b 2e b3 5d 8c e6 17 65 0f 2f 53 61 74 6f 73 68 ;..]...e./Satosh 0070 69 3a 30 2e 37 2e 32 2f c0 3e 03 00 i:0.7.2/.&gt;.. Message Header: F9 BE B4 D9 - Main network magic bytes 76 65 72 73 69 6F 6E 00 00 00 00 00 - &quot;version&quot; command 64 00 00 00 - Payload is 100 bytes long 3B 64 8D 5A - payload checksum Version message: 62 EA 00 00 - 60002 (protocol version 60002) 01 00 00 00 00 00 00 00 - 1 (NODE_NETWORK services) 11 B2 D0 50 00 00 00 00 - Tue Dec 18 10:12:33 PST 2012 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 FF FF 00 00 00 00 00 00 - Recipient address info - see Network Address 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 FF FF 00 00 00 00 00 00 - Sender address info - see Network Address 3B 2E B3 5D 8C E6 17 65 - Node ID 0F 2F 53 61 74 6F 73 68 69 3A 30 2E 37 2E 32 2F - &quot;/Satoshi:0.7.2/&quot; sub-version string (string is 15 bytes long) C0 3E 03 00 - Last block sending node has is block #212672 H3 verack 我就一展示数据的表格 value name description 1 NODE_NETWORK This node can be asked for full blocks instead of just headers. 2 NODE_GETUTXO See BIP 0064 4 NODE_BLOOM See BIP 0111 8 NODE_WITNESS See BIP 0144 1024 NODE_NETWORK_LIMITED See BIP 0159 verack消息以回复版本发送。 此消息仅包含带有命令字符串“verack”的消息头。 verack hexdump: 0000 F9 BE B4 D9 76 65 72 61 63 6B 00 00 00 00 00 00 ....verack...... 0010 00 00 00 00 5D F6 E0 E2 ........ Message header: F9 BE B4 D9 - Main network magic bytes 76 65 72 61 63 6B 00 00 00 00 00 00 - &quot;verack&quot; command 00 00 00 00 - Payload is 0 bytes long 5D F6 E0 E2 - Checksum H3 addr提供有关网络的已知节点的信息。通常3小时后应该忘记未广播的节点 数据结构： 我就一展示数据的表格 Field Size Description Data type Comments 1+ count var_int Number of address entries (max: 1000) 30x? addr_list (uint32_t + net_addr)[] Address of other nodes on the network. version &lt; 209 will only read the first one. The uint32_t is a timestamp (see note below). 在本本 31402之后，地址需要增加时间戳的前缀，如果这个地址没有时间戳，那么就不该把这个地址分享给其他的对等网络。 是为了最大程度确认该地址最近活动的时间，最大程度的确保分享出去的地址对等网络可以使用 hexdump 数据如下 0000 F9 BE B4 D9 61 64 64 72 00 00 00 00 00 00 00 00 ....addr........ 0010 1F 00 00 00 ED 52 39 9B 01 E2 15 10 4D 01 00 00 .....R9.....M... 0020 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 FF ................ 0030 FF 0A 00 00 01 20 8D ..... . Message Header: F9 BE B4 D9 - Main network magic bytes 61 64 64 72 00 00 00 00 00 00 00 00 - &quot;addr&quot; 1F 00 00 00 - payload is 31 bytes long ED 52 39 9B - checksum of payload Payload: 01 - 1 address in this message Address: E2 15 10 4D - Mon Dec 20 21:50:10 EST 2010 (only when version is &gt;= 31402) 01 00 00 00 00 00 00 00 - 1 (NODE_NETWORK service - see version message) 00 00 00 00 00 00 00 00 00 00 FF FF 0A 00 00 01 - IPv4: 10.0.0.1, IPv6: ::ffff:10.0.0.1 (IPv4-mapped IPv6 address) 20 8D - port 8333 H3 inv允许节点广播其对一个或多个对象的数据。它可以是未经请求的，也可以是对getblocks的回复。 有效载荷（最多50,000个条目，刚刚超过1.8兆字节）： 数据结构如下 我就一展示数据的表格 Field Size Description Data type Comments ? count var_int Number of inventory entries 36x? inventory inv_vect[] Inventory vectors H3 getdatagetdata用于响应inv，以检索特定对象的内容，并且通常在过滤已知元素之后在接收到inv包之后发送。它可用于检索事务，但仅当它们位于内存池或中继集中时 - 不允许对链中的事务进行任意访问，以避免客户端开始依赖具有完整事务索引的节点（现代节点不具有）。 有效载荷（最多50,000个条目，刚刚超过1.8兆字节）： 内存池，是未经确认处理的缓冲区 我就一展示数据的表格 Field Size Description Data type Comments ? count var_int Number of inventory entries 36x? inventory inv_vect[] Inventory vectors H3 notfoundnotfound是对getdata的响应，如果无法中继任何请求的数据项，则发送该数据，例如，因为请求的事务不在内存池或中继集中。 我就一展示数据的表格 Field Size Description Data type Comments ? count var_int Number of inventory entries 36x? inventory inv_vect[] Inventory vectors H3 getblocks返回一个inv数据包，其中包含在块定位器对象中最后一个已知散列之后开始的块列表，最多为hash_stop或500个块，以先到者为准。 定位器哈希由节点按消息中出现的顺序处理。如果在节点的主链中找到块散列，则通过inv消息返回其子节点列表，并且无论是否达到所请求的限制，都将忽略其余定位符。 要接收下一个块哈希，需要使用新的块定位器对象再次发出getblock。请记住，如果块定位器对象在无效分支上包含散列，则某些客户端可能会提供无效的块。 我就一展示数据的表格 ield Size Description Data type Comments 4 version uint32_t the protocol version 1+ hash count var_int number of block locator hash entries 32+ block locator hashes char[32] block locator object; newest back to genesis block (dense to start, but then sparse) 32 hash_stop char[32] hash of the last desired block; set to zero to get as many blocks as possible (500) 要创建块定位器哈希值，请继续推哈希值，直到返回到创世块。在向后推10个哈希后，向后的步骤会使每个循环加倍： // From libbitcoin which is under AGPL std::vector&lt;size_t> block_locator_indexes(size_t top_height) { std::vector&lt;size_t> indexes; // Modify the step in the iteration. int64_t step = 1; // Start at the top of the chain and work backwards. for (auto index = (int64_t)top_height; index > 0; index -= step) { // Push top 10 indexes first, then back off exponentially. if (indexes.size() >= 10) step *= 2; indexes.push_back((size_t)index); } // Push the genesis block index. indexes.push_back(0); return indexes; } 请注意，允许将较少的已知哈希值发送到最少只有一个哈希值。但是，块定位器对象的目的是检测调用者主链中的错误分支。如果对等方检测到您不在主链上，它将发送早于最后一个已知块的块哈希。因此，如果你只是发送你最后一次已知的哈希并且它不在主链上，那么对等体将从块＃1开始 H3 getheaders返回一个头文件包，其中包含从块定位器对象中最后一个已知哈希之后开始的块头，最多为hash_stop或2000个块，以先到者为准。要接收下一个块头，需要使用新的块定位器对象再次发出getheaders。该getheaders命令使用瘦客户机快速下载块链，其中交易的内容是不相关的（因为他们不是我们的）。请记住，如果块定位器对象在无效分支上包含散列，则某些客户端可能会提供无效的块标头。 有效载荷： 我就一展示数据的表格 Field Size Description Data type Comments 4 version uint32_t the protocol version 1+ hash count var_int number of block locator hash entries 32+ block locator hashes char[32] block locator object; newest back to genesis block (dense to start, but then sparse) 32 hash_stop char[32] hash of the last desired block header; set to zero to get as many blocks as possible (2000) H3 txtx描述了比特币交易，以回复getdata 我就一展示数据的表格 Field Size Description Data type Comments 4 version int32_t Transaction data format version (note, this is signed) 0 or 2 flag optional uint8_t[2] If present, always 0001, and indicates the presence of witness data 1+ tx_in count var_int Number of Transaction inputs (never zero) 41+ tx_in tx_in[] A list of 1 or more transaction inputs or sources for coins 1+ tx_out count var_int Number of Transaction outputs 9+ tx_out tx_out[] A list of 1 or more transaction outputs or destinations for coins 0+ tx_witnesses tx_witness[] A list of witnesses, one for each input; omitted if flag is omitted above 4 lock_time uint32_t The block number or timestamp at which this transaction is unlocked: Value Description 0 Not locked &lt; 500000000 Block number at which this transaction is unlocked &gt;= 500000000 UNIX timestamp at which this transaction is unlocked If all TxIn inputs have final (0xffffffff) sequence numbers then lock_time is irrelevant. Otherwise, the transaction may not be added to a block until after lock_time (see NLockTime). Txin 数据结构 我就一展示数据的表格 Field Size Description Data type Comments 36 previous_output outpoint The previous output transaction reference, as an OutPoint structure 1+ script length var_int The length of the signature script ? signature script uchar[] Computational Script for confirming transaction authorization 4 sequence uint32_t Transaction version as defined by the sender. Intended for “replacement” of transactions when information is updated before inclusion into a block. Txout 数据结构 我就一展示数据的表格 Field Size Description Data type Comments 32 hash char[32] The hash of the referenced transaction. 4 index uint32_t The index of the specific output in the transaction. The first output is 0, etc. 脚本结构由一系列与交易价值相关的信息和操作组成。（将来要扩展的结构…有关更多信息，请参阅script.h和script.cpp以及脚本）TxOut结构包含以下字段： 我就一展示数据的表格 Field Size Description Data type Comments 8 value int64_t Transaction Value 1+ pk_script length var_int Length of the pk_script ? pk_script uchar[] Usually contains the public key as a Bitcoin script setting up conditions to claim this output. TxWitness结构由见证数据组件的var_int计数组成，后跟（对于每个见证数据组件）组件的var_int长度和原始组件数据本身。 000000 F9 BE B4 D9 74 78 00 00 00 00 00 00 00 00 00 00 ....tx.......... 000010 02 01 00 00 E2 93 CD BE 01 00 00 00 01 6D BD DB .............m.. 000020 08 5B 1D 8A F7 51 84 F0 BC 01 FA D5 8D 12 66 E9 .[...Q........f. 000030 B6 3B 50 88 19 90 E4 B4 0D 6A EE 36 29 00 00 00 .;P......j.6)... 000040 00 8B 48 30 45 02 21 00 F3 58 1E 19 72 AE 8A C7 ..H0E.!..X..r... 000050 C7 36 7A 7A 25 3B C1 13 52 23 AD B9 A4 68 BB 3A .6zz%;..R#...h.: 000060 59 23 3F 45 BC 57 83 80 02 20 59 AF 01 CA 17 D0 Y#?E.W... Y..... 000070 0E 41 83 7A 1D 58 E9 7A A3 1B AE 58 4E DE C2 8D .A.z.X.z...XN... 000080 35 BD 96 92 36 90 91 3B AE 9A 01 41 04 9C 02 BF 5...6..;...A.... 000090 C9 7E F2 36 CE 6D 8F E5 D9 40 13 C7 21 E9 15 98 .~.6.m...@..!... 0000A0 2A CD 2B 12 B6 5D 9B 7D 59 E2 0A 84 20 05 F8 FC *.+..].}Y... ... 0000B0 4E 02 53 2E 87 3D 37 B9 6F 09 D6 D4 51 1A DA 8F N.S..=7.o...Q... 0000C0 14 04 2F 46 61 4A 4C 70 C0 F1 4B EF F5 FF FF FF ../FaJLp..K..... 0000D0 FF 02 40 4B 4C 00 00 00 00 00 19 76 A9 14 1A A0 ..@KL......v.... 0000E0 CD 1C BE A6 E7 45 8A 7A BA D5 12 A9 D9 EA 1A FB .....E.z........ 0000F0 22 5E 88 AC 80 FA E9 C7 00 00 00 00 19 76 A9 14 &quot;^...........v.. 000100 0E AB 5B EA 43 6A 04 84 CF AB 12 48 5E FD A0 B7 ..[.Cj.....H^... 000110 8B 4E CC 52 88 AC 00 00 00 00 .N.R...... Message header: F9 BE B4 D9 - main network magic bytes 74 78 00 00 00 00 00 00 00 00 00 00 - &quot;tx&quot; command 02 01 00 00 - payload is 258 bytes long E2 93 CD BE - checksum of payload Transaction: 01 00 00 00 - version Inputs: 01 - number of transaction inputs Input 1: 6D BD DB 08 5B 1D 8A F7 51 84 F0 BC 01 FA D5 8D - previous output (outpoint) 12 66 E9 B6 3B 50 88 19 90 E4 B4 0D 6A EE 36 29 00 00 00 00 8B - script is 139 bytes long 48 30 45 02 21 00 F3 58 1E 19 72 AE 8A C7 C7 36 - signature script (scriptSig) 7A 7A 25 3B C1 13 52 23 AD B9 A4 68 BB 3A 59 23 3F 45 BC 57 83 80 02 20 59 AF 01 CA 17 D0 0E 41 83 7A 1D 58 E9 7A A3 1B AE 58 4E DE C2 8D 35 BD 96 92 36 90 91 3B AE 9A 01 41 04 9C 02 BF C9 7E F2 36 CE 6D 8F E5 D9 40 13 C7 21 E9 15 98 2A CD 2B 12 B6 5D 9B 7D 59 E2 0A 84 20 05 F8 FC 4E 02 53 2E 87 3D 37 B9 6F 09 D6 D4 51 1A DA 8F 14 04 2F 46 61 4A 4C 70 C0 F1 4B EF F5 FF FF FF FF - sequence Outputs: 02 - 2 Output Transactions Output 1: 40 4B 4C 00 00 00 00 00 - 0.05 BTC (5000000) 19 - pk_script is 25 bytes long 76 A9 14 1A A0 CD 1C BE A6 E7 45 8A 7A BA D5 12 - pk_script A9 D9 EA 1A FB 22 5E 88 AC Output 2: 80 FA E9 C7 00 00 00 00 - 33.54 BTC (3354000000) 19 - pk_script is 25 bytes long 76 A9 14 0E AB 5B EA 43 6A 04 84 CF AB 12 48 5E - pk_script FD A0 B7 8B 4E CC 52 88 AC Locktime: 00 00 00 00 - lock time H3 block响应于getdata消息发送块消息，该消息从块散列请求事务信息。 我就一展示数据的表格 Field Size Description Data type Comments 4 version int32_t Block version information (note, this is signed) 32 prev_block char[32] The hash value of the previous block this particular block references 32 merkle_root char[32] The reference to a Merkle tree collection which is a hash of all transactions related to this block 4 timestamp uint32_t A Unix timestamp recording when this block was created (Currently limited to dates before the year 2106!) 4 bits uint32_t The calculated difficulty target being used for this block 4 nonce uint32_t The nonce used to generate this block… to allow variations of the header and compute different hashes ? txn_count var_int Number of transaction entries ? txns tx[] Block transactions, in format of “tx” command 标识每个块（并且必须具有0位运行）的SHA256哈希值是根据此结构的前6个字段计算的（版本，prev_block，merkle_root，时间戳，位，nonce和标准SHA256填充，使得两个64-所有的字节块）而不是完整的块。要计算哈希值，SHA256算法只需要处理两个块。由于nonce字段在第二个块中，因此第一个块在挖掘期间保持不变，因此只需要处理第二个块。但是，比特币散列是散列的散列，因此每次挖掘迭代都需要两个SHA256循环。有关详细信息和示例，请参阅块散列算法。 H3 headers头包返回块头以响应getheaders包 我就一展示数据的表格 Field Size Description Data type Comments ? count var_int Number of block headers 81x? headers block_header[] Block headers 请注意，此数据包中的块头包含事务计数（var_int，因此每个头可能超过81个字节），而不是由矿工进行哈希处理的块头。 H3 getaddrgetaddr消息向节点发送请求，询问有关已知活动对等体的信息，以帮助查找网络中的潜在节点。对接收该消息的响应是与来自已知活动对等体的数据库的一个或多个对等体一起发送一个或多个addr消息。典型的假设是，如果节点在过去三小时内发送消息，则该节点可能处于活动状态。此消息不会传输其他数据。 H3 mempoolmempool消息向节点发送请求，询问有关已验证但尚未确认的事务的信息。接收此消息的响应是一条inv消息，其中包含节点的mempool中所有事务的事务哈希。此消息不会传输其他数据。它在BIP 35中指定。从BIP 37开始，如果加载了布隆过滤器，则只回复与过滤器匹配的事务。 H3 checkorder , submitorder and reply此消息用于IP事务。由于IP事务已被弃用，因此不再使用它 Sending bitcoins to an IP address was a convenient way of sending bitcoins to a Bitcoin address along with additional information. Your client contacts the IP address to find out if they’re actually running Bitcoin and accepting IP transactions. If not, no transaction occurs. Your additional information (“from”, “message”, etc.) is exchanged with the server. The server generates a brand new Bitcoin public key and sends it to your client. Your client sends coins to this public key.Unfortunately, the implementation provided no authentication, so any “man in the middle” could have intercepted your bitcoins during the transaction. When they see that you’re sending a Bitcoin payment by IP address, they pretend to be the actual destination and send back their Bitcoin address. You end up sending bitcoins to the wrong person. It’s therefore no longer a good idea to send bitcoins in this way, especially if you’re using a proxy. 删除原因 参考 Remove send to IP address and IP transactions support H3 ping发送ping消息主要是为了确认TCP / IP连接仍然有效。传输中的错误被假定为闭合连接，并且该地址作为当前对等体被移除。 我就一展示数据的表格 Field Size Description Data type Comments 8 nonce uint64_t random nonce H3 pong发送pong消息以响应ping消息。在现代协议版本中，使用ping中包含的随机数生成pong响应。 我就一展示数据的表格 Field Size Description Data type Comments 8 nonce uint64_t nonce from ping H3 reject拒绝消息时 发送的消息 我就一展示数据的表格 Field Size Description Data type Comments 1+ message var_str type of message rejected 1 ccode char code relating to rejected message 1+ reason var_str text version of reason for rejection 0+ data char Optional extra data provided by some errors. Currently, all errors which provide this field fill it with the TXID or block header hash of the object being rejected, so the field is 32 bytes. ccode 我就一展示数据的表格 Value Name Description 0x01 REJECT_MALFORMED 0x10 REJECT_INVALID 0x11 REJECT_OBSOLETE 0x12 REJECT_DUPLICATE 0x40 REJECT_NONSTANDARD 0x41 REJECT_DUST 0x42 REJECT_INSUFFICIENTFEE 0x43 REJECT_CHECKPOINT H3 filterload, filteradd, filterclear, merkleblock这些消息与连接的Bloom过滤有关，并在BIP 0037中定义。filterload命令定义如下： 我就一展示数据的表格 Field Size Description Data type Comments ? filter uint8_t[] The filter itself is simply a bit field of arbitrary byte-aligned size. The maximum size is 36,000 bytes. 4 nHashFuncs uint32_t The number of hash functions to use in this filter. The maximum value allowed in this field is 50. 4 nTweak uint32_t A random value to add to the seed value in the hash function used by the bloom filter. 1 nFlags uint8_t A set of flags that control how matched items are added to the filter. 有关Bloom过滤器算法的说明以及如何为所需的误报率选择nHashFuncs和过滤器大小，请参见下文。在接收到filterload命令后，远程对等体将立即将其宣告的广播事务（在inv数据包中）限制为与过滤器匹配的事务，其中匹配算法在下面指定。标志控制匹配算法的更新行为。filteradd命令定义如下： 我就一展示数据的表格 Field Size Description Data type Comments ? data uint8_t[] The data element to add to the current filter. 数据字段的大小必须小于或等于520字节（任何可能匹配的对象的最大大小）。给定的数据元素将添加到Bloom过滤器中。必须先使用filterload提供过滤器。如果将新密钥或脚本添加到客户端钱包，同时它与网络连接打开时，此命令很有用，它可以避免重新计算并向每个对等方发送全新过滤器的需要（尽管这样做通常建议使用保持匿名）。 filterclear命令根本没有参数。在设置过滤器之后，节点不仅停止宣布不匹配的事务，它们还可以提供过滤的块。过滤后的块由merkleblock消息定义，定义如下： 我就一展示数据的表格 Field Size Description Data type Comments 4 version int32_t Block version information, based upon the software version creating this block (note, this is signed) 32 prev_block char[32] The hash value of the previous block this particular block references 32 merkle_root char[32] The reference to a Merkle tree collection which is a hash of all transactions related to this block 4 timestamp uint32_t A timestamp recording when this block was created (Limited to 2106!) 4 bits uint32_t The calculated difficulty target being used for this block 4 nonce uint32_t The nonce used to generate this block… to allow variations of the header and compute different hashes 4 total_transactions uint32_t Number of transactions in the block (including unmatched ones) ? hashes uint256[] hashes in depth-first order (including standard varint size prefix) ? flags byte[] flag bits, packed per 8 in a byte, least significant bit first (including standard varint size prefix) H3 alertNote: Support for alert messages has been removed from bitcoin core in March 2016. Read more here H3 sendheaders请求直接标题公告。收到此消息后，允许但不要求节点通过headers命令（而不是inv命令）通知新块。协议版本&gt; = 70012或比特币核心版本&gt; = 0.12.0支持此消息。有关更多信息，请参阅BIP 130。此消息不会传输其他数据 H3 feefilter有效负载总是8个字节长，它编码64位整数值（LSB / little endian）的费用。该值代表最小费用，以每1000字节的satoshis表示。在收到“费用过滤器”消息后，该节点将被允许但不是必需的，以过滤低于费用过滤器消息中提供的费用率的交易的交易保护，该费用被解释为每千字节的satoshis。费用过滤器是附加的，用于交易的布隆过滤器，因此如果SPV客户端要加载布隆过滤器并发送费用过滤器消息，则只有在通过两个过滤器时才会中继交易。如果存在，则从mempool消息生成的Inv也需要收费过滤器。通过检查协议版本&gt; = 70013启用功能发现有关更多信息，请参阅BIP 133 H3 sendcmpct sendcmpct 消息被定义为包含1字节整数后跟8字节整数的消息，其中pchCommand ==“sendcmpct”。 第一个整数应解释为布尔值（并且必须具有1或0的值） 第二个整数应解释为little-endian版本号。发送sendcmpct消息的节点当前必须将此值设置为1。 收到第一个和第二个整数设置为1的“sendcmpct”消息后，节点应该通过发送cmpctblock消息来通告新的块。 在收到第一个整数设置为0的“sendcmpct”消息后，节点不应该通过发送cmpctblock消息来通告新块，但是应该通过发送由BIP130定义的inv或头来发布新块。 在收到第二个整数设置为1以外的“sendcmpct”消息时，节点必须将对等体视为没有收到消息（因为它表明对等体将提供意外的编码） cmpctblock和/或其他消息）。这允许将来的版本发送具有不同版本的重复sendcmpct消息，作为未来版本的版本握手的一部分。 在发送sendcmpct消息之前，节点应该检查协议版本&gt; = 70014。 在收到来自该对等体的sendcmpct消息之前，节点不得向对等体发送对MSG_CMPCT_BLOCK对象的请求。此消息仅受协议版本&gt; = 70014支持 有关更多信息，请参阅BIP 152。 H3 cmpctblock cmpctblock消息被定义为包含序列化HeaderAndShortIDs消息和pchCommand ==“cmpctblock”的消息。 在发送sendcmpct消息后收到cmpctblock消息后，节点应该为他们可用的每个未确认的事务（即在他们的mempool中）计算短事​​务ID，并将每个事务ID与cmpctblock消息中的每个短事务ID进行比较。 在找到已经可用的事务之后，没有可用于重建完整块的所有事务的节点应该使用getblocktxn消息来请求丢失的事务。 节点绝不能发送cmpctblock消息，除非它们能够响应请求块中每个事务的getblocktxn消息。 节点必须不发送cmpctblock消息，而不验证标头是否正确提交到块中的每个事务，并且正确地构建在具有有效工作证明的现有链之上。节点可以在验证块中的每个事务有效地花费现有UTXO集条目之前发送cmpctblock。 此消息仅受协议版本&gt; = 70014支持 有关更多信息，请参阅BIP 152。 H3 getblocktxn getblocktxn消息被定义为包含序列化BlockTransactionsRequest消息和pchCommand ==“getblocktxn”的消息。 在收到格式正确的getblocktxnmessage后，最近为这种消息的发送者提供了该消息中标识的块散列的cmpctblock的节点必须用适当的blocktxn消息进行响应。这样的blocktxn消息必须完全且仅包含在请求的顺序中在getblocktxn索引列表中指定的索引处的适当块中存在的每个事务。此消息仅受协议版本&gt; = 70014支持 有关更多信息，请参阅BIP 152。 H3 blocktxn blocktxn消息被定义为包含序列化BlockTransactions消息和pchCommand ==“blocktxn”的消息。 在收到格式正确的请求的blocktxn消息后，节点应该尝试通过以下方式重建整个块： 从原始cmpctblock中获取 prefilledtxn事务并将它们放在标记位置。 对于来自原始cmpctblock的每个短事务ID ，按顺序从blocktxn消息或其他源中查找相应的事务，并将其置于块中的第一个可用位置。 一旦块被重建，它将被正常处理，记住短事务ID偶尔会发生冲突，并且节点不得因这些冲突而受到惩罚，无论它们出现在何处。此消息仅受协议版本&gt; = 70014支持 有关更多信息，请参阅BIP 152。 H2 别人如何知道我的 如何交换数据其实i 看到这里，我们如何交易数据的就已经很清楚了。 H2 NAT 与， p2p 和 区块链H3 什么事 NAT NAT是个什么鬼？它的全称是Network Address Translation，翻译过来就是网络地址转换。好事的人立马就得问了：好端端的为啥要地址转换，直接用IP地址不就行了么？ 在TCP/IP协议创建的时候，他的创始人（Robert E.Kahn和Vinton G.Cerf）可能都没有预料到互联网的膨胀速度会如此之快，快到短短二三十年的时间，IPV4的地址就有要枯竭之势。随着越来越多的设备加入到互联网中，IPV4地址不够用的问题成了燃眉之急。 解决IP地址不够用的一个办法是大家已经非常熟悉的IPV6，但是这么多年过去了，IPV6似乎还是不温不火，始终普及不起来。于是就有了NAT的解决方案，可以说正是NAT把IPV4从死亡边缘拉了回来，NAT到底是用了什么方法立下如此奇功，本节我们来简单的了解一下。 平时我们无论是在家里，还是在公司，其实都是在一个私有的局域网，此时电脑上分配到的IP地址是私有IP地址。RFC1918规范里规定了3个保留地址段：10.0.0.0-10.255.255.255，172.16.0.0-172.31.255.255，192.168.0.0-192.168.255.255，这三个范围分别处于A、B、C类的地址段，专门用于组织或者企业内部使用，不需要进行申请。和公有IP地址相比，这些私有IP地址只在企业内部使用，不能作为全球路由地址，出了企业或组织的管理范围，这类私有地址就不在有任何意义。注意：任何一个组织都可以在内部使用这些私有地址，因此两个不同网络中存在相同IP地址的情况是很可能出现的，但是同一个网络中不允许两台主机拥有相同IP地址，否则将发生地址冲突。 当私有网络中的主机想请求公网中服务器的服务时，需要在网络出口处部署NAT网关。NAT的作用就是在报文离开私网进入Internet的时候，把报文中的源IP地址替换为公网地址，然后等服务端的响应报文到达网关时，NAT再把目的地址替换为私网中主机的IP地址。 听上去似乎很简单，NAT不就是替换了一下IP地址么，也没干什么，但是这里需要注意两点： 有了NAT以后，内网的主机不在需要申请公网IP地址，只需要将内网主机地址和端口通过NAT映射到网络出口的公网IP即可，然后通信的两端在无感知的情况下进行通信。这也是为什么前文说NAT挽救了IPV4，因为大量的内网主机有了NAT，只需要很少的公网地址做映射就可以了，如此就可以节约出很多的IPV4地址空间。 当在私网网络出口处部署了NAT网关以后，只能由内网主机发起到外网主机的连接，外网主机无法主动发起连接到内网。这样虽然对外隔离了内网主机，但同时又限制了P2P的通信，这也是NAT带来的一大弊端，下一节介绍NAT穿透技术时会看到针对这一问题有哪些解决手段。 区块链是建立在P2P网络基础上的。在比特币系统中，穿透NAT建立节点之间点对点的P2P网络，采用的就是上一节所说的UPNP技术。比特币使用了开源的miniupnp，基本上就是调用miniupnp封装好的接口，实现比较简单，我们来看看源代码： 比特币系统的初始化大部分都是在init.cpp中的AppInitMain中进行的： // Map ports with UPnP if (gArgs.GetBoolArg(\"-upnp\", DEFAULT_UPNP)) { StartMapPort(); } H3 NAT 穿透前文提到过，使用NAT的缺陷之一就是只能由内网主机发起连接，外网主机无法主动连接到内网。这就意味着外部节点无法和内网主机进行P2P通信，就像第一节中提到的那个场景：因为两个人在不同的局域网中，相互不知道对方的公网地址和端口，所以无法直接建立起点对点连接。解决这个问题的办法就是NAT穿透技术。下面简单介绍几种常见的NAT穿越技术。 H4 STUNSTUN全称为Simple Tranversal of UDP through NAT。其穿透原理参考下图： STUN 穿透原理 假设两个不同网络中的设备A和B想穿透NAT进行点对点通信，通过STUN进行NAT穿透的过程如上图，其中STUN SERVER是部署在公网中的STUN服务器。 CLIENT A通过NAT网关向STUN SERVER发送STUN请求消息(UDP)，查询并注册自己经过NAT映射后的公网地址； STUN SERVER响应，并将CLIENT A经过转换后的公网IP地址和端口填在 CLIENT B通过NAT网关向STUN SERVER发送STUN请求消息(UDP)，查询并注册自己经过NAT映射后 STUN SERVER响应，并将CLIENT B经过转换后的公网IP地址和端口填在 此时CLIENT A已经知道了自己映射后对应的公网IP地址和端口号，它把这些信息打包在请求中发送给STUN SERVER，请求和 STUN SERVER查询到B注册的公网地址和端口，然后将请求通过NAT网 B从消息中知道A的公网地址和端口，于是通过此地址和端口，向A发送消息，消息中包含B映射后的公网地址和端口号，A收到消息后就知道了B的公网地址及端口，这样在A和B之间建立起了通信通道。 从代码中可以看到，如果在启动bitcoind时开启了upnp选项，将会进行端口映射，如果想将自己的节点加入到比特币p2p网络中，让其他网络中的节点访问，可以开启此选项进行端口映射，然后把映射后的公网ip地址广播给网络中的其他节点。 StartMapPort()中开启了一个线程进行端口映射，线程函数为net.cpp中的ThreadMapPort： H4 TURNSTUN穿透技术的缺点在于无法穿透对称型NAT，这可以通过TURN技术进行改进。TURN的工作过程和STUN非常相似，区别在于在TURN中，公网地址和端口不由NAT网关分配，而是由TURN服务器分配。 TURN可以解决STUN无法穿透对称NAT的问题，但是由于所有的请求都需要经过TURN服务器，所以网络延迟和丢包的可能性较大，实际当中通常将STUN和TURN混合使用。 H4 UPNPUPNP意为通用即插即用协议，是由微软提出的一种NAT穿透技术。使用UPNP需要内网主机、网关和应用程序都支持UPNP技术。 UPNP通过网关映射请求可以动态的为客户分配映射表项，而NAT网关只需要执行地址和端口的转换。UPNP客户端发送到公网侧的信令或者控制消息中，会包含映射之后公网IP和端口，接收端根据这些信息就可以建立起P2P连接。 UPNP穿透的过程大致如下： 发送查找消息： 一个设备添加到网络以后，会多播大量发现消息来通知其嵌入式设备和服务，所有的控制点都可以监听多播地址以接收通知，标准的多播地址是239.255.255.250：1900。可以通过发送http请求查询局域网中upnp设备，消息形式如下 M-SEARCH * HTTP/1.1 \\r\\n HOST 239.255.255.250:1900 \\r\\n ST:UPnP rootdevice \\r\\n MAN:\\&quot;ssdp:discover\\&quot; \\r\\n MX:\\r\\n\\r\\n 获得根设备描述url 如果网络中存在upnp设备，此设备会向发送了查找请求的多播通道的源IP地址和端口发送响应消息，其形式如下： HTTP/1.1 200 OK CACHE_CONTROL: max-age=100 DATE: XXXX LOCATION:http://192.168.1.1:1900/igd.xml SERVER: TP-LINK Wireness Router UPnP1.0 ST: upnp:rootdevice 首先通过200 OK确定成功的找到了设备。然后要从响应中找到根设备的描述URL（例如上面响应报文中的http://192.168.1.1:1900/igd.xml），通过此URL就可以找到根设备的描述信息，从根设备的描述信息中又可以得到设备的控制URL，通过控制URL就可以控制UPNP的行为。上面这个响应中表示我们在局域网中成功的找到了一台支持UPNP的无线路由器设备。 通过（2）中找到的设备描述URL的地址得到设备描述URL得到XML文档。发送HTTP请求消息： GET /igd.xml HTTP/1.1 HOST:192.168.1.1:1900 Connection: Close 然后就能得到一个设备描述文档，从中可以找到服务和UPNP控制URL。每一种设备都有对应的serviceURL和controlURL。其中和端口映射有关的服务时WANIPConnection和WANPPPConnection。 进行端口映射 拿到设备的控制URL以后就可以发送控制信息了。每一种控制都是根据HTTP请求来发送的，请求形式如下： POST path HTTP/1.1 HOST: host:port SOAPACTION:serviceType#actionName CONTENT-TYPE: text/xml CONTENT-LENGTH: XXX .... 其中path表示控制url，host:port就是目的主机地址，actionName就是控制upnp设备执行响应的指令。UPNP支持的指令如下： 我就一展示数据的表格 actionName 描述 GetStatusInfo 查看UPNP设备状态 AddPortMapping 添加一个端口映射 DeletePortMapping 删除一个端口映射 GetExternalIPAddress 查看映射的外网地址 GetConnectionTypeInfo 查看连接状态 GetSpecificPortMappingEntry 查询指定的端口映射 GetGenericPortMappingEntry 查询端口映射表 通常我们需要用到的是AddPortMapping进行端口映射，以及GetExternalIPAddress获取到映射的公网地址。UPNP完整的协议栈比较复杂，有兴趣的读者可以自行查找资料做更加深入的学习。 H3 UPNP在比特币P2P网络中的应用#ifdef USE_UPNP static CThreadInterrupt g_upnp_interrupt; static std::thread g_upnp_thread; static void ThreadMapPort() { std::string port = strprintf(\"%u\", GetListenPort()); const char * multicastif = nullptr; const char * minissdpdpath = nullptr; struct UPNPDev * devlist = nullptr; char lanaddr[64]; #ifndef UPNPDISCOVER_SUCCESS /* miniupnpc 1.5 */ devlist = upnpDiscover(2000, multicastif, minissdpdpath, 0); #elif MINIUPNPC_API_VERSION &lt; 14 /* miniupnpc 1.6 */ int error = 0; devlist = upnpDiscover(2000, multicastif, minissdpdpath, 0, 0, &amp;error); #else /* miniupnpc 1.9.20150730 */ int error = 0; devlist = upnpDiscover(2000, multicastif, minissdpdpath, 0, 0, 2, &amp;error); #endif struct UPNPUrls urls; struct IGDdatas data; int r; r = UPNP_GetValidIGD(devlist, &amp;urls, &amp;data, lanaddr, sizeof(lanaddr)); if (r == 1) { if (fDiscover) { char externalIPAddress[40]; r = UPNP_GetExternalIPAddress(urls.controlURL, data.first.servicetype, externalIPAddress); if(r != UPNPCOMMAND_SUCCESS) LogPrintf(\"UPnP: GetExternalIPAddress() returned %d\\n\", r); else { if(externalIPAddress[0]) { CNetAddr resolved; if(LookupHost(externalIPAddress, resolved, false)) { LogPrintf(\"UPnP: ExternalIPAddress = %s\\n\", resolved.ToString().c_str()); AddLocal(resolved, LOCAL_UPNP); } } else LogPrintf(\"UPnP: GetExternalIPAddress failed.\\n\"); } } std::string strDesc = \"Bitcoin \" + FormatFullVersion(); do { #ifndef UPNPDISCOVER_SUCCESS /* miniupnpc 1.5 */ r = UPNP_AddPortMapping(urls.controlURL, data.first.servicetype, port.c_str(), port.c_str(), lanaddr, strDesc.c_str(), \"TCP\", 0); #else /* miniupnpc 1.6 */ r = UPNP_AddPortMapping(urls.controlURL, data.first.servicetype, port.c_str(), port.c_str(), lanaddr, strDesc.c_str(), \"TCP\", 0, \"0\"); #endif if(r!=UPNPCOMMAND_SUCCESS) LogPrintf(\"AddPortMapping(%s, %s, %s) failed with code %d (%s)\\n\", port, port, lanaddr, r, strupnperror(r)); else LogPrintf(\"UPnP Port Mapping successful.\\n\"); } while(g_upnp_interrupt.sleep_for(std::chrono::minutes(20))); r = UPNP_DeletePortMapping(urls.controlURL, data.first.servicetype, port.c_str(), \"TCP\", 0); LogPrintf(\"UPNP_DeletePortMapping() returned: %d\\n\", r); freeUPNPDevlist(devlist); devlist = nullptr; FreeUPNPUrls(&amp;urls); } else { LogPrintf(\"No valid UPnP IGDs found\\n\"); freeUPNPDevlist(devlist); devlist = nullptr; if (r != 0) FreeUPNPUrls(&amp;urls); } } 首先第一行拿到比特币系统所使用的端口号，默认为8333，之后将要映射此端口到公网ip上； 调用upnpDiscover查找当前局域网中的所有upnp设备； 调用UPNP_GetValidIGD，从（2）中找到的upnp设备列表中找到有效的IGD设备； 如果UPNPGetValidIGD返回1，表示有一个连接，此时调用UPNP GetExternalIPAddress获取公网地址，然后对此公网地址进行DNS查询，将解析到的地址记录到内存中，这些公网地址之后将会被广播给P2P网络中的其他节点，一传十，十传百。 通过UPNP_AddPortMapping进行端口映射，假设内网获取的有效IGD设备的IP地址为192.168.0.1，网关出口的外网地址为192.169.1.1，采用比特币的默认端口8333，则端口映射后就是将内网中192.168.0.1：8333映射到网关出口的公有IP地址和端口：192.169.1.1:8333，之后外部节点通过此公网IP和端口，就可以与内网节点进行通信了。 H2 小结这篇文章，主要介绍了，如何获取节点，以及节点的交流方式。逐个分析了，每个消息的结构。后面介绍了NAT以及常见的NAT穿透技术。因为建立P2P通信很重要的一步就是穿透NAT以建立起节点之间的通信通道。常见的NAT穿透技术有STUN，TURN以及UPNP，而比特币P2P组网采用的正是UPNP技术，具体实现时比特币采用了开源的miniupnp。 参考链接 比特币源码分析–P2P网络初始化 比特币源码分析–端口映射 Bitcoin wiki - Protocol documentation Bitcoin wiki - Network 区块链 p2p认识.md","categories":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/categories/区块链/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/tags/区块链/"},{"name":"p2p","slug":"p2p","permalink":"http://blog.msiter.com/tags/p2p/"},{"name":"dns seed","slug":"dns-seed","permalink":"http://blog.msiter.com/tags/dns-seed/"}],"keywords":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/categories/区块链/"}]},{"title":"web3js 学习 智能合约学习","slug":"web3js 学习 智能合约学习","date":"2018-07-03T18:39:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"web3js xx znh,gyxx-20180703.html","link":"","permalink":"http://blog.msiter.com/web3js xx znh,gyxx-20180703.html","excerpt":"接下来，我们会创建一个智能合约，发布并且完成智能合约的调用。 阅读本篇文章的所需要具备的基础 熟悉 Solidity 基本的操作，可以书写 简单的智能合约 电脑上安装 truffle 用于 sol的解析，当然你也可以使用 solcjs 进行 bin 以及 abi的编译 电脑上安装 genache 用于创建一个 测试网络 当然如果你只是想在电脑运行一份，聊天智能合约的话，只需要装一个 genache 就可以了，直接跳转到最下面就可以了。","text":"接下来，我们会创建一个智能合约，发布并且完成智能合约的调用。 阅读本篇文章的所需要具备的基础 熟悉 Solidity 基本的操作，可以书写 简单的智能合约 电脑上安装 truffle 用于 sol的解析，当然你也可以使用 solcjs 进行 bin 以及 abi的编译 电脑上安装 genache 用于创建一个 测试网络 以太坊-图灵完备智能合约最佳实践者 当然如果你只是想在电脑运行一份，聊天智能合约的话，只需要装一个 genache 就可以了，直接跳转到最下面就可以了。 H2 创建 一个智能合约pragma solidity ^0.4.0; contract Chat{ bytes32[] messages; event ReceivedMessage(address fromuser,bytes32 message); function sendMessage(bytes32 message) public { messages.push(message); emit ReceivedMessage(msg.sender,message); } function test() public returns (bytes32){ bytes32 name = \"你好\"; return name; } } H2 编译 智能合约H3 使用 solcjs 编译使用命令 solcjs Chat.sol -o ./out --bin --abi ## docs solcjs [filepath] -o [outpath] [--bin or --abi] H3 使用 truffle 编译H2 web3js 调用 以及 部署智能合约H3 部署智能合约我们首先引入 web3js ， &lt;script src=\"https://cdn.jsdelivr.net/gh/ethereum/web3.js/dist/web3.min.js\">&lt;/script> 引用之后 const web3 = new Web3(new Web3.providers.HttpProvider(\"http://localhost:9545\")); const abiString = '[{\"constant\":false,\"inputs\":[{\"name\":\"message\",\"type\":\"bytes32\"}],\"name\":\"sendMessage\",\"outputs\":[],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"constant\":false,\"inputs\":[],\"name\":\"test\",\"outputs\":[{\"name\":\"\",\"type\":\"bytes32\"}],\"payable\":false,\"stateMutability\":\"nonpayable\",\"type\":\"function\"},{\"anonymous\":false,\"inputs\":[{\"indexed\":false,\"name\":\"fromuser\",\"type\":\"address\"},{\"indexed\":false,\"name\":\"message\",\"type\":\"bytes32\"}],\"name\":\"ReceivedMessage\",\"type\":\"event\"}]' const binString = '0x608060405234801561001057600080fd5b50610184806100206000396000f30060806040526004361061004c576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff168063e12c9ca814610051578063f8a8fd6d14610082575b600080fd5b34801561005d57600080fd5b5061008060048036038101908080356000191690602001909291905050506100b5565b005b34801561008e57600080fd5b5061009761012b565b60405180826000191660001916815260200191505060405180910390f35b7f8772b97689ed084ec4a4d86ec0d3b5c75e46d77b4c0cc886c5aaaf602cbc93323382604051808373ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff16815260200182600019166000191681526020019250505060405180910390a150565b6000807fe4bda0e5a5bd0000000000000000000000000000000000000000000000000000905080915050905600a165627a7a72305820d65d0484d4c51b85359ec95f030a8f84b1ccd24f9e2f4b262bdf7a9a8a4ffb0c0029' const Contract = web3.eth.contract(JSON.parse(abiString)); // Deploy contract instance const contractInstance = Contract.new({ data: binS, from: web3.eth.coinbase, gas: 90000*2 }, (err, res) => { if (err) { console.log(err); return; } // If we have an address property, the contract was deployed if (res.address) { console.log('Contract address: ' + res.address); } }); 执行完成后，我们就可以获取到我们的智能合约部署的地址了。 H3 获取智能合约 调用方法const contract = web3.eth.contract(JSON.parse(abiS)).at(&#39;0xb5c0a3f96c6f0dd334c158ee766641f1df34ef98&#39;); // 打印； call 方法，会出结果，但是不会影响到实际区块链 console.log(contract.test.call()); // 打印； sendTransaction方法，实际影响到区块链 console.log(contract.test.sendTransaction()); H3 监听 event 事件儿this.contract.ReceivedMessage(function(error,result){ // ... }) 使用该方法可以检测，智能合约中的 ReceivedMessage 事件儿。 H2 运行一个聊天 DAPPpragma solidity ^0.4.0; contract Chat{ bytes32[] messages; event ReceivedMessage(address fromuser,bytes32 message); function sendMessage(bytes32 message) public { messages.push(message); emit ReceivedMessage(msg.sender,message); } function test() public returns (bytes32){ bytes32 name = \"你好\"; return name; } } 生成 abi 和 bin 字段 const binS = &quot;0x608060405234801561001057600080fd5b506101b6806100206000396000f30060806040526004361061004c576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff168063e12c9ca814610051578063f8a8fd6d14610082575b600080fd5b34801561005d57600080fd5b5061008060048036038101908080356000191690602001909291905050506100b5565b005b34801561008e57600080fd5b5061009761015d565b60405180826000191660001916815260200191505060405180910390f35b60008190806001815401808255809150509060018203906000526020600020016000909192909190915090600019169055507f8772b97689ed084ec4a4d86ec0d3b5c75e46d77b4c0cc886c5aaaf602cbc93323382604051808373ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff16815260200182600019166000191681526020019250505060405180910390a150565b6000807fe4bda0e5a5bd0000000000000000000000000000000000000000000000000000905080915050905600a165627a7a7230582077134383b2da18c9d2798d5b3f6d4e18d7dc3dd8a8f96ee8774d75ea8e6bca970029&quot; const abiS = &#39;[ { &quot;anonymous&quot;: false, &quot;inputs&quot;: [ { &quot;indexed&quot;: false, &quot;name&quot;: &quot;fromuser&quot;, &quot;type&quot;: &quot;address&quot; }, { &quot;indexed&quot;: false, &quot;name&quot;: &quot;message&quot;, &quot;type&quot;: &quot;bytes32&quot; } ], &quot;name&quot;: &quot;ReceivedMessage&quot;, &quot;type&quot;: &quot;event&quot; }, { &quot;constant&quot;: false, &quot;inputs&quot;: [ { &quot;name&quot;: &quot;message&quot;, &quot;type&quot;: &quot;bytes32&quot; } ], &quot;name&quot;: &quot;sendMessage&quot;, &quot;outputs&quot;: [], &quot;payable&quot;: false, &quot;stateMutability&quot;: &quot;nonpayable&quot;, &quot;type&quot;: &quot;function&quot; }, { &quot;constant&quot;: false, &quot;inputs&quot;: [], &quot;name&quot;: &quot;test&quot;, &quot;outputs&quot;: [ { &quot;name&quot;: &quot;&quot;, &quot;type&quot;: &quot;bytes32&quot; } ], &quot;payable&quot;: false, &quot;stateMutability&quot;: &quot;nonpayable&quot;, &quot;type&quot;: &quot;function&quot; } ]&#39; index.html 界面 &lt;!DOCTYPE html> &lt;html> &lt;head> &lt;title>&lt;/title> &lt;script src=\"https://cdn.jsdelivr.net/gh/ethereum/web3.js/dist/web3.min.js\">&lt;/script> &lt;/head> &lt;body> 选择用户【余额=地址】:&lt;select id=\"users\">&lt;/select> &lt;ul id=\"list\">&lt;/ul> &lt;input type=\"text\" id=\"message\" name=\"\" placeholder=\"输入一些内容吧\">&lt;button onclick=\"App.sendMessage()\">发送&lt;/button> &lt;/body> &lt;script type=\"text/javascript\"> window.App = { init: function(){ const web3 = new Web3(new Web3.providers.HttpProvider(\"http://localhost:9545\")); const abiS = '[ { \"anonymous\": false, \"inputs\": [ { \"indexed\": false, \"name\": \"fromuser\", \"type\": \"address\" }, { \"indexed\": false, \"name\": \"message\", \"type\": \"bytes32\" } ], \"name\": \"ReceivedMessage\", \"type\": \"event\" }, { \"constant\": false, \"inputs\": [ { \"name\": \"message\", \"type\": \"bytes32\" } ], \"name\": \"sendMessage\", \"outputs\": [], \"payable\": false, \"stateMutability\": \"nonpayable\", \"type\": \"function\" }, { \"constant\": false, \"inputs\": [], \"name\": \"test\", \"outputs\": [ { \"name\": \"\", \"type\": \"bytes32\" } ], \"payable\": false, \"stateMutability\": \"nonpayable\", \"type\": \"function\" } ]' this.contract = web3.eth.contract(JSON.parse(abiS)).at('0xb5c0a3f96c6f0dd334c158ee766641f1df34ef98'); // 如果 没有智能合约地址，需要使用下面的方法 进行 部署智能合约并且获取智能合约地址 // const binS = \"0x608060405234801561001057600080fd5b506101b6806100206000396000f30060806040526004361061004c576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff168063e12c9ca814610051578063f8a8fd6d14610082575b600080fd5b34801561005d57600080fd5b5061008060048036038101908080356000191690602001909291905050506100b5565b005b34801561008e57600080fd5b5061009761015d565b60405180826000191660001916815260200191505060405180910390f35b60008190806001815401808255809150509060018203906000526020600020016000909192909190915090600019169055507f8772b97689ed084ec4a4d86ec0d3b5c75e46d77b4c0cc886c5aaaf602cbc93323382604051808373ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff16815260200182600019166000191681526020019250505060405180910390a150565b6000807fe4bda0e5a5bd0000000000000000000000000000000000000000000000000000905080915050905600a165627a7a7230582077134383b2da18c9d2798d5b3f6d4e18d7dc3dd8a8f96ee8774d75ea8e6bca970029\" // const contractInstance = Contract.new({ // data: binS, // from: web3.eth.coinbase, // gas: 90000*2 // }, (err, res) => { // if (err) { // console.log(err); // return; // } // // If we have an address property, the contract was deployed // if (res.address) { // console.log('Contract address: ' + res.address); // } // }); this.watch(); this.setUsers(); }, addAnother:function(fromuser,message,gasused){ var ul = document.getElementById(\"list\"); var li = document.createElement(\"li\"); var children = ul.children.length + 1 li.setAttribute(\"id\", \"element\"+children) try { li.appendChild(document.createTextNode(\"来自：\"+fromuser+\"消耗【\"+gasused+\"】\"+\":消息\"+web3.toUtf8(message))); }catch(err){ li.appendChild(document.createTextNode(\"来自：\"+fromuser+\"下号【\"+gasused+\"】\"+\":消息[\"+err+\"]\"+message)); } ul.appendChild(li) }, sendMessage:function(){ const e = document.getElementById(\"users\"); const strUser = e.options[e.selectedIndex].value; const input_view = document.getElementById(\"message\"); this.contract.sendMessage.sendTransaction(input_view.value,{from: strUser }); input_view.value = \"\"; }, watch:function(){ this.contract.ReceivedMessage(function(error,result){ this.addAnother(result.args.fromuser,result.args.message,web3.eth.getTransactionReceipt(result.transactionHash).gasUsed) this.setUsers(); }.bind(this)) }, setUsers: function(){ const datasource = web3.eth.accounts const select = document.getElementById(\"users\"); const select_index = select.selectedIndex == -1 ? 0 : select.selectedIndex select.options.length = 0; for (var i = datasource.length - 1; i >= 0; i--) { // console.log(); const balance = web3.eth.getBalance(datasource[i]); select.options[select.options.length] = new Option(balance+\"=\"+datasource[i], datasource[i]); } select.selectedIndex = select_index } } window.addEventListener('load', () => { // Checking if Web3 has been injected by the browser (Mist/MetaMask) if (typeof web3 !== 'undefined') { window.web3 = new Web3(web3.currentProvider); } else { window.web3 = new Web3(new Web3.providers.HttpProvider(\"http://127.0.0.1:9545\")); } App.init(); }); &lt;/script> &lt;/html> H3 预览 聊天 智能合约预览 web3js 学习 智能合约学习.md","categories":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/categories/区块链/"}],"tags":[{"name":"Web3js","slug":"Web3js","permalink":"http://blog.msiter.com/tags/Web3js/"},{"name":"Ethereum","slug":"Ethereum","permalink":"http://blog.msiter.com/tags/Ethereum/"},{"name":"Solidity","slug":"Solidity","permalink":"http://blog.msiter.com/tags/Solidity/"},{"name":"truffle","slug":"truffle","permalink":"http://blog.msiter.com/tags/truffle/"},{"name":"ganache","slug":"ganache","permalink":"http://blog.msiter.com/tags/ganache/"}],"keywords":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/categories/区块链/"}]},{"title":"手势密码解锁界面","slug":"手势密码解锁界面","date":"2018-06-14T13:46:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"ssmmj,xsjm-20180614.html","link":"","permalink":"http://blog.msiter.com/ssmmj,xsjm-20180614.html","excerpt":"休陪产假了，在家里实在是没什么事儿干了。每天都是洗尿布… 不过每天早上都是6.7点起床。哇。。。每一天的时间被拉长了呢 在家里的时候偶然想要创建一个 锁屏界面，下面就是我创建的额手势密码的一个例子。","text":"休陪产假了，在家里实在是没什么事儿干了。每天都是洗尿布… 不过每天早上都是6.7点起床。哇。。。每一天的时间被拉长了呢 在家里的时候偶然想要创建一个 锁屏界面，下面就是我创建的额手势密码的一个例子。 手势密码预览 H2 废话不多说接下来就是全部的代码，使用方法，复制该代码到Xcode中，使用 init(frame:) //or required init?(coder aDecoder) 手写代码和Storyboard，两种方式。其中，FingerPasswordView 宽高建议为相同的数值。 // // FingerPasswordView.swift // FingerPassWord // // Created by 荆文征 on 2018/6/14. // Copyright © 2018年 com.baimaodai. All rights reserved. // import UIKit let FingerPasswordColor = UIColor(red: 168.0/255, green: 216.0/255, blue: 185.0/255, alpha: 1) class FingerPasswordView: UIView { /// 配置手指滑动的路径的 绘制 private let fingerPasswordLayer = CAShapeLayer() /// 手势动作 private let fingerPasswordPan = FingerPasswordPanGestureRecognizer() override init(frame: CGRect) { super.init(frame: frame) __init() } required init?(coder aDecoder: NSCoder) { super.init(coder: aDecoder) __init() } private var collectionView:UICollectionView! private func __init(){ self.isUserInteractionEnabled = true fingerPasswordPan.delegate = self fingerPasswordPan.addTarget(self, action: #selector(_fingerPasswordPanHandleMethod(pan:))) addGestureRecognizer(fingerPasswordPan) let viewLayout = UICollectionViewFlowLayout() viewLayout.scrollDirection = .vertical collectionView = UICollectionView(frame: .zero, collectionViewLayout: viewLayout) collectionView.isScrollEnabled = false collectionView.isUserInteractionEnabled = false self.addSubview(collectionView) collectionView.allowsMultipleSelection = true collectionView.backgroundColor = UIColor.clear collectionView.dataSource = self collectionView.delegate = self collectionView.register(FingerPasswordCollectionCell.self, forCellWithReuseIdentifier: \"cell\") collectionView.translatesAutoresizingMaskIntoConstraints = false self.addConstraints([ NSLayoutConstraint(item: collectionView, attribute: .top, relatedBy: .equal, toItem: self, attribute: .top, multiplier: 1, constant: 0), NSLayoutConstraint(item: collectionView, attribute: .bottom, relatedBy: .equal, toItem: self, attribute: .bottom, multiplier: 1, constant: 0), NSLayoutConstraint(item: collectionView, attribute: .left, relatedBy: .equal, toItem: self, attribute: .left, multiplier: 1, constant: 0), NSLayoutConstraint(item: collectionView, attribute: .right, relatedBy: .equal, toItem: self, attribute: .right, multiplier: 1, constant: 0), ]) self.fingerPasswordLayer.fillColor = UIColor.clear.cgColor self.fingerPasswordLayer.lineWidth = 3 self.fingerPasswordLayer.lineJoin = kCALineCapRound self.fingerPasswordLayer.lineCap = kCALineCapRound self.fingerPasswordLayer.strokeColor = FingerPasswordColor.cgColor self.layer.addSublayer(self.fingerPasswordLayer) } private var path = UIBezierPath() private var movePanPoint:CGPoint! private var throughPanCell = [FingerPasswordCollectionCell](){ didSet{ if let first = self.throughPanCell.first { let path = UIBezierPath() path.move(to: first.center) for (index,cell) in self.throughPanCell.enumerated() { if index == 0 { continue } path.addLine(to: cell.center) } self.path = path } } } } // MARK: - UICollectionViewDataSource extension FingerPasswordView: UICollectionViewDataSource { func collectionView(_ collectionView: UICollectionView, numberOfItemsInSection section: Int) -> Int { return 9 } func collectionView(_ collectionView: UICollectionView, cellForItemAt indexPath: IndexPath) -> UICollectionViewCell { let cell = collectionView.dequeueReusableCell(withReuseIdentifier: \"cell\", for: indexPath) return cell } } // MARK: - UICollectionViewDelegateFlowLayout extension FingerPasswordView: UICollectionViewDelegateFlowLayout { func collectionView(_ collectionView: UICollectionView, layout collectionViewLayout: UICollectionViewLayout, sizeForItemAt indexPath: IndexPath) -> CGSize { return CGSize(width: (frame.width-20)/3, height: (frame.width-20)/3) } func collectionView(_ collectionView: UICollectionView, layout collectionViewLayout: UICollectionViewLayout, minimumLineSpacingForSectionAt section: Int) -> CGFloat { return 10 } func collectionView(_ collectionView: UICollectionView, layout collectionViewLayout: UICollectionViewLayout, minimumInteritemSpacingForSectionAt section: Int) -> CGFloat { return 10 } } // MARK: - UIPanGestureRecognizer Handle Extension extension FingerPasswordView { /// Pan GetstureRecongnizer Handle Method @objc fileprivate func _fingerPasswordPanHandleMethod(pan:UIPanGestureRecognizer){ switch pan.state { case .began: break case .changed: _movePointMethod(point: pan.location(in: pan.view)) default: _movePointMethod(point: nil) } // print(pan.location(in: pan.view).x) } /// 手势滑动对象 滑动 处理方法 /// /// - Parameter point: point private func _movePointMethod(point:CGPoint?){ if let cell = identifyFootprintsMethod() { appendFingerCellMethod(cell: cell) } let _path = path.copy() as! UIBezierPath if let _point = point { _path.addLine(to: _point) } self.fingerPasswordLayer.path = _path.cgPath } } extension FingerPasswordView: UIGestureRecognizerDelegate{ /// 手势 是否开始处理 /// /// - Parameter gestureRecognizer: 手势处理 /// - Returns: 是否开始处理该手势 override func gestureRecognizerShouldBegin(_ gestureRecognizer: UIGestureRecognizer) -> Bool { if let cell = identifyFootprintsMethod() { appendFingerCellMethod(cell: cell) return true } return false } /// 辨识足迹 根据Point 进行相对应的数据处理 /// /// - Returns: 当前的足迹 是否涉及到了某个 Cell func identifyFootprintsMethod() -> FingerPasswordCollectionCell?{ let localPoint = self.fingerPasswordPan.location(in: fingerPasswordPan.view) for _cell in self.collectionView.visibleCells where ((_cell as? FingerPasswordCollectionCell) != nil) { let cell = _cell as! FingerPasswordCollectionCell let frame = self.convert(cell.spotView.frame, from: cell) if frame.contains(localPoint) { return cell } } return nil } /// 经过点新增 一个 Cell /// /// - Parameter cell: Cell func appendFingerCellMethod(cell:FingerPasswordCollectionCell){ guard !self.throughPanCell.contains(cell) else { return } self.throughPanCell.append(cell) self.collectionView.selectItem(at: self.collectionView.indexPath(for: cell), animated: true, scrollPosition: UICollectionViewScrollPosition.bottom) } } import UIKit.UIGestureRecognizerSubclass /// UIPanGestureRecognizer do something immediately when touched /// Is there a way to increase the size of a puzzle piece once the finger has touched the puzzle piece and then continue with the pan gesture. /// /// source: https://stackoverflow.com/a/19145354/4242817 /// Make appropriate modifications class FingerPasswordPanGestureRecognizer: UIPanGestureRecognizer { override func touchesBegan(_ touches: Set&lt;UITouch>, with event: UIEvent) { if (self.state == UIGestureRecognizerState.began) { return } super.touchesBegan(touches, with: event) self.state = UIGestureRecognizerState.began } } /// SubView class FingerPasswordCollectionCell: UICollectionViewCell { let spotView = UIView() private let apertureView = UIView() private let lable = UILabel() override init(frame: CGRect) { super.init(frame: frame) self.contentView.addSubview(apertureView) self.contentView.addSubview(spotView) spotView.translatesAutoresizingMaskIntoConstraints = false self.contentView.addConstraints([ NSLayoutConstraint(item: spotView, attribute: .centerX, relatedBy: .equal, toItem: self.contentView, attribute: .centerX, multiplier: 1, constant: 0), NSLayoutConstraint(item: spotView, attribute: .centerY, relatedBy: .equal, toItem: self.contentView, attribute: .centerY, multiplier: 1, constant: 0), NSLayoutConstraint(item: spotView, attribute: .width, relatedBy: .equal, toItem: nil, attribute: .notAnAttribute, multiplier: 1, constant: 20), NSLayoutConstraint(item: spotView, attribute: .height, relatedBy: .equal, toItem: nil, attribute: .notAnAttribute, multiplier: 1, constant: 20), ]) apertureView.translatesAutoresizingMaskIntoConstraints = false self.contentView.addConstraints([ NSLayoutConstraint(item: apertureView, attribute: .centerX, relatedBy: .equal, toItem: self.contentView, attribute: .centerX, multiplier: 1, constant: 0), NSLayoutConstraint(item: apertureView, attribute: .centerY, relatedBy: .equal, toItem: self.contentView, attribute: .centerY, multiplier: 1, constant: 0), NSLayoutConstraint(item: apertureView, attribute: .width, relatedBy: .equal, toItem: nil, attribute: .notAnAttribute, multiplier: 1, constant: 40), NSLayoutConstraint(item: apertureView, attribute: .height, relatedBy: .equal, toItem: nil, attribute: .notAnAttribute, multiplier: 1, constant: 40), ]) spotView.layer.cornerRadius = 10 apertureView.layer.cornerRadius = 20 spotView.clipsToBounds = true apertureView.clipsToBounds = true self.isSelected = false } required init?(coder aDecoder: NSCoder) { fatalError(\"init(coder:) has not been implemented\") } override var isSelected: Bool{ didSet{ UIView.animate(withDuration: 0.3) { if self.isSelected { self.spotView.backgroundColor = FingerPasswordColor self.apertureView.backgroundColor = FingerPasswordColor.withAlphaComponent(0.3) }else{ self.spotView.backgroundColor = UIColor.gray.withAlphaComponent(0.3) self.apertureView.backgroundColor = UIColor.clear } } } } } H2 创建一个 九宫格本来打算使用九个UIView去创建一个九宫格视图，但是最后还是打算使用UICollectionView来创建，主要在于他针对于后期的一些维护会很方便，比如当想要选中展示错误的时候，我们可以根据选中的Cell处理如下： self.throughPanCell.forEach { (cell) in // .. cell configure method } // - OR self.throughPanCell.map{ cell as? CUSTOMCELL }.filter{ $0 != nil }.map{ cell as! CUSTOMCELL }.forEach{(cell) in // .. cell.wrong() } 我们其实还可以抽象一个配置对象,将这些代码发布出去，但是主要还是不知道如何处理，自定义cell和 注册 identifier的问题。总觉得每一个自定义的视图都注册的话，会觉的很麻烦。 H2 使用 UICollectionView的好处因为 ColletionViewCell 本身就存在 Selected 状态，所以不需要额外配置很多方法。 只需要创建如下方法就可以实现 override var isSelected: Bool{ didSet{ UIView.animate(withDuration: 0.3) { if self.isSelected { self.spotView.backgroundColor = FingerPasswordColor self.apertureView.backgroundColor = FingerPasswordColor.withAlphaComponent(0.3) }else{ self.spotView.backgroundColor = UIColor.gray.withAlphaComponent(0.3) self.apertureView.backgroundColor = UIColor.clear } } } } 手势密码解锁界面.md","categories":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/categories/ios/"}],"tags":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"手势密码","slug":"手势密码","permalink":"http://blog.msiter.com/tags/手势密码/"}],"keywords":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/categories/ios/"}]},{"title":"创建自己的Cocoapods 源","slug":"创建自己的Cocoapods源","date":"2018-05-18T11:14:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"cjzjdCocoapodsy-20180518.html","link":"","permalink":"http://blog.msiter.com/cjzjdCocoapodsy-20180518.html","excerpt":"这个问题和Maven的自己的本地源一样，就是想向 Cocoapods Spac 一样的工作。那么接下来我们就来结合一个我现实中遇到的实例来实现这个问题 最近公司需要引入百度的人脸识别，以及身份证等文字识别两个sdk，但是百度这种大公司，根本不会让你很舒服的引入，只能手动引入，但是我不是很喜欢，所以我就使用本地 Cocoapods 来完成这个事情。 在使用的时候，遇到了一些问题，特此记录一下","text":"这个问题和Maven的自己的本地源一样，就是想向 Cocoapods Spac 一样的工作。那么接下来我们就来结合一个我现实中遇到的实例来实现这个问题 最近公司需要引入百度的人脸识别，以及身份证等文字识别两个sdk，但是百度这种大公司，根本不会让你很舒服的引入，只能手动引入，但是我不是很喜欢，所以我就使用本地 Cocoapods 来完成这个事情。 在使用的时候，遇到了一些问题，特此记录一下 H2 本地设置文字识别Frameworks最开始，我第一个制作的是 文字识别 我们只需要创建一个 PodSpec文件 Pod::Spec.new do |spec| spec.name = 'AipOcr' spec.version = '0.0.1' spec.license = { :type => 'MIT' } spec.homepage = 'https://ai.baidu.com/sdk#ocr' spec.authors = { 'baidu .Inc' => 'https://baidu.com' } spec.summary = 'Baidu ocr [idcard,bankcard...].' spec.source = { :git => 'git@github.com:aimobier/AipOcr.git', :tag => '0.0.1' } spec.vendored_frameworks = 'AipBase.framework','AipOcrSdk.framework', 'IdcardQuality.framework' end 将该文件，放置在本地的文件夹中,一般放置在根目录。比如在根目录下，创建一个 AipOcr 文件夹 将需要的 spec.vendored_frameworks = &#39;AipBase.framework&#39;,&#39;AipOcrSdk.framework&#39;, &#39;IdcardQuality.framework&#39; 三个文件，放置在 AipOcr 下，在 pod 文件中使用 pod 'AipOcr', :path => 'AipOcr' 即可。 H2 人脸识别 SDK 引入但是在这里，我出现了问题，最主要的问题就是。人脸识别包含两个库，一个简单来说就是 FaceSDK，一个是 FaceUISdk 其中 FaeUISDK需要 FaceSDK。 spec.vendored_frameworks = '' 最开始使用这个方式，来进行导入依赖。但是，编译中发现， 系统认为 FaceUISDK 是 FaceSDK的，所以不对外公开 我们只能使用 spec.dependency 'FaceSDK' 但是这里出现的问题就是，我并不想提交 FaceSDK到实际的 Spce仓库中，只希望自己用用。 H2 私人源其实私人源，特别简单，就是在pod install，你需要告诉Cocoapods，要在哪里查找这些依赖的第三方插件。 H3 直接在 Podfile文件中增加源我们在 Podfile 文件中，增加源的配置方法。 source 'https://github.com/CocoaPods/Specs.git' source 'https://github.com/aimobier/Specs.git' H3 使用命令增加源pod repo add master https://git.coding.net/CocoaPods/Specs.git pod repo update 一劳永逸，但是没测试，不清楚 H3 配置仓库内容这时候你在你的仓库，直接放置类似于 . ├── AipOcr │ └── 0.0.1 │ └── AipOcr.podspec ├── FaceSDK │ └── 0.0.2 │ └── FaceSDK.podspec ├── LICENSE └── README.md 目录就可以了。 H3 使用使用 pod update ，就可以使用了 创建自己的Cocoapods源.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/tags/IOS/"},{"name":"cocoapods","slug":"cocoapods","permalink":"http://blog.msiter.com/tags/cocoapods/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"使用DataTable来展示修改历史","slug":"使用dataTable来展示修改历史专栏","date":"2018-04-24T10:41:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"sydataTablelzsxglszl-20180424.html","link":"","permalink":"http://blog.msiter.com/sydataTablelzsxglszl-20180424.html","excerpt":"昨天在整理博客的时候，发现还是存在一些问题的，比如搜素时候貌似中文搜索不出来？还有就是我的修改历史存在如果修改历史过多，内容会过于向下，导致内容出现乱掉的情况。 今天我就打算使用DataTable修复这个问题，当然是通过分页的方式，你可以使用任意一种分页的方式解决这个问题。","text":"昨天在整理博客的时候，发现还是存在一些问题的，比如搜素时候貌似中文搜索不出来？还有就是我的修改历史存在如果修改历史过多，内容会过于向下，导致内容出现乱掉的情况。 今天我就打算使用DataTable修复这个问题，当然是通过分页的方式，你可以使用任意一种分页的方式解决这个问题。 H2 DataTablesDataTables 是一个非常好的插件，包含非常多的功能，并且官方的教程非常的完备，让你学习起来不会有太大的阻碍。 哎哟…. 我发觉的 Datatable 主页改版了…. DataTables | Table plug-in for jQuery 这比以前的那个样子好看多了… 以前让人觉的是真的技术人员写的网页，现在看起来就大气多了… 好了，废话不多说，这里我也不想多多介绍Datatables .. 具体的话 我会考虑会面出一篇文章来讲解一下这个插件 H2 修复 UI 层面的问题接下来，我们会一步步的记录我所遇到的问题以及解决方法。 H3 创建Datatable首先，我是用的是 HTML (DOM) sourced data方式，直接创建的table,这种方式是说，首先创建一个完善的 Table ，之后在使用 DataTable 方法进行一些配置。 在我们上一篇讲解到如何请求 commit ，我们请求完成之后，生成了的是 li 标签，这里我们把他们包围在 tr td 中，之后填充到 tbody 中，再调用 Datatable 就可以看到效果了。 $(\"#commit-history-new-body\").html(liRes.join(\"\")); $('#commit-history-new').DataTable(); 至此，我们已经可以看到，我们的内容展示在Datatable了。但是我们也发现又很多我们不需要的内容。比如 选择器，分页，搜索，信息之类的。 H3 隐藏一些内容$(\"#commit-history-new-body\").html(liRes.join(\"\")); $('#commit-history-new').DataTable({ autoWidth: false, ordering: false, searching: false, lengthChange: false, pageLength: 2, info: false }); 修改配置，我们可以看到，我们的排序，搜索，每页展示2个，结果信息也隐藏了。 H3 配置 pager接下来我们来进行分页的配置 $('#commit-history-new').DataTable({ data: datas, autoWidth: false, ordering: false, searching: false, lengthChange: false, pageLength: 4, info: false, pagingType: \"cutsomPage\" }); 我们之前的配置，放上之后，发现了一个问题，我们的搜索和修改内容却出现了冲突，接下来我们修改分页器 H4 点击分页器置顶问题我们之前的分页器，使用的&lt;a&gt;标签的 href 为 # ，这样带来的问题会导致我们点击超链接的时候，会跳转到顶部。有两种方法可以解决这个问题。 function NextConMethod(){ var resString = '\\ &lt;li class=\"list-inline-item float-sm-right\">\\ &lt;a class=\"u-pagination-v1__item u-pagination-v1-4 g-rounded-50 g-pa-7-16\" aria-label=\"Next\">\\ &lt;span aria-hidden=\"true\">\\ 下一页\\ &lt;i class=\"fa fa-angle-right g-ml-5\">&lt;/i>\\ &lt;/span>\\ &lt;span class=\"sr-only\">Next&lt;/span>\\ &lt;/a>\\ &lt;/li>\\ '; // 直接删除 href 属性 return resString; }; function NormalNumberConMethod(number){ var resString = '\\ &lt;li class=\"list-inline-item g-hidden-sm-down hidden-all-list-li-link-elment\">\\ &lt;a class=\"u-pagination-v1__item u-pagination-v1-4 g-rounded-50 g-pa-7-14\" href=\"javascript:void(0)\">'+number+'&lt;/a>\\ &lt;/li>'; // javascript:void(0) 解决该问题 return resString; }; 直接删除 href 属性 javascript:void(0) 解决该问题 H4 分页器的扩展性在共同使用的时候，由于我们之前很多属性修改的选择器都是使用的ID，导致我们在进行两个视图同时存在的时候会出现问题。 const selectorStr = oSettings.oInstance.selector+'_paginate'; // 通过该方法 可以获取到 分页器的id 并且完成获取Element 的操作 我们通过 oSettings.oInstance.selector 可以获取到分页器所服务器的ID，我们通过选择器，添加 _paginate获取到分页器。 if (oSettings._iCurrentPage === 1) { $(selectorStr+' a[aria-label=\"Previous\"]').addClass(\"u-pagination-v1__item--disabled\"); } else { $(selectorStr+' a[aria-label=\"Previous\"]').removeClass(\"u-pagination-v1__item--disabled\"); } if (oSettings._iTotalPages === 0 || oSettings._iCurrentPage === oSettings._iTotalPages) { $(selectorStr+' a[aria-label=\"Next\"]').addClass(\"u-pagination-v1__item--disabled\"); } else { $(selectorStr+' a[aria-label=\"Next\"]').removeClass(\"u-pagination-v1__item--disabled\"); } /// OR ->>>>>>>>> var i, oNumber, oNumbers = $(selectorStr+\" ul[class='list-inline']\"); $(selectorStr+\" .hidden-all-list-li-link-elment\").remove(); H4 页码展示问题修复我们之前的分页器有默认配置的 iShowPages 为3 第三个问题， 配饰 iShowPages ，在之前我们设置了为三个，但是由于之前的代码为 var iShowPages = oSettings.oInit.iShowPages || this.default.iShowPages, 导致即使我们想不显示页码也会不得不显示3个，所以我们作出一下修改 var iShowPages = oSettings.oInit.iShowPages; 并且在下方生成 页码的方法中增加判断方法，不需要展示的时候直接返回。 if (!oSettings._iShowPages) { return; } H2 安全访问属性问题之前没有遇到过这个问题，现在遇到了js访问属性的空值问题。 比如 a.b.c.d 其中，b不存在，那么会报错。 这个在Swift中还是很好解决的 a?.b?.c?.d 就可以解决了。但是貌似js没有这个东西，目前好像还在开发中。 那么我们就是用如下方法 以下内容是 Twitter引用，需要翻墙查阅 In case you need a idx function.const idx = (p, o) =&gt; p.reduce((xs, x) =&gt; (xs &amp;&amp; xs[x]) ? xs[x] : null, o)Access deeply nested values… pic.twitter.com/lyoUIZudF7&mdash; A. Sharif (@sharifsbeat) 2017年3月18日 const get = (p, o) => p.reduce((xs, x) => (xs &amp;&amp; xs[x]) ? xs[x] : undefined, o) // const commit = safe(comm); const date = new Date(commit.commit.committer.date); commit_commit_message = (get(['commit','message'],commit) || \"no message\").replace(/\\n/g, \"&lt;br>\") commit_sha = get(['sha'],commit) || \"\"; commit_author_html_url = get(['author','html_url'],commit) || \"\"; commit_author_avatar_url = get(['author','avatar_url'],commit) || \"\" ; commit_html_url = get(['html_url'],commit) || \"\"; commit_author_login = get(['author','login'],commit) || \"\"; 至此所有问题就都解决了。 所有涉及到的代码，都可以在本篇文章提交的commit中查看。 使用dataTable来展示修改历史专栏.md","categories":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}],"tags":[{"name":"博客美化","slug":"博客美化","permalink":"http://blog.msiter.com/tags/博客美化/"},{"name":"hexo","slug":"hexo","permalink":"http://blog.msiter.com/tags/hexo/"}],"keywords":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}]},{"title":"给博客文章增加修改历史专栏","slug":"给博客文章增加修改历史专栏","date":"2018-04-23T15:11:00.000Z","updated":"2018-08-29T10:33:16.506Z","comments":true,"path":"g,jbkwzzjxglszl-20180423.html","link":"","permalink":"http://blog.msiter.com/g,jbkwzzjxglszl-20180423.html","excerpt":"很久没有更新文章了，总想着最近要写点什么。 看着自己的博客，觉的修改历史还是比较帅气的，那么这次我们来谈一下如何实现修改历史吧。 修改历史，其实无非就是git commit历史，那么我们就来一步步的讲一讲我是如何实现，这个修改历史功能的吧。","text":"很久没有更新文章了，总想着最近要写点什么。 看着自己的博客，觉的修改历史还是比较帅气的，那么这次我们来谈一下如何实现修改历史吧。 修改历史，其实无非就是git commit历史，那么我们就来一步步的讲一讲我是如何实现，这个修改历史功能的吧。 H2 获取git commit 历史我目前的博客使用github pages 功能，所以获取git commit 功能是github api 提供的，我们可以这个样子获取到。 发起一个GET请求，请求地址为https://api.github.com/repos/{仓库所有人名称}/{仓库名称}/commits以我的博客仓库地址为例就是https://api.github.com/repos/aimobier/aimobier.github.io/commits 这个请求需要 我就一展示数据的表格 参数名称 含义 sha 目标分支 path 目标文件路径 这个时候我们可以先尝试一下https://api.github.com/repos/aimobier/aimobier.github.io/commits?sha=master&amp;path=404.html [ { \"sha\": \"72aa633b57313257e643e5b3d3216b34f22406f1\", \"commit\": { \"author\": { \"name\": \"aimobier\", \"email\": \"200739491@qq.com\", \"date\": \"2018-04-17T06:37:07Z\" }, \"committer\": { \"name\": \"aimobier\", \"email\": \"200739491@qq.com\", \"date\": \"2018-04-17T06:37:07Z\" }, \"message\": \"Site updated: 2018-04-17 06:36:56\", \"tree\": { \"sha\": \"7eb0a9f414c576382bf0aae5f375829e79383758\", \"url\": \"https://api.github.com/repos/aimobier/aimobier.github.io/git/trees/7eb0a9f414c576382bf0aae5f375829e79383758\" }, \"url\": \"https://api.github.com/repos/aimobier/aimobier.github.io/git/commits/72aa633b57313257e643e5b3d3216b34f22406f1\", \"comment_count\": 0, \"verification\": { \"verified\": false, \"reason\": \"unsigned\", \"signature\": null, \"payload\": null } }, \"url\": \"https://api.github.com/repos/aimobier/aimobier.github.io/commits/72aa633b57313257e643e5b3d3216b34f22406f1\", \"html_url\": \"https://github.com/aimobier/aimobier.github.io/commit/72aa633b57313257e643e5b3d3216b34f22406f1\", \"comments_url\": \"https://api.github.com/repos/aimobier/aimobier.github.io/commits/72aa633b57313257e643e5b3d3216b34f22406f1/comments\", \"author\": { \"login\": \"aimobier\", \"id\": 6121524, \"avatar_url\": \"https://avatars2.githubusercontent.com/u/6121524?v=4\", \"gravatar_id\": \"\", \"url\": \"https://api.github.com/users/aimobier\", \"html_url\": \"https://github.com/aimobier\", \"followers_url\": \"https://api.github.com/users/aimobier/followers\", \"following_url\": \"https://api.github.com/users/aimobier/following{/other_user}\", \"gists_url\": \"https://api.github.com/users/aimobier/gists{/gist_id}\", \"starred_url\": \"https://api.github.com/users/aimobier/starred{/owner}{/repo}\", \"subscriptions_url\": \"https://api.github.com/users/aimobier/subscriptions\", \"organizations_url\": \"https://api.github.com/users/aimobier/orgs\", \"repos_url\": \"https://api.github.com/users/aimobier/repos\", \"events_url\": \"https://api.github.com/users/aimobier/events{/privacy}\", \"received_events_url\": \"https://api.github.com/users/aimobier/received_events\", \"type\": \"User\", \"site_admin\": false }, \"committer\": { \"login\": \"aimobier\", \"id\": 6121524, \"avatar_url\": \"https://avatars2.githubusercontent.com/u/6121524?v=4\", \"gravatar_id\": \"\", \"url\": \"https://api.github.com/users/aimobier\", \"html_url\": \"https://github.com/aimobier\", \"followers_url\": \"https://api.github.com/users/aimobier/followers\", \"following_url\": \"https://api.github.com/users/aimobier/following{/other_user}\", \"gists_url\": \"https://api.github.com/users/aimobier/gists{/gist_id}\", \"starred_url\": \"https://api.github.com/users/aimobier/starred{/owner}{/repo}\", \"subscriptions_url\": \"https://api.github.com/users/aimobier/subscriptions\", \"organizations_url\": \"https://api.github.com/users/aimobier/orgs\", \"repos_url\": \"https://api.github.com/users/aimobier/repos\", \"events_url\": \"https://api.github.com/users/aimobier/events{/privacy}\", \"received_events_url\": \"https://api.github.com/users/aimobier/received_events\", \"type\": \"User\", \"site_admin\": false }, \"parents\": [ { \"sha\": \"191f968e43f2685925cba24cfa49fe7465fc99d3\", \"url\": \"https://api.github.com/repos/aimobier/aimobier.github.io/commits/191f968e43f2685925cba24cfa49fe7465fc99d3\", \"html_url\": \"https://github.com/aimobier/aimobier.github.io/commit/191f968e43f2685925cba24cfa49fe7465fc99d3\" } ] } ] 至此，我们已经可以获取到自己的commit日志了，那么接下来的问题就是，如何知道文件的名称了 H2 获取文件的路径我们的每一篇文章，文件名称和标题是不一定存在的。当然我们可以将标题和文件名称自己去约束自己完成这个操作，这样子我们直接使用标题拼接字符串就可以完成路径的获取了，但是这种需要人为配置的方式，我不是很喜欢，要是写错了，那还得配置很久呢。 所以我们来试用一下方式来完成该操作。 首先我们创建一个脚本拦截文章配置之后的事件儿after_post_render 我们之前的文章筛选代码如下 /** * Created by jingwenzheng on 2018/3/8. */ var cheerio; hexo.extend.filter.register('after_post_render', function(data){ if (!cheerio) cheerio = require('cheerio'); var $ = cheerio.load(data.content); ulliHandle($); codeHandle($); imageHandle($); blockquoteHandle($); handleTable($); data.content = $.html(); return data; }); 我们接下来需要增加一个 hidden 标签，让它来存储我们需要的路径字段 /** * Created by jingwenzheng on 2018/3/8. */ var cheerio; hexo.extend.filter.register('after_post_render', function(data){ const appendHtmlString = '\\ &lt;p hidden id=\"CurrentFileName\">'+data.full_source.split(\"/\").slice(-1)[0]+'&lt;/p>\\ '; data.content += appendHtmlString; if (!cheerio) cheerio = require('cheerio'); var $ = cheerio.load(data.content); ulliHandle($); codeHandle($); imageHandle($); blockquoteHandle($); handleTable($); data.content = $.html(); return data; }); 这样子我们就可以使用 $(&quot;#CurrentFileName&quot;)获取到我们的额路径地址了 H2 最终完成好了，现在我们万事俱备让我们来书写我们的最终代码吧。 const GitHubHistoryReq = { requestBodyParams: { sha: \"make-blog\", // 分支名称 path: \"source/_posts/\", // 文章存储路径 paramF: function(fn) { // 返回请求的参数对象 return { sha: \"make-blog\", path: \"source/_posts/\" + fn, } } }, requestUrlParams: { user: \"aimobier\", // 用户名称 repos: \"aimobier.github.io\", // 仓库名称 urlF: function() { // 返回完整的请求链接地址 return \"https://api.github.com/repos/\" + this.user + \"/\" + this.repos + \"/commits\"; } }, Request: function() { const fileName = $(\"#CurrentFileName\").text(); if (fileName !== null || fileName !== undefined || fileName !== '') { $.getJSON(this.requestUrlParams.urlF(), this.requestBodyParams.paramF(fileName), this.requestSuccess.bind(this)); }; }, timeSince: function(date) { var seconds = Math.floor((new Date() - date) / 1000); var interval = Math.floor(seconds / 31536000); if (interval > 1) { return interval + \" years ago\"; } interval = Math.floor(seconds / 2592000); if (interval > 1) { return interval + \" months ago\"; } interval = Math.floor(seconds / 86400); if (interval > 1) { return interval + \" days ago\"; } interval = Math.floor(seconds / 3600); if (interval > 1) { return interval + \" hours ago\"; } interval = Math.floor(seconds / 60); if (interval > 1) { return interval + \" minutes ago\"; } return Math.floor(seconds) + \" seconds ago\"; }, returnHtmlElment: function(commit) { const date = new Date(commit.commit.committer.date); commit.commit.message = commit.commit.message.replace(/\\n/g,\"&lt;br>\"); return '\\ &lt;li class=\"media g-brd-around g-brd-gray-light-v4 g-pa-20 g-mb-minus-1\">\\ &lt;div class=\"d-flex g-mt-2 g-mr-15\">\\ &lt;a target=\"_blank\" href=\"' + commit.author.html_url + '\">&lt;img class=\"g-width-30 g-height-30 rounded-circle\" src=\"' + commit.author.avatar_url + '\" alt=\"Image Description\">&lt;/a>\\ &lt;/div>\\ &lt;div class=\"media-body\">\\ &lt;div class=\"d-flex justify-content-between\">\\ &lt;a target=\"_blank\" href=\"' + commit.author.html_url + '\">&lt;strong class=\"g-font-size-9\">' + commit.author.login + '&lt;/strong>&lt;/a>\\ &lt;a target=\"_blank\" href=\"' + commit.html_url + '\">&lt;span class=\"align-self-center g-font-size-9 text-nowrap\">' + (commit.sha.slice(0, 5) + '..') + '&lt;/span>&lt;/a>\\ &lt;/div>\\ &lt;span class=\"align-self-center g-font-size-9 text-nowrap g-color-gray-dark-v4\">'+timeago(null, 'zh_CN').format(date)+'&lt;/span>\\ &lt;span class=\"d-block g-font-size-11\">' + commit.commit.message + '&lt;/span>\\ &lt;/div>\\ &lt;/li>\\ '; }, requestSuccess: function(body) { var liRes = body.map(function(item, index, input) { return this.returnHtmlElment(item); }.bind(this)); $(\"#commit-history\").html(liRes.join(\"\")); }, editHtmlMethod:function(){ const fileName = $(\"#CurrentFileName\").text(); const urlString = \"https://github.com/aimobier/aimobier.github.io/tree/make-blog/source/_posts/\"+fileName; const editHtml = '\\ &lt;li class=\"list-inline-item g-mx-10\">/&lt;/li>\\ &lt;li class=\"list-inline-item g-mr-10\">\\ &lt;a target=\"_blank\" class=\"u-link-v5 g-color-deeporange g-color-orange--hover\" href=\"'+urlString+'\">\\ &lt;i class=\"align-middle mr-2 fa fa-edit u-line-icon-pro\">&lt;/i>发现错误，编辑本页\\ &lt;/a>\\ &lt;/li>\\ '; $(\"#editHtmlElement\").append(editHtml); } } $(function() { GitHubHistoryReq.Request(); GitHubHistoryReq.editHtmlMethod(); }); 我们最终在 editHtmlMethod 方法中，完成了历史的植入。另外的布局不在这里展开了。 可以查阅 c7b07a2a730b77620e012e22d7e6d5daec25fdd4 来具体查看我的代码。 H2 增加编辑本页其实我们已经做到这一步了，这个就很简单了，无非就是增加一个链接的事儿了。增加链接的目的就是让用户点击可以到用户所查看的文章的源文件。 把我们的本篇文章的链接，贴到页面，用户可以提交修改内容，我们只需要进行审批就好了。 给博客文章增加修改历史专栏.md","categories":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}],"tags":[{"name":"博客美化","slug":"博客美化","permalink":"http://blog.msiter.com/tags/博客美化/"},{"name":"hexo","slug":"hexo","permalink":"http://blog.msiter.com/tags/hexo/"}],"keywords":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}]},{"title":"隔离见证 闪电网络 理解","slug":"比特币隔离见证和闪电网络理解","date":"2018-04-16T17:25:00.000Z","updated":"2018-08-29T10:33:16.506Z","comments":true,"path":"btbglj,xzhsdwllj,x-20180416.html","link":"","permalink":"http://blog.msiter.com/btbglj,xzhsdwllj,x-20180416.html","excerpt":"bitcoin也许是有这样那样的问题，但是它是划时代的，面向未来的一次实验。 如今反对bitcoin的人的观点都是使用现今经济模式理论的，但他们有严重的逻辑缺陷——显然bitcoin是用来破坏这一模式的。 比如很多人阐述的bitecoin没有政府信用担保。事实上政府的存在也是依靠大众的信用。政府的信用只不过是大众赋予的。bitcoin本身就是大众（目前来说还是少数人）对政府控制铸币权的挑战。","text":"要是可以回到5年前。一定要买比特币。 bitcoin也许是有这样那样的问题，但是它是划时代的，面向未来的一次实验。 如今反对bitcoin的人的观点都是使用现今经济模式理论的，但他们有严重的逻辑缺陷——显然bitcoin是用来破坏这一模式的。 比如很多人阐述的bitecoin没有政府信用担保。事实上政府的存在也是依靠大众的信用。政府的信用只不过是大众赋予的。bitcoin本身就是大众（目前来说还是少数人）对政府控制铸币权的挑战。 接下来我们会从以下这几个方面完成一些讨论。 H2 隔离见证 Segregated Witness, or SegWit, is the name used for an implemented soft fork change in the transaction format of the cryptocurrency bitcoin, which has also been implemented on currencies such as Litecoin, DigiByte, Vertcoin and Feathercoin 在SegWit Wikipedia中，我们可以看到，主要是为了防止延展性。所以接下来我们先来看看，如果没有隔离见证会发生什么样的问题呢？ H3 为什么需要隔离见证久负盛名的比特币交易所 MT.Gox 莫名其妙就破产了，MT.Gox 在比特币的发展史上作用巨大，一直作为比特币价格的风向标。直到上周它宣布破产，先前的“谣言”得到证实，人们才敢相信 MT.Gox 真的是倒闭了。 MT.Gox 在 2010 年就开始了比特币交易，比特币象征着自由、民主，具备改变世界金融秩序的潜力，MT.Gox 作为交易所也因此印上了离经叛道的光环。MT.Gox 尽管对比特币的发展贡献巨大，但作为一个交易所，一个商业机构，本身却做得一团糟，尤其是内部管理混乱、缺乏经验。 这种混乱的结果是，MT.Gox 逐渐积重难返，最后被黑客轻易得手，偷走了 4.6 亿美元的资产，MT.Gox 就此终结。连线记者讲述了这段离奇的故事，MT.Gox 最早是美国企业家 Jed McCaleb 在 2010 年 7 月创办，域名注册于 2007 年，并在 2010 年底转为比特币交换平台。McCaleb 想法很简单，当时一个比特币已经可兑换数美元，而且挖矿机正在源源不断地产出新的比特币，他想建立一个交易所连接买家和卖家。 很快，这个交易所花光了 McCaleb 所有的积蓄，他意识到自己玩不下去了，于是出售给另一位比特币爱好者，网名叫 Magicaltux。 Magicaltux 正是 Mark Karpeles 的网名，他在法国出生，出生后在以色列呆了很长时间，最后定居日本、结婚，成为一名父亲。Karpeles 的生活可谓用悠闲来形容，除了照顾孩子，闲时还喜欢发一些猫咪的视频。当然，他喜欢比特币，2011 年，他将 MT.Gox 收购。 Karpeles 将网站的后端软件重写，改进了用户体验，加上他在比特币社区的活跃，越来越多的人在这里交易比特币，最终它变成了最流行的交易平台，承担着全球 70% 的交易。 这次收购促成 MT.Gox 一跃成为市场的领头羊，事实证明，Karpeles 对于技术的精通在网站发展初期十分有效，但是在后期，Karpeles 在商业管理的不足逐渐凸现出来，但 MT.Gox 并未因此做出改变。 比特币价格的飞涨给参与进来的人巨大的回报，MT.Gox 处理的流水越来越多，通过手续费累积的比特币也越来越多，数量达到了 10 万级别，总价值数千万美元。Karpeles 的身价也水涨船高，他拥有 MT.Gox 88% 的股权，前任拥有者 McCaleb 拥有剩余的 12%。 比特币的交易是建立在信用基础上，作为一名比特币爱好者，Karpeles 很注重外界对他的评价，这种想法甚至高于 MT.Gox 在商业上的成功。根据内部员工透露，他总是跟人说起自己是门萨俱乐部的一员，拥有高于常人的 IQ，这名员工说道： Mark Karpeles “他喜欢被赞扬的感觉，喜欢被叫做比特币之王。” Karpeles 花费 5000 个比特币建立比特币基金会，在其中出任董事会成员，这是一个非盈利性组织，这将给他在比特币世界里带来威望。 但这些光环却掩盖不了 MT.Gox 在业务上的问题，MT.Gox 就像是在等待灾难来临，却从不去解决问题。 问题主要还是出在产品上，MT.Gox 很长一段时间都不使用控制软件来制定专业的开发环境，这意味着两个同事在同一个文件夹下工作，很有可能覆盖掉对方的代码。他们甚至把许多不经测试的软件推送到用户手机上，要知道他们是做金融服务的，这样做很容易引发问题。 在 MT.Gox 里，只有一个人有权限修改网站的源代码，即 Karpeles，这意味着源代码出问题的时候，需要 Karpeles 亲手来解决，但 CEO 通常都很忙，许多问题会拖好几周。糟糕的是，据员工透露，源代码的问题很多，bug 不断。 这些问题引发大商业客户的不满，去年他们被 CoinLab 起诉，要求赔偿 7500 万美元，原因是这家客户提现的时间居然被延迟了数月之久。彼时，许多其他交易网站逐渐崛起，MT.Gox 的交易数量额已经从第一掉到了第三名。 Karpeles 不重视产品简直到了无以复加的地步，2011 年 6 月，MT.Gox 首次遭遇黑客攻击，比特币爱好者 Jesse Powell 从旧金山赶过来，与好友 Roger Ver 一起帮 MT.Gox 解决问题，他们还没来得及放下行李就去办公室工作。当时受此影响，MT.Gox 比特币的价格暴跌，从 30 美元跌至 0.01 美元，比特币市场遭遇重创。 Powell、Ver 和 Karpeles 工作了一整周来修复问题，回答用户的咨询等，但是直到周末，问题还没解决。Powell、Ver 准备周末接着干，但意外的是，Karpeles 却决定周末放假休息，让两个志愿者大跌眼镜，他们感到十分泄气。 Karpeles 并未真正重视这个问题，等到周一开工，他却花时间在整理信封，把问题丢在一边。 接触他的人认为，Karpeles 逐渐厌倦做 CEO 了，对于问题采用消极的态度，他更喜欢花时间修理服务器、安装一些小工具等。 MT.Gox 新的大楼在建的时候，他还迷恋上新的项目：比特币咖啡馆。游人可以在里面休息，喝咖啡，但是付账只能使用比特币，这是 Karpeles 破解收银机的成果，Karpeles 很以此得意。当时 MT.Gox 已经处在下坡路上，这些周边的事物花去了 Karpeles 太多的精力。 “咖啡馆可能是 Karpeles 每天与银行、客户打交道这些暗无天日的日子里，唯一可以让他轻松的地方。”Powell 说道。可惜的是，咖啡馆终究没能开业。 随着 2 月份到来，危机终于降临，黑客利用比特币“可锻性”，将 MT.Gox 中的比特币洗劫一空，MT.Gox 也“暂停”提现比特币。在沉默了多天之后，示威者开始出现在办公室外面，谣言四起，但纸包不住火… 以上文字 引自MT.Gox 倒闭内幕：不负责任的领导者葬送一切 H3 什么是交易延展性什么叫做 延展性，说是延展性，也可以理解为可塑性。举个例子来说《龙门镖局》中的白敬祺为了藏私房钱，将银锭打成了银夜壶，而银夜壶和银锭的价值是相当的，这就是金属“可锻性”的物理表现。比特币的一个“交易”是一段指令，这段指令告诉整个网络：我作为一些比特币的拥有者，要把他们的所有权转移到目标地址。这样，谁拥有目标地址，我就把钱打给谁了。这段指令本质上是一个hash字符串，就像这样： 01000000017a06ea98cd40ba2e3288262b28638cec5337c1456aaf5eedc8e9e5a20f062bdf000000008b48304502202ef6483a2509394551eadf333afe2a749dbe77729a7b729ad79bf2f2246483b0022100ce8a3f1801e32e95aeceac4ab400713b783120930f436774d27ca85c27428bfa014104e0ba531dc5d2ad13e2178 然后，你对这个字符串提取一个所谓的哈希，可以理解为用摘要的方式获得一个比较短的字符串，像这样的： 0735353e82b8496eb87fc910d8cf814384028d0a853926c6acfd7b01190ea0b4 将这一个字符串进行解码之后，我们格式化出以下这一段JSON。 { \"ver\":1, \"inputs\":[ { \"sequence\":4294967295, \"witness\":\"\", \"prev_out\":{ \"spent\":true, \"tx_index\":52155217, \"type\":0, \"addr\":\"1DAtxVrwDDofiSwBqqiz4fkfPv1dCvt2Lx\", \"value\":5020000, \"n\":1554, \"script\":\"76a91485809fdc9c4cfebe73793cf1c4ddb328806737fd88ac\"}, \"script”:”483045022100efe12e2584bbd346bccfe67fd50a54191e4f45f……\" } ], \"weight\":768, \"block_height\":290000, \"relayed_by\":\"24.13.82.77\", \"out\":[ { \"spent\":true, \"tx_index\":52159814, \"type\":0, \"addr\":\"1JKygTtQjrY1mzMHLGuSdTEgi4P75vnjbG\", \"value\":5010000, \"n\":0, \"script\":\"76a914be10f0a78f5ac63e8746f7f2e62a5663eed0578888ac\" } ] // .... 更多 } 在结构体中 input 第一个结构中 script “483045022100efe12e2584bbd346bccfe67fd50a54191e4f45f……” 就是咱们的输入脚本，这种格式下很难去辨认，所以格式化输出可以得到以下的结果。 // 输入 脚本结构 // 其中 asm 为 签名 一起 公钥 { \"result\": { \"asm\": \"3045022100efe12e2584bbd346bccfe67fd50a54191e4f45f945e3853658284358d9c062ad02200121e00b6297c0874650d00b786971f5b4601e32b3f81afa9f9f8108e93c752201 038b29d4fbbd12619d45c84c83cb4330337ab1b1a3737250f29cec679d7551148a\", \"type\": \"nonstandard\", \"p2sh\": \"3C7mDUFw5MLBw37bbsAN79mKuHi7oyjKwb\" }, \"error\": null, \"id\": null } 同理，我们可以得到输出的格式化结构 { \"result\": { \"asm\": \"OP_DUP OP_HASH160 be10f0a78f5ac63e8746f7f2e62a5663eed05788 OP_EQUALVERIFY OP_CHECKSIG\", \"reqSigs\": 1, \"type\": \"pubkeyhash\", \"addresses\": [ \"1JKygTtQjrY1mzMHLGuSdTEgi4P75vnjbG\" ], \"p2sh\": \"3PDv3dAkEp7B57ReMs64grHiaEwTr3YEmb\" }, \"error\": null, \"id\": null } 我们已经得到脚本的结构了。接下来看看脚本到底是如何做到检验脚本的 H4 逆波兰表达式 逆波兰结构由弗里德里希·鲍尔（Friedrich L. Bauer）和艾兹格·迪科斯彻在1960年代早期提议用于表达式求值，以利用堆栈结构减少计算机内存访问。逆波兰记法和相应的算法由澳大利亚哲学家、计算机学家查尔斯·汉布林（Charles Hamblin）在1960年代中期扩充— 摘自 维基百科 大概的意思，它是基于堆栈的，先进后出 FILO(First-In-Last-Out)。就比如说，正常来说，我们实现一个加法操作。本来应该是 1 + 2 = 按照 逆波兰 表达式来看的话，就是。 1 2 + = 首先 1 2 进栈。接着 运行到+，这个时候 1 2 出栈，计算结果并入栈。 之后运行到 = 将结果出栈。 H4 运行脚本我们的bitCoin的脚本也是使用的这种堆栈式执行的方式。我们来运行以下看看如何。(关于脚本的解释，引自BitCoin Wiki Script) 运行输入脚本 输入的 签名进栈 ，公钥进栈 运行输出脚本 运行 OP_DUP 它的含义是 复制栈顶元素 -&gt; 复制公钥 运行 OP_HASH160 含义是 将栈顶元素做 先SHA-256，在做 RIPEMD-160 -&gt; 得到 公钥的HASH值 之后 运行到 一段Hash 值，我们把它压栈 运行到 OP_EQUALVERIFY 含义是 将栈顶前两个元素出栈 并判断是否相等 如果相等 就继续 否则就跳出并返回false 运行到 OP_CHECKSIG 含义是检验 私钥和签名是否为真 结果同上 H4 OP_CHECKSIG 细节 摘自 &lt;廖雪峰的官方网站 - 深入理解比特币交易的脚本&gt; 廖雪峰 把当前Transaction的所有TxIn的scriptSig去掉（红色部分），并把当前TxIn的scriptSig替换为UTXO的script（蓝色部分），调整长度字段（绿色部分）： 签名检验部分 最后加上小端序4字节的签名类型0x01（灰色部分），计算两次SHA256，我们得到： c2d48f45...2669 现在，使用ECDSA算法对签名进行验证： boolean ecdsa_verify_signature(byte[] message, byte[] signature, byte[] pubkey) 我们讲完了，执行过程，我们来看一下，如何完成交易延展性攻击。比特币区块链上每笔交易记录里都包含有见证信息，交易的唯一标识（交易的哈希值）也是包括了见证信息计算出来的。由于见证算法的数学特性，任何人在拿到一个交易记录后，拿到其中的见证信息，然后可以在不需要知道私钥的情况下，很容易的拼凑出另外一个有效的见证信息。这样，他可以用拼凑出来的另外那个见证信息，拼凑上交易记录中的其他交易信息，制造出一个另外一个交易记录（哈希值不同）。如果可以让拼凑出来的交易记录先被写入区块链，那么，之前那个原始交易记录会被认为是无效的交易而失败。这不会造成双花，也不会对区块链造成破坏，但是对原始交易记录的发起者会造成困扰，因为如果拿着原始交易记录的哈希值找不到交易的成功记录。尤其是对于一些交易所，如果没有完整的内部日志，可能无法追溯交易记录，导致攻击者利用拼凑的交易记录先成功提币，再申诉说没有提到币，要求再次提币。隔离见证后，见证信息不再是交易记录的一部分，也就不参与交易记录哈希的计算，无法再通过修改见证信息来拼凑另外一个交易记录。 作者：blockchain链接：https://www.zhihu.com/question/58567061/answer/301418337来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 H4 MT.Gox 攻击模拟当交易发送到比特币网络中后，网络中的各个结点会根据之前生成的签名来验证交易的真实性，这些做法都是很正确很理所当然的，MT就是这么做的，当你提现的时候，它就发出一个交易，然后记录下这个ID。当有人提现出问题要求重发时，他们就用这个ID去比特币网络检查这个ID有没有被确认，如果没有的话就重发。而问题就出现在签名算法中，由于现在大部分使用的签名算法都是基于OpenSSL的ECDSA（椭圆曲线数字签名），这个签名算法的一个问题就是，修改签名的某个字节能够使得签名依然校验成功，这样伪造签名之后交易依然能成功进行。如果单在比特币网络中这似乎没什么大不了的，顶多可以捣捣乱，因为你能使用的输出就那一个，你其中一笔交易使用了输出，第二笔自然就不会成功。但是对于第三方交易系统就不同了 你像交易所发起交易请求，交易所向比特币网络广播交易 你通过矿机获取到交易，利用交易延展性，修改Txid 假如你的交易率先完成了写入区块，攻击完成，你首先得到自己伪造交易的比特币 你想交易所，申请，自己没有提到钱，申请在此提取 交易所再次发起交易 你会得到两份比特币 大家还会有一个疑问，就是我们伪造的交易请求是在正常交易请求之后发出的，如果正常交易被采纳了，那我们伪造的交易如何能够奏效呢？这里就要说到比特币网络的一个特性，发出一个比特币交易请求后不会立刻返回交易成功与否，在比特币网络中会有一个处理延时，而比特币网络由于自身的特性，所有交易请求是以网状形式随机处理的，两次交易请求并不会以队列形式依次处理。这就给攻击者提供了可乘之机，专业的讲叫做时间条件竞争，通俗的讲就是拼人品。我们伪造的交易和正常的交易都在比特币网络中，如果伪造的交易先被处理，那么攻击成功。 H2 闪电网络Transactions for the Future Instant Payments. Lightning-fast blockchain payments without worrying about block confirmation times. Security is enforced by blockchain smart-contracts without creating a on-blockchain transaction for individual payments. Payment speed measured in milliseconds to seconds. Scalability. Capable of millions to billions of transactions per second across the network. Capacity blows away legacy payment rails by many orders of magnitude. Attaching payment per action/click is now possible without custodians. Low Cost. By transacting and settling off-blockchain, the Lightning Network allows for exceptionally low fees, which allows for emerging use cases such as instant micropayments. Cross Blockchains. Cross-chain atomic swaps can occur off-chain instantly with heterogeneous blockchain consensus rules. So long as the chains can support the same cryptographic hash function, it is possible to make transactions across blockchains without trust in 3rd party custodians. 引自 Lightning Network 首页 H3 为什么需要闪电网络首先我们来说一下，现在比特币网络中存在的问题 处理能力在最理想状态下，平均每笔交易225 字节。在1M区块限制下，一般平均10分钟可以打包大约 4400 笔交易。每秒大约7.3笔交易，实际交易平均大小是这个的一倍，那么容量减半，也就是每秒大约 3.6 笔交易。与当今的金融系统相比，Visa在标准的节假日每秒处理4.5万笔交易，通常的一个营业日则为数亿次交易。支付宝的每秒可以处理10万笔交易。而2017年的双11，支付峰值每秒25.6万笔。，然而比特币现在每秒约能支持7笔交易，同时还会受到区块链大小的限制。 时间延迟每一笔交易发起的时候，会出现10分钟的延迟，才会有可能被矿工确认。并且目前的交易量上升之后，你被确认的等待时间和你的手续费成反比，也就是说你的手续费越低，你被处理的顺序就越靠后。 交易最终性由于算哈希是随机的，加上网络有延迟，是有同时挖出两个区块的可能，然后不同的矿工根据他们收到的区块不同继续挖，然后还是有可能再出现分叉，但是几率会越来越小。一般认为一个区块在最长链上后面跟了五个区块，就不可能被分叉了。随着区块数量的增加，再次产生分叉的几率是呈指数下降的。到了6的区块的时候，就已经下降到不太可能分叉的情况 容量比特币，区块目前已经到51W多个区块。这么多的区块产生的容量是巨大的,而且以后只增不减 交易费中本聪最开始确定bitcoin一共有2100万个，当全部挖掘出来之后，矿工将不再获得奖励，到那个时候，矿工所有的收益都来自交易中的手续费。就目前为止，待确认交易堆积的这么多，也和交易费有关系，如果你想矿工早点确认你的交易，那么你就需要提高你的手续费，否则就没人处理。但是这个引起的来问题，也很明显，我就想买杯咖啡，就需要支付手续费吗？ 闪电网络就是为了这解决这些的。 H4 闪电网络 - RSMC闪电网络的基础是交易双方之间的双向微支付通道，RSMC（Recoverable Sequence Maturity Contract）定义了该双向微支付通道的最基本工作方式。 微支付通道中沉淀了一部分资金，通道也记录有双方对资金的分配方案。通道刚设立时，初值可能是{Alice: 0.4, Bob: 0.6}，意味着打入通道的资金共有1.0 BTC，其中Alice拥有0.4 BTC，Bob拥有0.6 BTC。通道的设立会记录在比特币区块链上。 假设稍后Bob决定向Alice支付0.1 BTC。双方在链下对最新余额分配方案{Alice:0.5, Bob:0.5} 签字认可，并签字同意作废前一版本的余额分配方案{Alice:0.4, Bob:0.6}，Alice就实际获得了0.5 BTC的控制权。 前后两个版本的余额分配方案 如果Alice暂时不需要将通道中现在属于她的0.5 BTC用作支付，她可以无需及时更新区块链上记录的通道余额分配方案，因为很可能一分钟后Alice又需要反过来向Bob支付0.1 BTC，此时他们仍然只需在链下对新的余额分配方案达成一致，并设法作废前一版本的余额分配方案就行了。 如果Alice打算终止通道并动用她的那份资金，她可以向区块链出示双方签字的余额分配方案。如果一段时间之内Bob不提出异议，区块链会终止通道并将资金按协议转入各自预先设立的提现地址。如果Bob能在这段时间内提交证据证明Alice企图使用的是一个双方已同意作废的余额分配方案，则Alice的资金将被罚没并给到Bob。 实际上，前面所说的“作废前一版本的余额分配”，正是通过构建适当的“举证”证据并结合罚没机制实现的。 为了鼓励双方尽可能久地利用通道进行交易，RSMC对主动终止通道方给予了一定的惩罚：主动提出方其资金到账将比对方晚，因此谁发起谁吃亏。这个设计虽然增加了技术复杂度，但应该说是合理的。 通道余额分配方案的本质是结算准备金。在此安排下，因为要完全控制资金交收风险，每笔交易都不能突破当前结算准备金所施限制。 H4 闪电网络 - HTLCRSMC只支持最简单的无条件资金支付，HTLC（Hashed Timelock Contract）进一步实现了有条件的资金支付，通道余额的分配方式也因此变得更为复杂。 通过HTLC，Alice和Bob可以达成这样一个协议：协议将锁定Alice的0.1 BTC，在时刻T到来之前（T以未来的某个区块链高度表述），如果Bob能够向Alice出示一个适当的R（称为秘密），使得R的哈希值等于事先约定的值H(R)，Bob就能获得这0.1 BTC；如果直到时刻T过去Bob仍然未能提供一个正确的R，这0.1 BTC将自动解冻并归还Alice。 由于到期时间T、提款条件H(R)、支付金额、支付方向的不同，同一个通道上可以同时存在多个活动的HTLC合约，加上唯一的通过RSMC协议商定的无条件资金余额，余额分配方式会变得相当复杂。假设双方初始各存入0.5 BTC，一段时间后余额分配可能这样： 一段时间后的余额分配方案 余额分配方案是一种快照，只能整体刷新。接上表，如果Alice下一刻决定无条件向Bob支付0.1 BTC，或者Alice在T1前向Bob出示了符合H(R1)的秘密，双方将在链下交换并共同签字认定新的快照，然后构建适当的“举证”证据，结合罚没机制作废前一版本的快照。这些动作完全不出现在区块链上。引入HTLC后，任何一方仍然能通过在区块链上公开最终余额快照的方式终止通道。 H4 闪电网络基于HTLC可以实现终极目标“闪电网络”。 闪电网络的支付路径 如上图所示，Alice想给Dave发送0.05 BTC，但Alice和Dave之间并没有微支付通道。但这没关系，Alice找到了一条经过Bob、Carol到达Dave的支付路径，该路径由Alice/Bob, Bob/Carol和Carol/Dave这样三个微支付通道串接而成。 Dave生成一个秘密R并将Hash(R)发送给Alice，Alice不需要知道R。R和Hash(R)的作用就像是古代调兵用的一对虎符。 Alice和Bob商定一个HTLC合约：只要Bob能在3天内向Alice出示哈希正确的R，Alice会支付Bob 0.052 BTC；如果Bob做不到这点，这笔钱3天后自动退还Alice。 同样地，Bob和Carol商定一个HTLC合约：只要Carol能在2天内向Bob出示哈希正确的R，Bob会支付Carol 0.051 BTC；如果Carol做不到这点，这笔钱到期自动退还Bob。 最后，Carol和Dave商定一个HTLC合约：只要Dave能在1天内向Carol出示哈希正确的R，Carol会支付Dave 0.05 BTC；如果Dave做不到这点，这笔钱到期自动退还Carol。 一切就绪后，Dave及时向Carol披露R并拿到0.05 BTC；现在Carol知道了R，她可以向Bob出示密码R并拿到0.051 BTC（差额部分的0.001 BTC成了Carol的佣金）；Bob知道R后当然会向Alice出示并拿到他的那份0.052 BTC，差额部分的0.001 BTC成了Bob的佣金。 闪电网络逐级提款 整个过程很容易理解。最终效果是Alice支付了0.052 BTC，Dave安全地拿到0.05 BTC，整个闪电支付网络为此收取的佣金成本是0.002 BTC。上述过程中的全部动作都发生在比特币区块链之外。 尽管闪电网络本身可以基于任何合适的传统技术构建，闪电网络的支付通道也可能逐渐向少数大型中介集中，变成若干大型中介彼此互联、普通用户直连大型中介的形式，但这种方案仍然具有传统中心化方案不可比拟的优势，因为用户现在并不需要信任中介，不需要在中介处存钱才能转移支付，资金安全受到比特币区块链的充分保护。 比特币闪电网络的实现方式非常复杂，不拟在此展开讲解，有兴趣的读者可以在附录一中找到详细的技术剖析。 闪电网络学习自 详解最近大热的闪电网络、雷电网络和CORDA 上交所朱立 H4 吐槽百度真的不得不吐槽下百度哈….. 都是搜索文章标题，为什么差距有些大 百度搜索结果 Google搜索结果 H2 原子交易A picks a random number x A creates TX1: “Pay w BTC to &lt;B’s public key&gt; if (x for H(x) known and signed by B) or (signed by A &amp; B)” A creates TX2: “Pay w BTC from TX1 to &lt;A’s public key&gt;, locked 48 hours in the future, signed by A” A sends TX2 to B B signs TX2 and returns to A 1) A submits TX1 to the network B creates TX3: “Pay v alt-coins to if (x for H(x) known and signed by A) or (signed by A &amp; B)” B creates TX4: “Pay v alt-coins from TX3 to &lt;B’s public key&gt;, locked 24 hours in the future, signed by B” B sends TX4 to A A signs TX4 and sends back to B 2) B submits TX3 to the network 3) A spends TX3, revealing x 4) B spends TX1 using x This is atomic (with timeout). If the process is halted, it can be reversed no matter when it is stopped. Before 1: Nothing public has been broadcast, so nothing happensBetween 1 &amp; 2: A can use refund transaction after 72 hours to get his money backBetween 2 &amp; 3: B can get refund after 24 hours. A has 24 more hours to get his refundAfter 3: Transaction is completed by 2 A must spend his new coin within 24 hours or B can claim the refund and keep his coins B must spend his new coin within 72 hours or A can claim the refund and keep his coins For safety, both should complete the process with lots of time until the deadlines. H2 原子交易 闪电网络Special thanks to @bitconner for his super hard work on this! 🙌And @roasbeef and @SatoshiLite for the help and feedback!&mdash; Lightning Labs⚡️ (@lightning) 2017年11月16日 H2 动画演示更多详解 可以查看 Pages 以及 它的描述文件 比特币隔离见证和闪电网络理解.md","categories":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/categories/区块链/"}],"tags":[{"name":"Segwit","slug":"Segwit","permalink":"http://blog.msiter.com/tags/Segwit/"},{"name":"Lightning Network","slug":"Lightning-Network","permalink":"http://blog.msiter.com/tags/Lightning-Network/"},{"name":"Atomic Transaction","slug":"Atomic-Transaction","permalink":"http://blog.msiter.com/tags/Atomic-Transaction/"}],"keywords":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/categories/区块链/"}]},{"title":"bitcoin hierarchical deterministic wallets","slug":"BIP32-39-43-44","date":"2018-03-23T17:25:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"BIP32-39-43-44-20180323.html","link":"","permalink":"http://blog.msiter.com/BIP32-39-43-44-20180323.html","excerpt":"私钥 公钥 比特币地址一个比特币钱包中包含一系列的密钥对，每个密钥对包括一个私钥和一个公钥。私钥（k）是一个数字，通常是随机选出的。有了私钥，我们就可以使用椭圆曲线乘法这个单向加密函数产生一个公钥（K）。有了公钥（K），我们就可以使用一个单向加密哈希函数生成比特币地址（A）。","text":"H2 私钥 公钥 比特币地址一个比特币钱包中包含一系列的密钥对，每个密钥对包括一个私钥和一个公钥。私钥（k）是一个数字，通常是随机选出的。有了私钥，我们就可以使用椭圆曲线乘法这个单向加密函数产生一个公钥（K）。有了公钥（K），我们就可以使用一个单向加密哈希函数生成比特币地址（A）。 公私钥单向关系示意图 H3 私钥私钥就是一个随机选出的数字而已。一个比特币地址中的所有资金的控制取决于相应私钥的所有权和控制权。在比特币交易中，私钥用于生成支付比特币所必需的签名以证明资金的所有权。私钥必须始终保持机密，因为一旦被泄露给第三方，相当于该私钥保护之下的比特币也拱手相让了。私钥还必须进行备份，以防意外丢失，因为私钥一旦丢失就难以复原，其所保护的比特币也将永远丢失。 比特币私钥只是一个数字。你可以用硬币、铅笔和纸来随机生成你的私钥：掷硬币256次，用纸和笔记录正反面并转换为0和1，随机得到的256位二进制数字可作为比特币钱包的私钥。该私钥可进一步生成公钥。 H3 公钥通过椭圆曲线算法可以从私钥计算得到公钥，这是不可逆转的过程：K = k * G 。其中k是私钥，G是被称为生成点的常数点，而K是所得公钥。其反向运算，被称为“寻找离散对数”——已知公钥K来求出私钥k——是非常困难的，就像去试验所有可能的k值，即暴力搜索。 H3 比特币地址比特币地址是一个由数字和字母组成的字符串，可以与任何想给你比特币的人分享。由公钥（一个同样由数字和字母组成的字符串）生成的比特币地址以数字“1”开头。下面是一个比特币地址的例子： 1J7mdg5rbQyUHENYdx39WVWK7fsLpEoXZy 在交易中，比特币地址通常以收款方出现。如果把比特币交易比作一张支票，比特币地址就是收款人，也就是我们要写入收款人一栏的内容。一张支票的收款人可能是某个银行账户，也可能是某个公司、机构，甚至是现金支票。支票不需要指定一个特定的账户，而是用一个普通的名字作为收款人，这使它成为一种相当灵活的支付工具。与此类似，比特币地址的使用也使比特币交易变得很灵活。比特币地址可以代表一对公钥和私钥的所有者，也可以代表其它东西，比如“P2SH (Pay-to-Script-Hash)”付款脚本。 H4 如何生成比特币地址比特币地址可由公钥经过单向的加密哈希算法得到。哈希算法是一种单向函数，接收任意长度的输入产生指纹摘要。加密哈希函数在比特币中被广泛使用：比特币地址、脚本地址以及在挖矿中的工作量证明算法。由公钥生成比特币地址时使用的算法是Secure Hash Algorithm (SHA)和the RACE Integrity Primitives Evaluation Message Digest (RIPEMD)，特别是SHA256和RIPEMD160。 以公钥 K 为输入，计算其SHA256哈希值，并以此结果计算RIPEMD160 哈希值，得到一个长度为160比特（20字节）的数字： /// K是公钥，A是生成的比特币地址。 A = RIPEMD160(SHA256(K)) 比特币地址与公钥不同。比特币地址是由公钥经过单向的哈希函数生成的。 H2 私钥 公钥 格式H3 公钥的格式公钥也可以用多种不同格式来表示，最重要的是它们分为非压缩格式或压缩格式公钥这两种形式。 我们从前文可知，公钥是在椭圆曲线上的一个点，由一对坐标（x，y）组成。公钥通常表示为前缀04紧接着两个256比特的数字。其中一个256比特数字是公钥的x坐标，另一个256比特数字是y坐标。前缀04是用来区分非压缩格式公钥，压缩格式公钥是以02或者03开头。 下面是由前文中的私钥所生成的公钥，其坐标x和y如下： x = F028892BAD7ED57D2FB57BF33081D5CFCF6F9ED3D3D7F159C2E2FFF579DC341A y = 07CF33DA18BD734C600B96A72BBC4749D5141C90EC8AC328AE52DDFE2E505BDB 下面是同样的公钥以520比特的数字（130个十六进制数字）来表达。这个520比特的数字以前缀04开头，紧接着是x及y坐标，组成格式为04 x y K = 04F028892BAD7ED57D2FB57BF33081D5CFCF6F9ED3D3D7F159C2E2FFF579DC341A07CF33DA18BD734C600B96A72BBC4749D5141C90EC8AC328AE52DDFE2E505BDB H4 压缩格式化公钥引入压缩格式公钥是为了减少比特币交易的字节数，从而可以节省那些运行区块链数据库的节点磁盘空间。大部分比特币交易包含了公钥，用于验证用户的凭据和支付比特币。每个公钥有520比特（包括前缀，x坐标，y坐标）。如果每个区块有数百个交易，每天有成千上万的交易发生，区块链里就会被写入大量的数据。 一个公钥是一个椭圆曲线上的点(x, y)。而椭圆曲线实际是一个数学方程，曲线上的点实际是该方程的一个解。因此，如果我们知道了公钥的x坐标，就可以通过解方程y2 mod p = (x3 + 7) mod p得到y坐标。这种方案可以让我们只存储公钥的x坐标，略去y坐标，从而将公钥的大小和存储空间减少了256比特。每个交易所需要的字节数减少了近一半，随着时间推移，就大大节省了很多数据传输和存储。 未压缩格式公钥使用04作为前缀，而压缩格式公钥是以02或03作为前缀。需要这两种不同前缀的原因是：因为椭圆曲线加密的公式的左边是y2 ，也就是说y的解是来自于一个平方根，可能是正值也可能是负值。更形象地说，y坐标可能在x坐标轴的上面或者下面。从椭圆曲线图中可以看出，曲线是对称的，从x轴看就像对称的镜子两面。因此，如果我们略去y坐标，就必须储存y的符号（正值或者负值）。换句话说，对于给定的x值，我们需要知道y值在x轴的上面还是下面，因为它们代表椭圆曲线上不同的点，即不同的公钥。当我们在素数p阶的有限域上使用二进制算术计算椭圆曲线的时候，y坐标可能是奇数或者偶数，分别对应前面所讲的y值的正负符号。因此，为了区分y坐标的两种可能值，我们在生成压缩格式公钥时，如果y是偶数，则使用02作为前缀；如果y是奇数，则使用03作为前缀。这样就可以根据公钥中给定的x值，正确推导出对应的y坐标，从而将公钥解压缩为在椭圆曲线上的完整的点坐标。下图阐释了公钥压缩： 公钥压缩下面是前述章节所生成的公钥，使用了264比特（66个十六进制数字）的压缩格式公钥格式，其中前缀03表示y坐标是一个奇数 K = 03F028892BAD7ED57D2FB57BF33081D5CFCF6F9ED3D3D7F159C2E2FFF579DC341A 带来的问题： 这个压缩格式公钥对应着同样的一个私钥，这意味它是由同样的私钥所生成。但是压缩格式公钥和非压缩格式公钥差别很大。更重要的是，如果我们使用双哈希函数(RIPEMD160(SHA256(K)))将压缩格式公钥转化成比特币地址，得到的地址将会不同于由非压缩格式公钥产生的地址。这种结果会让人迷惑，因为一个私钥可以生成两种不同格式的公钥——压缩格式和非压缩格式，而这两种格式的公钥可以生成两个不同的比特币地址。但是，这两个不同的比特币地址的私钥是一样的。 压缩格式公钥渐渐成为了各种不同的比特币客户端的默认格式，它可以大大减少交易所需的字节数，同时也让存储区块链所需的磁盘空间变小。然而，并非所有的客户端都支持压缩格式公钥，于是那些较新的支持压缩格式公钥的客户端就不得不考虑如何处理那些来自较老的不支持压缩格式公钥的客户端的交易。这在钱包应用导入另一个钱包应用的私钥的时候就会变得尤其重要，因为新钱包需要扫描区块链并找到所有与这些被导入私钥相关的交易。比特币钱包应该扫描哪个比特币地址呢？新客户端不知道应该使用哪个公钥：因为不论是通过压缩的公钥产生的比特币地址，还是通过非压缩的公钥产生的地址，两个都是合法的比特币地址，都可以被私钥正确签名，但是他们是完全不同的比特币地址。 为了解决这个问题，当私钥从钱包中被导出时，较新的比特币客户端将使用一种不同的钱包导入格式（Wallet Import Format）。这种新的钱包导入格式可以用来表明该私钥已经被用来生成压缩的公钥，同时生成的比特币地址也是基于该压缩的公钥。这个方案可以解决导入私钥来自于老钱包还是新钱包的问题，同时也解决了通过公钥生成的比特币地址是来自于压缩格式公钥还是非压缩格式公钥的问题。最后新钱包在扫描区块链时，就可以使用对应的比特币地址去查找该比特币地址在区块链里所发生的交易。 H3 私钥的格式化实际上“压缩格式私钥”是一种名称上的误导，因为当一个私钥被使用WIF压缩格式导出时，不但没有压缩，而且比“非压缩格式”私钥长出一个字节。这个多出来的一个字节是私钥被加了后缀01，用以表明该私钥是来自于一个较新的钱包，只能被用来生成压缩的公钥。私钥是非压缩的，也不能被压缩。“压缩的私钥”实际上只是表示“用于生成压缩格式公钥的私钥”，而“非压缩格式私钥”用来表明“用于生成非压缩格式公钥的私钥”。为避免更多误解，应该只可以说导出格式是“WIF压缩格式”或者“WIF”，而不能说这个私钥是“压缩”的。 要注意的是，这些格式并不是可互换使用的。在较新的实现了压缩格式公钥的钱包中，私钥只能且永远被导出为WIF压缩格式（以K或L为前缀）。对于较老的没有实现压缩格式公钥的钱包，私钥将只能被导出为WIF格式（以5为前缀）导出。这样做的目的就是为了给导入这些私钥的钱包一个信号：到底是使用压缩格式公钥和比特币地址去扫描区块链，还是使用非压缩格式公钥和比特币地址。 如果一个比特币钱包实现了压缩格式公钥，那么它将会在所有交易中使用该压格式缩公钥。钱包中的私钥将会被用来生成压缩格式公钥，压缩格式公钥然后被用来生成交易中的比特币地址。当从一个实现了压缩格式公钥的比特币钱包导出私钥时，钱包导入格式（WIF）将会被修改为WIF压缩格式，该格式将会在私钥的后面附加一个字节大小的后缀01。最终的Base58Check编码格式的私钥被称作WIF（“压缩”）私钥，以字母“K”或“L”开头。而以“5”开头的是从较老的钱包中以WIF（非压缩）格式导出的私钥。 H3 比特币地址格式通常用户见到的比特币地址是经过“Base58Check”编码的，这种编码使用了58个字符（一种Base58数字系统）和校验码，提高了可读性、避免歧义并有效防止了在地址转录和输入中产生的错误。Base58Check编码也被用于比特币的其它地方，例如比特币地址、私钥、加密的密钥和脚本哈希中，用来提高可读性和录入的正确性。 比特币地址生成流程 H4 Base58和Base58Check编码为了更简洁方便地表示长串的数字，许多计算机系统会使用一种以数字和字母组成的大于十进制的表示法。例如，传统的十进制计数系统使用0-9十个数字，而十六进制系统使用了额外的 A-F 六个字母。一个同样的数字，它的十六进制表示就会比十进制表示更短。更进一步，Base64使用了26个小写字母、26个大写字母、10个数字以及两个符号（例如“+”和“/”），用于在电子邮件这样的基于文本的媒介中传输二进制数据。Base64通常用于编码邮件中的附件。Base58是一种基于文本的二进制编码格式，用在比特币和其它的加密货币中。这种编码格式不仅实现了数据压缩，保持了易读性，还具有错误诊断功能。Base58是Base64编码格式的子集，同样使用大小写字母和10个数字，但舍弃了一些容易错读和在特定字体中容易混淆的字符。具体地，Base58不含Base64中的0（数字0）、O（大写字母o）、l（小写字母L）、I（大写字母i），以及“+”和“/”两个字符。简而言之，Base58就是由不包括（0，O，l，I）的大小写字母和数字组成。 比特币的Base58字母表 123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz Base58Check是一种常用在比特币中的Base58编码格式，增加了错误校验码来检查数据在转录中出现的错误。校验码长4个字节，添加到需要编码的数据之后。校验码是从需要编码的数据的哈希值中得到的，所以可以用来检测并避免转录和输入中产生的错误。使用Base58check编码格式时，编码软件会计算原始数据的校验码并和结果数据中自带的校验码进行对比。二者不匹配则表明有错误产生，那么这个Base58Check格式的数据就是无效的。例如，一个错误比特币地址就不会被钱包认为是有效的地址，否则这种错误会造成资金的丢失。 H4 Base58编码生成流程为了使用Base58Check编码格式对数据（数字）进行编码，首先我们要对数据添加一个称作“版本字节”的前缀，这个前缀用来明确需要编码的数据的类型。例如，比特币地址的前缀是0（十六进制是0x00），而对私钥编码时前缀是128（十六进制是0x80）。 接下来，我们计算“双哈希”校验码，意味着要对之前的结果（前缀和数据）运行两次SHA256哈希算法： checksum = SHA256(SHA256(prefix+data)) 在产生的长32个字节的哈希值（两次哈希运算）中，我们只取前4个字节。这4个字节就作为校验码。校验码会添加到数据之后。 结果由三部分组成：前缀、数据和校验码。这个结果采用之前描述的Base58字母表编码。下图描述了Base58Check编码的过程。 Base58 编码流程 我就一展示数据的表格 种类 版本前缀 (hex) Base58格式 Bitcoin Address 0x00 1 Pay-to-Script-Hash Address 0x05 3 Bitcoin Testnet Address 0x6F m or n Private Key WIF 0x80 5, K or L BIP38 Encrypted Private Key 0x0142 6P BIP32 Extended Public Key 0x0488B21E xpub H2 比特币钱包钱包是私钥的容器，通常通过有序文件或者简单的数据库实现。另外一种制作私钥的途径是 确定性密钥生成。在这里你可以用原先的私钥，通过单向哈希函数来生成每一个新的私钥，并将新生成的密钥按顺序连接。只要你可以重新创建这个序列，你只需要第一个私钥（称作种子、主私钥）来生成它们。 比特币钱包只包含私钥而不是比特币。每一个用户有一个包含多个私钥的钱包。钱包中包含成对的私钥和公钥。用户用这些私钥来签名交易，从而证明它们拥有交易的输出（也就是其中的比特币）。比特币是以交易输出的形式来储存在区块链中（通常记为vout或txout）。 H3 非确定性（随机）钱包在最早的一批比特币客户端中，钱包只是随机生成的私钥集合。这种类型的钱包被称作零型非确定钱包。举个例子，比特币核心客户端预先生成100个随机私钥，从最开始就生成足够多的私钥并且每把钥匙只使用一次。这种类型的钱包有一个昵称“Just a Bunch Of Keys（一堆私钥）”简称JBOK。这种钱包现在正在被确定性钱包替换，因为它们难以管理、备份以及导入。随机钥匙的缺点就是如果你生成很多，你必须保存它们所有的副本。这就意味着这个钱包必须被经常性地备份。每一把钥匙都必须备份，否则一旦钱包不可访问时，钱包所控制的资金就付之东流。这种情况直接与避免地址重复使用的原则相冲突——每个比特币地址只能用一次交易。地址通过关联多重交易和对方的地址重复使用会减少隐私。0型非确定性钱包并不是钱包的好选择，尤其是当你不想重复使用地址而创造过多的私钥并且要保存它们。虽然比特币核心客户包含0型钱包，但比特币的核心开发者并不想鼓励大家使用。下图表示包含有松散结构的随机钥匙的集合的非确定性钱包。 非确定性（随机）钱包 H3 确定性（种子）钱包确定性，或者“种子”钱包包含通过使用单项离散方程而可从公共的种子生成的私钥。种子是随机生成的数字。这个数字也含有比如索引号码或者可生成私钥的“链码”。在确定性钱包中，种子足够收回所有的已经产生的私钥，所以只用在初始创建时的一个简单备份就足以搞定。并且种子也足够让钱包输入或者输出。这就很容易允许使用者的私钥在钱包之间轻松转移输入。 H3 助记码词汇助记码词汇是英文单词序列代表（编码）用作种子对应所确定性钱包的随机数。单词的序列足以重新创建种子，并且从种子那里重新创造钱包以及所有私钥。在首次创建钱包时，带有助记码的，运行确定性钱包的钱包的应用程序将会向使用者展示一个12至24个词的顺序。单词的顺序就是钱包的备份。它也可以被用来恢复以及重新创造应用程序相同或者兼容的钱包的钥匙。助记码代码可以让使用者复制钱包更容易一些，因为它们相比较随机数字顺序来说，可以很容易地被读出来并且正确抄写。 建议使用若干个助记词来替换之前直接生成随机数的方式，通过助记词推导出随机的Master Seed。 H4 助记词列表其中WordList，是存在这里的。包含以下语言,每种语言都存在2048个单词，来成为助记词备选者。 每一种语言都提供对了对应的2048个词。其中都包含了，英文，日文，汉语，西班牙语，简体中文，繁体中文，法语，意大利。 English Japanese Korean Spanish Chinese (Simplified) Chinese (Traditional) French Italian 因为这些词语是通过随机的 128-256bits随机种子产生的助记词。所以，这些词是随机的，并且不可修改 H5 这些词是不是安全的？好吧，我觉得 随机的东西… 主要有足够的时间，无限猴子理论。我只要重复实验下去，绝对会有这么一天，到时候，我会和另一个人拥有同样的Master Seed！！！ 当然….几率有多小呢。。。通过 以下公式，我们可以得出在m个数据中，抽取n个数据的组合方式个数。 $$A^{m}_{n}=n\\left( n-1\\right) \\ldots \\left( n-m+1\\right) =\\dfrac {n!}{\\left( n-m\\right) !}$$ 假设使用的是 128为的随机种子，产生了12个助记词。也就是在2048个数据中提取12个，总数为： $$\\dfrac {2048!}{\\left( 2048-12\\right) !}$$ 这个还只是，没有排列顺序的方式，他抽取的助记词，顺序也是一种随机因素。所以只会比这个还大。 好吧，还是不好理解，那么我们来说一下我们熟知的双色球红球概率。 $$\\dfrac {33!}{\\left( 33-6\\right) !}$$ 有797 448 960个组合方式，这个几率就已经很少有人中奖了… 何况这么大… emmmmm… 至少，我算不出来他的几率是多少。。。因为光是2048 的阶乘,,,就写满了一页纸。。。。 H4 生成的方式接下来会说明下，生成助记词和通过助记词生成 Master Seed 的原理 H4 生成助记词的过程 规定熵的位数必须是 32 的整数倍，所以熵的长度取值位 128 到 256 之间取 32 的整数倍的值，分别为 128, 160, 192, 224, 256； 校验和的长度为熵的长度/32 位, 所以校验和长度可为 4，5，6，7，8 位 助记词库有 2048 个词，用 11 位可全部定位词库中所有的词，作为词的索引，故一个词用 11 位表示，助记词的个数可为 (熵+校验和)/11，值为 12，15，18，21，24 我就一展示数据的表格 熵(bits) 校验和(bits) 熵+校验和(bits) 助记词 128 (128/32)4 132 (132/11) -&gt; 12 160 (160/32)4 165 (132/11) -&gt; 15 192 (192/32)4 198 (132/11) -&gt; 18 224 (224/32)4 231 (132/11) -&gt; 21 256 (256/32)4 264 (132/11) -&gt; 24 ## CS 为 校验和的长度 CS = ENT / 32 ## MS 为 助记词的个数 MS = (ENT + CS) / 11 | ENT | CS | ENT+CS | MS | +-------+----+--------+------+ | 128 | 4 | 132 | 12 | | 160 | 5 | 165 | 15 | | 192 | 6 | 198 | 18 | | 224 | 7 | 231 | 21 | | 256 | 8 | 264 | 24 | 步骤如下： 生成一个长度为 128~256 位 (bits) 的随机序列(熵) 取熵哈希后的前 n 位作为校验和 (n= 熵长度/32) 随机序列 + 校验和 -&gt; 拼接起来 把步骤三得到的结果每 11 位切割 步骤四得到的每 11 位字节(二进制转为-&gt;十进制)通过Index获取匹配词库的一个词 步骤五得到的结果就是助记词串 生成助记词过程 H4 助记词生成 Master Seed的过程为了从助记词中生成二进制种子，BIP39 采用 PBKDF2 函数推算种子，其参数如下： 助记词句子作为密码 “mnemonic” + passphrase 作为盐 2048 作为重复计算的次数 HMAC-SHA512 作为随机算法 512 位(64 字节)是期望得到的密钥长度 助记词推出随机种子 H3 分层确定性钱包确定性钱包被开发成更容易从单个“种子”中生成许多关键的钥匙。最高级的来自确定性钱包的形是通过BIP0032标准生成的 the hierarchical deterministic wallet or HD wallet defined。分层确定性钱包包含从数结构所生成的钥匙。这种母钥匙可以生成子钥匙的序列。这些子钥匙又可以衍生出孙钥匙，以此无穷类推。这个树结构表如下图所示。 分层确定性钱包 HD钱包提供了随机（不确定性）钥匙有两个主要的优势。第一，树状结构可以被用来表达额外的组织含义。比如当一个特定分支的子密钥被用来接收交易收入并且有另一个分支的子密钥用来负责支付花费。不同分支的密钥都可以被用在企业环境中，这就可以支配不同的分支部门，子公司，具体功能以及会计类别。 HD钱包的第二个好处就是它可以允许让使用者去建立一个公共密钥的序列而不需要访问相对应的私钥。这可允许HD钱包在不安全的服务器中使用或者在每笔交易中发行不同的公共钥匙。公共钥匙不需要被预先加载或者提前衍生，但是在服务器中不具有可用来支付的私钥。 H4 从种子中创造HD钱包HD钱包从单个root seed中创建，为128到256位的随机数。HD钱包的所有的确定性都衍生自这个根种子。任何兼容HD钱包的根种子也可重新创造整个HD钱包。所以简单的转移HD钱包的根种子就让HD钱包中所包含的成千上百万的密钥被复制，储存导出以及导入。根种子一般总是被表示为a mnemonic word sequence，助记码词汇可以让人们更容易地抄写和储存。 创建主密钥以及HD钱包地主链代码的过程如下图所示。 创建主密钥以及HD钱包地主链代码的过程 根种子输入到HMAC-SHA512算法中就可以得到一个可用来创造master private key(m) 和 a master chain code的哈希。主私钥（m）之后可以通过使用我们在本章先前看到的那个普通椭圆曲线m * G过程生来成相对应的主公钥（M）。链代码可以给从母密钥中创造子密钥的那个方程中引入的熵。 H4 私有子秘钥的衍生分层确定性钱包使用CKD（child key derivation)方程去从母密钥衍生出子密钥。 子密钥衍生方程是基于单项哈希方程。这个方程结合了： 一个母私钥或者公共钥匙（ECDSA未压缩键） 一个叫做链码（256 bits）的种子 一个索引号（32 bits） 链码是用来给这个过程引入看似的随机数据的，使得索引不能充分衍生其他的子密钥。因此，有了子密钥并不能让它发现自己的相似子密钥，除非你已经有了链码。最初的链码种子（在密码树的根部）是用随机数据构成的，随后链码从各自的母链码中衍生出来。 这三个项目相结合并散列可以生成子密钥，如下。 母公共钥匙——链码——以及索引号合并在一起并且用HMAC-SHA512方程散列之后可以产生512位的散列。所得的散列可被拆分为两部分。散列右半部分的256位产出可以给子链当链码。左半部分256位散列以及索引码被加载在母私钥上来衍生子私钥。 延长母私钥去创造子私钥 改变索引可以让我们延长母密钥以及创造序列中的其他子密钥。比如子0，子1，子2等等。每一个母密钥可以右20亿个子密钥。 向密码树下一层重复这个过程，每个子密钥可以依次成为母密钥继续创造它自己的子密钥，直到无限代。 H4 使用衍生的子密钥子私钥不能从非确定性（随机）密钥中被区分出来。因为衍生方程是单向方程，所以子密钥不能被用来发现他们的母密钥。子密钥也不能用来发现他们的相同层级的姊妹密钥。如果你有第n个子密钥，你不能发现它前面的（第n－1）或者后面的子密钥（n＋1）或者在同一顺序中的其他子密钥。只有母密钥以及链码才能得到所有的子密钥。没有子链码的话，子密钥也不能用来衍生出任何孙密钥。你需要同时有子密钥以及对应的链码才能创建一个新的分支来衍生出孙密钥。 那子私钥自己可被用做什么呢？它可以用来做公共钥匙和比特币地址。之后它就可以被用那个地址来签署交易和支付任何东西。 子密钥、对应的公共钥匙以及比特币地址都不能从随机创造的密钥和地址中被区分出来。事实是它们所在的序列，在创造他们的HD钱包方程之外是不可见的。一旦被创造出来，它们就和“正常”钥匙一样运行了。 H4 扩展秘钥正如我们之前看到的，密钥衍生方程可以被用来创造钥匙树上任何层级的子密钥。这只需要三个输入量：一个密钥，一个链码以及想要的子密钥的索引。密钥以及链码这两个重要的部分被结合之后，就叫做extended key。术语“extended key”也被认为是“可扩展的密钥”是因为这种密钥可以用来衍生子密钥。 扩展密钥可以简单地被储存并且表示为简单的将256位密钥与256位链码所并联的512位序列。有两种扩展密钥。扩展的私钥是私钥以及链码的结合。它可被用来衍生子私钥（子私钥可以衍生子公共密钥）公共钥匙以及链码组成扩展公共钥匙。 想象一个扩展密钥作为HD钱包中钥匙树结构的一个分支的根。你可以衍生出这个分支的剩下所有部分。扩展私人钥匙可以创建一个完整的分支而扩展公共钥匙只能够创造一个公共钥匙的分支 扩展密钥通过Base58Check来编码，从而能轻易地在不同的BIP0032-兼容钱包之间导入导出。扩展密钥编码用的Base58Check使用特殊的版本号，这导致在Base58编码字符中，出现前缀“xprv”和“xpub”。这种前缀可以让编码更易被识别。因为扩展密钥是512或者513位，所以它比我们之前所看到的Base58Check-encoded串更长一些。 H4 公共子钥匙推导正如之前提到的，分层确定性钱包的一个很有用的特点就是可以不通过私钥而直接从公共母钥匙派生出公共子钥匙的能力。这就给了我们两种去衍生子公共钥匙的方法：或者通过子私钥，再或者就是直接通过母公共钥匙。 因此，扩展的公共钥匙可以再HD钱包结构的分支中，被用来衍生所有的公钥（且只有公共钥匙）。 这种快捷方式可以用来创造非常保密的public-key-only配置。在配置中，服务器或者应用程序不管有没有私钥，都可以有扩展公共钥匙的副本。这种配置可以创造出无限数量的公共钥匙以及比特币地址。但是不可以花送到这个地址里的任何比特币。与此同时，在另一种更保险的服务器上，扩展私钥可以衍生出所有的对应的可签署交易以及花钱的私钥。 扩展母公共钥匙来创造一个子公共钥匙 H4 硬化子密钥的衍生从扩展公共钥匙衍生一个分支公共钥匙的能力是很重要的，但牵扯一些风险。访问扩展公共钥匙并不能得到访问子私人密钥的途径。但是，因为扩展公共钥匙包含有链码，如果子私钥被知道或者被泄漏的话，链码就可以被用来衍生所有的其他子私钥。一个简单地泄露的私钥以及一个母链码，可以暴露所有的子密钥。更糟糕的是，子私钥与母链码可以用来推断母私钥。 为了应对这种风险，HD钱包使用一种叫做hardened derivation的替代衍生方程。这就“打破”了母公共钥匙以及子链码之间的关系。这个硬化衍生方程使用了母私钥去推到子链码，而不是母公共钥匙。这就在母/子顺序中创造了一道“防火墙”——有链码但并不能够用来推算子链码或者姊妹私钥。强化的衍生方程看起来几乎与一般的衍生的子私钥相同，不同的是是母私钥被用来输入散列方程中而不是母公共钥 子密钥的强化衍生；忽略了母公共密钥 H4 正常衍生和强化衍生的索引号码用在衍生方程中的索引号码是32位的整数。为了区分密钥是从正常衍生方程中衍生出来还是从强化衍生方程中产出，这个索引号被分为两个范围。索引号在0和 \\(2^{31}\\) \\(2^{31}–1\\) (0x0 to 0x7FFFFFFF)之间的是只被用在常规衍生。索引号在\\(2^{31}\\)和\\(2^{32}–1\\)(0x80000000 to 0xFFFFFFFF)之间的只被用在强化衍生方程。因此，索引号小于231就意味着子密钥是常规的，而大于或者等于231的子密钥就是强化型的。 为了让索引号码更容易被阅读和展示，强化子密码的索引号码是从0开始展示的，但是右上角有一个小撇号。第一个常规子密钥因此被表述为0，但是第一个强化子密钥（索引号为0x80000000）就被表示为0’。第二个强化密钥依序有了索引号0x80000001，且被显示为1’，以此类推。当你看到HD钱包索引号i’，这就意味着 \\(2^{31}+i\\) 。 H4 HD钱包密钥识别符（路径）HD钱包中的密钥是用“路径”命名的，且每个级别之间用斜杠（/）字符来表示（见表4-8）。由主私钥衍生出的私钥起始以“m”打头。因此，第一个母密钥生成的子私钥是m/0。第一个公共钥匙是M/0。第一个子密钥的子密钥就是m/0/1，以此类推。 密钥的“祖先”是从右向左读，直到你达到了衍生出的它的主密钥。举个例子，标识符m/x/y/z描述的是子密钥m/x/y的第z个子密钥。而子密钥m/x/y又是m/x的第y个子密钥。m/x又是m的第x个子密钥 我就一展示数据的表格 HD path 密钥描述 m/0 从主私钥（m）衍生出的第一个（0）子密钥。 m/0/0 第一个私人子密钥（m/0）的子密钥。 m/0’/0 第一个子强化密钥first hardened child（m/0’）的第一个常规子密钥。 H4 HD钱包树状结构的导航HD钱包树状结构提供了极大的灵活性。每一个母扩展密钥有40已个子密钥：20亿个常规子密钥和20亿个强化子密钥。而每个子密钥又会有40亿个子密钥并且以此类推。只要你愿意，这个树结构可以无限类推到无穷代。但是，又由于有了这个灵活性，对无限的树状结构进行导航就变得异常困难。尤其是对于在不同的HD钱包之间进行转移交易，因为内部组织到内部分支以及亚分支的可能性是无穷的。 两个比特币改进建议（BIPs）提供了这个复杂问的解决办法——通过创建几个HD钱包树的提议标准。BIP0043提出使用第一个强化子索引作为特殊的标识符表示树状结构的“purpose”。基于BIP0043，HD钱包应该使用且只用第一层级的树的分支，而且有索引号码去识别结构并且有命名空间来定义剩余的树的目的地。举个例子，HD钱包只使用分支m/i’/是为了表明那个被索引号“i”定义的特殊为目地。 在BIP0043标准下，为了延长的那个特殊规范，BIP0044提议了多账户结构作为“purpose”。所有遵循BIP0044的HD钱包依据只使用树的第一个分支的要求而被定义：m/44’/。 BIP0044指定了包含5个预定义树状层级的结构： m / purpose' / coin_type' / account' / change / address_index 第一层的目的地总是被设定为44’。 第二层的“coin_type”特指密码货币硬币的种类并且允许多元货币HD钱包中的货币在第二个层级下有自己的亚树状结构。目前有三种货币被定义：Bitcoin is m/44’/0’、Bitcoin Testnet is m/44’/1’，以及Litecoin is m/44’/2’。 更多的币种 树的第三层级是“account”，这可以允许使用者为了会计或者组织目的，而去再细分他们的钱包到独立的逻辑性亚账户。举个例子，一个HD钱包可能包含两个比特币“账户”：m/44’/0’/0’ 和 m/44’/0’/1’。每个账户都是它自己亚树的根。 第四层级就是“change”。每一个HD钱包有两个亚树，一个是用来接收地址一个是用来创造找零地址。注意无论先前的层级是否使用是否使用强化衍生，这一层级使用的都是常规衍生。这是为了允许这一层级的树可以在可供不安全环境下，输出扩展的公共钥匙。被HD钱包衍生的可用的地址是第四层级的子级，就是第五层级的树的“address_index”。比如，第三个层级的主账户收到比特币支付的地址就是 M/44’/0’/0’/0/2。 我就一展示数据的表格 HD 路径 主要描述 M/44’/0’/0’/0/2 第三个收到公共钥匙的主比特币账户 M/44’/0’/3’/1/14 第十五改变地址公钥的第四个比特币账户 m/44’/2’/0’/0/1 为了签署交易的在莱特币主账户的第二个私钥 H2 扩展知识 高级密钥和地址H3 加密私钥（BIP0038）私钥必须保密。私钥的机密性需求事实情况是，在实践中相当难以实现，因为该需求与同样重要的安全对象可用性相互矛盾。当你需要为了避免私钥丢失而存储备份时，会发现维护私钥私密性是一件相当困难的事情。通过密码加密内有私钥的钱包可能要安全一点，但那个钱包也需要备份。有时，例如用户因为要升级或重装钱包软件，而需要把密钥从一个钱包转移到另一个。私钥备份也可能需要存储在纸张上或者外部存储介质里，比如U盘。但如果一旦备份文件失窃或丢失呢？这些矛盾的安全目标推进了便携、方便、可以被众多不同钱包和比特币客户端理解的加密私钥标准BIP0038的出台。 BIP0038提出了一个通用标准，使用一个口令加密私钥并使用Base58Check对加密的私钥进行编码，这样加密的私钥就可以安全地保存在备份介质里，安全地在钱包间传输，保持密钥在任何可能被暴露情况下的安全性。这个加密标准使用了AES，这个标准由NIST建立，并广泛应用于商业和军事应用的数据加密。 BIP0038加密方案是：输入一个比特币私钥，通常使用WIF编码过，base58chek字符串的前缀“5”。此外BIP0038加密方案需要一个长密码作为口令，通常由多个单词或一段复杂的数字字母字符串组成。BIP0038加密方案的结果是一个由base58check编码过的加密私钥，前缀为6P。如果你看到一个6P开头的的密钥，这就意味着该密钥是被加密过，并需要一个口令来转换（解码）该密钥回到可被用在任何钱包WIF格式的私钥（前缀为5）。许多钱包APP现在能够识别BIP0038加密过的私钥，会要求用户提供口令解码并导入密钥。第三方APP，诸如非常好用基于浏览器的Bit Address，可以被用来解码BIP00038的密钥。 最通常使用BIP0038加密的密钥用例是纸钱包——一张纸张上备份私钥。只要用户选择了强口令，使用BIP0038加密的私钥的纸钱包就无比的安全，这也是一种很棒的比特币离线存储方式（也被称作“冷存储”）。 我就一展示数据的表格 私钥（WIF） 5J3mBbAH58CpQ3Y5RNJpUKPE62SQ5tfcvU2JpbnkeyhfsYB1Jcn 密码 MyTestPassphrase 加密私钥（BIP0038） 6PRTHL6mWa48xSopbU1cKrVjpKbBZxcLRRCdctLJ3z5yxE87MobKoXdTsJ H3 P2SH (Pay-to-Script Hash)和多重签名地址正如我们所知，传统的比特币地址从数字1开头，来源于公钥，而公钥来源于私钥。虽然任何人都可以将比特币发送到一个1开头的地址，但比特币只能在通过相应的私钥签名和公钥哈希值后才能消费。 以数字3开头的比特币地址是P2SH地址，有时被错误的称谓多重签名或多重签名地址。他们指定比特币交易中受益人作为哈希的脚本，而不是公钥的所有者。这个特性在2012年1月由BIP0016引进，目前因为BIP0016提供了增加功能到地址本身的机会而被广泛的采纳。不同于P2PKH交易发送资金到传统1开头的比特币地址，资金被发送到3开头的地址时，需要的不仅仅是一个公钥的哈希值，同时也需要一个私钥签名作为所有者证明。在创建地址的时候，这些要求会被定义在脚本中，所有对地址的输入都会被这些要求阻隔。 一个P2SH地址从事务脚本中创建，它定义谁能消耗这个事务输出。编码一个P2SH地址涉及使用一个在创建比特币地址用到过的双重哈希函数，并且只能应用在脚本而不是公钥： script hash = RIPEMD160(SHA256(script)) 脚本哈希的结果是由Base58Check编码前缀为5的版本、编码后得到开头为3的编码地址。一个P2SH地址例子是32M8ednmuyZ2zVbes4puqe44NZumgG92sM。 P2SH 不一定是多重签名的交易。虽然P2SH地址通常都是代表多重签名，但也可能是其他类型的交易脚本。 H4 多重签名地址和P2SH目前，P2SH函数最常见的实现是用于多重签名地址脚本。顾名思义，底层脚本需要多个签名来证明所有权，此后才能消费资金。设计比特币多重签名特性是需要从总共N个密钥中需要M个签名（也被称为“阈值”），被称为M-N多签名，其中M是等于或小于N。例如，第一章中提到的咖啡店主鲍勃使用多重签名地址需要1-2签名，一个是属于他的密钥和一个属于他同伴的密钥，以确保其中一方可以签署度过一个事务锁定输出到这个地址。这类似于传统的银行中的一个“联合账户”，其中任何一方配偶可以凭借单一签名消费。或Gopesh， Bob雇佣的网页设计师创立一个网站，可能为他的业务需要一个2-3的多签名地址，确保没有资金会被花费除非至少两个业务合作伙伴签署这笔交易。 我们将会在第五章节探索如何使用P2SH地址创建事务用来消费资金。 H3 比特币靓号地址靓号地址包含了可读信息的有效比特币地址。例如，1LoveBPzzD72PUXLzCkYAtGFYmK5vYNR33就是包含了Base-58字母love的。靓号地址需要生成并通过数十亿的候选私钥测试，直到一个私钥能生成具有所需图案的比特币地址。虽然有一些优化过的靓号生成算法，该方法必须涉及随机上选择一个私钥，生成公钥，再生成比特币地址，并检查是否与所要的靓号图案相匹配，重复数十亿次，直到找到一个匹配。 一旦找到一个匹配所要图案的靓号地址，来自这个靓号地址的私钥可以和其他地址相同的方式被拥有者消费比特币。靓号地址不比其他地址具有更多安全性。它们依靠和其他地址相同的ECC和SHA。你无法比任何别的地址更容易的获得一个靓号图案开头的私钥。 例如：我们介绍了Eugenia，一位在菲律宾工作的儿童慈善总监。我们假设Eugenia组织了一场比特币募捐活动，并希望使用靓号比特币地址来宣布这个募捐活动。Eugenia将会创造一个以1Kids开头的靓号地址来促进儿童慈善募捐的活动。让我们看看这个靓号地址如何被创建，这个靓号地址对Eugenia慈善募捐的安全性又意味着什么。 H4 生成靓号地址我们必须认识到使用来自Base58字母表中简单符号来代表比特币地址是非常重要的。搜索“1kids”开头的图案我们会发现从1Kids11111111111111111111111111111到1Kidszzzzzzzzzzzzzzzzzzzzzzzzzzzzz的地址。这些以“1kid”开头的地址范围中大约有58的29次方地址 我们把“1Kids”这个前缀当作数字，我们可以看看比特币地址中这个前缀出现的频率。如果是一台普通性能的桌面电脑，没有任何特殊的硬件，可以每秒发现大约10万个密钥。 我就一展示数据的表格 长度 地址前缀 概率 平均生成时间 1 1K \\(\\dfrac {1}{58}\\) &lt; 1毫秒 2 1Ki \\(\\dfrac {1}{3364}\\) 50毫秒 3 1Kid \\(\\dfrac {1}{195\\times 10^{3}}\\) &lt; 2秒 4 1Kids \\(\\dfrac {1}{11\\times 10^{6}}\\) 1分钟 5 1KidsC \\(\\dfrac {1}{656\\times 10^{6}}\\) 1小时 6 1KidsCh \\(\\dfrac {1}{38\\times 10^{9}}\\) 2天 7 1KidsCha \\(\\dfrac {1}{2.2\\times 10^{12}}\\) 3–4 月 8 1KidsChar \\(\\dfrac {1}{128\\times 10^{12}}\\) 13–18年 9 1KidsChari \\(\\dfrac {1}{7\\times 10^{15}}\\) 800年 10 1KidsCharit \\(\\dfrac {1}{400\\times 10^{15}}\\) 46,000年 11 1KidsCharity \\(\\dfrac {1}{23\\times 10^{18}}\\) 250万年 正如你所见，Eugenia将不会很快地创建出以“1KidsCharity”开头的靓号地址，即使她有数千台的电脑同时进行运算。每增加一个字符就会增加58倍的计算难度。超过七个字符的搜索模式通常需要专用的硬件才能被找出，譬如用户定制的具有多图形处理单元（GPU）的桌面级设备。那些通常是无法继续在比特币挖矿中盈利的钻机，被重新赋予了寻找靓号地址的任务。用GPU系统搜索靓号的速度比用通用CPU要快很多个量级。 另一种寻找靓号地址的方法是将工作外包给一个矿池里的靓号矿工们，如靓号矿池中的矿池。一个矿池是一种允许那些GPU硬件通过为他人寻找靓号地址来获得比特币的服务。对小额的账单，Eugenia可以外包搜索模式为7个字符靓号地址寻找工作，在几个小时内就可以得到结果，而不必用一个CPU搜索上几个月才得到结果。 生成一个靓号地址是一项通过蛮力的过程：尝试一个随机密钥，检查结果地址是否和所需的图案相匹配，重复这个过程直到成功找到为止 H5 靓号挖掘程序#include &lt;bitcoin/bitcoin.hpp> // The string we are searching for const std::string search = \"1kid\"; // Generate a random secret key. A random 32 bytes. bc::ec_secret random_secret(std::default_random_engine&amp; engine); // Extract the Bitcoin address from an EC secret. std::string bitcoin_address(const bc::ec_secret&amp; secret); // Case insensitive comparison with the search string. bool match_found(const std::string&amp; address); int main() { std::random_device random; std::default_random_engine engine(random()); // Loop continuously... while (true) { // Generate a random secret. bc::ec_secret secret = random_secret(engine); // Get the address. std::string address = bitcoin_address(secret); // Does it match our search string? (1kid) if (match_found(address)) { // Success! std::cout &lt;&lt; \"Found vanity address! \" &lt;&lt; address &lt;&lt; std::endl; std::cout &lt;&lt; \"Secret: \" &lt;&lt; bc::encode_hex(secret) &lt;&lt; std::endl; return 0; } } // Should never reach here! return 0; } bc::ec_secret random_secret(std::default_random_engine&amp; engine) { // Create new secret... bc::ec_secret secret; // Iterate through every byte setting a random value... for (uint8_t&amp; byte: secret) byte = engine() % std::numeric_limits&lt;uint8_t>::max(); // Return result. return secret; } std::string bitcoin_address(const bc::ec_secret&amp; secret) { // Convert secret to pubkey... bc::ec_point pubkey = bc::secret_to_public_key(secret); // Finally create address. bc::payment_address payaddr; bc::set_public_key(payaddr, pubkey); // Return encoded form. return payaddr.encoded(); } bool match_found(const std::string&amp; address) { auto addr_it = address.begin(); // Loop through the search string comparing it to the lower case // character of the supplied address. for (auto it = search.begin(); it != search.end(); ++it, ++addr_it) if (*it != std::tolower(*addr_it)) return false; // Reached end of search string, so address matches. return true; } 示例程序需要用C编译器链接libbitcoin库（此库需要提前装入该系统）进行编译。直接执行vanity-miner的可执行文件,它就会尝试碰撞以“1kid”开头的比特币地址。 $ # Compile the code with g++ $ g++ -o vanity-miner vanity-miner.cpp $(pkg-config --cflags --libs libbitcoin) $ # Run the example $ ./vanity-miner Found vanity address! 1KiDzkG4MxmovZryZRj8tK81oQRhbZ46YT Secret: 57cc268a05f83a23ac9d930bc8565bac4e277055f4794cbd1a39e5e71c038f3f $ # Run it again for a different result $ ./vanity-miner Found vanity address! 1Kidxr3wsmMzzouwXibKfwTYs5Pau8TUFn Secret: 7f65bbbbe6d8caae74a0c6a0d2d7b5c6663d71b60337299a1a2cf34c04b2a623 # Use \"time\" to see how long it takes to find a result $ time ./vanity-miner Found vanity address! 1KidPWhKgGRQWD5PP5TAnGfDyfWp5yceXM Secret: 2a802e7a53d8aa237cd059377b616d2bfcfa4b0140bc85fa008f2d3d4b225349 real 0m8.868s user 0m8.828s sys 0m0.035s 正如我们运行Unix命令time所测出的运行时间所示，示例代码要花几秒钟来找出匹配“kid”三个字符模板的结果。读者们可以在源代码中改变search这一搜索模板，看一看如果是四个字符或者五个字符的搜索模板需要花多久时间！ H4 靓号地址安全性靓号地址既可以增加、也可以削弱安全措施，它们着实是一把双刃剑。用于改善安全性时，一个独特的地址使对手难以使用他们自己的地址替代你的地址，以欺骗你的顾客支付他们的账单。不幸的是，靓号地址也可能使得任何人都能创建一个类似于随机地址的地址，甚至另一个靓号地址，从而欺骗你的客户。 Eugenia可以让捐款人捐款到她宣布的一个随机生成地址（例如：1J7mdg5rbQyUHENYdx39WVWK7fsLpEoXZy）。或者她可以生成一个以“1Kids”开头的靓号地址以显得更独特。 在这两种情况下，使用单一固定地址（而不是每比捐款用一个独立的动态地址）的风险之一是小偷有可能会黑进你的网站，用他自己的网址取代你的网址，从而将捐赠转移给自己。如果你在不同的地方公布了你的捐款地址，你的用户可以在付款之前直观地检查以确保这个地址跟在你的网站、邮件和传单上看到的地址是同一个。在随机地址1j7mdg5rbqyuhenydx39wvwk7fslpeoxzy的情况下，普通用户可能会只检查头几个字符“1j7mdg”，就认为地址匹配。使用靓号地址生成器，那些想通过替换类似地址来盗窃的人可以快速生成与前几个字符相匹配的地址 那靓号地址会不会增加安全性？如果Eugenia生成1Kids33q44erFfpeXrmDSz7zEqG2FesZEN的靓号地址，用户可能看到靓号图案的字母和一些字符在上面，例如在地址部分中注明了1Kids33。这样就会迫使攻击者生成至少6个字母相匹配的的靓号地址（比之前多2个字符），就要花费比Eugenia多3364倍的靓号图案。本质上，Eugenia付出的努力（或者靓号池付出的）迫使攻击者不得不生成更长的靓号图案。如果Eugenia花钱请矿池生成8个字符的靓号地址，攻击者将会被逼迫到10字符的境地，那将是个人电脑，甚至昂贵自定义靓号挖掘机或靓号池也无法生成。对Eugenia来说可承担的起支出，对攻击者来说则变成了无法承担支出，特别是如果欺诈的回报不足以支付生成靓号地址所需的费用。 H3 纸钱包纸钱包是打印在纸张上的比特币私钥。有时纸钱包为了方便起见也包括对应的比特币地址，但这并不是必要的，因为地址可以从私钥中导出。纸钱包是一个非常有效的建立备份或者线下存储比特币（即冷钱包）的方式。作为备份机制，一个纸钱包可以提供安全性，以防在电脑硬盘损坏、失窃或意外删除的情况下造成密钥的的丢失。作为一个冷存储的机制，如果纸钱包密钥在线下生成并永久不在电脑系统中存储，他们在应对黑客攻击，键盘记录器，或其他在线电脑欺骗更有安全性。 纸钱包有许多不同的形状，大小，和外观设计，但非常基本的原则是一个密钥和一个地址打印在纸张上。 BIP32-39-43-44.md","categories":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/categories/区块链/"}],"tags":[{"name":"HD Wallet","slug":"HD-Wallet","permalink":"http://blog.msiter.com/tags/HD-Wallet/"},{"name":"BIP32-44","slug":"BIP32-44","permalink":"http://blog.msiter.com/tags/BIP32-44/"},{"name":"Block chain","slug":"Block-chain","permalink":"http://blog.msiter.com/tags/Block-chain/"}],"keywords":[{"name":"区块链","slug":"区块链","permalink":"http://blog.msiter.com/categories/区块链/"}]},{"title":"球在矩形内弹射的题目思考","slug":"关于弹射面试题的思考","date":"2018-03-06T11:33:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"gyd,ts,ymstdsk-20180306.html","link":"","permalink":"http://blog.msiter.com/gyd,ts,ymstdsk-20180306.html","excerpt":"题目 如图所示，在证书坐标系内有一个矩形（高M，宽N。M，N是随机整数值，大小不确定），现在从矩形内原点（0,0）以45° ，向上发射一个点（点的大小忽略），词典在矩形内做直线运动，碰到矩形边后完全弹性碰撞反弹，现假设此点在矩形内一直重复做碰撞运动，（即碰撞次数无限），请设计一个程序打印出这个点与矩形每次碰撞的坐标，精确到整数。PS：可使用伪代码或者任意编程语言实现。","text":"H2 题目 面试题 示意图 如图所示，在证书坐标系内有一个矩形（高M，宽N。M，N是随机整数值，大小不确定），现在从矩形内原点（0,0）以45° ，向上发射一个点（点的大小忽略），词典在矩形内做直线运动，碰到矩形边后完全弹性碰撞反弹，现假设此点在矩形内一直重复做碰撞运动，（即碰撞次数无限），请设计一个程序打印出这个点与矩形每次碰撞的坐标，精确到整数。PS：可使用伪代码或者任意编程语言实现。 今天上班的时候，同时给我发了一下这个题目，一开始觉的难点在于数学计算上，慢慢的发现并不是。接下来我们就来看看这道题的解题思路把。 以下代码，均为 Swift4 版本。 H2 解题思路其实这个问题看着感觉无从下手，其实我们一步步地分析起来还是很简单的 H3 设置点的类型首先我们来假设这个Point为一种类型，所以有以下代码,分别有X和Y点来假设球的坐标。 /// 弹射的每一个点的类型抽象 struct Point{ let x:Int let y:Int } H3 思考点的弹射方向接下来我们来思考球都会有哪些行为。球可以向上弹射，也可以向下，也可以向右，也可以向左，总结来看就是球可以做四种方向的运动。分别为上左，上右，下左，下右。由此设计以下枚举 /// 球 弹射的方向 /// /// - topl: 上左 /// - topr: 上右 /// - bottoml: 下左 /// - bottomr: 下右 enum Dir{ case topl case topr case bottoml case bottomr } H3 思考球碰壁的几种情况这个时候，我们也会注意到，球碰壁的时候会有几种情况呢？ 其实就是球的X，因为X才是限制球的位置的根本，所以X的情况: 正常的情况 0&gt;X&gt;N 非正常的晴空 XN 非常巧合的状况 X=0 以及 X=N H2 根据方向来得出点以及情况我们接下来，以第一次弹射（TopRight方向）来进行该题的实际解体。 H3 正常情况如图所示 正常情况 示意图 在这种情况下，下一个点的记录为 (x+n,y+m)，并且我们可以预测到他的以下次碰撞的角度是 下右 H3 超出范围的情况 超出范围的情况 示意图 我们根据图可以看到，我们想要的点在 (n,y+(n-x))。我们可以预测下一次发射角度为 上左 H3 正好撞在角上 撞在角上 示意图 我们根据图中可以看出，下一次的点在 (n,m) 。下一次撞击方向为 下左 H3 其他三种角度其他三种角度，这里就不一一赘述了，总是利用这个方法我们可以得以下4个方法 extension Point{ /// 将此 Point 按照 上右方向发射 func topr() -> (Point,Dir) { let x = self.x + m let y = self.y + m if x > n { return (Point(x: n, y: n-self.x),.topl) }else if x &lt; n{ return (Point(x: x, y: y),.bottomr) }else{ return (Point(x: x, y: y),.bottoml) } } /// 将此 Point 按照 上左方向发射 func topl() -> (Point,Dir) { let x = self.x - (m-self.y) let y = self.y + (m-self.y) if x &lt; 0 { return (Point(x: 0, y: self.x),.topr) }else if x > 0{ return (Point(x: x, y: y),.bottoml) }else{ return (Point(x: 0, y: m),.bottomr) } } /// 将此 Point 按照 下左方向发射 func bottoml() -> (Point,Dir) { let x = self.x - m let y = self.y - m if x &lt; 0 { return (Point(x: 0, y: m-self.x),.bottomr) }else if x > 0{ return (Point(x: x, y: y),.topl) }else{ return (Point(x: 0, y: 0),.topr) } } /// 将此 Point 按照 下右方向发射 func bottomr() -> (Point,Dir) { let x = self.x + m let y = self.y - m if x > n { return (Point(x: n, y: m-self.x),.bottoml) }else if x &lt; n{ return (Point(x: x, y: y),.topr) }else{ return (Point(x: x, y: y),.topl) } } } H2 完整例子//: Playground - noun: a place where people can play import UIKit /// X - Y 的极限数值 let n = 24 let m = 10 /// 弹射次数 var count = 10 /// 弹射的每一个点的类型抽象 struct Point{ let x:Int let y:Int } extension Point{ /// 将此 Point 按照 上右方向发射 func topr() -> (Point,Dir) { let x = self.x + m let y = self.y + m if x > n { return (Point(x: n, y: n-self.x),.topl) }else if x &lt; n{ return (Point(x: x, y: y),.bottomr) }else{ return (Point(x: x, y: y),.bottoml) } } /// 将此 Point 按照 上左方向发射 func topl() -> (Point,Dir) { let x = self.x - (m-self.y) let y = self.y + (m-self.y) if x &lt; 0 { return (Point(x: 0, y: self.x),.topr) }else if x > 0{ return (Point(x: x, y: y),.bottoml) }else{ return (Point(x: 0, y: m),.bottomr) } } /// 将此 Point 按照 下左方向发射 func bottoml() -> (Point,Dir) { let x = self.x - m let y = self.y - m if x &lt; 0 { return (Point(x: 0, y: m-self.x),.bottomr) }else if x > 0{ return (Point(x: x, y: y),.topl) }else{ return (Point(x: 0, y: 0),.topr) } } /// 将此 Point 按照 下右方向发射 func bottomr() -> (Point,Dir) { let x = self.x + m let y = self.y - m if x > n { return (Point(x: n, y: m-self.x),.bottoml) }else if x &lt; n{ return (Point(x: x, y: y),.topr) }else{ return (Point(x: x, y: y),.topl) } } } /// 球 弹射的方向 /// /// - topl: 上左 /// - topr: 上右 /// - bottoml: 下左 /// - bottomr: 下右 enum Dir{ case topl case topr case bottoml case bottomr } func run(d:Dir,point:Point){ var res:(Point,Dir)! switch d { case .topr: res = point.topr() case .topl: res = point.topl() case .bottoml: res = point.bottoml() case .bottomr: res = point.bottomr() } count -= 1 if count &lt; 0 { return } print(\"x:\",res.0.x,\",y:\",res.0.y) run(d: res.1, point: res.0) } let point = Point(x: 0, y: 0) run(d: .topl, point: point) 这些就是全部的代码，包含了，次数的限制，否则无限递归，会陷入死循环。 运行上方代码结果为 x: 0 ,y: 0 x: 10 ,y: 10 x: 20 ,y: 0 x: 24 ,y: 4 x: 18 ,y: 10 x: 8 ,y: 0 x: 0 ,y: 8 x: 10 ,y: 18 x: 20 ,y: 8 x: 24 ,y: 4 结果我没有特别的演算过，主要是还是这个思路。如果有什么问题，告诉我，我会及时修改。 关于弹射面试题的思考.md","categories":[{"name":"面试题目","slug":"面试题目","permalink":"http://blog.msiter.com/categories/面试题目/"}],"tags":[{"name":"面试题目","slug":"面试题目","permalink":"http://blog.msiter.com/tags/面试题目/"},{"name":"递归","slug":"递归","permalink":"http://blog.msiter.com/tags/递归/"}],"keywords":[{"name":"面试题目","slug":"面试题目","permalink":"http://blog.msiter.com/categories/面试题目/"}]},{"title":"hexo 增加目录","slug":"hexo 增加目录","date":"2018-03-01T22:41:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"hexo zjml-20180301.html","link":"","permalink":"http://blog.msiter.com/hexo zjml-20180301.html","excerpt":"一直都想给自己的也看增加一个目录，默认的hexo是有默认的目录登记的 官方示例 - toc解析内容中的标题标签 (h1~h6) 并插入目录。 Hexo博客系统的核心支持生成目录（Table of Contents）,生成目录之后，由于没有配置的时候，如果文章目录结构很大的话会出现问题。所以我希望增加一个滑动的时候，展开和隐藏目录结构的方法。这样也会显的非常酷炫= 接下来的代码多半都是在 NEXT HEXO THEME中获得的，在这里非常感谢作者，毕竟我第一个博客主题就是用的NEXT，只是又一次作者的某个版本修改的非常多，导致我的博客挂掉了… 我就决定要自己写一个模版，至少不要因为主题升级版本博客死掉了。","text":"一直都想给自己的也看增加一个目录，默认的hexo是有默认的目录登记的 H2 官方示例 - toc解析内容中的标题标签 (h1~h6) 并插入目录。 Hexo博客系统的核心支持生成目录（Table of Contents）,生成目录之后，由于没有配置的时候，如果文章目录结构很大的话会出现问题。所以我希望增加一个滑动的时候，展开和隐藏目录结构的方法。这样也会显的非常酷炫= 接下来的代码多半都是在 NEXT HEXO THEME中获得的，在这里非常感谢作者，毕竟我第一个博客主题就是用的NEXT，只是又一次作者的某个版本修改的非常多，导致我的博客挂掉了… 我就决定要自己写一个模版，至少不要因为主题升级版本博客死掉了。 我就一展示数据的表格 参数 描述 默认值 class Class 名称 toc list_number 显示编号 true H3 示例 H2 自定义 自己的目录结构接下来我们会一步步的完成咱们的目录结构以及动画 H3 生成目录 &lt;div class=&quot;g-mb-40&quot;&gt; &lt;div class=&quot;g-mb-40 post-toc&quot;&gt; &lt;div class=&quot;u-heading-v3-1 g-mb-30&quot;&gt; &lt;h2 class=&quot;h5 u-heading-v3__title g-color-gray-dark-v1 text-uppercase g-brd-primary&quot;&gt;目录&lt;/h2&gt; &lt;/div&gt; &lt;%- toc(page.content,{&quot;class&quot;:&quot;post-nav&quot;})%&gt; &lt;/div&gt; &lt;/div&gt; H3 增加CSS &lt;style> .post-toc { overflow: auto; } .post-toc ol { margin: 0; padding: 0 2px 5px 10px; text-align: left; list-style: none; font-size: 14px; } .post-toc ol>ol { padding-left: 0; } .post-toc ol a { transition-duration: 0.2s; transition-timing-function: ease-in-out; transition-delay: 0s; transition-property: all; color: #111; border-bottom-color: #555; } .post-toc ol a:hover { color: #4f72c1; border-bottom-color: #ccc; } .post-toc .post-nav-item { overflow: hidden; text-overflow: ellipsis; white-space: nowrap; line-height: 1.8; } .post-toc .post-nav .post-nav-child { display: none; } .post-toc .post-nav .active>.post-nav-child { display: block; } .post-toc .post-nav .active-current>.post-nav-child { display: block; } .post-toc .post-nav .active-current>.post-nav-child>.post-nav-item { display: block; } .post-toc .post-nav .active>a { color: #6281c8; border-bottom-color: #87daff; } .post-toc .post-nav .active-current>a { color: #6281c8; } .post-toc .post-nav .active-current>a:hover { color: #87daff; } &lt;/style> H3 增加js方法实现&lt;script type=\"text/javascript\"> function escapeSelector(selector) { return selector.replace(/[!\"$%&amp;'()*+,.\\/:;&lt;=>?@[\\\\\\]^`{|}~]/g, '\\\\$&amp;'); } + function($) { 'use strict'; // SCROLLSPY CLASS DEFINITION // ========================== function ScrollSpy(element, options) { this.$body = $(document.body) this.$scrollElement = $(element).is(document.body) ? $(window) : $(element) this.options = $.extend({}, ScrollSpy.DEFAULTS, options) this.selector = (this.options.target || '') + ' .post-nav li > a' this.offsets = [] this.targets = [] this.activeTarget = null this.scrollHeight = 0 this.$scrollElement.on('scroll.bs.scrollspy', $.proxy(this.process, this)) this.refresh() this.process() } ScrollSpy.VERSION = '3.3.2' ScrollSpy.DEFAULTS = { offset: 10 } ScrollSpy.prototype.getScrollHeight = function() { return this.$scrollElement[0].scrollHeight || Math.max(this.$body[0].scrollHeight, document.documentElement.scrollHeight) } ScrollSpy.prototype.refresh = function() { var that = this var offsetMethod = 'offset' var offsetBase = 0 this.offsets = [] this.targets = [] this.scrollHeight = this.getScrollHeight() if (!$.isWindow(this.$scrollElement[0])) { offsetMethod = 'position' offsetBase = this.$scrollElement.scrollTop() } this.$body .find(this.selector) .map(function() { var $el = $(this) var href = $el.data('target') || $el.attr('href') var $href = /^#./.test(href) &amp;&amp; $(escapeSelector(href)) // Need to escape selector. return ($href &amp;&amp; $href.length &amp;&amp; $href.is(':visible') &amp;&amp; [ [$href[offsetMethod]().top + offsetBase, href] ]) || null }) .sort(function(a, b) { return a[0] - b[0] }) .each(function() { that.offsets.push(this[0]) that.targets.push(this[1]) }) } ScrollSpy.prototype.process = function() { var scrollTop = this.$scrollElement.scrollTop() + this.options.offset var scrollHeight = this.getScrollHeight() var maxScroll = this.options.offset + scrollHeight - this.$scrollElement.height() var offsets = this.offsets var targets = this.targets var activeTarget = this.activeTarget var i if (this.scrollHeight != scrollHeight) { this.refresh() } if (scrollTop >= maxScroll) { return activeTarget != (i = targets[targets.length - 1]) &amp;&amp; this.activate(i) } if (activeTarget &amp;&amp; scrollTop &lt; offsets[0]) { $(this.selector).trigger('clear.bs.scrollspy') // Add a custom event. this.activeTarget = null return this.clear() } for (i = offsets.length; i--;) { activeTarget != targets[i] &amp;&amp; scrollTop >= offsets[i] &amp;&amp; (!offsets[i + 1] || scrollTop &lt;= offsets[i + 1]) &amp;&amp; this.activate(targets[i]) } } ScrollSpy.prototype.activate = function(target) { this.activeTarget = target this.clear() var selector = this.selector + '[data-target=\"' + target + '\"],' + this.selector + '[href=\"' + target + '\"]' var active = $(selector) .parents('li') .addClass('active') if (active.parent('.dropdown-menu').length) { active = active .closest('li.dropdown') .addClass('active') } active.trigger('activate.bs.scrollspy') } ScrollSpy.prototype.clear = function() { $(this.selector) .parentsUntil(this.options.target, '.active') .removeClass('active') } // SCROLLSPY PLUGIN DEFINITION // =========================== function Plugin(option) { return this.each(function() { var $this = $(this) var data = $this.data('bs.scrollspy') var options = typeof option == 'object' &amp;&amp; option if (!data) $this.data('bs.scrollspy', (data = new ScrollSpy(this, options))) if (typeof option == 'string') data[option]() }) } var old = $.fn.scrollspy $.fn.scrollspy = Plugin $.fn.scrollspy.Constructor = ScrollSpy // SCROLLSPY NO CONFLICT // ===================== $.fn.scrollspy.noConflict = function() { $.fn.scrollspy = old return this } // SCROLLSPY DATA-API // ================== $(window).on('load.bs.scrollspy.data-api', function() { $('[data-spy=\"scroll\"]').each(function() { var $spy = $(this) Plugin.call($spy, $spy.data()) }) }) }(jQuery); &lt;/script> H2 完成这个时候我们已经完成了目录，多层目录，滑动时候就可以看到展开和合并效果了。 H3 需要注意的问题我们的目录结构，必须是大小嵌套的 这种方式是正确的 # ## ### ### 这种发式就是错误的 ## # ### ## H3 没有完成的问题如果某个层级的目录过多，会导致目录视图超出视图范围，这个问题，暂时还没考虑好如何解决，只能以后写文章的时候注意不要过多的某个层级的目录 在移动模式的状态下，其实是不用展示的，但是现在因为技术能力问题，隐藏不了…先这样吧 hexo 增加目录.md","categories":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}],"tags":[{"name":"博客美化","slug":"博客美化","permalink":"http://blog.msiter.com/tags/博客美化/"},{"name":"hexo","slug":"hexo","permalink":"http://blog.msiter.com/tags/hexo/"}],"keywords":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}]},{"title":"Spring boot 服务器","slug":"Spring boot 服务器","date":"2018-03-01T13:29:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Spring boot fwq-20180301.html","link":"","permalink":"http://blog.msiter.com/Spring boot fwq-20180301.html","excerpt":"以前写过一篇文章，但是那个时候感觉是很茫然，不知道为什么garde配置文件为什么这样子，不明白为什么这样设置，虽然最后也连接到了数据库，完成了增删改查，但是和没学的区别也不会很大。今天我打算好好端正我的态度，一步一步的来学习。 创建一个SpringBoot 项目接下来我们要开始开发Springboot项目了。 创建一个 Java 项目本项目使用的第三方包依赖管理插件是 maven，为什么不使用 grade，emmm… 随便吧。这次就想用maven。 赞很多的教程中，我能看到的都是使用maven来创建项目，比如idea，和eclipse都有相关的步骤，选择这个选择那个的….我真的是….如果放在以前，我真的就按照这些步骤来了，现在有可能真的开发时间久了，并且开发IOS的时候 Cocoapods第三方管理，所有的项目最开始都是一清二白的，什么都没有，一步步填充的，所以下意识的我想就一个单纯的文件夹开始完成接下来的教程。","text":"以前写过一篇文章，但是那个时候感觉是很茫然，不知道为什么garde配置文件为什么这样子，不明白为什么这样设置，虽然最后也连接到了数据库，完成了增删改查，但是和没学的区别也不会很大。今天我打算好好端正我的态度，一步一步的来学习。 H2 创建一个SpringBoot 项目接下来我们要开始开发Springboot项目了。 H3 创建一个 Java 项目本项目使用的第三方包依赖管理插件是 maven，为什么不使用 grade，emmm… 随便吧。这次就想用maven。 赞很多的教程中，我能看到的都是使用maven来创建项目，比如idea，和eclipse都有相关的步骤，选择这个选择那个的….我真的是….如果放在以前，我真的就按照这些步骤来了，现在有可能真的开发时间久了，并且开发IOS的时候 Cocoapods第三方管理，所有的项目最开始都是一清二白的，什么都没有，一步步填充的，所以下意识的我想就一个单纯的文件夹开始完成接下来的教程。 H3 创建一个 空的文件夹好吧，话接上边,我们创建一个文件夹，比如名字就叫做 ‘Study’,这个文件除了默认的 .和.. 文件夹什么都没有，接下来，我们使用idea打开这个文件。之后出现了 .idea 文件夹，但是对我们并没有影响，好吧开始之前我们先来创建一个 src 接下来我就不赘述了。最后目录如下： . ├── StudyJava.iml ├── src │ └── main │ ├── java │ ├── resources │ └── webapp └── target 其中imi文件是idea默认的配置文件，所以没啥用处。 H3 创建 pom.xml说实话，咱们使用idea或者eclipse创建的maven，我们可以发现除了生成一个pom.xml，什么都没有产生了，所以其实所有的配置都在xml文件中，我们其实可以直接创建，这样子的好处，大概就是说任何一个项目都可以支持maven，没有必要必须新产生的项目才可以使用。 这些选择创建的项目其实使用了maven的命令，如下： mvn archetype:generate -DgroupId={project-packaging} -DartifactId={project-name}-DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false 我们这里就是直接创建了一个pom.xml 里面添加了一些内容。所以最后我们的样子大概如下： &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;groupId>com.mycompany.app&lt;/groupId> &lt;artifactId>my-app&lt;/artifactId> &lt;version>1.0-SNAPSHOT&lt;/version> &lt;packaging>war&lt;/packaging> &lt;name>Maven Quick Start Archetype&lt;/name> &lt;url>http://maven.apache.org&lt;/url> &lt;/project> 大概的意思我不解释了，为什么呢？第一行那些我不是很明白，后面的这几行，我不想解释。 到这个时候我们的目录结构如下 . ├── StudyJava.iml ├── pom.xml ├── src │ └── main │ ├── java │ ├── resources │ └── webapp └── target H3 配置Spring boot接下来，咱们应该去Spring boot官方网站去学习了。我其实很希望咱们任何人在学习一个东西的时候，第一时间是去官方网站去看，毕竟人家开发的人家的文档才是最好的，我们这些学习完的人确实会有一些独特的见解或者经验可以帮助你快速而好的理解，但是因人而异，或者理解不对地方，所以第一时间应该是去官方网站而不要去搜索引擎搜索教程 来到官方网站，我们看到官方网站非常友好的教你如何快速的运行起来。 首先添加以下代码 &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>1.5.10.RELEASE&lt;/version> &lt;/parent> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;/dependencies> 之后使用maven刷新以下这个导入需要的框架，好吧，我不使用maven命令的，直接使用的idea自带的刷新…你有兴趣的话可以研究下外链内容。 H3 第一个Hello World等到maven将第三方内容导入之后，我们就可以开发了。我们创建以下目录 . ├── StudyJava.iml ├── pom.xml ├── src │ └── main │ ├── java │ │ └── com │ │ └── study │ │ ├── controller │ │ │ └── SampleController.java │ ├── resources │ └── webapp 在SampleController.java 复制粘贴 Spring Boot 文档的代码，当然我们的package 不是 hello，而是package com.study.controller; package com.study.controller; import org.springframework.boot.*; import org.springframework.boot.autoconfigure.*; import org.springframework.stereotype.*; import org.springframework.web.bind.annotation.*; @Controller @EnableAutoConfiguration public class SampleController { @RequestMapping(\"/\") @ResponseBody String home() { return \"Hello World!\"; } public static void main(String[] args) throws Exception { SpringApplication.run(SampleController.class, args); } } 这个时候我们运行main方法，在好看的注释汇总，我们的服务器就运行起来了，打开 0.0.0.0:8080. 日。。。就好了….这样子下去，我都快忘记以前 SSH 配置文件 XML，各种配置的噩梦了… H3 Tomcat 可以配置好吧，其实也非常简单 创建一下文件 . ├── StudyJava.iml ├── pom.xml ├── src │ └── main │ ├── java │ │ └── com │ │ └── study │ │ ├── StudyApplication.java │ │ ├── controller │ │ │ └── SampleController.java │ ├── resources │ └── webapp 代码如下 目前为止来说的话我们已经可以运行起来了，接下来我们来运行到Tomcat H4 修改打包方式在pom.xml设置 &lt;packaging&gt;war&lt;/packaging&gt; 如果以前是 jar 也修改 war H4 添加 servlet-api依赖下面两种方式都可以，任选其一 &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-servlet-api&lt;/artifactId&gt; &lt;version&gt;8.0.36&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; H4 修改启动类，并重写初始化方法上面我们都是用的main方法来启动的服务器，接下俩我们来修改为以下 增加 SpringBootServletInitializer 继承。并重写方法 package com.study; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.builder.SpringApplicationBuilder; import org.springframework.boot.web.support.SpringBootServletInitializer; @SpringBootApplication public class StudyApplication extends SpringBootServletInitializer{ @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) { return super.configure(builder); } public static void main(String[] args) { SpringApplication.run(StudyApplication.class,args); } } H4 maven 打包 并运行 tomcat将 maven 放置在 tomcat下的webapps目录下，并且启动tomcat，访问地址 localhost:8080/项目名称/接口地址 之前一直不明白package与 install的区别，今天测试了下。 如果b项目依赖a项目，而a打了包(package),jar仅仅时打到了a项目的target下。这时编译b项目，还是会报错，找不到所依赖的a项目，说明b项目在本地仓库是没有找到它所依赖的a项目。然后，我install a项目这时，有以下日志,[INFO] Installing G:\\projects\\a\\target\\a-0.0.1-SNAPSHOT.jar to F:\\repository\\com\\chenjun\\a\\0.0.1-SNAPSHOT\\a-0.0.1-SNAPSHOT.jar[INFO] Installing G:\\projects\\a\\pom.xml to F:\\repository\\com\\chenjun\\a\\0.0.1-SNAPSHOT\\a-0.0.1-SNAPSHOT.pom,说明a项目已安装到本地仓库了,并且是jar和pom同时安装的. 这时候去compileb项目，编译通过. 总之，package是把jar打到本项目的target下，而install时把target下的jar安装到本地仓库，供其他项目使用. H2 集成JDBC这个时候我们已经看到一些想过了，但是服务器只是做到这个程度肯定是不行的，我们接下来来进行数据库的链接。本博文中的使用的数据库为mysql。 mysql Ver 14.14 Distrib 5.7.19, for macos10.12 (x86_64) using EditLine wrapper H3 maven添加依赖库&lt;!-- MYSQL --> &lt;dependency> &lt;groupId>mysql&lt;/groupId> &lt;artifactId>mysql-connector-java&lt;/artifactId> &lt;/dependency> &lt;!-- Spring Boot JDBC --> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-jdbc&lt;/artifactId> &lt;/dependency> H3 数据库添加数据 MySQL默认是不区分大小写的 随便创建一个数据库，并且增加一个表，我这里是创建了一个 Study 数据库并且创建了一个 Student 表。 我的代码如下 create table `Student` ( u_id int unsigned auto_increment, u_last_name varchar(20), u_first_name varchar(20), u_address varchar(255), u_age int, u_sex int, u_brithday timestamp, primary key(u_id) ) 我在添加数据的时候，只添加了 id last first 这三个字段…测试嘛 H3 增加 Spring 配置文件我们 Resource文件夹下，随便哪里创建一个 application.properties 代码如下 spring.datasource.url=jdbc:mysql://localhost:3306/study #spring.datasource.name=study spring.datasource.username=root spring.datasource.password=123456 spring.datasource.driver-class-name=com.mysql.jdbc.Driver H3 实体类添加我们来创建一个 Student 实体类用来接收从数据库中获取的数据 package com.study.model; public class Student { private int uid; private String ulastname; private String ufirstname; public int getUid() { return uid; } public void setUid(int uid) { this.uid = uid; } public String getUlastname() { return ulastname; } public void setUlastname(String ulastname) { this.ulastname = ulastname; } public String getUfirstname() { return ufirstname; } public void setUfirstname(String ufirstname) { this.ufirstname = ufirstname; } } H3 数据库查询具体我也不写了，我使用的是 JDBCTemplete 来查询的 @RequestMapping(&quot;/hello&quot;) @ResponseBody List&lt;Student&gt; home() { String sql = &quot;select u_Id,u_last_name,u_first_name from student&quot;; return jdbcTemplate.query(sql, new RowMapper&lt;Student&gt;() { @Override public Student mapRow(ResultSet resultSet, int i) throws SQLException { Student stu = new Student(); stu.setUid(resultSet.getInt(&quot;u_id&quot;)); stu.setUfirstname(resultSet.getString(&quot;u_first_name&quot;)); stu.setUlastname(resultSet.getString(&quot;u_last_name&quot;)); return stu; } }); } H3 完成这个时候我们请求 hello这个接口的时候就会获取到数据库中的数据了 [ { \"uid\": 1, \"ulastname\": \"张\", \"ufirstname\": \"三\" } ] H2 ROM 辅助框架这里指的是 MyBitis，hibernate，jooq等，这种框架，这里由于我们公司使用的是 jooq，所以我研究也是这个东西。 以下是官方例子中的七步学习 H3 第一步：准备好吧，其实就是 maven 配置而已。。。 好多种 H4 Open Source Edition&lt;dependency> &lt;groupId>org.jooq&lt;/groupId> &lt;artifactId>jooq&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.jooq&lt;/groupId> &lt;artifactId>jooq-meta&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.jooq&lt;/groupId> &lt;artifactId>jooq-codegen&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> H4 Commercial Editions (Java 8+)&lt;!-- Note: These aren't hosted on Maven Central. Import them manually from your distribution --> &lt;dependency> &lt;groupId>org.jooq.pro&lt;/groupId> &lt;artifactId>jooq&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.jooq.pro&lt;/groupId> &lt;artifactId>jooq-meta&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.jooq.pro&lt;/groupId> &lt;artifactId>jooq-codegen&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> H4 ommercial Editions (Java 6+)&lt;!-- Note: These aren't hosted on Maven Central. Import them manually from your distribution --> &lt;dependency> &lt;groupId>org.jooq.pro-java-6&lt;/groupId> &lt;artifactId>jooq&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.jooq.pro-java-6&lt;/groupId> &lt;artifactId>jooq-meta&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.jooq.pro-java-6&lt;/groupId> &lt;artifactId>jooq-codegen&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> H4 Commercial Editions (Free Trial)&lt;!-- Note: These aren't hosted on Maven Central. Import them manually from your distribution --> &lt;dependency> &lt;groupId>org.jooq.trial&lt;/groupId> &lt;artifactId>jooq&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.jooq.trial&lt;/groupId> &lt;artifactId>jooq-meta&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>org.jooq.trial&lt;/groupId> &lt;artifactId>jooq-codegen&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;/dependency> 向资本主义低头… 自然选择第一个啊 H3 第二步：配置你的数据库我这里是使用的是他官方文档中提供的sql文件，它是基于 oracle的所以修改为mysql为 use jooq; CREATE TABLE language ( id INT NOT NULL PRIMARY KEY, cd CHAR(2) NOT NULL, description VARCHAR(50) ); CREATE TABLE author ( id INT NOT NULL PRIMARY KEY, first_name VARCHAR(50), last_name VARCHAR(50) NOT NULL, date_of_birth DATE, year_of_birth INT, distinguished INT ); CREATE TABLE book ( id INT NOT NULL PRIMARY KEY, author_id INT NOT NULL, title VARCHAR(225) NOT NULL, published_in INT NOT NULL, language_id INT NOT NULL, CONSTRAINT fk_book_author FOREIGN KEY (author_id) REFERENCES author(id), CONSTRAINT fk_book_language FOREIGN KEY (language_id) REFERENCES language(id) ); CREATE TABLE book_store ( name VARCHAR(400) NOT NULL UNIQUE ); CREATE TABLE book_to_book_store ( name VARCHAR(225) NOT NULL, book_id INTEGER NOT NULL, stock INTEGER, PRIMARY KEY(name, book_id), CONSTRAINT fk_b2bs_book_store FOREIGN KEY (name) REFERENCES book_store (name) ON DELETE CASCADE, CONSTRAINT fk_b2bs_book FOREIGN KEY (book_id) REFERENCES book (id) ON DELETE CASCADE ); INSERT INTO language (id, cd, description) VALUES (1, 'en', 'English'); INSERT INTO language (id, cd, description) VALUES (2, 'de', 'Deutsch'); INSERT INTO language (id, cd, description) VALUES (3, 'fr', 'Français'); INSERT INTO language (id, cd, description) VALUES (4, 'pt', 'Português'); INSERT INTO author (id, first_name, last_name, date_of_birth , year_of_birth) VALUES (1 , 'George' , 'Orwell' , DATE '1903-06-26', 1903 ); INSERT INTO author (id, first_name, last_name, date_of_birth , year_of_birth) VALUES (2 , 'Paulo' , 'Coelho' , DATE '1947-08-24', 1947 ); INSERT INTO book (id, author_id, title , published_in, language_id) VALUES (1 , 1 , '1984' , 1948 , 1 ); INSERT INTO book (id, author_id, title , published_in, language_id) VALUES (2 , 1 , 'Animal Farm' , 1945 , 1 ); INSERT INTO book (id, author_id, title , published_in, language_id) VALUES (3 , 2 , 'O Alquimista', 1988 , 4 ); INSERT INTO book (id, author_id, title , published_in, language_id) VALUES (4 , 2 , 'Brida' , 1990 , 2 ); INSERT INTO book_store VALUES ('Orell Füssli'); INSERT INTO book_store VALUES ('Ex Libris'); INSERT INTO book_store VALUES ('Buchhandlung im Volkshaus'); INSERT INTO book_to_book_store VALUES ('Orell Füssli' , 1, 10); INSERT INTO book_to_book_store VALUES ('Orell Füssli' , 2, 10); INSERT INTO book_to_book_store VALUES ('Orell Füssli' , 3, 10); INSERT INTO book_to_book_store VALUES ('Ex Libris' , 1, 1 ); INSERT INTO book_to_book_store VALUES ('Ex Libris' , 3, 2 ); INSERT INTO book_to_book_store VALUES ('Buchhandlung im Volkshaus', 3, 1 ); H3 第三步：生成代码好吧这一步着实麻烦了些，来吧，看看官方文档如何说的 首先你需要准备三个文件！！！ 有三个文件，可jooq，是从http://www.jooq.org/download或从中心下载Maven： jooq-3.10.5.jar你将在你的应用程序运行jooq主图书馆 jooq-meta-3.10.5.jar您将在构建中包含的实用程序来导航您的数据库模式生成代码。这也可以用作模式爬虫。 jooq-codegen-3.10.5.jar将包含在生成中以生成数据库模式的实用程序。 好吧 就是咱们maven 引入的那三个 H4 配置jooq的代码生成器好吧，就是一个xml文件，这个文件理你需要告诉jooq，你都需要如何去转换文件 &lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?> &lt;configuration> &lt;!-- Configure the database connection here --> &lt;jdbc> &lt;driver>oracle.jdbc.OracleDriver&lt;/driver> &lt;url>jdbc:oracle:thin:@[your jdbc connection parameters]&lt;/url> &lt;user>[your database user]&lt;/user> &lt;password>[your database password]&lt;/password> &lt;!-- You can also pass user/password and other JDBC properties in the optional properties tag: --> &lt;properties> &lt;property>&lt;key>user&lt;/key>&lt;value>[db-user]&lt;/value>&lt;/property> &lt;property>&lt;key>password&lt;/key>&lt;value>[db-password]&lt;/value>&lt;/property> &lt;/properties> &lt;/jdbc> &lt;generator> &lt;database> &lt;!-- The database dialect from jooq-meta. Available dialects are named org.util.[database].[database]Database. Natively supported values are: org.jooq.util.ase.ASEDatabase org.jooq.util.cubrid.CUBRIDDatabase org.jooq.util.db2.DB2Database org.jooq.util.derby.DerbyDatabase org.jooq.util.firebird.FirebirdDatabase org.jooq.util.h2.H2Database org.jooq.util.hsqldb.HSQLDBDatabase org.jooq.util.informix.InformixDatabase org.jooq.util.ingres.IngresDatabase org.jooq.util.mariadb.MariaDBDatabase org.jooq.util.mysql.MySQLDatabase org.jooq.util.oracle.OracleDatabase org.jooq.util.postgres.PostgresDatabase org.jooq.util.sqlite.SQLiteDatabase org.jooq.util.sqlserver.SQLServerDatabase org.jooq.util.sybase.SybaseDatabase This value can be used to reverse-engineer generic JDBC DatabaseMetaData (e.g. for MS Access) org.jooq.util.jdbc.JDBCDatabase This value can be used to reverse-engineer standard jOOQ-meta XML formats org.jooq.util.xml.XMLDatabase You can also provide your own org.jooq.util.Database implementation here, if your database is currently not supported --> &lt;name>org.jooq.util.oracle.OracleDatabase&lt;/name> &lt;!-- All elements that are generated from your schema (A Java regular expression. Use the pipe to separate several expressions) Watch out for case-sensitivity. Depending on your database, this might be important! You can create case-insensitive regular expressions using this syntax: (?i:expr) Whitespace is ignored and comments are possible. --> &lt;includes>.*&lt;/includes> &lt;!-- All elements that are excluded from your schema (A Java regular expression. Use the pipe to separate several expressions). Excludes match before includes, i.e. excludes have a higher priority --> &lt;excludes> UNUSED_TABLE # This table (unqualified name) should not be generated | PREFIX_.* # Objects with a given prefix should not be generated | SECRET_SCHEMA\\.SECRET_TABLE # This table (qualified name) should not be generated | SECRET_ROUTINE # This routine (unqualified name) ... &lt;/excludes> &lt;!-- The schema that is used locally as a source for meta information. This could be your development schema or the production schema, etc This cannot be combined with the schemata element. If left empty, jOOQ will generate all available schemata. See the manual's next section to learn how to generate several schemata --> &lt;inputSchema>[your database schema / owner / name]&lt;/inputSchema> &lt;/database> &lt;generate> &lt;!-- Generation flags: See advanced configuration properties --> &lt;/generate> &lt;target> &lt;!-- The destination package of your generated classes (within the destination directory) jOOQ may append the schema name to this package if generating multiple schemas, e.g. org.jooq.your.packagename.schema1 org.jooq.your.packagename.schema2 --> &lt;packageName>[org.jooq.your.packagename]&lt;/packageName> &lt;!-- The destination directory of your generated classes --> &lt;directory>[/path/to/your/dir]&lt;/directory> &lt;/target> &lt;/generator> &lt;/configuration> 将他转换为中文大概是如下这样子的 &lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?> &lt;configuration xmlns=\"http://www.jooq.org/xsd/jooq-codegen-3.8.0.xsd\"> &lt;!-- 配置jdbc驱动连接 --> &lt;jdbc> &lt;driver>com.mysql.jdbc.Driver&lt;/driver> &lt;url>jdbc:mysql://localhost:3306/admin&lt;/url> &lt;user>root&lt;/user> &lt;password>123456&lt;/password> &lt;/jdbc> &lt;generator> &lt;!-- 代码生成器 --> &lt;name>org.jooq.util.JavaGenerator&lt;/name> &lt;database> &lt;!-- 数据库类型 --> &lt;name>org.jooq.util.mysql.MySQLDatabase&lt;/name> &lt;!-- 数据库名 --> &lt;inputSchema>admin&lt;/inputSchema> &lt;!-- 生成包含，*表示包含所有内容 --> &lt;includes>.*&lt;/includes> &lt;!--剔除，此处未剔除 --> &lt;excludes>&lt;/excludes> &lt;/database> &lt;target> &lt;!-- 生成的代码所在的包结构 --> &lt;packageName>org.test.jooq.generated&lt;/packageName> &lt;!-- 生成的代码存放路径，默认会以src同目录开始 --> &lt;directory>src/main/java/&lt;/directory> &lt;/target> &lt;/generator> &lt;/configuration> There are also lots of advanced configuration parameters, which will be treated in the manual’s section about advanced code generation features Note, you can find the official XSD file for a formal specification at:http://www.jooq.org/xsd/jooq-codegen-3.10.0.xsd H4 运行jooq代码生成器org.jooq.util.GenerationTool /jooq-config.xml 要确保以下文件放置在 classpath 下： The XML configuration file jooq-3.10.5.jar, jooq-meta-3.10.5.jar, jooq-codegen-3.10.5.jar The JDBC driver you configured H4 命令行生成 把配置文件和jooq*.jar三个文件和JDBC Driver 文件放到同一个目录中 进入这个目录 运行 Run java -cp jooq-3.10.5.jar;jooq-meta-3.10.5.jar;jooq-codegen-3.10.5.jar;[JDBC-driver].jar;. org.jooq.util.GenerationTool /[XML file] H4 使用 maven 生成Using the official jOOQ-codegen-maven plugin, you can integrate source code generation in your Maven build process: &lt;plugin> &lt;!-- Specify the maven code generator plugin --> &lt;!-- Use org.jooq for the Open Source Edition org.jooq.pro for commercial editions, org.jooq.pro-java-6 for commercial editions with Java 6 support, org.jooq.trial for the free trial edition Note: Only the Open Source Edition is hosted on Maven Central. Import the others manually from your distribution --> &lt;groupId>org.jooq&lt;/groupId> &lt;artifactId>jooq-codegen-maven&lt;/artifactId> &lt;version>3.10.5&lt;/version> &lt;!-- The plugin should hook into the generate goal --> &lt;executions> &lt;execution> &lt;goals> &lt;goal>generate&lt;/goal> &lt;/goals> &lt;/execution> &lt;/executions> &lt;!-- Manage the plugin's dependency. In this example, we'll use a PostgreSQL database --> &lt;dependencies> &lt;dependency> &lt;groupId>org.postgresql&lt;/groupId> &lt;artifactId>postgresql&lt;/artifactId> &lt;version>9.4.1212&lt;/version> &lt;/dependency> &lt;/dependencies> &lt;!-- Specify the plugin configuration. The configuration format is the same as for the standalone code generator --> &lt;configuration> &lt;!-- JDBC connection parameters --> &lt;jdbc> &lt;driver>org.postgresql.Driver&lt;/driver> &lt;url>jdbc:postgresql:postgres&lt;/url> &lt;user>postgres&lt;/user> &lt;password>test&lt;/password> &lt;/jdbc> &lt;!-- Generator parameters --> &lt;generator> &lt;database> &lt;name>org.jooq.util.postgres.PostgresDatabase&lt;/name> &lt;includes>.*&lt;/includes> &lt;excludes>&lt;/excludes> &lt;!-- In case your database supports catalogs, e.g. SQL Server: &lt;inputCatalog>public&lt;/inputCatalog> --> &lt;inputSchema>public&lt;/inputSchema> &lt;/database> &lt;target> &lt;packageName>org.jooq.util.maven.example&lt;/packageName> &lt;directory>target/generated-sources/jooq&lt;/directory> &lt;/target> &lt;/generator> &lt;/configuration> &lt;/plugin> H3 第四步：获取链接// For convenience, always static import your generated tables and jOOQ functions to decrease verbosity: import static test.generated.Tables.*; import static org.jooq.impl.DSL.*; import java.sql.*; public class Main { public static void main(String[] args) throws SQLException{ String userName = \"root\"; String password = \"\"; String url = \"jdbc:mysql://localhost:3306/library\"; Connection conn = DriverManager.getConnection(url, userName, password); } } H3 第五步：查询DSLContext create = DSL.using(conn, SQLDialect.MYSQL); Result&lt;Record> result = create.select().from(AUTHOR).fetch(); 首先得到dslcontext实例我们可以写一个简单的选择查询。我们将MySQL连接的实例传递给DSL。请注意，dslcontext不关闭连接。我们必须自己做那件事。 然后我们使用DSL jooq查询返回结果的一个实例。我们将在下一步中使用这个结果。 H3 第六步：处理数据for (Record r : result) { Integer id = r.getValue(AUTHOR.ID); String firstName = r.getValue(AUTHOR.FIRST_NAME); String lastName = r.getValue(AUTHOR.LAST_NAME); System.out.println(\"ID: \" + id + \" first name: \" + firstName + \" last name: \" + lastName); } 完整的代码如下 package test; // For convenience, always static import your generated tables and // jOOQ functions to decrease verbosity: import static test.generated.Tables.*; import static org.jooq.impl.DSL.*; import java.sql.*; import org.jooq.*; import org.jooq.impl.*; public class Main { /** * @param args */ public static void main(String[] args) throws SQLException { String userName = \"root\"; String password = \"\"; String url = \"jdbc:mysql://localhost:3306/library\"; // Connection is the only JDBC resource that we need // PreparedStatement and ResultSet are handled by jOOQ, internally Connection conn = DriverManager.getConnection(url, userName, password); DSLContext create = DSL.using(conn, SQLDialect.MYSQL); Result&lt;Record> result = create.select().from(AUTHOR).fetch(); for (Record r : result) { Integer id = r.getValue(AUTHOR.ID); String firstName = r.getValue(AUTHOR.FIRST_NAME); String lastName = r.getValue(AUTHOR.LAST_NAME); System.out.println(\"ID: \" + id + \" first name: \" + firstName + \" last name: \" + lastName); } } } 但是其实咱们已经配置完 Spring JDBC 之后，可以直接使用反射 @Autowired DSLContext dsl; 差不多像这样子 package com.study.controller; import com.study.model.tables.Author; import org.jooq.DSLContext; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.autoconfigure.*; import org.springframework.stereotype.*; import org.springframework.web.bind.annotation.*; @Controller @EnableAutoConfiguration public class SampleController { @Autowired DSLContext dsl; @RequestMapping(\"/hello\") @ResponseBody Object[] home() { return dsl.select().from(Author.AUTHOR).fetchAnyArray(); } } H2 结语到这里 我们就结束了，因为我也是第一次使用 jooq，这些框架，很多东西不一定对，但是至少这是一个思路。 努力吧。 Spring boot 服务器.md","categories":[{"name":"服务器","slug":"服务器","permalink":"http://blog.msiter.com/categories/服务器/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.msiter.com/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"http://blog.msiter.com/tags/spring-boot/"},{"name":"jooq","slug":"jooq","permalink":"http://blog.msiter.com/tags/jooq/"}],"keywords":[{"name":"服务器","slug":"服务器","permalink":"http://blog.msiter.com/categories/服务器/"}]},{"title":"博客增加MathJax支持","slug":"hexo 增加Mathjax支持","date":"2018-02-22T12:07:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"hexo zjMathjaxzc-20180222.html","link":"","permalink":"http://blog.msiter.com/hexo zjMathjaxzc-20180222.html","excerpt":"今天是上班的第一天，来到公司之后学习了RSA算法之后，就想好好的写一篇关于rsa的文章，但是遇到的第一个问题就是数据公式展示的问题。 在展示问题上无非就是MathJax和LaTex两种数学公式方法。 我们现在来说说如何在Hexo中展示数学公式吧。我们使用的Hexo的第三方框架 Hexo-Math.除了引入这个框架之外还需要引入","text":"今天是上班的第一天，来到公司之后学习了RSA算法之后，就想好好的写一篇关于rsa的文章，但是遇到的第一个问题就是数据公式展示的问题。 在展示问题上无非就是MathJax和LaTex两种数学公式方法。 我们现在来说说如何在Hexo中展示数学公式吧。我们使用的Hexo的第三方框架 Hexo-Math.除了引入这个框架之外还需要引入 \"dependencies\": { ... more \"hexo-inject\": \"^1.0.0\", \"hexo-math\": \"\", \"hexo-renderer-mathjax\": \"\", ... more } 引入完成这三个框架之后，参见 How to config it to make it work? · Issue #26 · hexojs/hexo-math 在 config.yml文件中配置 # MathJS ## Hexo Math JS LTX math: engine: 'mathjax' # or 'katex' mathjax: src: \"//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\" config: # MathJax config katex: css: #custom_css_source js: #custom_js_source # not used config: # KaTeX config 接下来就可以在实际的博客中使用公式了。例子： /// 行内公式 Simple inline \\\\(a = b + c\\\\). /// 块级公式 $$\\frac{\\partial u}{\\partial t} = h^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} + \\frac{\\partial^2 u}{\\partial z^2}\\right)$$ /// 行内公式Simple inline \\(a = b + c\\). /// 块级公式$$\\frac{\\partial u}{\\partial t}= h^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} +\\frac{\\partial^2 u}{\\partial y^2} +\\frac{\\partial^2 u}{\\partial z^2}\\right)$$ ps: 在实际使用中由于 hexo的markdown的解析的问题，我们可能需要使用 {%raw%}{%endraw%} 或者 {%math%}{%endmath%} hexo 增加Mathjax支持.md","categories":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}],"tags":[{"name":"博客美化","slug":"博客美化","permalink":"http://blog.msiter.com/tags/博客美化/"},{"name":"hexo","slug":"hexo","permalink":"http://blog.msiter.com/tags/hexo/"},{"name":"mathjax","slug":"mathjax","permalink":"http://blog.msiter.com/tags/mathjax/"}],"keywords":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}]},{"title":"IOS 逆向学习","slug":"IOS逆向学习","date":"2018-01-29T14:25:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"IOSnxxx-20180129.html","link":"","permalink":"http://blog.msiter.com/IOSnxxx-20180129.html","excerpt":"一年之前学习过一次，但是当初很快就被忙碌的工作占据，并且当时学习的晕晕乎乎的。现在我打算重新学习一下。别的就不开始多说了，开始搭建theos环境吧。","text":"一年之前学习过一次，但是当初很快就被忙碌的工作占据，并且当时学习的晕晕乎乎的。现在我打算重新学习一下。别的就不开始多说了，开始搭建theos环境吧。 H2 搭建Theos环境写作时间 2018-1-29theos 版本 2.3macos 10.13.3xcode Version 9.2 (9C40b) H3 配置环境变量因为我们需要让系统明白 theos放在哪里了，需要设置以下环境变量。有以下几种方式来设置，你可以根据自己喜欢来设置自己想要的。 配置环境变量的语法为 export [变量名称]=\"$PATH::::...:\" 下面无论哪种方都可以使用以下方法来实验是否设置完成 echo [变量名称] H4 只在当前终端生效的方式这种方式只在终端中生效，当你关闭了，就需要重新配置了.emmmmm…这种方式，具体看你喜好了。 就是直接在命令行中调用配置环境变量方法就可以了。如： export THEOS = /opt/theos H4 文件中保存的环境变量/etc/profile ## 全局（公有）配置，不管是哪个用户，登录时都会读取该文件。 /etc/paths ## 全局变量 ~/.bash_profile ### 用户 ~/.bash_login ### 用户 ~/.profile ### 用户 ~/.bashrc ### 用户 我是在这里配置的 /etc/profile:此文件为系统的每个用户设置环境信息,当用户第一次登录时,该文件被执行.并从/etc/profile.d目录的配置文件中搜集shell的设置./etc/bashrc:为每一个运行bash shell的用户执行此文件.当bash shell被打开时,该文件被读取.~/.bash_profile:每个用户都可使用该文件输入专用于自己使用的shell信息,当用户登录时,该文件仅仅执行一次!默认情况下,他设置一些环境变量,执行用户的.bashrc文件.~/.bashrc:该文件包含专用于你的bash shell的bash信息,当登录时以及每次打开新的shell时,该该文件被读取.~/.bash_logout:当每次退出系统(退出bash shell)时,执行该文件.所以/home/oracle/.bash_profile oracle用户的配置/etc/skel/.bash_profile 默认配置/root/.bash_profile root用户的配置 如果没有文件可以直接生成 touch [文件名称] 之后写入命令。 H3 下载theos在安装之前需要安装 brew install ldid 安装，在咱们完成了 环境变量的配置之后。 $ git clone --recursive https://github.com/theos/theos.git $THEOS 记得使用 --recursive 命令，这个命令，会在clone的时候，clone这个仓库徐耀的子模块。如果你忘记了这一点的话，进入theos命令运行。make update-theos 其他常见的地方是/opt/theos和/var/theos。 如果要使用/ var，/ opt或其他类似的目录，请记住，除root用户之外，它们将不可写入。 您必须在上面的命令中使用sudo，然后将所有者更改为自己 $ sudo chown -R $(id -u):$(id -g) theos 尽管你可以直接食用 download zip ，下载theos，但是不推荐这么做，因为这样做不利于后的版本更新。 In order to use make troubleshoot, you need to install Ghostbin’s ghost.sh script. 为了使用make troubleshoot，你需要安装Ghostbin的ghost.sh脚本。 $ curl https://ghostbin.com/ghost.sh -o $THEOS/bin/ghost $ chmod +x $THEOS/bin/ghost H3 升级Theos采用的是滚动发布模式，这意味着最新的提交到Git仓库是可用的最新版本的Theos。 偶尔，你应该更新Theos。 这可以通过切换到包含Theos makefile的目录然后运行： $ make update-theos 如果遇到问题，更新Theos是你应该做的第一件事。 如果你要求别人帮忙，这样可以更容易地找到问题。 如果在运行该命令时看到以下内容： make: *** No rule to make target 'update-theos'. Stop. 那么你现在不在Theos项目目录中，或者正在使用比此功能更早的Theos版本。 H2 配置 IOS 设备 ssh 免密码登录首先需要在本地创建 rsh 文件 ssh-keygen -t rsa -C \"xxxxx@xxxxx.com\" # Generating public/private rsa key pair... # 三次回车即可生成 ssh key cd ~/.ssh ## 进入 ssh ls ## 查看 有id_ras 和 id_ras.pub 文件 这样就说明创建完成了，将.pub文件拷贝至收集目录下的 /var/root/.ssh 名称为 authorized_keys. scp ~/.ssh/id_rsa.pub root@172.16.41.66:/var/root/.ssh/authorized_keys 这个时候，就完成了，直接使用试试吧。 ssh root@DeviceIP H2 获取头文件接下来我们将开始演示如何敲壳，之后获取应用的头文件，接下来我们以微信为例。 这里所有的先决条件是这样子的 你有一个 越狱的 手机 并且装了微信的手机 装有 openshh 连接上 (OpenSSH的root密码默认为alpine) 连接上之后，我们需要找到我们的WeChat.app，首先保证你的微信处于运行状态，之后运行 ps -e 执行命令之后你会看到列出的所有进程，找到其中有WeChat结尾的，记录该地址。 之后，我们来进行敲壳获取 decrypted 文件。 H3 敲壳 dumpdecrypteddumpdecrypted clone到本地，之后进入文件之后运行 make 命令，结束之后，会出现一个 dumpdecrypted.dylib 。 将这个文件传输到手机上，为了方便，我们吧文件放置在 微信的 Document。使用如下方法获取到该文件夹的位置。 Misterde-iPod:/System root# cycript -p WeChat cy# NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, true)[0]; @\"/var/mobile/Containers/Data/Application/487D41FD-2118-4015-BE79-FF61A9029B1E/Documents\" cy# 接下来让我们把 dumpdecrypted.dylib 复制到Documents文件夹中。 scp ~/Desktop/dumpdecrypted/dumpdecrypted.dylib root@172.16.41.66:/var/mobile/Containers/Data/Application/487D41FD-2118-4015-BE79-FF61A9029B1E/Documents/ 接下来我们就可以进行敲壳了，敲壳之前，我们要确定当前的目录，因为完成后的文件会被放置在当前的目录，推荐是Docustoms 文件夹。 # DYLD_INSERT_LIBRARIES = 咱们的dylib文件 目标文件也就是咱们的WeChat DYLD_INSERT_LIBRARIES=/var/mobile/Containers/Data/Application/487D41FD-2118-4015-BE79-FF61A9029B1E/Documents/dumpdecrypted.dylib /var/mobile/Containers/Bundle/Application/BD2D25AB-8B36-4614-84BE-79806AB53FB8/WeChat.app/WeChat mach-o decryption dumper DISCLAIMER: This tool is only meant for security research purposes, not for application crackers. [+] detected 32bit ARM binary in memory. [+] offset to cryptid found: @0x75a4c(from 0x75000) = a4c [+] Found encrypted data at address 00004000 of length 49430528 bytes - type 1. [+] Opening /private/var/mobile/Containers/Bundle/Application/BD2D25AB-8B36-4614-84BE-79806AB53FB8/WeChat.app/WeChat for reading. [+] Reading header [+] Detecting header type [+] Executable is a FAT image - searching for right architecture [+] Correct arch is at offset 16384 in the file [+] Opening WeChat.decrypted for writing. [+] Copying the not encrypted start of the file [+] Dumping the decrypted data into the file [+] Copying the not encrypted remainder of the file [+] Setting the LC_ENCRYPTION_INFO->cryptid to 0 at offset 4a4c [+] Closing original file [+] Closing dump file 这个时候，我们发现文件夹下已经有了一个WeChat.decrypted.我们使用 scp 命令把这个文件传输到我们的电脑。 scp root@172.16.41.66:/var/mobile/Containers/Data/Application/487D41FD-2118-4015-BE79-FF61A9029B1E/Documents/WeChat.decrypted ~/Desktop H3 获取 头文件我们接下来使用 class-dump 来获取文件的头文件。下载到本地 (class-dump)[http://stevenygard.com/projects/class-dump/] 你可以任意选择类型，压缩包还是执行文件，里面都是有一个已经编译好的执行文件以及一个源代码文件夹。直接使用执行文件即可。 这里我们需要了解下 class-dump的用法 class-dump 3.5 (64 bit) Usage: class-dump [options] where options are: -a show instance variable offsets -A show implementation addresses --arch choose a specific architecture from a universal binary (ppc, ppc64, i386, x86_64, armv6, armv7, armv7s, arm64) -C only display classes matching regular expression -f find string in method name -H generate header files in current directory, or directory specified with -o -I sort classes, categories, and protocols by inheritance (overrides -s) -o output directory used for -H -r recursively expand frameworks and fixed VM shared libraries -s sort classes and categories by name -S sort methods by name -t suppress header in output, for testing --list-arches list the arches in the file, then exit --sdk-ios specify iOS SDK version (will look in /Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS.sdk --sdk-mac specify Mac OS X version (will look in /Developer/SDKs/MacOSX.sdk --sdk-root specify the full SDK root path (or use --sdk-ios/--sdk-mac for a shortcut) 关于平台以下 arm64：iPhone6s | iphone6s plus｜iPhone6｜ iPhone6 plus｜iPhone5S | iPad Air｜ iPad mini2(iPad mini with Retina Display) armv7s：iPhone5｜iPhone5C｜iPad4(iPad with Retina Display) armv7：iPhone4｜iPhone4S｜iPad｜iPad2｜iPad3(The New iPad)｜iPad mini｜iPod Touch 3G｜iPod Touch4 i386是针对intel通用微处理器32位处理器 x86_64是针对x86架构的64位处理器 模拟器32位处理器测试需要i386架构， 模拟器64位处理器测试需要x86_64架构， 真机32位处理器需要armv7,或者armv7s架构， 真机64位处理器需要arm64架构。 ./class-dump-3.5/class-dump -s -S -H ./WeChat.decrypted -o ./header 这样我们在 header 就已经获得所有的头文件了，接下来就是慢慢的看….. H2 MonkeyDev 原有iOSOpenDev的升级，非越狱插件开发集成神器！ 可以使用Xcode开发CaptainHook Tweak、Logos Tweak 和 Command-line Tool，在越狱机器开发插件，这是原来iOSOpenDev功能的迁移和改进。 只需拖入一个砸壳应用，自动集成class-dump、restore-symbol、Reveal、Cycript和注入的动态库并重签名安装到非越狱机器。 支持调试自己编写的动态库和第三方App 支持通过CocoaPods第三方应用集成SDK以及非越狱插件，简单来说就是通过CocoaPods搭建了一个非越狱插件商店。 给跪…… 安装移步官方Wiki 遇到的一个坑 因为安装的theos没有在 /opt/theos 目录，导致失败解决办法,建立一个软连接 ln -s 你的目录 /opt/theos 或者你可以每次都设置项目的BuildString 中的 theos 位置 H3 拥有taget-action的方法和类名在这个时候你已经可以运行在设备上了，并且就像平时咱们调试应用一样了。这个时候咱们想找到比如微信的登陆按钮点击了之后触发了什么时间呢？这个很简单 使用我们Xcode自带的试图查看器，点击到按钮的时候就可以查看 target-action了就和咱们平时一样。 比如咱们获取到 点击方法为 onFirstViewLogin Target 为 WCAccountLoginControlLogic 则有以下代码 CHDeclareClass(WCAccountLoginControlLogic) CHOptimizedMethod(0, self, void,WCAccountLoginControlLogic ,onFirstViewLogin){ //get origin value CHSuper(0, WCAccountLoginControlLogic, onFirstViewLogin); NSLog(@\"点击了 登陆按钮\"); } CHConstructor{ CHLoadLateClass(WCAccountLoginControlLogic); CHClassHook(0, WCAccountLoginControlLogic, onFirstViewLogin); } 运行之后，咱们点击登陆按钮之后就会打印 H3 打印那些没有target-action的方法当然这个时候，我们很兴奋，但是忽然沉寂了，如何获取更多的方法呢？应用不是蠢到每一个操作都需要这样触发的。那怎么办这个时候就需要一个可以实时打印方法的日志机制。好在这个还是不需要我们努力….真的成搬砖了，，，到头了 还是搬砖….难过 使用 ANYMethodLog 具体移步前往查看详细。 __attribute__((constructor)) // 在main函数被调用之前调用 __attribute__((destructor)) // 在main函数被调用之后调 使用这两个方法可以完成咱们想要的监听操作 __attribute__((constructor)) void entry() { [ANYMethodLog logMethodWithClass:NSClassFromString(@\"WCAccountLoginControlLogic\") condition:^BOOL(SEL sel) { NSLog(@\"method:%@\", NSStringFromSelector(sel)); return NO; } before:nil after:nil]; } 但是这里就有一个问题，，， WCAccountLoginControlLogic 哪里来的？我们监听哪个类的方法？ 好吧接下来看下一张让我们找到我们想要看到的视图名称 H3 使用 lldb来进行更多的操作lldb是一个很好用的工具，这块是一个非常大的一块内容需要单独学习，当然其实掌握其中一点就已经受用了。 我使用的是非常简单的一块，首先了解 lldb ，之后在看下面 目前我知道的，有两种情况可以进入到 lldb，让咱们来进行一些操作。 使用 Xcode 自带的视图层次查看器 断点 使用Xcode 自带的层次查看器 就不多说了。我们来说说断点。 当然，我们都进入了 层次查看器了，其实也是可以看到的。。主要是还是为了方便吧。。。 我们创建一个 Sysmbolic BreakPoint ，创建的一个断点。方法设置为 viewDidLoad 这样在 任意的对象调用到了这个方法就会进入调试。 这个时候我们就可以操作了，但是在此之前！！！！！！我们需要安装一个辅助工具 chisel.具体移步 在此之后我们运行 pvc可以看到vc 结构。 &lt;MMUINavigationController 0x185a9b30&gt;, state: disappeared, view: &lt;UILayoutContainerView 0x186d2390&gt; not in the window | &lt;WCAccountLoginFirstViewController 0x1728cc00&gt;, state: disappeared, view: &lt;UIView 0x185c7600&gt; not in the window + &lt;MMUINavigationController 0x185653b0&gt;, state: appeared, view: &lt;UILayoutContainerView 0x183f7290&gt;, presented with: &lt;_UIFullscreenPresentationController 0x186f8a80&gt; | | &lt;WCAccountMainLoginViewController 0x17b1c800&gt;, state: appeared, view: &lt;UIView 0x18459cc0&gt; 这个时候我们就可以使用我们刚才说到的监测方法调用的方法，来查看都有哪些方法被调用了。 IOS逆向学习.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"逆向","slug":"逆向","permalink":"http://blog.msiter.com/tags/逆向/"},{"name":"theos","slug":"theos","permalink":"http://blog.msiter.com/tags/theos/"},{"name":"tweak","slug":"tweak","permalink":"http://blog.msiter.com/tags/tweak/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"extern与static用法","slug":"extern与static用法","date":"2018-01-22T19:32:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"externystaticyf-20180122.html","link":"","permalink":"http://blog.msiter.com/externystaticyf-20180122.html","excerpt":"c/c++ 中的 Static在C语言中，static可以用来修饰局部变量，全局变量以及函数。在不同的情况下static的作用不尽相同。 在C++中static还具有其它功能，如果在C++中对类中的某个函数用static进行修饰，则表示该函数属于一个类而不是属于此类的任何特定对象；如果对类中的某个变量进行static修饰，表示该变量为类以及其所有的对象所有。它们在存储空间中都只存在一个副本。可以通过类和对象去调用。对于静态成员函数，只能访问静态成员函数和静态成员变量，不能访问非静态成员函数或者变量。 c/c++ 中的 extern在C语言中，修饰符extern用在变量或者函数的声明前，用来说明“此变量/函数是在别处定义的，要在此处引用”。 在上面的例子中可以看出，在file2中如果想调用file1中的变量a，只须用extern进行声明即可调用a，这就是extern的作用。在这里要注意extern声明的位置对其作用域也有关系，如果是在main函数中进行声明的，则只能在main函数中调用，在其它函数中不能调用。其实要调用其它文件中的函数和变量，只需把该文件用#include包含进来即可，为啥要用extern？因为用extern会加速程序的编译过程，这样能节省时间。 在C++中extern还有另外一种作用，用于指示C或者C＋＋函数的调用规范。比如在C＋＋中调用C库函数，就需要在C＋＋程序中用extern “C”声明要引用的函数。这是给链接器用的，告诉链接器在链接的时候用C函数规范来链接。主要原因是C＋＋和C程序编译完成后在目标代码中命名规则不同，用此来解决名字匹配的问题。","text":"H3 c/c++ 中的 Static在C语言中，static可以用来修饰局部变量，全局变量以及函数。在不同的情况下static的作用不尽相同。 在C++中static还具有其它功能，如果在C++中对类中的某个函数用static进行修饰，则表示该函数属于一个类而不是属于此类的任何特定对象；如果对类中的某个变量进行static修饰，表示该变量为类以及其所有的对象所有。它们在存储空间中都只存在一个副本。可以通过类和对象去调用。对于静态成员函数，只能访问静态成员函数和静态成员变量，不能访问非静态成员函数或者变量。 H3 c/c++ 中的 extern在C语言中，修饰符extern用在变量或者函数的声明前，用来说明“此变量/函数是在别处定义的，要在此处引用”。 在上面的例子中可以看出，在file2中如果想调用file1中的变量a，只须用extern进行声明即可调用a，这就是extern的作用。在这里要注意extern声明的位置对其作用域也有关系，如果是在main函数中进行声明的，则只能在main函数中调用，在其它函数中不能调用。其实要调用其它文件中的函数和变量，只需把该文件用#include包含进来即可，为啥要用extern？因为用extern会加速程序的编译过程，这样能节省时间。 在C++中extern还有另外一种作用，用于指示C或者C＋＋函数的调用规范。比如在C＋＋中调用C库函数，就需要在C＋＋程序中用extern “C”声明要引用的函数。这是给链接器用的，告诉链接器在链接的时候用C函数规范来链接。主要原因是C＋＋和C程序编译完成后在目标代码中命名规则不同，用此来解决名字匹配的问题。 H3 展开说明在讨论全局变量之前我们先要明白几个基本的概念： 编译单元(模块)： 在IDE开发工具大行其道的今天，对于编译的一些概念很多人已经不再清楚了，很多程序员最怕的就是处理连接错误(LINK ERROR), 因为它不像编译错误那样可以给出你程序错误的具体位置，你常常对这种错误感到懊恼，但是如果你经常使用gcc，makefile等工具在linux或者嵌 入式下做开发工作的话，那么你可能非常的理解编译与连接的区别！当在VC这样的开发工具上编写完代码，点击编译按钮准备生成exe文件时，VC其实做了两 步工作，第一步，将每个.cpp(.c)和相应.h文件编译成obj文件；第二步，将工程中所有的obj文件进行LINK生成最终的.exe文件，那么错 误就有可能在两个地方产生，一个是编译时的错误，这个主要是语法错误，另一个是连接错误，主要是重复定义变量等。我们所说的编译单元就是指在编译阶段生成 的每个obj文件，一个obj文件就是一个编译单元，也就是说 一个cpp(.c)和它相应的.h文件共同组成了一个编译单元，一个工程由很多个编译单元组 成，每个obj文件里包含了变量存储的相对地址等 。 声明与定义的区别 函数或变量在声明时，并没有给它实际的物理内存空间，它有时候可以保证你的程序编译通过， 但是当函数或变量定义的时候，它就在内存中有了实际的物理空间，如果你在编译模块中引用的外部变量没有在整个工程中任何一个地方定义的话， 那么即使它在编译时可以通过，在连接时也会报错，因为程序在内存中找不到这个变量！你也可以这样理解， 对同一个变量或函数的声明可以有多次，而定义只能有一次! extern的作用 extern有两个作用，第一个,当它与”C”一起连用时，如: extern “C” void fun(int a, int b); 则告诉编译器在编译fun这个函数名时 按着C的规则去翻译相应的函数名而不是C++的， C++的规则在翻译这个函数名时会把fun这个名字变得面目全非，可能是fun@aBc_int_int#%$也可能是别的，这要看编译器的”脾气”了 (不同的编译器采用的方法不一样)，为什么这么做呢，因为C++支持函数的重载啊，在这里不去过多的论述这个问题，如果你有兴趣可以去网上搜索，相信你可 以得到满意的解释! 当extern不与”C”在一起修饰变量或函数时，如在头文件中: extern int g_Int; 它的作用就是声明函数或全局变量的作用范围的关键字，其声明的函数和变量可以在本模块或者其他模块中使用，记住它是一个声明不是定义! 也就是说B模块(编译 单元)要是引用模块(编译单元)A中定义的全局变量或函数时，它只要包含A模块的头文件即可, 在编译阶段，模块B虽然找不到该函数或变量，但它不会报错，它会在连接时从模块A生成的目标代码中找到此函数。 如果你对以上几个概念已经非常明白的话，那么让我们一起来看以下几种全局变量/常量的使用区别: H3 用extern修饰的全局变量以上已经说了extern的作用，下面我们来举个例子,如:在test1.h中有下列声明: #ifndef TEST1H #define TEST1H extern char g_str[]; // 声明全局变量g_str void fun1(); #endif 在test1.cpp中 #include \"test1.h\" char g_str[] = \"123456\"; // 定义全局变量g_str void fun1() { cout &lt;&lt; g_str &lt;&lt; endl; } 以上是test1模块， 它的编译和连接都可以通过,如果我们还有test2模块也想使用g_str,只需要在原文件中引用就可以了 #include \"test1.h\" void fun2(){ cout &lt;&lt; g_str &lt;&lt; endl; } 以上test1和test2可以同时编译连接通过，如果你感兴趣的话可以用ultraEdit打开test1.obj,你可以在里面着”123456”这 个字符串,但是你却不能在test2.obj里面找到，这是因为g_str是整个工程的全局变量，在内存中只存在一份, test2.obj这个编译单元不需要再有一份了，不然会在连接时报告重复定义这个错误!有些人喜欢把全局变量的声明和定义放在一起，这样可以防止忘记了定义，如把上面test1.h改为 extern char g_str[] = \"123456\"; // 这个时候相当于没有extern 然后把test1.cpp中的g_str的定义去掉,这个时候再编译连接test1和test2两个模块时，会报连接错误，这是因为你把全局变量 g_str的定义放在了头文件之后，test1.cpp这个模块包含了test1.h所以定义了一次g_str,而 test2.cpp也包含了test1.h所以再一次定义了g_str, 这个时候连接器在连接test1和test2时发现两个g_str。如果你非要把g_str的定义放在test1.h中的话，那么就把test2的代码 中#include “test1.h”去掉 换成: extern char g_str[]; void fun2() { cout &lt;&lt; g_str &lt;&lt; endl; } 这个时候编译器就知道g_str是引自于外部的一个编译模块了，不会在本模块中再重复定义一个出来，但是我想说这样做非常糟糕，因为你由于无法在 test2.cpp中使用#include “test1.h”, 那么test1.h中声明的其他函数你也无法使用了，除非也用都用extern修饰，这样的话你光声明的函数就要一大串，而且头文件的作用就是要给外部提 供接口使用的，所以 请记住， 只在头文件中做声明，真理总是这么简单。 H3 用static修饰的全局变量首先，我要告诉你static与extern是一对“水火不容”的家伙，也就是说extern和static不能同时修饰一个变量；其次，static修 饰的全局变量声明与定义同时进行，也就是说当你在头文件中使用static声明了全局变量后，它也同时被定义了；最后，static修饰全局变量的作用域 只能是本身的编译单元，也就是说它的“全局”只对本编译单元有效，其他编译单元则看不到它,如: test1.h: #ifndef TEST1H #define TEST1H static char g_str[] = \"123456\"; void fun1(); #endif test1.cpp: #include \"test1.h\" void fun1() { cout &lt;&lt; g_str &lt;&lt; endl; } test2.cpp #include \"test1.h\" void fun2() { cout &lt;&lt; g_str &lt;&lt; endl; } 以上两个编译单元可以连接成功, 当你打开test1.obj时，你可以在它里面找到字符串”123456”, 同时你也可以在test2.obj中找到它们，它们之所以可以连接成功而没有报重复定义的错误是因为虽然它们有相同的内容，但是存储的物理地址并不一样， 就像是两个不同变量赋了相同的值一样，而这两个变量分别作用于它们各自的编译单元。也许你比较较真，自己偷偷的跟踪调试上面的代码,结果你发现两个编译单元（test1, test2）的g_str的内存地址相同，于是你下结论static修饰的变量也可以作用于其他模块，但是我要告诉你，那是你的编译器在欺骗你，大多数编 译器都对代码都有优化功能，以达到生成的目标程序更节省内存，执行效率更高，当编译器在连接各个编译单元的时候，它会把相同内容的内存只拷贝一份，比如上 面的”123456”, 位于两个编译单元中的变量都是同样的内容，那么在连接的时候它在内存中就只会存在一份了， 如果你把上面的代码改成下面的样子，你马上就可以 拆穿编译器的谎言: test1.cpp: #include \"test1.h\" void fun1() { g_str[0] = 'a'; cout &lt;&lt; g_str &lt;&lt; endl; } test2.cpp #include \"test1.h\" void fun2() { cout &lt;&lt; g_str &lt;&lt; endl; } void main() { fun1(); // a23456 fun2(); // 123456 } 这个时候你在跟踪代码时，就会发现两个编译单元中的g_str地址并不相同，因为你在一处修改了它，所以 编译器被强行的恢复内存的原貌，在内存中存在了两份拷贝给两个模块中的变量使用。 正是因为static有以上的特性，所以一般定义static全局变量时，都把它放在原文件中而不是头文件，这样就不会给其他模块造成不必要的信息污染，同样记住这个原则吧！ H3 转载 浅谈C/C++中的static和extern关键字 【转】extern与static用法 extern与static用法.md","categories":[{"name":"学习资料","slug":"学习资料","permalink":"http://blog.msiter.com/categories/学习资料/"}],"tags":[{"name":"c","slug":"c","permalink":"http://blog.msiter.com/tags/c/"},{"name":"c++","slug":"c","permalink":"http://blog.msiter.com/tags/c/"}],"keywords":[{"name":"学习资料","slug":"学习资料","permalink":"http://blog.msiter.com/categories/学习资料/"}]},{"title":"objc学习之路-inline","slug":"objc学习之路-inline","date":"2018-01-22T10:31:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"objcxxzl-inline-20180122.html","link":"","permalink":"http://blog.msiter.com/objcxxzl-inline-20180122.html","excerpt":"在学习oc 之前，c的基础非常的不好所以今天我学习以下 inline的意思，要不然每次看到的时候心里都觉的有东西没理解。以下的文章转载自C++中的inline用法 从今天开始修改以前的学习模式，以前的模式是说，没有学习完成之前不会写博客，从现在开始每次学习到了一些新的小知识也会记录下来 inline的作用之前在学习递归函数的时候，就知道了，在大量的递归的时候，会创建很多个函数的对象，导致函数对象所占用的空间增大，让我们在使用的时候，看情况的使用，循环和递归两种方法来做事情。而inline就是为了解决一些频繁使用的小函数大量消耗空间(斩内存)的问题，特别引入的修饰符，表示该函数为 内联函数。占空间就是指放置程式的局部数据也就是函数内数据的内存空间，在系统下，栈内存是有限的，假如频繁大量的使用就会造成因栈空间不足所引起的程式错误，函数的死循环循环递归的最终结果就是导致栈内存空间枯竭。下面我们来使用一段代码来解释什么事 内联函数。","text":"在学习oc 之前，c的基础非常的不好所以今天我学习以下 inline的意思，要不然每次看到的时候心里都觉的有东西没理解。以下的文章转载自C++中的inline用法 从今天开始修改以前的学习模式，以前的模式是说，没有学习完成之前不会写博客，从现在开始每次学习到了一些新的小知识也会记录下来 H3 inline的作用之前在学习递归函数的时候，就知道了，在大量的递归的时候，会创建很多个函数的对象，导致函数对象所占用的空间增大，让我们在使用的时候，看情况的使用，循环和递归两种方法来做事情。而inline就是为了解决一些频繁使用的小函数大量消耗空间(斩内存)的问题，特别引入的修饰符，表示该函数为 内联函数。占空间就是指放置程式的局部数据也就是函数内数据的内存空间，在系统下，栈内存是有限的，假如频繁大量的使用就会造成因栈空间不足所引起的程式错误，函数的死循环循环递归的最终结果就是导致栈内存空间枯竭。下面我们来使用一段代码来解释什么事 内联函数。 #include &lt;stdio.h> //函数定义为inline即:内联函数 inline char* dbtest(int a) { return (i % 2 > 0) ? \"奇\" : \"偶\"; } int main() { int i = 0; for (i=1; i &lt; 100; i++) { printf(\"i:%d 奇偶性:%s /n\", i, dbtest(i)); } } 上面的例子就是标准的内联函数的用法，使用inline修饰符带来的好处我们表面看不出来，其实在内部的工作就是在每个for循环的内部任何调用dbtest(i)的地方都换成了(i%2&gt;0)?”奇”:”偶”这样就避免了频繁调用函数对栈内存重复开辟所带来的消耗。 H3 inline使用限制当然inline的使用是有所限制的，inline只适合涵数体内代码简单的涵数使用，不能包含复杂的结构控制语句例如while、switch，并且不能内联函数本身不能是直接递归函数(自己内部还调用自己的函数)。 H3 inline仅是一个对编译器的建议inline函数仅仅是一个建议,对编译器的建议,所以最后能否真正内联,看编译器的意思,它如果认为函数不复杂,能在调用点展开,就会真正内联,并不是说声明了内联就会内联,声明内联只是一个建议而已. H3 建议：inline函数的定义放在头文件中其次，因为内联函数要在调用点展开，所以编译器必须随处可见内联函数的定义，要不然就成了非内联函数的调用了。所以，这要求每个调用了内联函数的文件都出现了该内联函数的定义。 因此，将内联函数的定义放在头文件里实现是合适的，省却你为每个文件实现一次的麻烦。 声明跟定义要一致：如果在每个文件里都实现一次该内联函数的话，那么，最好保证每个定义都是一样的，否则，将会引起未定义的行为。如果不是每个文件里的定义都一样，那么，编译器展开的是哪一个，那要看具体的编译器而定。所以，最好将内联函数定义放在头文件中。 H3 类中的成员函数与inline二类中的成员函数缺省都是内联的，如果在类定义时就在类中给出函数，那当然最好。如果在类中未出函数定义，而又想内联该函数的话，就需要在类外增加 inline，否则就认为不是内联的. 例如： class A { public:void Foo(int x, int y) { } // 自动地成为内联函数 } 将成员函数的定义体放在类声明之中虽然能带来书写上的方便，但不是一种良好的编程风格，上例应该改成： // 头文件 class A { public: void Foo(int x, int y); } // 定义文件 inline void A::Foo(int x, int y){} H3 inline 是一种“用于实现的关键字”关键字inline 必须与 函数定义体 放在一起才能使函数成为内联，仅将inline 放在函数声明前面不起任何作用。 如下风格的函数Foo 不能成为内联函数： inline void Foo(int x, int y); // inline 仅与函数声明放在一起 void Foo(int x, int y){} 而如下风格的函数Foo 则成为内联函数： void Foo(int x, int y); inline void Foo(int x, int y) {} // inline 与函数定义体放在一起 所以说，inline 是一种“用于实现的关键字”，而不是一种“用于声明的关键字”。一般地，用户可以阅读函数的声明，但是看不到函数的定义。尽管在大多数教科书中内联函数的声明、定义体前面都加了inline 关键字，但我认为inline不应该出现在函数的声明中。这个细节虽然不会影响函数的功能，但是体现了高质量C++/C 程序设计风格的一个基本原则：声明与定义不可混为一谈，用户没有必要、也不应该知道函数是否需要内联。 H3 慎用inline内联能提高函数的执行效率，为什么不把所有的函数都定义成内联函数？如果所有的函数都是内联函数，还用得着“内联”这个关键字吗？内联是以代码膨胀（复制）为代价，仅仅省去了函数调用的开销，从而提高函数的执行效率。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。以下情况不宜使用内联： 如果函数体内的代码比较长，使用内联将导致内存消耗代价较高。 如果函数体内出现循环，那么执行函数体内代码的时间要比函数调用的开销大。类的构造函数和析构函数容易让人误解成使用内联更有效。要当心构造函数和析构函数可能会隐藏一些行为，如“偷偷地”执行了基类或成员对象的构造函数和析构函数。所以不要随便地将构造函数和析构函数的定义体放在类声明中。一个好的编译器将会根据函数的定义体，自动地取消不值得的内联（这进一步说明了 inline 不应该出现在函数的声明中）。 H3 总结内联函数并不是一个增强性能的灵丹妙药。只有当函数非常短小的时候它才能得到我们想要的效果；但是，如果函数并不是很短而且在很多地方都被调用的话，那么将会使得可执行体的体积增大。最令人烦恼的还是当编译器拒绝内联的时候。在老的实现中，结果很不尽人意，虽然在新的实现中有很大的改善，但是仍然还是不那么完善的。一些编译器能够足够的聪明来指出哪些函数可以内联哪些不能，但是大多数编译器就不那么聪明了，因此这就需要我们的经验来判断。如果内联函数不能增强性能，就避免使用它！ H3 参考资料 C++中的inline用法 关于c中的inline objc学习之路-inline.md","categories":[{"name":"学习资料","slug":"学习资料","permalink":"http://blog.msiter.com/categories/学习资料/"}],"tags":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"objc","slug":"objc","permalink":"http://blog.msiter.com/tags/objc/"}],"keywords":[{"name":"学习资料","slug":"学习资料","permalink":"http://blog.msiter.com/categories/学习资料/"}]},{"title":"配置一个很舒服的终端","slug":"终端优化 历程","date":"2018-01-19T13:35:43.000Z","updated":"2018-08-29T10:33:16.506Z","comments":true,"path":"zdyh lc-20180119.html","link":"","permalink":"http://blog.msiter.com/zdyh lc-20180119.html","excerpt":"好吧，程序员学习真的是没有尽头的，，这段时间都是在调整我的博客，在调整博客的过程中其中的一件事儿，我觉的引发了好多事儿，特此记录一下的。写完了博客之后，发觉自己的博客没有绿色的小锁，所以想搞https 证书认证，可以查看我的另一篇博客 Hexo本地搜索，在搜索栏直接查看就好了的（搜索 “HEXO 本地搜索 或者本地搜索”）。使用了Https之后导致，我的七牛云的资源，引入的时候因为七牛的图片都是http的，全部都加载失败了。我自然而然的觉的开启了七牛云的https就好了的，我就开始尝试去开启七牛云的https。两种方式，一种是在他们上面申请一个SSL证书，要不然就是上传自己的证书。（唉，知识真的非常浅薄，只知道https，但是不知道到底是怎么回事儿。这个问题会专门写一篇文章去记录我学习https的过程。），虽然现在市面上的https证书都是需要收费的并且价格不菲，但是我还是找到了免费的证书。接下来就是上传了，，，，日！ 我TM甚至不知道怎么上传。。。。","text":"好吧，程序员学习真的是没有尽头的，，这段时间都是在调整我的博客，在调整博客的过程中其中的一件事儿，我觉的引发了好多事儿，特此记录一下的。写完了博客之后，发觉自己的博客没有绿色的小锁，所以想搞https 证书认证，可以查看我的另一篇博客 Hexo本地搜索，在搜索栏直接查看就好了的（搜索 “HEXO 本地搜索 或者本地搜索”）。使用了Https之后导致，我的七牛云的资源，引入的时候因为七牛的图片都是http的，全部都加载失败了。我自然而然的觉的开启了七牛云的https就好了的，我就开始尝试去开启七牛云的https。两种方式，一种是在他们上面申请一个SSL证书，要不然就是上传自己的证书。（唉，知识真的非常浅薄，只知道https，但是不知道到底是怎么回事儿。这个问题会专门写一篇文章去记录我学习https的过程。），虽然现在市面上的https证书都是需要收费的并且价格不菲，但是我还是找到了免费的证书。接下来就是上传了，，，，日！ 我TM甚至不知道怎么上传。。。。 好吧，我放弃了，但是我真的想看看我的小锁，会不会出现我的名字，所以我就开始搞以前一直想做但是一直没有做的东西，nginx ，好吧，我甚至不了解这个服务器，真是难过，什么都不会，以前就会一个 Tomcat ，还是就会一些最基本的操作。 没办法学习吧。另外讲（搜索 nginx 查看文章） 在我学习 nginx之后，发现了一个问题，我Iterm2 代码没有高亮！！！！ 真的，讲了这么多才讲到这里。。。。我真的也是醉了，，，好吧我们言归正传！ H3 什么是 ZSHzsh是什么东西，其实他是一个 shell解释器。 Shell 编程跟 java、php 编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。 这个问题有些大，总的来说，你写了一个脚本，比如，js,Perl,Ruby,Python,sh,csh等等，这些东西都是脚本。脚本语言是为了解决以前的【编写-&gt;编译-&gt;链接-&gt;运行】这些过程才能运行的语言而出现的。脚本通常需要的是 解释执行，脚本语言不会像c\\c++\\java等可以编译成二进制代码，以可执行的文件形式存在，脚本语言是不需要编译的，可以直接有解释器解释运行。而zsh就是其中一种，他有什么特点呢？ Zsh是一个Linux用户很少使用的shell，这是由于大多数Linux产品安装，以及默认使用bash shell。几乎每一款Linux产品都包含有zsh，通常可以用apt-get、urpmi或yum等包管理器进行安装。 额，，，我们的百度狠狠的diss了一下ZSH，以下是这个解释器的特点。 Zsh具有以下主要功能： 开箱即用、可编程的命令行补全功能可以帮助用户输入各种参数以及选项。 在用户启动的所有shell中共享命令历史。 通过扩展的文件通配符，可以不利用外部命令达到find命令一般展开文件名。 改进的变量与数组处理。 在缓冲区中编辑多行命令。 多种兼容模式，例如使用/bin/sh运行时可以伪装成Bourne shell。 可以定制呈现形式的提示符；包括在屏幕右端显示信息，并在键入长命令时自动隐藏。 可加载的模块，提供其他各种支持：完整的TCP与Unix域套接字控制，FTP客户端与扩充过的数学函数。 完全可定制化。好吧，我觉得他的好处也很简而易见 兼容 可加载模块 完全可定制化！！！！ H3 什么是 oh-my-zsh好吧，因为这些特点，我们的现在就需要的就是 oh-my-zsh这个 ZSH的框架了。omz这个框架可以说，他整理很多的 组建以及定义了非常多的好看的样式。那么我们来安装他们吧。。。。好吧，我们来检查以下 zsh的版本，以及我们需要设置默认的shell解释器。 另外我们的 ohmyzsh 需要版本至少 4.3.9 或者更高的。查看自己的shell 解释器都有哪些,如果没有 zsh 需要安装。 cat /etc/shells ### ---> 结果 # List of acceptable shells for chpass(1). # Ftpd will not allow users to connect who are not using # one of these shells. /bin/bash /bin/csh /bin/ksh /bin/sh /bin/tcsh /bin/zsh ### ---> 如果没有安装 ### ---> 默认来使用 zsh chsh -s `which zsh` ### ----> 查看是否设置成功 echo $SHELL 确认自己有了之后，就可以安装 oh-my-zsh le .via curl sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; via wget sh -c &quot;$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot; H4 oh-my-zsh 主题其实这个时候我们发现已经可以变化了。打开终端之后，发现已经是变了个样子了 打开终端之后，已经好了，发现已经是变了个样子了，但是如何美化呢。那么我们就需要配置 Theme了，你可以在主题列表预览和选择自己喜欢的主题了。修改地址的话是在 ~/.zshrc文件中。配置 ZSH_THEME=\"robbyrussell\" 当然你要是觉的一种配色太单调。。。你可以随机 ZSH_THEME=\"agnoster\" # (this is one of the fancy ones) 这个时候重启之后就可以看到好看的样式了～选择一个自己喜欢的吧～ H4 oh-my-zsh 组件oh-my-zsh提供了一些非常方便的组件植入方式。以 powerline-shell 为例子 # 首先下载 组件 git clone https://github.com/b-ryan/powerline-shell ~/.oh-my-zsh/custom/plugins 设置 组件的启用 在 ~/.zshrc 中 function powerline_precmd() { PS1=&quot;$(powerline-shell --shell zsh $?)&quot; } function install_powerline_precmd() { for s in &quot;${precmd_functions[@]}&quot;; do if [ &quot;$s&quot; = &quot;powerline_precmd&quot; ]; then return fi done precmd_functions+=(powerline_precmd) } if [ &quot;$TERM&quot; != &quot;linux&quot; ]; then install_powerline_precmd fi 这样我们就成功的完成了 Powerline 的安装了。 H3 powerline 字体这个东西就是设置一个更好看，更易用的 Sehll prompt（终端提示符）的东西。按照上面的例子我们已经安装完成了，但是这个时候我们还可以发现。乱码了,,,日，好吧。这个时候，我们需要设置一些字体了。首先我们要将这些字体安装到我们的机器上。 # 将字体现在下来 git clone https://github.com/powerline/fonts.git --depth=1 # 进入文件夹中之后 安装文件 cd fonts ./install.sh # 之后咋们就可以删除咱们下载的文件了 cd .. rm -rf fonts 在这个时候我们打开我们的终端客户端，比如 Iterm2 或者 自带的客户端，设置他的字体。为带有 powerline结尾的字体就好了。 PS： 在设置 Iterm2 的时候，我设置了字体还是出现乱码，但是当我关闭了 Use a different font for non-ASCLL txt选项之后就好了。 H3 powerline 的主题好吧，，，都是主题！ 都是主题！！！ 默认的话 powerline 是没有配置主题的，我们需要在sehll 运行 powerline-shell --generate-config > ~/.powerline-shell.json 生成了之后，我们就可以配置主题等文件了更多查看。 这个时候，我们就已经可以看到我们的成果了。 终端优化 历程.md","categories":[{"name":"hexo","slug":"hexo","permalink":"http://blog.msiter.com/categories/hexo/"}],"tags":[{"name":"Iterm","slug":"Iterm","permalink":"http://blog.msiter.com/tags/Iterm/"},{"name":"zsh","slug":"zsh","permalink":"http://blog.msiter.com/tags/zsh/"},{"name":"主题","slug":"主题","permalink":"http://blog.msiter.com/tags/主题/"}],"keywords":[{"name":"hexo","slug":"hexo","permalink":"http://blog.msiter.com/categories/hexo/"}]},{"title":"hexo 自定义辅助类","slug":"hexo 自定义辅助类","date":"2018-01-17T22:41:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"hexo zdyfz,cl-20180117.html","link":"","permalink":"http://blog.msiter.com/hexo zdyfz,cl-20180117.html","excerpt":"在做模块的时候，一般情况下我们都可以直接使用提供的变量以及一些方法完成整个博客的开发，当时当我们真的遇到比如我们需要修改我们的Table的样式的时候怎么办呢？ 难道每次都等到页面加载完成之后，使用 js/Jquery 方式修改Class,接下来我们来整理几个我在项目中使用到的几个辅助类 修改TABLE &amp;&amp; IMG样式hexo.extend.filter.register(&#39;after_post_render&#39;, function(data){ data.content = data.content.replace(/&lt;table&gt;/, &#39;&lt;table class = &quot;table table-bordered&quot;&gt;&#39;); data.content = data.content.replace(/&lt;img/, &#39;&lt;img class = &quot;g-pl-90&quot; &#39;); return data; });","text":"在做模块的时候，一般情况下我们都可以直接使用提供的变量以及一些方法完成整个博客的开发，当时当我们真的遇到比如我们需要修改我们的Table的样式的时候怎么办呢？ 难道每次都等到页面加载完成之后，使用 js/Jquery 方式修改Class,接下来我们来整理几个我在项目中使用到的几个辅助类 H3 修改TABLE &amp;&amp; IMG样式hexo.extend.filter.register('after_post_render', function(data){ data.content = data.content.replace(/&lt;table>/, '&lt;table class = \"table table-bordered\">'); data.content = data.content.replace(/&lt;img/, '&lt;img class = \"g-pl-90\" '); return data; }); 这个方法很简单的使用了文字替换的方式，修复了表格和图片的样式。 H3 创建辅助函数在实际项目中，我需要获取到文章的第一张图片，因为文章有了图片会显的很好看，但是有些文章第一张图片在很后面的地方，会导致展示上很麻烦，所以现在咱们创建一个函数来完称这个功能 /// 创建一个 pfi 辅助函数 用来获取文章中的第一个图片 hexo.extend.helper.register('ph', function(content) { if (!cheerio) cheerio = require('cheerio'); .... }); 咱们首先获取一个 cheerio 对象，使用这个对象类似于 jquery 可以操作 elemnt 对象 H4 调整ULfunction ulliHandle($){ $(\"ul\").each(function(){ $(this).addClass(\"g-list-style-circle\"); }); } 在这个方法中，我们把每个 ul 都增加 class H4 代码预览视图/// 代码 处理方法 function codeHandle($){ $(\"pre\").each(function(){ if (!$(this).attr(\"class\")) { $(this).addClass('line-numbers language-txt'); $(this).find(\"code\").addClass('language-txt') } $(this).addClass(\"g-mb-30\"); }); } H4 引用文章的修改// 引用 内容的配置 function blockquoteHandle($){ $(\"blockquote\").each(function(){ var content = $(this).html(); var replaceString = '\\ &lt;!-- Taglines Bordered -->\\ &lt;div class=\"g-brd-around g-brd-gray-light-v4 g-brd-2 g-brd-red-left g-line-height-1_8 g-pa-30 g-mb-30\">\\ &lt;em style=\"padding:0px;margin:0px;\">'+content+'&lt;/em>\\ &lt;/div>\\ &lt;!-- End Taglines Bordered -->\\ '; $(this).replaceWith($(replaceString)); }); } H4 图片的处理/// 图片的处理 function imageHandle($){ $(\"img\").each(function(){ var url = $(this).attr(\"src\"); var title = $(this).attr(\"title\"); var replaceString = '\\ &lt;figure class=\"mb-4 text-center\">\\ \\ &lt;a class=\"js-fancybox-thumbs\" href=\"'+url+'\" title=\"Lightbox Gallery\" data-fancybox-gallery=\"lightbox-gallery-2\" data-fancybox-speed=\"500\" data-fancybox-slide-speed=\"1000\">\\ &lt;br/>&lt;img class=\"img-fluid g-brd-around g-brd-gray-light-v2 g-rounded-3\" src=\"'+url+'\" alt=\"Image Description\">\\ &lt;/a>'; if (title) { replaceString += '&lt;figcaption class=\"figure-caption g-font-size-12 g-color-gray-dark-v4 g-mt-5 text-center\">\\ '+title+'&lt;/figcaption>'; } replaceString += '&lt;/figure>'; $(this).replaceWith($(replaceString)); }); } H3 自定义分页器在这个时候，我们可以需要配置分页，我们可以简单的配置成 &lt;- -&gt; 只有一个前一页 后一页的方式。 当然我们真的喜欢的就是 &lt;- 1 2 3 ... 7 8 9 -&gt; 默认的话，其实Hexo 已经有默认的方式 &lt;%- paginator(options) %&gt; 插入分页链接。 我们使用该方法，重写他，自定义，来进行分页的处理 function paginatorHelper(options) { options = options || {}; var current = options.current || this.page.current || 0; var total = options.total || this.page.total || 1; var endSize = options.hasOwnProperty('end_size') ? +options.end_size : 1; var midSize = options.hasOwnProperty('mid_size') ? +options.mid_size : 2; var space = options.hasOwnProperty('space') ? options.space : '&amp;hellip;'; var base = options.base || this.page.base || ''; var format = options.format || this.config.pagination_dir + '/%d/'; var prevText = options.prev_text || 'Prev'; var nextText = options.next_text || 'Next'; var prevNext = options.hasOwnProperty('prev_next') ? options.prev_next : true; var transform = options.transform; var self = this; var result = ''; var i; if (!current) return ''; var currentPage = '&lt;li class=\"list-inline-item\">\\ &lt;a class=\"active u-pagination-v1__item g-width-30 g-height-30 g-brd-secondary-light-v2 g-brd-primary--active g-color-white g-bg-primary--active g-font-size-12 rounded g-pa-5\" >'+(transform ? transform(current) : current)+'&lt;/a>\\ &lt;/li>'; function link(i) { return self.url_for(i === 1 ? base : base + format.replace('%d', i)); } function pageLink(i) { return ' &lt;li class=\"list-inline-item\">\\ &lt;a class=\"u-pagination-v1__item g-width-30 g-height-30 g-brd-transparent g-brd-primary--hover g-brd-primary--active g-color-secondary-dark-v1 g-bg-primary--active g-font-size-12 rounded g-pa-5\" href=\"' + link(i) + '\">' +(transform ? transform(i) : i) +'&lt;/a>\\ &lt;/li>'; } // Display the link to the previous page if (prevNext &amp;&amp; current > 1) { result += '&lt;li class=\"list-inline-item\">\\ &lt;a class=\"u-pagination-v1__item g-brd-secondary-light-v2 g-brd-primary--hover g-color-gray-dark-v5 g-color-primary--hover g-font-size-12 rounded g-px-15 g-py-5 g-ml-15\" href=\"' + link(current - 1) + '\" aria-label=\"Previous\">\\ &lt;span aria-hidden=\"true\">\\ &lt;i class=\"mr-2 fa fa-angle-left\">&lt;/i>\\ ' + prevText + '\\ &lt;/span>\\ &lt;span class=\"sr-only\">' + prevText + '&lt;/span>\\ &lt;/a>\\ &lt;/li>' } if (options.show_all) { // Display pages on the left side of the current page for (i = 1; i &lt; current; i++) { result += pageLink(i); } // Display the current page result += currentPage; // Display pages on the right side of the current page for (i = current + 1; i &lt;= total; i++) { result += pageLink(i); } } else { // It's too complicated. May need refactor. var leftEnd = current &lt;= endSize ? current - 1 : endSize; var rightEnd = total - current &lt;= endSize ? current + 1 : total - endSize + 1; var leftMid = current - midSize &lt;= endSize ? current - midSize + endSize : current - midSize; var rightMid = current + midSize + endSize > total ? current + midSize - endSize : current + midSize; var spaceHtml = ' &lt;li class=\"list-inline-item\">\\ &lt;span class=\"g-width-30 g-height-30 g-color-gray-dark-v5 g-font-size-12 rounded g-pa-5\">'+space+'&lt;/span>\\ &lt;/li>'; // Display pages on the left edge for (i = 1; i &lt;= leftEnd; i++) { result += pageLink(i); } // Display spaces between edges and middle pages if (space &amp;&amp; current - endSize - midSize > 1) { result += spaceHtml; } // Display left middle pages if (leftMid > leftEnd) { for (i = leftMid; i &lt; current; i++) { result += pageLink(i); } } // Display the current page result += currentPage; // Display right middle pages if (rightMid &lt; rightEnd) { for (i = current + 1; i &lt;= rightMid; i++) { result += pageLink(i); } } // Display spaces between edges and middle pages if (space &amp;&amp; total - endSize - midSize > current) { result += spaceHtml; } // Dispaly pages on the right edge for (i = rightEnd; i &lt;= total; i++) { result += pageLink(i); } } // Display the link to the next page if (prevNext &amp;&amp; current &lt; total) { result += ' &lt;li class=\"list-inline-item\">\\ &lt;a class=\"u-pagination-v1__item g-brd-secondary-light-v2 g-brd-primary--hover g-color-gray-dark-v5 g-color-primary--hover g-font-size-12 rounded g-px-15 g-py-5 g-ml-15\" href=\"' + link(current + 1) + '\" aria-label=\"Next\">\\ &lt;span aria-hidden=\"true\">\\ ' + nextText + '\\ &lt;i class=\"ml-2 fa fa-angle-right\">&lt;/i>\\ &lt;/span>\\ &lt;span class=\"sr-only\">' + nextText + '&lt;/span>\\ &lt;/a>\\ &lt;/li>'; } return '&lt;!-- Pagination -->\\ &lt;div class=\"container g-pb-100\">\\ &lt;nav aria-label=\"Page Navigation\">\\ &lt;ul class=\"list-inline text-center mb-0\">\\ '+result+'\\ &lt;/ul>\\ &lt;/nav>\\ &lt;/div>\\ &lt;!-- End Pagination -->'; }; /// 生成 Page Number hexo.extend.helper.register('pgn', paginatorHelper); 在咱们需要插入分页控件的地方使用 &lt;%- pgn() %&gt; H3 更多更多的辅助函数都可以自己查看，可以在官方网站 HEXO查看文档 hexo 自定义辅助类.md","categories":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}],"tags":[{"name":"博客美化","slug":"博客美化","permalink":"http://blog.msiter.com/tags/博客美化/"},{"name":"hexo","slug":"hexo","permalink":"http://blog.msiter.com/tags/hexo/"}],"keywords":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}]},{"title":"hexo SEO 优化","slug":"hexo 标题自动转换为拼音","date":"2018-01-17T21:41:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"hexo btzdzhwpy-20180117.html","link":"","permalink":"http://blog.msiter.com/hexo btzdzhwpy-20180117.html","excerpt":"在上篇文章中，我们提到了SEO，其中还有一个是在url中尽量不存在中文。这里我们就来完成这个操作。 中文转换在这里，我们可以根据时间，或者直接将标题生成为 散列值。随便的hash算法都可以实现，但是默写时候还是希望可以标题可以某些方面反映出来我们的内容。所以有两种方式，转换为英文，或者转换为拼音。当然为了防止重复的问题，我们可以增加一个时间戳或者时间的格式字符串来进行区分 转换为英文首先，尝试转换标题为英文，毕竟显得高大上很多。 我们在 Hexo Plugins,搜索到了一个插件 hexo-translate-title. 哎呀，这多好啊，直接省略了所有的步骤，也不用开发轮子了。 当然机智的你，也发现了，要是这样就停止了，我们就不会有这么长的博文了。 好吧，毕竟现在的翻译不能保证都可以成功…所以还是放弃了，最终","text":"在上篇文章中，我们提到了SEO，其中还有一个是在url中尽量不存在中文。这里我们就来完成这个操作。 H2 中文转换在这里，我们可以根据时间，或者直接将标题生成为 散列值。随便的hash算法都可以实现，但是默写时候还是希望可以标题可以某些方面反映出来我们的内容。所以有两种方式，转换为英文，或者转换为拼音。当然为了防止重复的问题，我们可以增加一个时间戳或者时间的格式字符串来进行区分 H3 转换为英文首先，尝试转换标题为英文，毕竟显得高大上很多。 我们在 Hexo Plugins,搜索到了一个插件 hexo-translate-title. 哎呀，这多好啊，直接省略了所有的步骤，也不用开发轮子了。 当然机智的你，也发现了，要是这样就停止了，我们就不会有这么长的博文了。 好吧，毕竟现在的翻译不能保证都可以成功…所以还是放弃了，最终 H3 转换为拼音作为小学的语言，还是很亲近的，虽然某些方面看着不是很高大上…… 不影响 不影响～～ 首先我么要找到一个转换拼音的框架，，好吧，中间找了不少的框架，其中很多都是有问题的。这里只说我找到的，并且已经在使用的框架吧 pinyin 根据词组智能匹配最正确的拼音。 支持多音字。 简单的繁体支持。 支持多种不同拼音风格 好了既然都找到了框架了，那我们就来写入博客开发里吧。 H2 自定义博客文件名称很多个类似的框架，都是拦截的 before_post_render 方法，并且将修改完成的数据，需要重新格式化后，写入 .md 。这样才可以实现，但是问题也很明显，就是在于正在运行的服务器时候，写文章会出现，由于文章重新写入了文章，可能会导致文章写作出现内容刚刚输入的消失的问题。 咱们接下来就选择一个方法吧。 H3 更换方法 post_permalinkhexo.extend.filter.register('post_permalink', function(data){ // ... }); 我们可以在这里查看到官方的post_permalinkAPI 介绍，用来决定文章的永久链接。好吧原来这个才是官方推荐的。 H3 使用pinyin转换中文接下来就让我们使用咱们的第三方框架pinyin来吧我们文章的标题转换为中文吧 const final_title_str = pinyin(data.title, {style: pinyin.STYLE_FIRST_LETTER, heteronym: true}) 其中关于转换的细节，我就不具体讲了，在pinyin的GitHub 主页有详细的文档。我这里使用的是首字母。之后咱们使用 join 来拼接字符串 const final_title_str = pinyin(data.title, {style: pinyin.STYLE_FIRST_LETTER, heteronym: true}).join(\"\") 但是这个时候就出现了一些问题，就是这些数据在有关于特殊字符的时候会引发sitmap的问题。所以我们使用替换字符串的方式替换一下特殊字符 var final_title_str = pinyin(data.title, {style: pinyin.STYLE_FIRST_LETTER, heteronym: true}).join(\"\"); final_title_str = final_title_str.replace(/[\\ |\\~|\\`|\\!|\\@|\\#|\\$|\\%|\\^|\\&amp;|\\*|\\(|\\)|\\-|\\_|\\+|\\=|\\||\\\\|\\[|\\]|\\{|\\}|\\;|\\:|\\\"|\\'|\\,|\\&lt;|\\.|\\>|\\/|\\?]/g, \"\"); final_title_str = final_title_str.replace(/[\\u3002|\\uff1f|\\uff01|\\uff0c|\\u3001|\\uff1b|\\uff1a|\\u201c|\\u201d|\\u2018|\\u2019|\\uff08|\\uff09|\\u300a|\\u300b|\\u3008|\\u3009|\\u3010|\\u3011|\\u300e|\\u300f|\\u300c|\\u300d|\\ufe43|\\ufe44|\\u3014|\\u3015|\\u2026|\\u2014|\\uff5e|\\ufe4f|\\uffe5]/, \"\"); return final_title_str+\".html\" H3 SHA256其实在另一个方式来说的话 const secret = \"suibian\" const hash = crypto.createHmac('sha256',secret).update(data.title).digest(\"hex\"); return hash+\".html\"; 这个时候就完成了 SHA256的方式，，，，但是 标题好长啊… H2 完整代码接下来就是咱们的完整的代码，如下所示: var hexo = hexo || {}; var config = hexo.config; const pinyin = require(\"pinyin\"); const crypto = require('crypto'); const permalink = require('hexo/lib/plugins/filter/post_permalink') hexo.extend.filter.unregister('post_permalink', permalink); hexo.extend.filter.register('post_permalink', function(data){ /// 如果是将文章转换为 pinyin if(config.transform.toLowerCase() === \"pinyin\"){ var final_title_str = pinyin(data.title, {style: pinyin.STYLE_FIRST_LETTER, heteronym: true}).join(\"\"); final_title_str = final_title_str.replace(/[\\ |\\~|\\`|\\!|\\@|\\#|\\$|\\%|\\^|\\&amp;|\\*|\\(|\\)|\\-|\\_|\\+|\\=|\\||\\\\|\\[|\\]|\\{|\\}|\\;|\\:|\\\"|\\'|\\,|\\&lt;|\\.|\\>|\\/|\\?]/g, \"\"); final_title_str = final_title_str.replace(/[\\u3002|\\uff1f|\\uff01|\\uff0c|\\u3001|\\uff1b|\\uff1a|\\u201c|\\u201d|\\u2018|\\u2019|\\uff08|\\uff09|\\u300a|\\u300b|\\u3008|\\u3009|\\u3010|\\u3011|\\u300e|\\u300f|\\u300c|\\u300d|\\ufe43|\\ufe44|\\u3014|\\u3015|\\u2026|\\u2014|\\uff5e|\\ufe4f|\\uffe5]/, \"\"); return final_title_str+\".html\" } if(config.transform.toLowerCase() === \"sha256\"){ const secret = \"suibian\" const hash = crypto.createHmac('sha256',secret).update(data.title).digest(\"hex\"); return hash+\".html\"; } return permalink.apply(this, [data]) }); hexo 标题自动转换为拼音.md","categories":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}],"tags":[{"name":"博客美化","slug":"博客美化","permalink":"http://blog.msiter.com/tags/博客美化/"},{"name":"hexo","slug":"hexo","permalink":"http://blog.msiter.com/tags/hexo/"}],"keywords":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}]},{"title":"hexo SEO 优化","slug":"hexo SEO 优化","date":"2018-01-17T19:41:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"hexo SEO yh-20180117.html","link":"","permalink":"http://blog.msiter.com/hexo SEO yh-20180117.html","excerpt":"我们写了博客，当然希望搜索引擎将我们收录更好了。在我朋友的建议下，我来看看这个关于Hexo的优化吧 关于 Https好吧，我真的特别喜欢那些绿色的小锁，以及前面的一些字 比如 ‘Apple Inc.[US]’ 日日！ 好帅啊！好吧，最后实现了，虽然没有那些字，毕竟是免费的不计较的了。 CloudFlare 好吧 就是他，他其实也没有给你证书，只是给你做了一层 DNS 代理，这样子的话，你访问的时候会带上人家的 https 证书，当然你要是愿意支付每个月 5 美元的钱的话，是可以加小字的。。。没钱。。。","text":"我们写了博客，当然希望搜索引擎将我们收录更好了。在我朋友的建议下，我来看看这个关于Hexo的优化吧 H3 关于 Https好吧，我真的特别喜欢那些绿色的小锁，以及前面的一些字 比如 ‘Apple Inc.[US]’ 日日！ 好帅啊！好吧，最后实现了，虽然没有那些字，毕竟是免费的不计较的了。 CloudFlare 好吧 就是他，他其实也没有给你证书，只是给你做了一层 DNS 代理，这样子的话，你访问的时候会带上人家的 https 证书，当然你要是愿意支付每个月 5 美元的钱的话，是可以加小字的。。。没钱。。。 设置 page rules 可以将所有的 http 请求转换为 https。 另外其实还是有不少免费证书申请的，但是无奈，我没有自己的服务器，所以只能，这样子了。 H3 SEO 优化增加 mate 属性一些值 H3 减少url的层数减少 html url 的层数,在根目录下的 _config.yml,配置一下代码。 # URL ## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/' url: http://blog.msiter.com/ root: / # permalink: :year/:month/:day/:title/ permalink: :title-:year:month:day.html permalink_defaults: H3 增加 sitmapSitemap 可方便网站管理员通知搜索引擎他们网站上有哪些可供抓取的网页。最简单的 Sitemap 形式，就是XML 文件，在其中列出网站中的网址以及关于每个网址的其他元数据（上次更新的时间、更改的频率以及相对于网站上其他网址的重要程度为何等），以便搜索引擎可以更加智能地抓取网站。 \"hexo-generator-sitemap\": \"\", 安装 组建，在config 配置如下。 # sitemap ## SEO sitemap: path: sitemap.xml baidusitemap: path: baidusitemap.xml H3 url地址不要有中文这个优化方式会在下一片博文中提到 H3 向百度提交链接百度，，，，不做评价 爱咱们每一个页面都加入一个百度提供的js方法。 &lt;script> (function(){ var bp = document.createElement('script'); var curProtocol = window.location.protocol.split(':')[0]; if (curProtocol === 'https') { bp.src = 'https://zz.bdstatic.com/linksubmit/push.js'; } else { bp.src = 'http://push.zhanzhang.baidu.com/push.js'; } var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(bp, s); })(); &lt;/script> hexo SEO 优化.md","categories":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}],"tags":[{"name":"博客美化","slug":"博客美化","permalink":"http://blog.msiter.com/tags/博客美化/"},{"name":"hexo","slug":"hexo","permalink":"http://blog.msiter.com/tags/hexo/"}],"keywords":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}]},{"title":"hexo 增加本地搜索模块","slug":"hexo 增加本地搜索模块","date":"2018-01-17T18:41:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"hexo zjbdssmk-20180117.html","link":"","permalink":"http://blog.msiter.com/hexo zjbdssmk-20180117.html","excerpt":"马上要下班了,【笔芯】。 一直想做一个博客的搜索，拖了很久，本来看别人用 Swifty搜索之类的，都开始收费了！ 日日！ 作为一个穷屌，我认为只要是涉及到收费，就一定不是好公司！！手动 doge～ 好吧，那咱们就自己LocalSearch吧。这个博客的本地搜索，我做了一天半才做完，本来不是很难的功能，因为本身人家的搜索的数据都给你了。你就是负责一个显示怎么就这么难？ 好吧，确实好难啊，，，，我这个博客用的是 unify 的 HTML 模版，本身他没有搜索结果展示的相关的，我得自己想如何展示，一点点的抠出来了。接下来我主要来讲解一下我如何做的吧。","text":"马上要下班了,【笔芯】。 一直想做一个博客的搜索，拖了很久，本来看别人用 Swifty搜索之类的，都开始收费了！ 日日！ 作为一个穷屌，我认为只要是涉及到收费，就一定不是好公司！！手动 doge～ 好吧，那咱们就自己LocalSearch吧。这个博客的本地搜索，我做了一天半才做完，本来不是很难的功能，因为本身人家的搜索的数据都给你了。你就是负责一个显示怎么就这么难？ 好吧，确实好难啊，，，，我这个博客用的是 unify 的 HTML 模版，本身他没有搜索结果展示的相关的，我得自己想如何展示，一点点的抠出来了。接下来我主要来讲解一下我如何做的吧。 H3 生成 Search.xml好吧，search 是 Hexo 的 hexo-generator-search插件生成的，具体我没有去研究，但是我认为他提供的内容太少了，连文章时间都没有提供！不五星好评，有时间重新写一下，写成json的～首先我我们需要在项目中引入这个插件。 在package.json 中引入 hexo-generator-search 依赖 或者直接运行 npm install hexo-generator-search 命令 完成之后，配置 博客的 _config.yml 在任意位置添加该配置 # Search ## search some post in our blog search: path: search.xml field: all 之后使用 hexo clean &amp;&amp; hexo g &amp;&amp; hexo s 查看 public 文件夹下是不是出现了 search.xml，如果出现。OK 你的第一步已经完成了。如果没有，大兄弟～ 重新看看 再来一遍～ H3 产生搜索内容好吧，之后的步骤其实就是 ajax 请求这个xml 之后解析该文件获取里面的标题，内容以及url var search_path = \"&lt;%= config.search.path %>\"; if (search_path.length == 0) { search_path = \"search.xml\"; } var path = \"&lt;%= config.root %>\" + search_path; $.ajax({ url: path, dataType: \"xml\", success: function(xmlResponse) { // get the contents from search data var datas = $(\"entry\", xmlResponse).map(function() { return { title: $(\"title\", this).text(), content: $(\"content\", this).text(), url: $(\"url\", this).text() }; }).get(); // 此处的 data 就是你需要的东西，你可以自己查看 xml 内的构成 在 上方的 datas 生成方法哪修改你需要的东西 } }); 获取到了我们需要的数据之后，我们就需要筛选内容了。 datas.forEach(function(data) { // ata.title 文章标题 // ata.content 文章内容 // ata.url 文章地址 data_title.indexOf(keyword); data_content.indexOf(keyword); /// 这个时候就可以判断 这个内容是不是 存在 关键字了 }); 咱们在获取到第一个 index 之后其实就可以停止了。接下来我们获取到这个第一个 index 作为 String .subStr 第一个参数。如何获取第二个参数呢？100个200个都行的，自己决定，但是为了防止截取字符串的时候出现问题，我们需要判断，咱们的 start + 咱们详解去的长度 是不是尝过了 整篇内容的长度，如果是 那么 end index 就是本片篇文章的 长度-1。 咱们有时候还需要高亮 关键字，这个很简单，当我们按照以上方法，截取完成字符串之后 var regS = new RegExp(keyword, \"gi\"); content = content.replace(regS, \"&lt;span class=\\\"search-keyword\\\">\" + keyword + \"&lt;/span>\"); 之后我们设置 search-keyword 的calss 就可以了～ H3 使用 Datatables 分页展示内容到了以上其实就已经可以了,你只需要找到自己的需要的筛选结果显示器就可以了的。但是无奈我用的这套模版没有只能自己开发了。而且还遇到了一个问题。在小屏幕的时候显示的很差强人意.. 目前因为不熟悉 html 前端的开发，先放弃了。首先来说我们做这个显示结果总结的一些知识点吧。 H4 DataTable JavaScript DataSource Refresh关于这个筛选出来结果之后重新复制到 DataTables 出现了一个不可以重新 init 的问题，所以在查找了一些资料之后，发现了解决办法。 var SearchDataTablesElment; if (!SearchDataTablesElment) { SearchDataTablesElment = $(\"#PostSearchResults\").DataTable({ data: datas ); } else { SearchDataTablesElment.clear().rows.add(datas).draw(); } 我们可以通过判断 Table 是否存在，之后来觉的是生成还是重新绘制行。 H4 DataTables 一些配置关于 这个控件如果熟悉的话 就不需要继续看了，，我这是以前用过，但是现在许久没用了，自然就需要重新看了。。。 { data: datas, autoWidth: false, ordering: false, searching: false, lengthChange: false, pageLength: 4, info: false, pagingType: \"cutsomPage\", footerCallback: function(tfoot, data, start, end, display) { var keyWorkd = \"&lt;span style='color: #6281c8;font-weight: bold;'>\" + $(\"#PostSearchInput\").val() + \"&lt;/span>\"; var title = \"查询[\" + keyWorkd + \"]结果共\" + data.length + \"个,总耗时\" + times / 1000 + \"秒\"; $(\"#infomessagelabel\").html(title); }, columns: [{ title: \"\" }] } 这是我的一些配置。在这里查看更多的API H4 Custom DataTables pagingType这里真的是好麻烦的，，差了好多资料，大多都是一些修改 分页器的 Class这些东西的。涉及到其他的话就看不到了。最后终于还是在(官方网站)[https://datatables.net/plug-ins/pagination/]找到了方法。你也可以查看我的(自定义方法)[/assets/js/helpers/hs.pages.table.js]，我这里设置到了一些创建 包裹 控件的方法。 还有一些其他的东西，比如 监听 ecs 以及 左右键位来换页。代码如下。当然你也可以自己在这个HTML中查找，当时没有c抽象成js文件，直接就是写在这里面的。 function WatchLeftAndRightKeyWork() { $(document).keydown(function(event) { var pointEvent = event.which == 37 || event.which == 39 || event.which == 27 || event.which == 96; var pointStatus = $('#searchdownview').css('display') != 'none' || $(\"#PostSearchInput\").is(':focus') || $(\"#PostSearchInput\").val().length > 0; if (pointEvent &amp;&amp; pointStatus) { $(\"#PostSearchInput\").blur(); // 失去焦点 event.preventDefault(); // 组织键盘 switch (event.which) { //判断按键; case 37: // 上一页 SearchDataTablesElment.page('previous').draw('page'); break; case 39: // 下一页 SearchDataTablesElment.page('next').draw('page'); break; case 27: case 96: $(\"#PostSearchInput\").val(\"\"); $(\"#PostSearchInput\").trigger(\"input\"); break; default: break; } } }); } H4 关于TableView中有些内容会超出div的情况在这个问题上，我偶尔发现当我搜索结果出现大段的英文的时候，不会出现折行而是超出父控件。 #searchdownview table { table-layout: fixed; } #searchdownview td { word-break: break-all; word-wrap: break-word; } H4 关闭搜索输入框搜索历史另外 关于搜索输入框偶尔展示输入记录。autocomplete=&quot;off&quot;…. 博大… 程序员 没有google 百度，，，难以想象。。。 hexo 增加本地搜索模块.md","categories":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}],"tags":[{"name":"博客美化","slug":"博客美化","permalink":"http://blog.msiter.com/tags/博客美化/"},{"name":"hexo","slug":"hexo","permalink":"http://blog.msiter.com/tags/hexo/"}],"keywords":[{"name":"博客历程","slug":"博客历程","permalink":"http://blog.msiter.com/categories/博客历程/"}]},{"title":"Pthreads 学习3 - 信号量","slug":"Pthreads 学习3 - 信号量","date":"2018-01-11T23:22:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Pthreads xx3 - x,shl-20180111.html","link":"","permalink":"http://blog.msiter.com/Pthreads xx3 - x,shl-20180111.html","excerpt":"锁，在多个线程中一起访问同一个属性，如果不加锁的话，会导致数据出现错误。 举一个最简单的例子,又一个 int 类型的公共变量 值为 0，2个线程同时访问他，都做10次累加。那么极有可能会出现，这个值不等于20的情况。这种时候就需要锁这种东西，我觉的锁，其实和信号量还是挺像的，感觉像信号量的进阶？","text":"锁，在多个线程中一起访问同一个属性，如果不加锁的话，会导致数据出现错误。 举一个最简单的例子,又一个 int 类型的公共变量 值为 0，2个线程同时访问他，都做10次累加。那么极有可能会出现，这个值不等于20的情况。这种时候就需要锁这种东西，我觉的锁，其实和信号量还是挺像的，感觉像信号量的进阶？ 以下为5种方式.├── MutexForInType.cpp├── MutexForOutType.cpp├── NoLockType.cpp├── SemaphoreForInType.cpp└── SemaphoreForOutType.cpp H3 使用信号量来进行这个测试好吧，用了半个小时才搞完这个计算平均时间的小东西。。。 var res = \"1.[0.058362]&lt;br/>2.[0.058790]&lt;br/>3.[0.055453]&lt;br/>4.[0.058895]&lt;br/>5.[0.055795]&lt;br/>6.[0.063488]&lt;br/>7.[0.064370]&lt;br/>8.[0.057868]&lt;br/>9.[0.058790]&lt;br/>10.[0.056153]\"; var cal = /[0-9.]+\\[([0-9.]+)\\]/g; var m; var sum = 0; var count = 0; do{ m = cal.exec(res); if (m) { sum+=parseFloat(m[1]); count++; console.log(m[1],sum,count); } }while(m); console.log(sum/count); 我就一展示数据的表格 名称 线程安全 成绩 平均分 MutexForInType 是 1.[0.202137]2.[0.185789]3.[0.179368]4.[0.272630]5.[0.239758]6.[0.240693]7.[0.255223]8.[0.198637]9.[0.232774]10.[0.248535] 0.22555439999999996 MutexForOutType 是 1. [0.058362]2.[0.058790]3.[0.055453]4.[0.058895]5.[0.055795]6.[0.063488]7.[0.064370]8.[0.057868]9.[0.058790]10.[0.056153] 0.058796400000000006 NoLockType 否 1.[0.281418]2.[0.273135]3.[0.264430]4.[0.266663]5.[0.190819]6.[0.198963]7.[0.221909]8.[0.240771]9.[0.245478]10.[0.293448] 0.24770340000000002 SemaphoreForInType 否 1.[0.321427]2.[0.270053]3.[0.312442]4.[0.321051]5.[0.252933]6.[0.237228]7.[0.293928]8.[0.254666]9.[0.275634]10.[0.291737] 0.2831099 SemaphoreForOutType 是 1.[0.062282]2.[0.066465]3.[0.056639]4.[0.047239]5.[0.064882]6.[0.058525]7.[0.062361]8.[0.058302]9.[0.058728]10.[0.055138] 0.0590561 H3 关于 sem_open 方法传参问题运行 man sem_open 得到以下，还是不清楚他是如何穿参数的，我们只是知道了 oflag 有两个参数。 O_CREAT O_EXCL。 但是 oflag.是一个可变参数，他到底是什么呢？ 在IBM Knowledge Center - sem_open()–Open Named Semaphore找到了一些说法，也就是说，三个参数。 H4 name指向要打开的信号量的以空字符结尾的名称的指针。 该名称应以斜线（’/‘）字符开头。 如果名称不以斜杠（’/‘）字符开始，则系统会在名称的开头添加一个斜杠。假设这个参数在当前对作业有效的CCSID（编码字符集标识符）中表示。 如果作业的CCSID是65535，则假定此参数在作业的默认CCSID中表示。 该名称被添加到仅由命名信号量使用的一组名称中。 名称与任何文件系统路径名都没有关系。 名称的最大长度是SEM_NAME_MAX。 H4 oflagoflag选项参数。oflag参数值为零，或者通过对以下一个或多个常量执行OR运算来获得： 我就一展示数据的表格 可选项 解释 ‘0x0008’ or O_CREAT 如果不存在，则创建指定的信号量。 ‘0x0010’ or O_EXCL 如果O_CREAT也被设置并且指定的信号量已经存在，则会导致sem_open（）失败。 H4 mode权限标志。模式参数值可以是零，也可以通过对以下一个或多个常量列表执行OR操作来获得。 对于另一个打开信号量的进程，进程的有效UIDd必须能够以读写模式打开信号量。 我就一展示数据的表格 可选项 解释 ‘0x0100’ or S_IRUSR 允许指定信号量的创建者以读取模式打开信号量。 ‘0x0080’ or S_IWUSR 允许指定信号量的创建者在写入模式下打开信号量。 ‘0x0020’ or S_IRGRP 允许与指定信号相关联的组以打开信号量的读取模式。 ‘0x0010’ or S_IWGRP 允许与指定信号相关联的组以打开信号量的写入模式。 ‘0x0004’ or S_IROTH 允许其他人以读取模式打开指定的信号量。 ‘0x0002’ or S_IWOTH 允许其他人在写入模式下打开指定的信号量。. H4 value指定信号量的初始值。 如果感兴趣可以直接去查看源码 sem_open.c H3 关于有名信号量和无名信号量一开始觉的这是什么，，，，感觉很难啊，，，当我开始做的时候，发现，sem_init在OSX系统上被弃用了,,, 只能用，sem_open打开，而使用这个方法，我们也都讨论过了，需要传入一个名称。 至此，，，，，原来这就是有名 无名，，，还真是贴切…. H3 锁和信号量的区别我个人觉的 锁是针对 多个线程访问 公共变量的时候为了防止同步出现错误而进行的保护操作。而信号量则是一个交流吧？就是比如说 A线程和B线程都去找个妹子，A线程找到的时候，因为妹子没空，B线程只能等待。等到A线程约会完之后，妹子被释放，B线程才可以被访问。而信号量，则是说，咱们用别人都用的开灯关灯来说比较好。信号灯！ 没有量的时候，B线程就一直等着，等到A亮灯，B就知道了～ 哦哦哦· 该我了～这样子…. 以下说一下大家都说的几个区别。 互斥量用于线程的互斥，信号线用于线程的同步。 互斥量值只能为0/1，信号量值可以为非负整数。 互斥量的加锁和解锁必须由同一线程分别对应使用，信号量可以由一个线程释放，另一个线程得到。 Pthreads 学习3 - 信号量.md","categories":[{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/categories/线程/"}],"tags":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/tags/IOS/"},{"name":"Pthreads","slug":"Pthreads","permalink":"http://blog.msiter.com/tags/Pthreads/"},{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/tags/线程/"}],"keywords":[{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/categories/线程/"}]},{"title":"Objective-c修饰符探索","slug":"Objective-c修饰符探索","date":"2018-01-11T11:11:11.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Objective-cxsfts-20180111.html","link":"","permalink":"http://blog.msiter.com/Objective-cxsfts-20180111.html","excerpt":"最近想学习一下 objc的 一些修饰符的相关问题。比如 “retain”,”strong”,”weak”,”assign”这些区别到底在哪里了，之类的，就心思从源头解决这个问题。到底线程安全还是不安全，加锁不加锁之类的到底是怎么回事儿。所以我找到了 objc的源码 打算看看到底是什么？ 我们先来把objc源码目录都整理一遍,结果大概会得到","text":"最近想学习一下 objc的 一些修饰符的相关问题。比如 “retain”,”strong”,”weak”,”assign”这些区别到底在哪里了，之类的，就心思从源头解决这个问题。到底线程安全还是不安全，加锁不加锁之类的到底是怎么回事儿。所以我找到了 objc的源码 打算看看到底是什么？ 我们先来把objc源码目录都整理一遍,结果大概会得到 H2 文件结构H2 仅有h文件objc-api.hobjc.h objcrt.hruntime.hobjc-private.hobjc-object.hobjc-internal.hobjc-gdb.hobjc-abi.hobjc-config.hobjc-env.hmessage - hhashtable - h llvm-AlignOf.hllvm-DenseMap.hllvm-DenseMapInfo.hllvm-MathExtras.hllvm-type_traits.h H2 仅有mm文件objc-typeencoding.mmobjc-sel.mmobjc-sel-old.mmobjc-opt.mmobjc-lockdebug.mmobjc-layout.mmobjc-errors.mmobjc-externalref.mmobjc-block-trampolines.mm H3 h,mm文件NSObject - h,mmObject - h,mmList - h,mProtocol - h,mmhashtable2 - h,mmmaptable - h,mmobjc-accessors - h,mmobjc-auto-dump - h,mmobjc-auto - h,mmobjc-cache-old - h,mmobjc-cache - h,mmobjc-class - h,mmobjc-exception.hobjc-file-old.hobjc-file.hobjc-initialize.hobjc-load.hobjc-os.hobjc-runtime.hobjc-runtime-old.hobjc-runtime-new.hobjc-references.hobjc-loadmethod.hobjc-lockdebug.hobjc-sel-set.hobjc-sync.hobjc-weak.h H3 Objc-api.h该文件定义了若干个宏 方法 和 宏 定义 __has_feature 是否含有特征？ 但是无论传值如何，都是返回 0(false) __has_extension 是否含有扩展？ 直接调用的 __has_feature 还是返回都是 0(false) __has_attribute 是否含有参数？ 还是都返回 0(false) OBJC_API_VERSION OBJC API 版本。 存在两个值 0 或者 没有标记: Tiger (苹果Mac OS X 10.4操作系统)以及更早之前的 为 一类 2: Leopard(苹果Mac OS X 10.5操作系统) 以及更之后的系统版本 为 一类 OBJC_NO_GC 是否 NO！GC (Garbage Collection) 垃圾回收机制 1 不再支持 GC 机制 undef(没有声明) 支持GC判定条件的话 如果为 TARGET_OS_EMBEDDED(？嵌入式),iPhone,Win32为系统 或者 TARGET_OS_MAC &amp;&amp; __x86_64h__ 则为1 OBJC_NO_GC_API 是否不再导出 关于 GC 的API 1 库不需要导出与GC相关的符号. (不需要支持 GC) undef(没有声明) 库必须导出任何双模式代码可能链接到的符号判定条件的话 如果为 TARGET_OS_EMBEDDED(？嵌入式),iPhone,Win32为系统 则为 1 NS_ENFORCE_NSOBJECT_DESIGNATED_INITIALIZER 执行的默认初始化方法 如果为1的话 [NSObject init] 就是默认初始化方法 OBJC_OLD_DISPATCH_PROTOTYPES 等于 0 强制执行调度规则函数必须转换为适当的函数指针类型 OBJC_ISA_AVAILABILITY 每个Objective-C对象都有一个隐藏的数据结构，这个数据结构是Objective-C对象的第一个成员变量，它就是isa指针。这个参数就是说 如果为 OBJC2 的时候 就取消该 isa 指针，否则 就是可用。但是目前 是 必定为1 OBJC2_UNAVAILABLE OBJC2 是否可用判定条件：如果objc2 肯定是可用的 否则就表示 __OSX_AVAILABLE_BUT_DEPRECATED 可用单是在 __MAC_10_5,__MAC_10_5, __IPHONE_2_0,__IPHONE_2_0 之后 不可用 OBJC_ARC_UNAVAILABLE ARC是否可用。判定条件… 必定可用 ，具体可以看代码，除非我理解的前三个函数 有问题 OBJC_SWIFT_UNAVAILABLE Swift 是否可用 必定可用… OBJC_ARM64_UNAVAILABLE ARM64 64位 架构 模拟器32位处理器测试需要i386架构， 模拟器64位处理器测试需要x86_64架构， 真机32位处理器需要armv7,或者armv7s架构， 真机64位处理器需要arm64架构。 OBJC_GC_UNAVAILABLE GC 垃圾回收机制 是否可用 OBJC_EXTERN 一个返回特定 extern 方法如果为c++ extern &quot;c&quot; 否则 只是 extern OBJC_VISIBLE OBJC 是否可以使用 使用一个方法或者类，一个是提供者，一个是使用者，二者之间的接口是头文件。头文件中声明了方法， WIN32下在提供者那里方法应该被声明为__declspec(dllexport) WIN32下在使用者那里，方法应该被声明为__declspec(dllimport)。 非WIN32下 使用 __attribute__((visibility(&quot;default&quot;))) OBJC_EXPORT 一个集合方法 集合了 OBJC_EXTERN和 OBJC_VISIBLE OBJC_IMPORT 只是在后面 追加 extern 关键字 OBJC_ROOT_CLASS 指定为 根类型 __DARWIN_NULL 就是 NULL OBJC_INLINE 就是 __inline 关键字 OBJC_ENUM 以及 OBJC_OPTION 针对于 每一种语言都会有一种设置 H3 objc.h该方法 创建了一些类型 建立 objc_class 的 另一种读法 Class。建立 objc_object 的 另一种读法 id。建立 objc_selector 的 另一种读法 SEL。 创建一个objc_object 默认包含一个指针 Class isa 也就是 objc_class isa 对象，是否包含由objcapi.h OBJC_ISA_AVAILABILITY 决定 OBJC_OLD_DISPATCH_PROTOTYPES 终于有了作用区别在于 /// A pointer to the function of a method implementation. #if !OBJC_OLD_DISPATCH_PROTOTYPES typedef void (*IMP)(void /* id, SEL, ... */ ); #else typedef id (*IMP)(id, SEL, ...); #endif 目前还看不懂 声明了一个 OBJC_BOOL_DEFINED 没有找到他的作用 声明了 BOOL 和 (OBJC_BOOL_IS_BOOL | OBJC_BOOL_IS_CHAR ) 宏定义 区别在于如果为 iPhone 并且 为 LP64位 系统(linux 64位) 或者 是 手表系统 那么 BOOL值位 long 否则久违 char 接下来定义了 YES 和 NO NIL 和 nil 创建一个 宏 __strong /// 如果 没有定义了 __OBJC_GC__ 或者 false 拿起就是 没有 __strong #if ! (defined(__OBJC_GC__) || __has_feature(objc_arc)) #define __strong /* empty */ #endif 创建 __unsafe_unretained 和 __autoreleasing 创建了这些方法 sel_getName 返回一个 Char 得到 我们传递的 SEL 类型的对象的名称 sel_registerName 通过名称像 Objective-c runTime Sysytem 中注入一个 SEL必须保证 SEL 注入的名称不包含 系统默认的名称 如果已经注册过仅仅返回 这个SEL object_getClassName 获取对象的类型名称 object_getIndexedIvars 获取对象的指针？ sel_isMapped SEL 是否可用 sel_getUid 等同于 sel_registerName 但是具体在一些操作上不一样 // 过时的 ARC 转换，这个东西的废除 也就是最近的事儿了 // 使用 CFBridgingRetain, CFBridgingRelease, and __bridge 代替 typedef const void* objc_objectptr_t; 11. #if !__OBJC2__ // 如果不是 OBJC2 // The following declarations are provided here for source compatibility. #if defined(__LP64__) // 如果是 64 位 typedef long arith_t; // arith_t uarith_t 都适用 大字段 typedef unsigned long uarith_t; # define ARITH_SHIFT 32 #else typedef int arith_t; // arith_t uarith_t 都适用 小字段 typedef unsigned uarith_t; # define ARITH_SHIFT 16 #endif typedef char *STR; #define ISSELECTOR(sel) sel_isMapped(sel) // 是 否为可用 #define SELNAME(sel) sel_getName(sel) // 过去 SEL 名称 #define SELUID(str) sel_getUid(str) // 注册方法 #define NAMEOF(obj) object_getClassName(obj) // 获取类型的名称 #define IV(obj) object_getIndexedIvars(obj) // 获取 指针？ #endif H3 runtime.h Objective-c修饰符探索.md","categories":[{"name":"学习","slug":"学习","permalink":"http://blog.msiter.com/categories/学习/"}],"tags":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/tags/IOS/"},{"name":"ObjC","slug":"ObjC","permalink":"http://blog.msiter.com/tags/ObjC/"}],"keywords":[{"name":"学习","slug":"学习","permalink":"http://blog.msiter.com/categories/学习/"}]},{"title":"Pthreads 学习1","slug":"Pthreads 学习2 - 文档","date":"2018-01-11T08:22:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Pthreads xx2 - wd-20180111.html","link":"","permalink":"http://blog.msiter.com/Pthreads xx2 - wd-20180111.html","excerpt":"在共享内存多处理器体系结构中，可以使用线程来实现并行性。从历史上看，硬件供应商已经实现了自己的专有版本的线程，使得可移植性成为软件开发人员的关注点。对于UNIX系统，标准化的C语言线程编程接口已由IEEE POSIX 1003.1c标准规定。坚持这个标准的实现被称为POSIX线程或Pthreads。 本教程首先介绍使用Pthread的概念，动机和设计注意事项。然后介绍Pthreads API中三大类例程中的每一个：线程管理，互斥变量和条件变量。示例代码用于演示如何使用新Pthreads程序员所需的大部分Pthreads例程。本教程最后讨论了LLNL细节以及如何将MPI与pthreads混合。实验室练习还包括许多示例代码（C语言）。 级别/先决条件：本教程非常适合那些刚接触pthread的并行编程人员。在C中的并行编程的基本理解是必需的。对于那些不太熟悉并行编程的人来说，EC3500：并行计算入门所涉及的 内容将会很有帮助。","text":"在共享内存多处理器体系结构中，可以使用线程来实现并行性。从历史上看，硬件供应商已经实现了自己的专有版本的线程，使得可移植性成为软件开发人员的关注点。对于UNIX系统，标准化的C语言线程编程接口已由IEEE POSIX 1003.1c标准规定。坚持这个标准的实现被称为POSIX线程或Pthreads。 本教程首先介绍使用Pthread的概念，动机和设计注意事项。然后介绍Pthreads API中三大类例程中的每一个：线程管理，互斥变量和条件变量。示例代码用于演示如何使用新Pthreads程序员所需的大部分Pthreads例程。本教程最后讨论了LLNL细节以及如何将MPI与pthreads混合。实验室练习还包括许多示例代码（C语言）。 级别/先决条件：本教程非常适合那些刚接触pthread的并行编程人员。在C中的并行编程的基本理解是必需的。对于那些不太熟悉并行编程的人来说，EC3500：并行计算入门所涉及的 内容将会很有帮助。 H2 pthread_atforkH2 pthread_attr_destroy &amp;&amp; pthread_attr_initH3 含义销毁 线程属性对象 H3 概要#include &lt;pthread.h> /// 传递一个 pthread_attr_t 对象的指针 int pthread_attr_destroy（pthread_attr_t * attr）; H3 描述pthread_attr_destroy() 函数应该销毁一个线程属性对象。销毁后的线程属性对象是未定义的，销毁后的对象可以通过pthread_attr_init()重新定义。pthread_attr_init()函数。是初始化一个线程属性对象，每一个单个属性都会给定默认的实现由此产生的属性对象(通过设置单个属性可以修改),在使用 pthread_create()方法时传入。一个线程属性对象可以在多个线程中使用。如果调用pthread_attr_init()函数传入的只是一个已经定义了的属性对象，它的结果是不确定的。 H3 返回在成功完成 pthread_attr_destroy() 或 pthread_attr_init() 时返回0，否则就返回该操作的错误代码。 H3 错误pthread_attr_init()出现错误可能是： ENOMEM 没有足够的内存来初始化这个线程属性对象 这个方法不应该返回错误代码，如果返回了那么就出错了H2 pthread_attr_getdetachstate &amp;&amp; pthread_attr_setdetachstateH3 含义获取或者设置 detachstate 属性H3 概要````cpp#include int pthread_attr_getdetachstate（const pthread_attr_t attr，int detachstate）;int pthread_attr_setdetachstate（pthread_attr_t * attr，int detachstate）; ### 描述 `detachstate`属性是控制一个线程在创建的时候是否是独立的状态。如果这个线程创建是独立的，接下来使用他的ID来调用`pthread_detach()`或`pthread_join()`会出现一个错误。 这个`pthread_attr_getdetachstate()` 和 `pthread_attr_setdetachstate()`方法是用来获取或者设置 线程属性对象中的 `detachstate` 属性。 针对于 `pthread_attr_getdetachstate()`你能获取的只能是 `PTHREAD_CREATE_DETACHED`或者`PTHREAD_CREATE_JOINABLE` 针对于 `pthread_attr_setdetachstate` 你能设置的值也只能是 `PTHREAD_CREATE_DETACHED`或者`PTHREAD_CREATE_JOINABLE` 设置`PTHREAD_CREATE_DETACHED`将导致创建属性是在分离的状态中的所有线程，而使用`PTHREAD_CREATE_JOINABLE`将导致创建属性处于可连接状态的所有线程。该detachstate属性的默认值将`PTHREAD_CREATE_JOINABLE`。 ### 返回 在成功完成 `pthread_attr_getdetachstate()` 或 `pthread_attr_setdetachstate()` 时返回0，否则就返回该操作的错误代码。 ### 错误 `pthread_attr_setdetachstate()`出现错误可能是： 1. EINVAL 传入的`detachstate`属性没有通过验证 2. 这个方法不应该返回错误代码，如果返回了那么就出错了 ## pthread_attr_getguardsize &amp;&amp; pthread_attr_setguardsize ### 含义 获取或设置 线程保护属性 ### 概要 ````cpp #include &lt;pthread.h&gt; int pthread_attr_getguardsize（const pthread_attr_t * restrict attr， size_t * restrict guardsize）; int pthread_attr_setguardsize（pthread_attr_t * attr， size_t guardsize）; H3 描述pthread_attr_getguardsize()函数将得到线程属性中的保护属性。pthread_attr_setguardsize()函数应该设置线程属性对象guardsize属性。如果这个值为0，则不给予使用这个线程属性对象创建的线程提供守护区域，如果大于零，则需要为每个使用这个线程属性对象创建的线程提供至少为guardsize的守护大小guardsize 属性控制创建的线程的堆栈的保护区区域的大小。guardsize属性为创建线程的堆栈控制保护区大小。提供保护,防止堆栈指针溢出。如果线程的堆栈具有防护，那么在其堆栈移除的时候分配额外的内存。如果应用程序溢出到这个区域，将发出一个错误（一个 SIGSEGV 信号） H2 pthread_attr_getinheritsched &amp;&amp; pthread_attr_setinheritschedH3 描述函数将分别获取并设置inheritsched属性在attr的论点。 当pthread_create()创建一个线程的时候，inheritsched 属性决定了其继承性质。它可以被设置为以下两个值： PTHREAD_INHERIT_SCHED 指定的线程调度属性应当从创建线程的调度属性继承，这个属性参数将被忽略。 PTHREAD_EXPLICIT_SCHED 指定线程调度属性应设置为该属性对象的相应值H2 pthread_attr_getschedparam &amp;&amp; pthread_attr_setschedparamH3 NAME pthread_attr_getschedparam, pthread_attr_setschedparam - 获取或者设置 调度参数 H3 概要#include &lt;pthread.h> int pthread_attr_getschedparam(const pthread_attr_t *restrict attr, struct sched_param *restrict param); int pthread_attr_setschedparam(pthread_attr_t *restrict attr, const struct sched_param *restrict param); H3 描述pthread_attr_getschedparam()和pthread_attr_setschedparam()函数分别在attr参数中获取和设置调度参数属性。 param结构的内容在头文件中定义。 对于SCHED_FIFO和SCHED_RR策略，param的唯一必需成员是sched_priority。 对于SCHED_SPORADIC策略，param结构所需的成员是sched_priority，sched_ss_low_priority，sched_ss_repl_period，sched_ss_init_budget和sched_ss_max_repl。 指定的sched_ss_repl_period必须大于或等于指定的sched_ss_init_budget才能成功; 如果不是，则该功能将失败。 sched_ss_max_repl的值应该在函数成功的包含范围[1，{SS_REPL_MAX}]内; 如果不是，则该功能将失败。 H2 pthread_attr_getschedpolicy &amp;&amp; pthread_attr_setschedpolicyH3 名称pthread_attr_getschedpolicy, pthread_attr_setschedpolicy - get and setthe schedpolicy attribute (REALTIME THREADS) H3 概要#include &lt;pthread.h> int pthread_attr_getschedpolicy(const pthread_attr_t *restrict attr, int *restrict policy); int pthread_attr_setschedpolicy(pthread_attr_t *attr, int policy); H3 描述pthread_attr_getschedpolicy（）和pthread_attr_setschedpolicy（）函数将分别在attr参数中获取并设置schedpolicy属性。 支持的策略值应包括在头文件中定义的SCHED_FIFO，SCHED_RR和SCHED_OTHER。 当使用调度策略SCHED_FIFO，SCHED_RR或SCHED_SPORADIC执行的线程正在等待互斥体时，它们将在互斥体解锁时以优先级顺序获取互斥体。 H2 pthread_attr_getscopeH2 pthread_attr_getstackH2 pthread_attr_getstackaddrH2 pthread_attr_getstacksize## ## ## ## ## H2 pthread_attr_setscopeH2 pthread_attr_setstackH2 pthread_attr_setstackaddrH2 pthread_attr_setstacksizeH2 pthread_barrier_destroyH2 pthread_barrier_initH2 pthread_barrier_waitH2 pthread_barrierattr_destroyH2 pthread_barrierattr_getpsharedH2 pthread_barrierattr_initH2 pthread_barrierattr_setpsharedH2 pthread_cancelH3 名称取消线程的执行 H3 概要#include &lt;pthread.h> int pthread_cancel（pthread_t thread）; H3 描述取消指定的函数 H2 pthread_cleanup_pop &amp;&amp; pthread_cleanup_pushH3 概要 #include &lt;pthread.h> void pthread_cleanup_pop(int execute); void pthread_cleanup_push(void (*routine)(void*), void *arg); H3 描述两个方法为宏定义方法，主要是用来在一个线程退出的时候调用方法。以下三种情况会出发到这个推出栈调用。 线程退出(即调用pthread_exit()) 线程发出了 cancel 请求 线程正常调用到了 pthread_cleanup_pop方法这些函数可以作为宏实现。应用程序中应确保他们成对出现。就像 () 括号一样。 H2 pthread_cond_broadcastH2 pthread_cond_destroyH2 pthread_cond_initH2 pthread_cond_signalH2 pthread_cond_timedwaitH2 pthread_cond_waitH2 pthread_condattr_destroyH2 pthread_condattr_getclockH2 pthread_condattr_getpsharedH2 pthread_condattr_initH2 pthread_condattr_setclockH2 pthread_condattr_setpsharedH2 pthread_createH2 pthread_detachH2 pthread_equalH3 名称比较线程ID H3 概要#include &lt;pthread.h> int pthread_equal（pthread_t t1，pthread_t t2）; H3 描述这个函数比较线程 t1和t2. H3 返回值如果t1和t2相等,pthread_equal()函数将返回一个非零值;否则返回零。如果t1或t2不是有效的线程ID，则行为是未定义的。 H2 pthread_exitH3 名称线程终止 H3 概要#include &lt;pthread.h> void pthread_exit（void * value_ptr）; H3 描述pthread_exit()方法退出当前方法的线程The pthread_exit() function shall terminate the calling thread and make the value value_ptr available to any successful join with the terminating thread. Any cancellation cleanup handlers that have been pushed and not yet popped shall be popped in the reverse order that they were pushed and then executed. After all cancellation cleanup handlers have been executed, if the thread has any thread-specific data, appropriate destructor functions shall be called in an unspecified order. Thread termination does not release any application visible process resources, including, but not limited to, mutexes and file descriptors, nor does it perform any process-level cleanup actions, including, but not limited to, calling any atexit() routines that may exist. An implicit call to pthread_exit() is made when a thread other than the thread in which main() was first invoked returns from the start routine that was used to create it. The function’s return value shall serve as the thread’s exit status. The behavior of pthread_exit() is undefined if called from a cancellation cleanup handler or destructor function that was invoked as a result of either an implicit or explicit call to pthread_exit(). After a thread has terminated, the result of access to local (auto) variables of the thread is undefined. Thus, references to local variables of the exiting thread should not be used for the pthread_exit() value_ptr parameter value. The process shall exit with an exit status of 0 after the last thread has been terminated. The behavior shall be as if the implementation called exit() with a zero argument at thread termination time. H2 pthread_getconcurrencyH2 pthread_getcpuclockidH2 pthread_getschedparamH2 pthread_joinH3 概要 #include &lt;pthread.h> int pthread_join(pthread_t thread, void **value_ptr); H3 描述该方法会暂停执行，直到目标线程结束运行。你可以通过一个非空的value_ptr来获得线程运行的成功的结果，the value passed to pthread_exit() by the terminating thread shall be made available in the location referenced by value_ptr.是在是没办法理解这句话了…当pthread_join()返回成功时，这个目标线程就标志着结束。如果针对一个相同的线程同步调用多次这个pthread_join()其结果是不可预知的。如果目标线程已经被取消了，那么这个线程不再可分离。这个有没有指定线程是否已经退出，都不会记入{PTHREAD_THREADS_MAX}。 H2 pthread_key_create &amp;&amp; pthread_key_delete &amp;&amp; pthread_getspecific &amp;&amp; pthread_setspecificH3 概要#include &lt;pthread.h> int pthread_key_create(pthread_key_t *key, void (*destructor)(void*)); int pthread_key_delete(pthread_key_t key); void *pthread_getspecific(pthread_key_t key); int pthread_setspecific(pthread_key_t key, const void *value); H3 描述 在单线程程序中，我们经常要用到”全局变量”以实现多个函数间共享数据。在多线程环境下，由于数据空间是共享的，因此全局变量也为所有线程所共有。但有时 应用程序设计中有必要提供线程私有的全局变量，仅在某个线程中有效，但却可以跨多个函数访问，比如程序可能需要每个线程维护一个链表，而使用相同的函数操 作，最简单的办法就是使用同名而不同变量地址的线程相关数据结构。这样的数据结构可以由Posix线程库维护，称为线程私有数据（Thread- specific Data，或TSD）。 出自《Posix线程编程指南(2)-线程私有数据》 - 杨沙洲 在我看来这个就是在某一个线程根据key设置了一个值，这个值可以保存在这个线程呢。在这个线程内任何时候都是可以调用的。pthread_key_create 和 pthread_key_delete 是创建 和 销毁 这个 Key 的。pthread_getspecific 和 pthread_setspecific 使用获取和设置这个KEY在当前线程保存的数据的。 其实理解这个东西主要要理解 什么叫做 线程内的私有公共变量。。。好吧，，我理解的就是 一个进程中含有多个线程。每个线程都有自己的公共变量。如果没有这个东西的话，公共变量就是每个线程都可以访问的那么就不是线程私有的了。 以下，是官方文档。pthread_key_create()函数将创建一个线程内的公共参数的Key值。提供的Key是为了获取到线程内私有的公共变量的数据。当然相同的键值可以通过pthread_setspecific被绑定到不同的线程上。默认的键对应的值是NULL。如果你设置了destructor构析函数，那么在线程结束后，会调用该方法，并将该键所绑定的数据当作参数返回。 If, after all the destructors have been called for all non-NULL values with associated destructors, there are still some non-NULL values with associated destructors, then the process is repeated. If, after at least {PTHREAD_DESTRUCTOR_ITERATIONS} iterations of destructor calls for outstanding non-NULL values, there are still some non-NULL values with associated destructors, implementations may stop calling destructors, or they may continue calling destructors until no non-NULL values with associated destructors exist, even though this might result in an infinite loop.再一次看不懂了 pthread_key_delete函数将删除一个线程私有公共数据的键。当调用 pthread_key_delete()的时候与KEY相关联的数据需要不能为空。应用程序有责任释放任何应用程序存储，或对与任何线程中删除的键或相关联的线程特定数据相关的数据结构执行任何清理操作;在调用了pthread_key_delete()之后，任何使用key再次调用pthread_key_delete()的方法都会引起未知的结果。 pthread_key_delete()方法应该在构析函数中调用. pthread_getspecific()函数获取当前的线程中绑定key的值。pthread_setspecific()函数是线程将一个使用pthread_key_create()获得的键与值绑定在一起。这些值通常是指向动态分配的内存块的指针，这些内存是为调用线程保留的。在没有使用pthread_key_create()创建键之前，或者使用了pthread_key_delete()之后，调用pthread_getspecific()或pthread_setspecific()方法，结果是未知的。Both pthread_getspecific() and pthread_setspecific() may be called from a thread-specific data destructor function. A call to pthread_getspecific() for the thread-specific data key being destroyed shall return the value NULL, unless the value is changed (after the destructor starts) by a call to pthread_setspecific(). Calling pthread_setspecific() from a thread-specific data destructor routine may result either in lost storage (after at least PTHREAD_DESTRUCTOR_ITERATIONS attempts at destruction) or in an infinite loop.（再见👋～）pthread_getspecific()和pthread_setspecific()可以被实现为宏。 H2 pthread_killH3 名称pthread_kill - 发送一个信号给一个线程 H3 概要#include &lt;signal.h> int pthread_kill(pthread_t thread，int sig); H3 描述pthread_kill() 函数要求为指定的线程传递一个信号。与kill()中一样，如果sig为零，则应该执行错误检查，但不执行信号应该实际发送。 H3 返回值成功完成后，函数将返回零值。否则，该功能应该返回一个错误号码。如果pthread_kill（）函数失败，不发送信号。 H2 pthread_mutexH3 描述叫做互斥锁主要是为了对于公共变量的值访问的时候，进行锁定，防止多个线程同时访问修改数据导致错误。 // // Mutex.cpp // Thread // // Created by 荆文征 on 2018/1/9. // Copyright © 2018年 s. All rights reserved. // #include &lt;unistd.h> #include &lt;stdio.h> #include &lt;pthread.h> /// Thread Count Number #define TN 6 int count = 0; void * barriers(void * param){ for (long i = 0; i &lt; TN; i++) { count++; printf(\"线程[%ld]: 计数器 - &lt;%d> \\n\",((long)param),count); sleep(1); } pthread_exit(NULL); return NULL; } int main(void){ pthread_t threads[TN]; for (long i = 0; i &lt; TN; i++) { pthread_create(&amp;threads[i], NULL, barriers, (void * )i); } pthread_mutex_destroy(&amp;mutex_t); pthread_exit(NULL); } 这个就会出现错误 线程[0]: 计数器 - 线程[1]: 计数器 - 线程[2]: 计数器 - 线程[3]: 计数器 - 线程[4]: 计数器 - 线程[5]: 计数器 - 线程[1]: 计数器 - 线程[0]: 计数器 - 线程[2]: 计数器 - 线程[3]: 计数器 - 线程[4]: 计数器 - 线程[5]: 计数器 - 线程[0]: 计数器 - 线程[2]: 计数器 - 线程[3]: 计数器 - 线程[1]: 计数器 - 线程[4]: 计数器 - 线程[5]: 计数器 - 线程[0]: 计数器 - 线程[2]: 计数器 - 线程[3]: 计数器 - 线程[1]: 计数器 - 线程[4]: 计数器 - 线程[5]: 计数器 - 线程[0]: 计数器 - 线程[2]: 计数器 - 线程[3]: 计数器 - 线程[1]: 计数器 - 线程[4]: 计数器 - 线程[5]: 计数器 - 线程[0]: 计数器 - 线程[2]: 计数器 - 线程[3]: 计数器 - 线程[1]: 计数器 - 线程[4]: 计数器 - 线程[5]: 计数器 - 如果使用了互斥锁 // // Mutex.cpp // Thread // // Created by 荆文征 on 2018/1/9. // Copyright © 2018年 s. All rights reserved. // #include &lt;unistd.h> #include &lt;stdio.h> #include &lt;pthread.h> /// Thread Count Number #define TN 6 int count = 0; pthread_mutex_t mutex_t; void * barriers(void * param){ pthread_mutex_lock(&amp;mutex_t); for (long i = 0; i &lt; TN; i++) { count++; printf(\"线程[%ld]: 计数器 - &lt;%d> \\n\",((long)param),count); sleep(1); } pthread_mutex_unlock(&amp;mutex_t); pthread_exit(NULL); return NULL; } int main(void){ pthread_mutex_init(&amp;mutex_t, NULL); pthread_t threads[TN]; for (long i = 0; i &lt; TN; i++) { pthread_create(&amp;threads[i], NULL, barriers, (void * )i); } pthread_mutex_destroy(&amp;mutex_t); pthread_exit(NULL); } 以下是每个属性的各自的介绍以及学习。 H2 pthread_mutex_destroy &amp;&amp; pthread_mutex_initH3 名称pthread_mutex_destroy,pthread_mutex_init - 销毁/初始化一个互斥变量 H3 概要#include &lt;pthread.h> int pthread_mutex_destroy(pthread_mutex_t *mutex); int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr); pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; H3 描述pthread_mutex_destroy()函数应该销毁互斥体引用的互斥对象; 互斥对象实际上变成未初始化的。 实现可能会导致pthread_mutex_destroy()将互斥体引用的对象设置为无效值。 被破坏的互斥对象可以使用pthread_mutex_init()重新初始化; 否则在对象被销毁之后引用对象的结果是不确定的。销毁没有锁定的互斥锁应是安全的，尝试销毁锁定的互斥锁会导致未定义的行为。pthread_mutex_init()函数将用attr指定的属性初始化互斥体引用的互斥锁。 如果attr为NULL，则使用默认的互斥体属性; 其效果应与传递默认互斥对象的地址相同。 初始化成功后，互斥锁的状态被初始化和解锁。只有互斥体本身可以用于执行同步。 在调用pthread_mutex_lock()，pthread_mutex_trylock()，pthread_mutex_unlock()和pthread_mutex_destroy()的调用中引用互斥体的副本的结果是未定义的。尝试初始化已经初始化的互斥体会导致未定义的行为。在默认互斥量属性适当的情况下，宏PTHREAD_MUTEX_INITIALIZER可用于初始化静态分配的互斥量。 该效果应该相当于通过调用pthread_mutex_init()，将参数attr指定为NULL来动态初始化，除非不执行错误检查。 H2 pthread_mutex_getprioceiling &amp;&amp; pthread_mutex_setprioceilingH3 名称pthread_mutex_getprioceiling，pthread_mutex_setprioceiling - 获取并设置互斥锁的优先级上限（REALTIME THREADS） H3 概要#include &lt;pthread.h> int pthread_mutex_getprioceiling(const pthread_mutex_t *restrict mutex, int *restrict prioceiling); int pthread_mutex_setprioceiling(pthread_mutex_t *restrict mutex, int prioceiling, int *restrict old_ceiling); H3 描述pthread_mutex_getprioceiling()函数将返回互斥量的当前优先级上限。 pthread_mutex_setprioceiling()函数在解锁时锁定互斥锁，或者阻塞直到成功锁定互斥锁，然后改变互斥锁的优先级上限并释放互斥锁。 当更改成功时，优先级上限的先前值将在old_ceiling中返回。 锁定互斥锁的过程不需要遵守优先保护协议。 如果pthread_mutex_setprioceiling()函数失败，则不会更改互斥优先级上限。 H3 错误pthread_mutex_getprioceiling()和pthread_mutex_setprioceiling()功能可能会失败： EINVAL prioceiling要求的优先级超出范围。EINVAL 由互斥体指定的值不引用当前存在的互斥体。EPERM 调用者没有执行操作的权限。这些功能不应返回[EINTR]的错误代码。 H2 pthread_mutex_lock &amp;&amp; pthread_mutex_trylock &amp;&amp; pthread_mutex_unlockH3 名称pthread_mutex_lock, pthread_mutex_trylock, pthread_mutex_unlock - 锁定或者解锁一个互斥变量 H3 概要#include &lt;pthread.h> int pthread_mutex_lock(pthread_mutex_t *mutex); int pthread_mutex_trylock(pthread_mutex_t *mutex); int pthread_mutex_unlock(pthread_mutex_t *mutex); H3 描述互斥体引用的互斥体对象应通过调用pthread_mutex_lock()来锁定。 如果互斥锁已经被锁定，则调用线程将阻塞直到互斥锁变为可用。 这个操作应该以调用线程作为拥有者的锁定状态返回互斥体引用的互斥体对象。 如果互斥量类型为PTHREAD_MUTEX_NORMAL，则不提供死锁检测。 试图重新锁定互斥锁会导致死锁。 如果线程试图解锁未锁定的互斥锁或未锁定的互斥锁，则会导致未定义的行为。 如果互斥类型为PTHREAD_MUTEX_ERRORCHECK，则应提供错误检查。 如果线程试图重新锁定已锁定的互斥锁，则应返回错误。 如果线程试图解锁未锁定的互斥锁或解锁的互斥锁，则应返回错误。 如果互斥体类型是PTHREAD_MUTEX_RECURSIVE，那么互斥体应该保持锁计数的概念。 当线程第一次成功获取互斥锁时，锁定计数应设置为1。 每当一个线程重新锁定这个互斥锁，锁定计数应该加1。 每次线程解锁互斥锁时，锁定计数应减1。 当锁计数达到零时，互斥锁将变为可用于其他线程获取。 如果线程试图解锁未锁定的互斥锁或解锁的互斥锁，则应返回错误。 如果互斥体类型是PTHREAD_MUTEX_DEFAULT，则试图递归锁定互斥体将导致未定义的行为。 试图解锁互斥锁，如果它没有被调用线程锁定导致未定义的行为。 试图解锁互斥锁，如果它没有被锁定导致未定义的行为。 pthread_mutex_trylock()函数应该等同于pthread_mutex_lock()，只是如果互斥体引用的互斥对象当前被锁定（通过任何线程，包括当前线程），则立即返回调用。 如果互斥体类型为PTHREAD_MUTEX_RECURSIVE，且互斥体当前由调用线程拥有，则互斥锁的计数应加1，并且pthread_mutex_trylock()函数应立即返回成功。 pthread_mutex_unlock()函数将释放由互斥体引用的互斥对象。 互斥体的释放方式取决于互斥体的类型属性。 如果调用pthread_mutex_unlock()时，互斥体引用的互斥体对象上有线程被阻塞，导致互斥体变为可用，则调度策略应确定哪个线程将获取互斥体。 （在PTHREAD_MUTEX_RECURSIVE互斥量的情况下，当计数达到零时，互斥量将变为可用，并且调用线程不再在此互斥锁上有任何锁定。） 如果一个信号被传递给一个等待互斥体的线程，那么当从信号处理程序返回时，线程将继续等待互斥体，就好像它没有被中断一样。 H2 pthread_mutex_timedlockH3 名称pthread_mutex_timedlock - 锁定互斥（ADVANCED REALTIME） IOS — 没有啊 H3 概述#include &lt;pthread.h> #include &lt;time.h> int pthread_mutex_timedlock(pthread_mutex_t *restrict mutex, const struct timespec *restrict abs_timeout); H3 描述pthread_mutex_timedlock()函数将锁定由互斥体引用的互斥对象。如果互斥体已经被锁定，调用线程应该阻塞，直到互斥体变得可用，如在pthread_mutex_lock()函数中一样。如果互斥锁不能等待另一个线程解锁互斥锁，则当指定的超时到期时，该等待将被终止。 如果超时时间基于超时时间（即，当时钟的值等于或超过abs_timeout）测量，或由abs_timeout指定的绝对时间已经超过绝对时间，abs_timeout指定的绝对时间已过在通话时通过。 如果支持Timers选项，则超时应基于CLOCK_REALTIME时钟;如果Timers选项不被支持，则超时应基于time（）函数返回的系统时钟。 超时的分辨率应该是它所基于的时钟的分辨率。 timespec数据类型在头文件中定义。 如果互斥锁可以立即锁定，在任何情况下功能都不会超时。如果可以立即锁定互斥锁，则不需要检查abs_timeout参数的有效性。 由于优先级继承规则（对于使用PRIO_INHERIT协议初始化的互斥锁）的结果，如果定时互斥等待由于其超时终止而终止，则必须根据需要调整互斥所有者的优先级，以反映此线程不再是等待互斥体的线程之中。 H2 pthread_mutexattr_destroy &amp;&amp; pthread_mutexattr_initH3 名称pthread_mutex_destroy, pthread_mutex_init - 破坏或者初始化一个互斥变量 H3 概要#include &lt;pthread.h> int pthread_mutex_destroy(pthread_mutex_t *mutex); int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr); pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER; H3 描述pthread_mutex_destroy()函数应该销毁互斥体引用的互斥对象;互斥对象实际上变成未初始化的。实现可能会导致pthread_mutex_destroy()将互斥体引用的对象设置为无效值。被破坏的互斥对象可以使用pthread_mutex_init()重新初始化;否则在对象被销毁之后引用对象的结果是不确定的。 销毁已解锁的已初始化的互斥锁应是安全的。试图销毁锁定的互斥锁会导致未定义的行为。 pthread_mutex_init()函数将用attr指定的属性初始化互斥体引用的互斥锁。如果attr为NULL，则使用默认的互斥体属性;其效果应与传递默认互斥对象的地址相同。初始化成功后，互斥锁的状态被初始化和解锁。 只有互斥体本身可以用于执行同步。在调用pthread_mutex_lock()，pthread_mutex_trylock()，pthread_mutex_unlock()和pthread_mutex_destroy()的调用中引用互斥体的副本的结果是未定义的。 尝试初始化已经初始化的互斥体会导致未定义的行为。 在默认互斥量属性适当的情况下，宏PTHREAD_MUTEX_INITIALIZER可用于初始化静态分配的互斥量。该效果应该相当于通过调用pthread_mutex_init()，将参数attr指定为NULL来动态初始化，除非不执行错误检查。 H2 pthread_mutexattr_getprioceilingH2 pthread_mutexattr_getprotocolH2 pthread_mutexattr_getpsharedH2 pthread_mutexattr_gettypeH2 pthread_mutexattr_setprioceilingH2 pthread_mutexattr_setprotocolH2 pthread_mutexattr_setpsharedH2 pthread_mutexattr_settypeH2 pthread_onceH3 名称pthread_once - 动态包初始化 H3 概要#include &lt;pthread.h> int pthread_once（pthread_once_t * once_control， void（* init_routine）（void））; pthread_once_t once_control = PTHREAD_ONCE_INIT; H3 描述进程中的任何线程(具有给定的once_control)，调用pthread_once(),第一次调用的时候会调用init_routine.随后的调用pthread_once()都不会调用 init_routine.当pthread_once()返回时，init_routine已经完成了，once_control确定是否已经调用了相关的初始化例程。pthread_once()方法不是一个可以取消的点，但是，如果init_routine是一个可以返回的，并且返回了，那这个操作就像是没有调用过pthread_once()方法一样的。常量 PTHREAD_ONCE_INIT 在 &lt;pthread.h&gt; 头文件中定义。如果once_control具有自动存储持续时间或未由PTHREAD_ONCE_INIT初始化，则pthread_once()的行为是未定义的。 H2 pthread_rwlock_destroy &amp;&amp; pthread_rwlock_initH3 名称pthread_rwlock_destroy, pthread_rwlock_init - 销毁/创建一个 读写锁 H3 概要#include &lt;pthread.h> int pthread_rwlock_destroy(pthread_rwlock_t *rwlock); int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr); H3 描述pthread_rwlock_destroy()函数应销毁由rwlock引用的读写锁对象，并释放锁使用的所有资源。这时，除非另一个调用pthread_rwlock_init()来重新初始化这个锁，否则在销毁之后再次调用锁的结果是为定义的。调用pthread_rwlock_destroy()会讲 rwlock 设置为无效值。如果一个线程持有 rwlock 时候调用 pthread_rwlock_destroy()结果是为定义的。尝试销毁为初始化的读写锁结果也是为定义的。 pthread_rwlock_init()函数将分配使用由rwlock引用的读写锁所需的所有资源，并将该锁初始化为具有由attr引用的属性的解锁状态。 如果attr为NULL，则使用默认的读写锁属性;其效果与传递默认读写锁定属性对象的地址相同。一旦初始化，锁可以被使用任何次数而不被重新初始化。如果调用pthread_rwlock_init()指定已经初始化的读写锁，结果是未定义的。如果在未初始化的情况下使用读写锁，则结果是不确定的。 如果pthread_rwlock_init函数失败，则rwlock不会被初始化，并且rwlock的内容是不确定的。 只有rwlock引用的对象可以用于执行同步。在调用pthread_rwlock_destroy()之后，再调用pthread_rwlock_rdlock(),pthread_rwlock_timedrdlock(),pthread_rwlock_timedwrlock(),pthread_rwlock_tryrdlock(),pthread_rwlock_trywrlock(),pthread_rwlock_unlock(), 或者 pthread_rwlock_wrlock()的结果是未定义的。 H2 pthread_rwlock_rdlock &amp;&amp; pthread_rwlock_tryrdlockH3 名称pthread_rwlock_rdlock, pthread_rwlock_tryrdlock - 获取一个读锁 阻塞和非阻塞 H3 概要#include &lt;pthread.h> int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock); int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwlock); H3 描述pthread_rwlock_rdlock()函数应该将读锁定应用于由rwlock引用的读写锁定。调用线程获取读锁定，如果一个写程序没有保持锁定，并且锁定上没有写作者被锁定。 如果支持线程执行调度选项，并且锁中涉及的线程正在使用调度策略SCHED_FIFO或SCHED_RR执行，那么调用线程将不会获得锁，如果一个写者持有该锁或者具有较高或相等优先级的写者被阻止上锁;否则，调用线程将获得该锁。 如果支持线程执行调度选项，并且锁中涉及的线程正在使用SCHED_SPORADIC调度策略执行，则调用线程将不会获取该锁，如果一个写入者持有该锁或者具有较高或相等优先级的写入者被阻止锁;否则，调用线程将获得该锁。 如果线程执行调度选项不受支持，则在编写程序没有保持锁定且写入程序被锁定时，调用线程是否获取锁定是实现定义的。如果作者持有该锁，则调用线程将不会获取该读锁。如果没有获取读锁，则调用线程将阻塞直到它可以获取锁。调用线程可能死锁，如果在进行调用时它保持写入锁定。 线程可能在rwlock上保存多个并发读锁（即，成功调用pthread_rwlock_rdlock（）函数n次）。如果是这样，应用程序应确保线程执行匹配的解锁（即，它调用pthread_rwlock_unlock（）函数n次）。 实施保证的同时读取锁的最大数量可以应用于读写锁，应该被实现定义。如果超过这个最大值，pthread_rwlock_rdlock（）函数可能会失败。 pthread_rwlock_tryrdlock（）函数应该像在pthread_rwlock_rdlock（）函数中一样应用一个读锁定，除非该函数在等效的pthread_rwlock_rdlock（）调用会阻塞调用线程时将失败。在任何情况下，pthread_rwlock_tryrdlock（）函数都不会阻塞;它总是要么获得锁定或失败，并立即返回。 如果使用未初始化的读写锁调用这些函数中的任何一个，则结果是不确定的。 如果一个信号被传递给一个等待读写锁的线程读取，那么在从信号处理程序返回之后，线程将恢复等待读写锁的读取，就好像它没有被中断一样。 H2 pthread_rwlock_timedrdlockH2 pthread_rwlock_timedwrlockH2 pthread_rwlock_trywrlock &amp;&amp; pthread_rwlock_wrlockH3 名称 pthread_rwlock_trywrlock, pthread_rwlock_wrlock - 获得一个读写对象的 写入锁 H3 概要#include &lt;pthread.h> int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock); int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock); H3 描述pthread_rwlock_trywrlock（）函数将应用像pthread_rwlock_wrlock（）函数一样的写入锁定，除非函数在任何线程当前持有rwlock（用于读取或写入）时将失败。 pthread_rwlock_wrlock（）函数应该将写锁定应用到由rwlock引用的读写锁。如果没有其他线程（读写器）持有读写锁rwlock，则调用线程获取写锁。否则，线程将阻塞，直到它可以获得锁。调用线程可能会死锁，如果在调用时它保存读写锁（不管是读锁还是写锁）。 实现可能会偏爱写入锁而不是读锁，以避免作家饥饿。 如果使用未初始化的读写锁调用这些函数中的任何一个，则结果是不确定的。 如果一个信号被传递给一个线程等待一个读写锁定的写入，那么当从信号处理程序返回时，线程恢复等待读写锁定写入，就像它没有被中断一样。 H2 pthread_rwlock_unlockH3 名称pthread_rwlock_unlock - 解锁一个读写锁对象 H3 概要#include &lt;pthread.h> int pthread_rwlock_unlock(pthread_rwlock_t *rwlock); H3 描述pthread_rwlock_unlock（）函数将释放一个保存在由rwlock引用的读写锁对象上的锁。如果读写锁rwlock没有被调用线程保存，结果是不确定的。 如果调用此函数来释放读写锁对象的读锁，并且此读写锁对象上还存在其他读锁，则读写锁对象保持读锁定状态。如果这个函数释放这个读写锁对象的最后一个读锁，那么这个读写锁对象将被置于没有所有者的解锁状态。 如果调用这个函数来释放这个读写锁对象的写锁，那么这个读写锁对象应该处于解锁状态。 如果锁上有线程被阻塞，调度策略将确定哪个线程将获得锁。如果支持线程执行调度选项，当调度策略SCHED_FIFO，SCHED_RR或SCHED_SPORADIC执行的线程正在等待锁定时，它们将在锁定可用时按优先级顺序获取锁定。对于同等优先级的线程，写入锁应优先于读取锁。如果不支持线程执行调度选项，那么写入锁定是否优先于读取锁定是实现定义的。 如果使用未初始化的读写锁调用这些函数中的任何一个，则结果是不确定的。 H2 pthread_rwlockattr_destroyH2 pthread_rwlockattr_getpsharedH2 pthread_rwlockattr_initH2 pthread_rwlockattr_setpsharedH2 pthread_selfH3 名称pthread_self - 获取调用线程ID H3 概要#include &lt;pthread.h> pthread_t pthread_self（void）; H3 描述pthread_self()函数将返回调用的线程ID H2 pthread_setconcurrencyH2 pthread_setschedparamH2 pthread_setschedprioH2 pthread_sigmaskH3 名称 pthread_sigmask, sigprocmask - 检查和改变阻塞信号 H3 概要#include &lt;signal.h> int pthread_sigmask(int how, const sigset_t *restrict set, sigset_t *restrict oset); int sigprocmask(int how, const sigset_t *restrict set, sigset_t *restrict oset); H3 描述pthread_sigmask()函数将检查或更改（或两者）调用线程的信号掩码，而不管进程中的线程数量。该函数应与sigprocmask()等效，不受在单线程过程中调用的限制。 在单线程的过程中，sigprocmask()函数将检查或更改（或两者）调用线程的信号掩码。如果参数集不是空指针，则它指向一组用来改变当前阻塞集的信号。 参数如何指示集合被更改的方式，应用程序应确保它包含以下值之一： SIG_BLOCK得到的集合应该是当前集合和集合指向的信号集合的并集。 SIG_SETMASK结果集应该是set指向的信号集。 SIG_UNBLOCK得到的集合应该是当前集合和集合指向的信号集合的补集的交集。 如果参数oset不是空指针，则以前的掩码应存储在oset指向的位置。如果set为空指针，则参数的值不重要，并且过程的信号掩码不变;这样可以用来查询当前被阻塞的信号。 如果在调用sigprocmask()之后有未挂起的未阻塞信号，那么在调用sigprocmask()返回之前，至少应该有一个这样的信号被发送。 不可能阻止那些不可忽视的信号。这应该由系统执行而不会导致错误被指示。 如果SIGFPE，SIGILL，SIGSEGV或SIGBUS信号在被阻塞时产生，结果是未定义的，除非信号由kill()函数，sigqueue()函数或raise()函数产生。 如果sigprocmask()失败，线程的信号掩码将不会被改变。 在多线程进程中未指定使用sigprocmask()函数。 H2 pthread_spin_destroy &amp;&amp; pthread_spin_initH3 名称pthread_spin_destroy, pthread_spin_init - 销毁/初始化 一个自旋锁 H3 概要#include &lt;pthread.h> int pthread_spin_destroy(pthread_spinlock_t *lock); int pthread_spin_init(pthread_spinlock_t *lock, int pshared); H3 描述pthread_spin_destroy（）函数将销毁由锁引用的旋转锁，并释放该锁使用的所有资源。直到通过对pthread_spin_init（）的另一个调用重新初始化锁之后，才会定义后续使用锁的效果。如果在线程持有锁时调用pthread_spin_destroy（），或者使用未初始化的线程旋转锁调用此函数，则结果未定义。 pthread_spin_init（）函数将分配使用锁引用的自旋锁所需的所有资源，并将锁初始化为解锁状态。 如果支持线程进程 - 共享同步选项并且pshared的值是PTHREAD_PROCESS_SHARED，那么实现将允许任何线程访问自旋锁分配的内存，即使分配了自旋锁在由多个进程共享的内存中。 如果支持线程进程共享同步选项，并且pshared的值是PTHREAD_PROCESS_PRIVATE，或者如果该选项不受支持，则只能使用与初始化自旋锁的线程在同一进程内创建的线程来操作自旋锁。如果不同进程的线程尝试操作这种自旋锁，则行为是不确定的。 如果调用pthread_spin_init（）指定一个已经初始化的旋转锁定，结果是不确定的。如果在没有初始化的情况下使用自旋锁，则结果是不确定的。 如果pthread_spin_init（）函数失败，则锁定不会被初始化，锁定的内容也是未定义的。 只有被锁引用的对象可以用于执行同步。 在对pthread_spin_destroy（），pthread_spin_lock（），pthread_spin_trylock（）或pthread_spin_unlock（）的调用中引用该对象的副本的结果未定义。 H2 pthread_spin_lock &amp;&amp; pthread_spin_trylockH3 NAMEpthread_spin_lock, pthread_spin_trylock - 锁定一个自旋锁对象 H3 SYNOPSIS#include &lt;pthread.h> int pthread_spin_lock(pthread_spinlock_t *lock); int pthread_spin_trylock(pthread_spinlock_t *lock); H3 DESCRIPTIONpthread_spin_lock（）函数应该锁定由锁引用的自旋锁。 如果调用线程没有被另一个线程占用，调用线程将获得该锁。 否则，线程将旋转（也就是说，不应该从pthread_spin_lock（）调用中返回）直到锁定变为可用。 如果调用线程在调用时保持锁定，则结果是不确定的。 如果线程没有被锁定，pthread_spin_trylock（）函数应该锁定由lock引用的自旋锁。 否则，该功能将失败。 如果使用未初始化的旋转锁调用这些函数中的任何一个，则结果是不确定的。 H2 pthread_spin_unlockH2 pthread_testcancel &amp;&amp; pthread_setcancelstate &amp;&amp; pthread_setcanceltypeH3 名称pthread_setcancelstate, pthread_setcanceltype, pthread_testcancel - 设置取消状态 H3 概要 #include &lt;pthread.h> int pthread_setcancelstate(int state, int *oldstate); int pthread_setcanceltype(int type, int *oldtype); void pthread_testcancel(void); H3 描述pthread_setcancelstate()函数应原子地将调用线程的可取消状态设置为指示状态，并返回旧状态引用的位置的先前可取消性状态。 状态的合法值是PTHREAD_CANCEL_ENABLE和PTHREAD_CANCEL_DISABLE。 pthread_setcanceltype()函数应原子地将调用线程的可取消性类型设置为指示的类型，并返回旧类型引用的位置的先前可取消性类型。 类型的合法值是PTHREAD_CANCEL_DEFERRED和PTHREAD_CANCEL_ASYNCHRONOUS。 POSIX的取消类型有两种，一种是延迟取消(PTHREAD_CANCEL_DEFERRED)，这是系统默认的取消类型，即在线程到达取消点之前，不会出现真正的取消；另外一种是异步取消(PHREAD_CANCEL_ASYNCHRONOUS)，使用异步取消时，线程可以在任意时间取消。 任何新创建的线程（包括首次调用main()的线程）的可取消性状态和类型将分别为PTHREAD_CANCEL_ENABLE和PTHREAD_CANCEL_DEFERRED。 pthread_testcancel()函数将在调用线程中创建一个取消点。 如果取消可用性被禁用,pthread_testcancel()函数将不起作用。 Pthreads 学习2 - 文档.md","categories":[{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/categories/线程/"}],"tags":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/tags/IOS/"},{"name":"Pthreads","slug":"Pthreads","permalink":"http://blog.msiter.com/tags/Pthreads/"},{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/tags/线程/"}],"keywords":[{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/categories/线程/"}]},{"title":"Pthreads 学习1","slug":"Pthreads 学习1 - 一览","date":"2018-01-10T23:22:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Pthreads xx1 - yl-20180110.html","link":"","permalink":"http://blog.msiter.com/Pthreads xx1 - yl-20180110.html","excerpt":"为了学习IOS中的多线程，开始研究线程。但是感觉一开始就学习IOS的线程的话，很难理解，所以学习了Pthreads。 POSIX Threads Programming Author: Blaise Barney,Lawrence Livemore National Laboratory Abstract在共享内存多处理机架构中，线程可以用来实现并行。从历史来说，硬件供应商实现了他们各自的线程版本，使移植成为了软件开发人员关系的问题。在UNXI系统中，一个标准化C语言的线程API已经有了 IEEE POSIX 1003.1c ,坚持这个标准实现成为POSIX线程，或者 Pthreads.本教程首先介绍 Pthread的概念，动机和设计注意事项。然后介绍 Pthreads API中三个主要类的历程：线程管理，互斥变量和条件变量。示例代码是为了让新的使用Pthreads的程序员知道如何使用Pythreads。本教程最后讨论了 LLNL 细节以及如何将MPI与Pthreads混合学习这篇教程的先决条件：本教程非常适合那些刚接触Pthread的并行编程人员。在C中的并行编程基本理解是必需的。对于那些不太熟悉并行变成的人来说，EC3500：并行计算入门所设计的内容将很有帮助。","text":"为了学习IOS中的多线程，开始研究线程。但是感觉一开始就学习IOS的线程的话，很难理解，所以学习了Pthreads。 H1 POSIX Threads Programming Author: Blaise Barney,Lawrence Livemore National Laboratory H2 Abstract在共享内存多处理机架构中，线程可以用来实现并行。从历史来说，硬件供应商实现了他们各自的线程版本，使移植成为了软件开发人员关系的问题。在UNXI系统中，一个标准化C语言的线程API已经有了 IEEE POSIX 1003.1c ,坚持这个标准实现成为POSIX线程，或者 Pthreads.本教程首先介绍 Pthread的概念，动机和设计注意事项。然后介绍 Pthreads API中三个主要类的历程：线程管理，互斥变量和条件变量。示例代码是为了让新的使用Pthreads的程序员知道如何使用Pythreads。本教程最后讨论了 LLNL 细节以及如何将MPI与Pthreads混合学习这篇教程的先决条件：本教程非常适合那些刚接触Pthread的并行编程人员。在C中的并行编程基本理解是必需的。对于那些不太熟悉并行变成的人来说，EC3500：并行计算入门所设计的内容将很有帮助。 H2 Threads API 原来的Pthreads API是在 ANSI/IEEE POSIX 1003.1 - 1995 标准中定义。 POSIX标准不断发展并经过修订，包括Pthreads规范。 标准的副本可以从IEEE购买或从其他网站免费下载。 构成Pthreads API的子例程可以分为四个主要组： 线程管理 Thread management： 直接在线程上工作的例程-创建，分离，链接等。他们还包括设置/查询线程属性的功能（可连接，调度等） 互斥 Mutexes： 处理同步的例程成为“互斥”，他是“mutex”的缩写。互斥功能提供创建，销毁，锁定和解锁互斥。这些由互斥属性函数来补充，这些函数设置或修改与互斥量相关的属性。 条件变量 Condition variables： 解决共享互斥量的线程间通信的例程。基于程序员指定的条件。改组包括基于执行的变量值创建，销毁，等待和信号等功能。还包括查询/查询条件变量属性的函数 同步 Synchronization： 管理读/写和障碍的例程 命名约定：线程哭的所有表示符都以 Pthread_ 开头。一些例子如下所示。 H2 Thread ManagementH3 Creating and Terminating Threads/// 创建一个 pthread_t 对象 /// @param thread 要创建的thread的指针地址 例如： pthread_t thread; 传入 &amp;thread; /// @param attr 参数 thread_attr 包很多个参数 /// int detachstate; 线程的分离状态 /// int schedpolicy; 线程调度策略 /// structsched_param schedparam; 线程的调度参数 /// int inheritsched; 线程的继承性 /// int scope; 线程的作用域 /// size_t guardsize; 线程栈末尾的警戒缓冲区大小 /// int stackaddr_set; /// void* stackaddr; 线程栈的位置 /// size_t stacksize; 线程栈的大小 /// @param start_routine 线程创建后的方法 /// @param arg 传递的参数 需要为 (void *) = id /// /// @return int 类型 返回 0 是成功。 失败 返回错误号码。 pthread_create (thread,attr,start_routine,arg) /// 退出一个 thread，退出线程有如下个方法 /// 1. return normal 正常返回 /// 2. thread_exit 无论工作有没有完成 都会退出 /// 3. 该线程被另一个线程 通过 pthread_cancel 取消 /// 4. 整个过程 调用 exec() 或 exit() 而终止 /// 5. 如果 main() 首先完成，而不现实调用 thread_exit 本身 pthread_exit (status) /// 将子程序取消异步处理 /// @param thread 子例程的线程指针地址 /// /// int 类型 返回 0 是成功。 失败 返回错误号码。 pthread_cancel (thread) /// 初始化一个 pthread_attr 对象 /// @param attr pthread_attr 对象 /// /// int 类型 返回 0 是成功。 失败 返回错误号码。 pthread_attr_init (attr) /// 设置属性或获取属性方法 int pthread_attr_(get/set)detachstate // 获取/设置 线程的分离状态 int pthread_attr_(get/set)guardsize // 获取/设置 线程栈末尾的境界缓冲区大小 int pthread_attr_(get/set)inheritsched // 获取/设置 线程的继承性 int pthread_attr_(get/set)schedparam // 获取/设置 线程的调度参数 int pthread_attr_(get/set)schedpolicy // 获取/设置 线程的调度策略 int pthread_attr_(get/set)scope // 获取/设置 作用域 int pthread_attr_(get/set)stack // 获取/设置 线程栈 int pthread_attr_(get/set)stackaddr // 获取/设置 线程栈的位置 int pthread_attr_(get/set)stacksize // 获取/设置 线程栈的大小 /// 销毁线程属性对象 /// @param attr 属性对象 /// /// int 类型 返回 0 是成功。 失败 返回错误号码。 pthread_attr_destroy (attr) H3 Joining and Detaching Threads/// 等待线程终止 /// @param threadid 需要等待结束的线程 /// @param status 返回的结果 /// /// @return int 类型 返回 0 是成功。 失败 返回错误号码。 pthread_join (threadid,status) /// 与 pthread_join 相对应,你想让一个 thread 开始等待阻塞，那么当你后悔 就需要该函数 取消阻塞等待结果 /// 注意 如果想使用该方法 必须在创建 线程的时候 规定 线程是可以分离的.如下： /// /// pthread_attr_t attr; // 创建 attr /// pthread_attr_init(&amp;attr); // 初始化 attr /// pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_DETACHED); // 设置可分离 /// /// pthread_create(&amp;thread, &amp;attr, BusyWork, ((void *)t)); // 创建线程时候 传入 /// /// @param threadid 需要等待结束的线程 /// /// @return int 类型 返回 0 是成功。 失败 返回错误号码。 pthread_detach (threadid) /// 见上 pthread_attr_setdetachstate (attr,detachstate) pthread_attr_getdetachstate (attr,detachstate) H3 Stack Management在属性的时候，设置StackSize 以及 StackAddr 属性，在上面我们已经提到过。 pthread_attr_getstacksize (attr, stacksize) pthread_attr_setstacksize (attr, stacksize) pthread_attr_getstackaddr (attr, stackaddr) pthread_attr_setstackaddr (attr, stackaddr) H3 Miscellaneous/// 获取当前的 threadid 也就是地址位置 /// /// pthread_t tid = pthread_self(); /// printf(\"(0x%x)\\n\", (unsigned int)tid); pthread_self () /// 判断传入的 两个 thread 是否相等 == /// @param thread1,thread2 thread 对象 pthread_equal (thread1,thread2) /// 单例 /// pthread_once_t once = PTHREAD_ONCE_INIT; /// pthread_once(&amp;once , onceRun); /// /// @param once_control pthread_once_t 单例线程对象 /// @param init_routine 要执行的方法 /// /// @return int 类型 返回 0 是成功。 失败 返回错误号码。 pthread_once (once_control, init_routine) H2 Mutex Variables 互斥变量， 互斥变量是为了实现线程的同步和保护共享数据多次写入时的主要手段之一 一个互斥变量就像保护访问共享数据资源的“锁”。Pthreads中使用的互斥量的基本概念是，在任何给定时间只有一个线程可以锁定（或拥有）会变量。因此，即使有几个线程试图锁定一个互斥锁，也只有一个线程会成功。没有其他线程可以拥有该互斥体，知道拥有互斥体的线程解锁该互斥体。线程必须“轮流”访问受保护的数据。 互斥体可以用来放置“race” 问题。设计银行交易的竞争情况的一个例子如下所示： 我就一展示数据的表格 Thread 1 Thread 2 Banlance Read balance: $1000 $1000 Read balance: $1000 $1000 Deposit $200 $1000 Deposit $200 $1000 Update balance $1000+$200 $1200 Update balance $1000+$200 $1200 在上面的例子上，当一个线程正在使用共享数据资源时，应该使用互斥来锁定“Banlance”。 一个拥有互斥锁的线程执行的动作t通常是更新全局变量，这是一个安全的方法，确保当多个线程更新同一个变量时，最终只与只有一个线程更新时的值相同 使用互斥体的典型顺序如下 创建并初始化一个互斥变量 几个线程试图区锁定这个互斥变量 只有一个成功并且这个变量拥有这个互斥变量 这个拥有者线程执行一些设置操作 这个拥有着线程解锁这个互斥变量 其他的线程重复获取这个互斥变量 并且作出一样的操作 最后将这个互斥变量 解锁，分离。 当多个线程竞争这个互斥变量，失败者锁定这个竞争。。。理解就是 失败的人 应该是 “retry”，而不应该是 “lock”操作。 在保护共享数据时，程序员有责任确保每个需要适应到互斥变量的线程都使用互斥锁。例如，有4个线程正在更新相同的数据，但只有一个使用互斥体，则数据仍然可能被破坏。 H3 Creating and Destroying Mutexes 互斥变量必须声明为pthread_mutex_t类型，并且必须在调用之前初始化。这里有两个方法去初始化一个互斥变量： 静态方法，一下是声明它的例子： pthread_mutex_t mymutex = PTHREAD_MUTEX_INITIALIZER; 动态方法，常规的pthread_mutex_init方法，这个方法允许设置互斥对象的参数。初始化后的 互斥变量是 没有被锁定的。 这个 attr 对象用来建设互斥对象的特性，并且其必须为pthread_mutexattr_t(可以设置为NULL接受其设置为默认值)。Pthreads定义了三种互斥属性： 协议 Protocol: 指定用于防止互斥项优先级反转的协议。 优先级 Prioceiling: 指定互斥项的优先级上限。 进程共享 Process-shared: 指定互斥锁的进程共享。note: 并不是每个互斥对象都需要实现这三个属性。 pthread_mutexattr_init() 和 pthread_mutexattr_destroy() 用来创建和分离互斥属性对象 应该使用pthread_mutex_destroy()来释放不再需要的互斥对象。 /// 初始化 互斥变量 pthread_mutex_init (mutex,attr) /// 销毁 互斥变量 pthread_mutex_destroy (mutex) /// 互斥变量属性对象初始化 pthread_mutexattr_init (attr) /// 互斥变量属性对象释放 pthread_mutexattr_destroy (attr) H3 Locking and Unlocking Mutexes/// 该方法是常规的针对某个指定的互斥变量设置锁的方法 /// 如果该变量已经被其他线程锁定，它将会堵塞线程，知道这个互斥变量被解锁 pthread_mutex_lock (mutex) /// 将尝试去锁定一个互斥变量.然而，如果这个变量被其他线程锁定，这个方法会返回一个\"busy\"的错误代码。 /// 这个方法在防止死锁的情况非常有用。如在优先级反转的情况下。 pthread_mutex_trylock (mutex) /// 如果是拥有着互斥变量的线程对象调用的该方法，则会解锁该变量。 /// 在线程完成了对于受保护数据的操作后，调用这个方法是必须的。 /// 如果调用该方法出现了问题，那么可能是以下两种问题： /// 1. 这个互斥变量已经被解锁了 /// 2. 这个互斥变量不是调用方法的线程所持有的 pthread_mutex_unlock (mutex) 互斥并没有什么神奇的…事实上他们类似于线程之间的“君子协议”.这完全取决于代码的编写者针对于必要的线程都做出了正确的解锁加锁的操作。下面场景演示一个错误的示范： Thread 1 Thread 2 Thread 3 Lock Lock A = 2 A = A+1 A = A*B Unlock Unlock 问题： 当很多个线程都在等待这个已经被锁定的互斥变量解锁，那么当这个变量解锁之后，谁会第一个获得这个持有权呢？答案： 除非优先级别的调整，否则会将这个问题丢给系统调度器，这样就导致 这个结果或多或少的是随机的。 H4 Mutex Lock&amp;UnLock Example /// 创建一个 DODATA 类型 typedef struct { double *a; double *b; double sum; int veclen; }DODATA; /// 数组的个数 #define NUMTHRDS 4 #define VECLEN 100 /// 数据对象；线程数组；互斥对象； DODATA dotstr; pthread_t thread[NUMTHRDS]; pthread_mutex_t mutex; - (void)viewDidLoad { [super viewDidLoad]; double *a,*b; /* Assign storage and initialize values */ a = (double*) malloc (NUMTHRDS*VECLEN*sizeof(double)); b = (double*) malloc (NUMTHRDS*VECLEN*sizeof(double)); for (int i=0; i&lt;VECLEN*NUMTHRDS; i++) { a[i]=1.0; b[i]=a[i]; } dotstr.a = a; dotstr.b = b; dotstr.veclen = VECLEN; dotstr.sum = 0; /// 创建一个 线程属性对象 pthread_attr_t attr; pthread_attr_init(&amp;attr); pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE); /// 创建互斥变量 pthread_mutex_init(&amp;mutex, nil); /// 创建线程 for (long i = 0 ; i &lt; NUMTHRDS; i++) { pthread_create(&amp;thread[i], &amp;attr, MathSum, (void *)i); } /// join 阻塞 for (long i = 0 ; i &lt; NUMTHRDS; i++) { pthread_join(thread[i], nil); } /// 释放 pthread_attr_destroy(&amp;attr); pthread_mutex_destroy(&amp;mutex); free(a); free(b); pthread_exit(nil); } void *MathSum(void *arg){ int i, start, end, len ; long offset; double mysum, *x, *y; offset = (long)arg; len = dotstr.veclen; start = offset*len; end = start + len; x = dotstr.a; y = dotstr.b; mysum = 0; for (i=start; i&lt;end ; i++){ mysum += (x[i] * y[i]); } // pthread_mutex_lock(&amp;mutex); dotstr.sum += mysum; // pthread_mutex_unlock(&amp;mutex); NSLog(@\"第%ld次，MYSUM%f\",offset,dotstr.sum); pthread_exit((void *)0); return nil; } 。。。。很不明白，，，我注释和不注释 加锁 解锁，，，得到的结果除了顺序不一样之外，感觉没有发生数据错误。我本来以为的是，比如我在这里的写入的时候，其他地方也在写入。就会算出来。100200200300这样的问题呢，，，但是无论是否顺序一样，第四次执行得到的结果都是 400. H2 Condition Variables 条件变量是线程同步的另一种方式。虽然互斥通过控制线程对数据的访问来实现线程同步，而条件变量则允许通过数值的实际值来实现线程同步 在不使用条件变量的情况下，程序员需要不断轮询（可能在关键位置），去检查条件是否允许。这可能非常浪费资源，因为这个线程会这个活动中持续繁忙。条件变量是一种无序轮询即可实现相同目标的方法 一个条件变量总是和一个互斥变量一起使用 pthread_cond_init（condition，attr） pthread_cond_destroy（condition） pthread_condattr_init（attr） pthread_condattr_destroy（attr） 条件变量必须声明为pthread_cond_t类型，在使用之前必须初始化。有两种方法来初始化条件变量 静态，初始化的时候，例如 pthread_cond_t myconvar = PTHREAD_COND_INITIALIZER; 动态的使用pthread_cond_init()来创建。传入条件对象的id。该方法允许设置条件变量对象属性attr 可选的attr，用来设置条件变量属性。条件变量对象只有一个值，process-shared，他允许条件变量被其他进程中的线程看到。属性对象（如果使用的话）必须为pthread_condattr_t类型（可以指定NULL为默认值）。请注意不是所有的实现都需要提供进程共享属性 pthread_condarrt_init()和pthread_condattr_destory()用来创建和销毁条件变量属性的对象。 应该适应pthread_cond_destory()来释放不在需要的条件变量。 H3 Waiting and Signaling on Condition Variablespthread_cond_wait (condition,mutex) pthread_cond_signal (condition) pthread_cond_broadcast (condition) pthread_cond_wait()阻塞调用线程，知道制定条件为止。这个例程应该在互斥量被锁定的时候被调用，并且在他等待的时候会自动释放互斥量。接到信号并且线程唤醒后，互斥锁将被自动锁定以供线程使用。程序员然后负责在线程完成时解锁互斥体。建议：适应WHERE循环而不是IF语句（参阅下面的watch_count例程）来检查等待的条件可以帮助你处理几个潜在的问题。例如： 如果有几个县城正在等待相同的唤醒信号，他们将轮流获取互斥锁，并且其中任何一个线程都可以修改他们全部等待的条件。 如果线程由于程序错误而受到错误的信号 Pthreads 库允许在不违反标准的情况下，向虚拟线程发出虚假唤醒。 pthread_cond_signal()用于信号（或唤醒），其条件变量等待另一个线程。它应该在锁定互斥锁之后调用，并且解锁互斥锁才能完成 pthread_cond_wait() 调用 pthread_cond_broadcast()用来代替 pthread_cond_signal()如果多于一个线程处于阻塞等待状态。 调用 pthread_cond_wait() 之前调用 pthread_cond_signal() 是一个逻辑错误。 ！！！在使用这些方法中，正确锁定和解锁相关的互斥变量是至关重要的。例如 在调用pthread_cond_wait()之前没有锁定 互斥变量，可能导致不阻塞 在调用pthread_cond_signal()之后未能解锁互斥体 可能不允许匹配的 pthread_cond_wait()完成（它还是保持阻塞状态） H4 Waiting and Signaling on Condition Variables Example下面模拟两个线程，一个叫号，一个等待。 int number = 0; #define MYSELFNUMBER 13 #define WAITNUMBER 15 pthread_cond_t cond_t; pthread_mutex_t mutex_t; // 模拟叫号 void maisn(){ pthread_cond_init(&amp;cond_t, nil); pthread_mutex_init(&amp;mutex_t, nil); pthread_attr_t attr; pthread_attr_init(&amp;attr); pthread_attr_setdetachstate(&amp;attr, PTHREAD_CREATE_JOINABLE); pthread_t waitthread; pthread_t callthread; pthread_create(&amp;waitthread, &amp;attr, _wait, nil); pthread_create(&amp;callthread, &amp;attr, _call, nil); pthread_join(waitthread, nil); pthread_join(callthread, nil); pthread_attr_destroy(&amp;attr); pthread_mutex_destroy(&amp;mutex_t); pthread_cond_destroy(&amp;cond_t); pthread_exit(nil); } /// 等待 void *_wait(void * params){ pthread_mutex_lock(&amp;mutex_t); while (number &lt; MYSELFNUMBER) { pthread_cond_wait(&amp;cond_t, &amp;mutex_t); NSLog(@\"在的在的，这就来\"); } pthread_mutex_unlock(&amp;mutex_t); pthread_exit((void *)0); return nil; } /// 叫号 void *_call(void * params){ for (int i = 0 ; i &lt; WAITNUMBER; i++) { pthread_mutex_lock(&amp;mutex_t); number++; NSLog(@\"请第%d号，到柜台办理业务，过时不候～\",number); if (number == MYSELFNUMBER) { pthread_cond_signal(&amp;cond_t); } pthread_mutex_unlock(&amp;mutex_t); sleep(1); } NSLog(@\"今天的业务就到这里结束\"); pthread_exit((void *)0); return nil; } H1 代码理解解析 Pthreads 学习1 - 一览.md","categories":[{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/categories/线程/"}],"tags":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/tags/IOS/"},{"name":"Pthreads","slug":"Pthreads","permalink":"http://blog.msiter.com/tags/Pthreads/"},{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/tags/线程/"}],"keywords":[{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/categories/线程/"}]},{"title":"Pthreads 学习4 - 锁","slug":"Pthreads 学习4 - 锁","date":"2018-01-10T23:22:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Pthreads xx4 - s-20180110.html","link":"","permalink":"http://blog.msiter.com/Pthreads xx4 - s-20180110.html","excerpt":"我也已经学习了挺久了，那么接下来我会进行一些总结性的记录。 线程，就是进程中的一个动作，比如者活着是进程，那么吃饭就算是线程，当然跑步也算线程。线程有几个属性，CancelState 规定了，这个线程是否可以取消，比如跳楼，这个进程就不能返回。再比如说，坐公交车是可以随时不做的。但是这就牵涉到了怎么取消了CancelType，一种是 deffered延期的，啥意思呢？ 前面不是说了 坐公交车可以取消。那么这个 type的意思就是，你会在下一站下车，而不是想反回就返回的。另一种是 async 这种就比较暴躁了… 说要取消，立马取消！“老子才不管到没到站！给老子停车！！！！ 行！ 不听是吧！我跳！车！”specific，线程中的私有公共变量，在同一个线程中可以获取到的值，需要使用 pthread_key_t 来存储。大概的意思就是，比如跑步的时候 终点在哪儿，无论在跑步这个线程任何时间都是知道的，但是做饭这个线程就不需要知道这个 终点。schedparam，","text":"我也已经学习了挺久了，那么接下来我会进行一些总结性的记录。 线程，就是进程中的一个动作，比如者活着是进程，那么吃饭就算是线程，当然跑步也算线程。线程有几个属性，CancelState 规定了，这个线程是否可以取消，比如跳楼，这个进程就不能返回。再比如说，坐公交车是可以随时不做的。但是这就牵涉到了怎么取消了CancelType，一种是 deffered延期的，啥意思呢？ 前面不是说了 坐公交车可以取消。那么这个 type的意思就是，你会在下一站下车，而不是想反回就返回的。另一种是 async 这种就比较暴躁了… 说要取消，立马取消！“老子才不管到没到站！给老子停车！！！！ 行！ 不听是吧！我跳！车！”specific，线程中的私有公共变量，在同一个线程中可以获取到的值，需要使用 pthread_key_t 来存储。大概的意思就是，比如跑步的时候 终点在哪儿，无论在跑步这个线程任何时间都是知道的，但是做饭这个线程就不需要知道这个 终点。schedparam， H2 concurrency并发级别，查找到的资料说的，用户级线程可以映射的内核线程或进程的数目。 H2 schedparam设置线程的调度策略和优先级。 H3 调度策略线程的调度有三种策略：SCHED_OTHER、SCHED_RR和SCHED_FIFO。Policy用于指明使用哪种策略。下面我们简单的说明一下这三种调度策略。SCHED_OTHER它是默认的线程分时调度策略，所有的线程的优先级别都是0，线程的调度是通过分时来完成的。简单地说，如果系统使用这种调度策略，程序将无法设置线程的优先级。请注意，这种调度策略也是抢占式的，当高优先级的线程准备运行的时候，当前线程将被抢占并进入等待队列。这种调度策略仅仅决定线程在可运行线程队列中的具有相同优先级的线程的运行次序。 SCHED_FIFO它是一种实时的先进先出调用策略，且只能在超级用户下运行。这种调用策略仅仅被使用于优先级大于0的线程。它意味着，使用SCHED_FIFO的可运行线程将一直抢占使用SCHED_OTHER的运行线程J。此外SCHED_FIFO是一个非分时的简单调度策略，当一个线程变成可运行状态，它将被追加到对应优先级队列的尾部((POSIX 1003.1)。当所有高优先级的线程终止或者阻塞时，它将被运行。对于相同优先级别的线程，按照简单的先进先运行的规则运行。我们考虑一种很坏的情况，如果有若干相同优先级的线程等待执行，然而最早执行的线程无终止或者阻塞动作，那么其他线程是无法执行的，除非当前线程调用如pthread_yield之类的函数，所以在使用SCHED_FIFO的时候要小心处理相同级别线程的动作。 SCHED_RR鉴于SCHED_FIFO调度策略的一些缺点，SCHED_RR对SCHED_FIFO做出了一些增强功能。从实质上看，它还是SCHED_FIFO调用策略。它使用最大运行时间来限制当前进程的运行，当运行时间大于等于最大运行时间的时候，当前线程将被切换并放置于相同优先级队列的最后。这样做的好处是其他具有相同级别的线程能在“自私“线程下执行。 H3 优先级sched_priority当你得到调度参数时，这个成员反映了分配给线程或进程的优先级。它并不反映由于继承优先权而进行的任何临时调整。设置计划参数时，请将此成员设置为您要使用的优先级。调度策略的优先级必须在sched_get_priority_min（）和sched_get_priority_max（）返回的最小值和最大值之间。 sched_curpriority当你得到调度参数时，这个成员被设置为线程或进程当前正在运行的优先级。这是内核在进行调度决策时使用的值。当您设置计划参数时，该成员将被忽略。 其他成员用于零星调度。以下#define指令创建与这些成员相对应的POSIX名称，而不是直接访问成员。 sched_ss_low_priority正在执行的线程的后台或低优先级。sched_ss_max_repl补货计划的最大次数，通常是因为阻塞操作。在一个线程多次被阻塞之后，它会自动下降到低优先级，直到其执行预算被补充。sched_ss_repl_period在被阻止或超出最大补货数量后，应该用于计划补货执行预算的时间。这个时间被用作一个线程被准备就绪的时间的偏移量。sched_ss_init_budget应该用于线程执行预算的时间。由于线程以高优先级运行，其执行时间被划分为这个预算。一旦预算完全耗尽，线程将下降到低优先级，在可能的情况下，由于优先级安排，线程可以继续运行，直到执行预算得到补充。 H2 specific局部存储变量 H2 互斥锁H3 type如果互斥量类型为PTHREAD_MUTEX_NORMAL，则不提供死锁检测。 试图重新锁定互斥锁会导致死锁。 如果线程试图解锁未锁定的互斥锁或未锁定的互斥锁，则会导致未定义的行为。 如果互斥类型为PTHREAD_MUTEX_ERRORCHECK，则应提供错误检查。 如果线程试图重新锁定已锁定的互斥锁，则应返回错误。 如果线程试图解锁未锁定的互斥锁或解锁的互斥锁，则应返回错误。 如果互斥体类型是PTHREAD_MUTEX_RECURSIVE，那么互斥体应该保持锁计数的概念。 当线程第一次成功获取互斥锁时，锁定计数应设置为1。 每当一个线程重新锁定这个互斥锁，锁定计数应该加1。 每次线程解锁互斥锁时，锁定计数应减1。 当锁计数达到零时，互斥锁将变为可用于其他线程获取。 如果线程试图解锁未锁定的互斥锁或解锁的互斥锁，则应返回错误。 如果互斥体类型是PTHREAD_MUTEX_DEFAULT，则试图递归锁定互斥体将导致未定义的行为。 试图解锁互斥锁，如果它没有被调用线程锁定导致未定义的行为。 试图解锁互斥锁，如果它没有被锁定导致未定义的行为。 H3 pshared设置是否分享该互斥变量锁住的值。 进程共享属性被设置为PTHREAD_PROCESS_SHARED，以允许任何有权访问互斥量被分配的内存的线程操作互斥量，即使互斥量被分配到多进程共享的内存中。 如果进程共享属性是PTHREAD_PROCESS_PRIVATE，互斥量只能由与初始化互斥量的线程在同一进程内创建的线程操作; 如果不同进程的线程试图在这样的互斥体上进行操作，则行为是不确定的。 属性的默认值应该是PTHREAD_PROCESS_PRIVATE Pthreads 学习4 - 锁.md","categories":[{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/categories/线程/"}],"tags":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/tags/IOS/"},{"name":"Pthreads","slug":"Pthreads","permalink":"http://blog.msiter.com/tags/Pthreads/"},{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/tags/线程/"},{"name":"POSIX","slug":"POSIX","permalink":"http://blog.msiter.com/tags/POSIX/"}],"keywords":[{"name":"线程","slug":"线程","permalink":"http://blog.msiter.com/categories/线程/"}]},{"title":"Xcode 关键字不高亮显示","slug":"Xcode 关键字不高亮显示","date":"2018-01-09T14:23:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Xcode gjzb,fglxs-20180109.html","link":"","permalink":"http://blog.msiter.com/Xcode gjzb,fglxs-20180109.html","excerpt":"Xcode 在长时间运行之后，会出现一个问题，那就是 例如 return 不再高亮显示了。重启Xcode 重启机器 也不能解决和个问题。后来找了一些资料 解决了这个问题","text":"Xcode 在长时间运行之后，会出现一个问题，那就是 例如 return 不再高亮显示了。重启Xcode 重启机器 也不能解决和个问题。后来找了一些资料 解决了这个问题 由于 DerivedData 问题 关闭项目 进入 DerivedData目录 Xcode 设置进入 Command+, 打开 Xcode 设置 选择 Localtions 点击 Derived Data 的的箭头进入 DerivedData 目录 直接进入进入 /Users/jingwenzheng/Library/Developer/Xcode/DerivedData 目录 删除这里面所有的文件 重启Xcode 由于 pch 文件的问题 把.pch里的内容全部注释掉 clean掉项目里的内容 把.pch里的注释去掉，编译。 代码高亮，语法提示功能都回来了。 由于 Organizer 的问题 关闭项目 选择Window-&gt;Organizer-&gt;Projects 选择失效的那一个工程，右健，Remove from Organizer 打开工程，失效的功能都回来了 参考资料： xcode 代码不高亮 不提示语法错误 解决方法 Xcode 关键字不高亮显示.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/tags/IOS/"},{"name":"稀奇古怪的问题","slug":"稀奇古怪的问题","permalink":"http://blog.msiter.com/tags/稀奇古怪的问题/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"Xcode8 无响应 点击Stop 卡死问题","slug":"Xcode 8 点击Stop 没有反应,卡死问题","date":"2018-01-09T14:18:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Xcode 8 djStop myfy,q,kswt-20180109.html","link":"","permalink":"http://blog.msiter.com/Xcode 8 djStop myfy,q,kswt-20180109.html","excerpt":"最近在学习 Pthreads,写了一些代码，每次运行结束后，都会出现无法Stop，每次都需要强制关闭 Xcode的问题。一开始没觉得什么，就是强制关闭，后来烦了，，，好吧 ，最后终于找到了一些资料解决了这个问题。 在这里记录一下。","text":"最近在学习 Pthreads,写了一些代码，每次运行结束后，都会出现无法Stop，每次都需要强制关闭 Xcode的问题。一开始没觉得什么，就是强制关闭，后来烦了，，，好吧 ，最后终于找到了一些资料解决了这个问题。 在这里记录一下。 进入 /User/{username}/Library/Autosave Information 这个文件夹下 删除里面 开头 Unsaved Xcode 的文件. 重启 就搞定了 不知道是不是最近使用 跳一跳外拐的问题，，我发现我的这个文件夹下面有两个 跳一跳的分析距离的图片？不知道是不是这个原因，导致的，毕竟以前没怎么遇到的。 参考资料： Xcode8无响应/假死状态/点击stop无反应？ Xcode 8 点击Stop 没有反应,卡死问题.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/tags/IOS/"},{"name":"稀奇古怪的问题","slug":"稀奇古怪的问题","permalink":"http://blog.msiter.com/tags/稀奇古怪的问题/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"大话数据结构 - 树 （6）","slug":"大话数据结构-树","date":"2018-01-05T10:19:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"d,thsjjg-s-20180105.html","link":"","permalink":"http://blog.msiter.com/d,thsjjg-s-20180105.html","excerpt":"树的定义之前我么你只在谈的是一对一的线性结构，可现实中，还有很多一对多的情况徐耀处理，所以我们需要研究这种一对多的数据结构—–“树”，考虑他的各种特性，来解决我们在编程中遇到的相关问题。 树(Tree)是n（n&gt;=0）个结点的有限集。n=0时称为空树。在任意一颗非空树中：(1)有且仅有一个特定的称为根(Root)的结点；(2)当n&gt;1时，其余结点可分为m(m&gt;0)个互不相交的有限集T1,T2,….Tm，其中每个节点本身又是一棵树，并且成为根的子树(SubTree)","text":"H2 树的定义之前我么你只在谈的是一对一的线性结构，可现实中，还有很多一对多的情况徐耀处理，所以我们需要研究这种一对多的数据结构—–“树”，考虑他的各种特性，来解决我们在编程中遇到的相关问题。 树(Tree)是n（n&gt;=0）个结点的有限集。n=0时称为空树。在任意一颗非空树中：(1)有且仅有一个特定的称为根(Root)的结点；(2)当n&gt;1时，其余结点可分为m(m&gt;0)个互不相交的有限集T1,T2,….Tm，其中每个节点本身又是一棵树，并且成为根的子树(SubTree) 树示意图树的定义其实就是我们在讲解栈时提到的递归的方法。也就是在树的定义之中还用到了树的概念，这是一种比较新的定义方法。图6-2-2的子树T1和子树T2就是根结点A的子树。当然，D，G，H，I组成的树又是B为结点的子树，E，J组成的树是C为结点的子树。 子树示意图对于树的定义还需要强调两点： n&gt;0 时根结点时唯一的，不可能存在多个跟结点，别和现实中的大树混在一起，现实中的树有很多的根须，那是真实的树，数据结构中的树只能有一个根结点 m&gt;0 时，子树的个数没有限制，但他们一定是互不相欠的。像图6-2-3中的两个结构就不符合树的定义，因为他们都有相交的子树。 错误的树结构 H3 结点分类树的结点包含一个数据元素及若干指向其子树的分之。结点拥有的子树数称为结点的度（Degree）。度为0的结点称为叶结点（Leaf）或终端结点；度不为0 的结点称为非终端结点或分之结点。除跟结点之外，分支结点也称为内部结点。树的度是树的个结点的度的最大值。 如图6-2-4所示，因为这棵树结点的度最大值D的度为3，所以树的度也为3。 结点分类树度示意图 H3 结点间关系结点的子树的根称为该结点的孩子（Child），相应地，该结点称为孩子的双亲（Parent）。 嗯，为什么不是父或母，叫双亲呢？呵呵，对于结点来说，其父母同题，唯一的一个，所以只能称他为双亲了。同一个双亲的孩子之间称为（Slibling）。结点的祖先是从到该结点所经分枝上的所有结点。 所以对于H来说，D，B，A都是它的祖先。反之，以某结点为根的子树中的热一结点都称为该结点的子孙。 结点关系示意图 H3 树的其他相关概念结点的层次（Level）从根开始定义起，根为第一层，根的孩子为第二层。 所某结点在第l层，则其子树的根就在l+1层。其双亲在同一层的结点互为堂兄弟。 显然图6-2-6中的D，E，F是堂兄弟，而G，H，I，J也是。树中结点最大层次成为树的深度（Depth）或高度， 当前树的深度为4。 树的深度高度示意图如果将树中结点的各子树看成从左至右是有次序的，不能互换的，称为该树为有序树，否则称为无序树。森林（Forest）是m（m&gt;=0）棵互不相交的树的集合。对树中每个节点而言，其子树的集合即为森林。对于图6-2-1中的树而言，图6-2-2中的两颗子树其实就可以理解为森林。对比线性表与树的结构，他们有很大的不同。| 线性结构 | 树结构 || ————- |:————-:|| 第一个元素：无前驱 | 根结点：无双亲，唯一 || 最后一个元素：无后继 | 叶结点：无孩子，可以多个 || 中间元素：一个前驱一个后继 | 中间结构：一个双亲多个孩子 | H2 树的存储结构说到存储结构，就会想到我们前面章节讲过的顺序存储和链式存储两种结构。先来看看顺序存储结构，用一段地址连续的存储依次存储线性表的数据元素。这对于线性表来说自然是正常的，对于树这种一对多的结构呢？树中某个节点的孩子可以是多个的，这就意味着，无论按照和中环许将书中所有节点存出道数组中，结点的存储位置都无法直接反映逻辑关系，你想想看，数据元素挨个的存储，谁是谁的双亲，谁是谁的孩子呢？简单的顺序存储结构是不能满足树的实现要求的。不过充分利用顺序存储和链式存储结构的特点，完全可以实现对树的存储结构的表示。我们这里就要介绍三种不同的表示法：双亲表示法，孩子表示法，孩子兄弟表示法 H3 双亲表示法我们人可能因为种种原因，没有孩子，但无论是谁都不可能是从石头里蹦出来的，孙武哦那个显然不能算是人，所以人是一定要有父母的。树这种结构也不例外，除了跟结点外，其余每个结点，他不一定有孩子，但是一定有且仅有一个双亲。我们假设以一组连续空间存储树的结点，同时 在每个结点中，附设一个指示器指示器双亲结点到链表中的位置。 也就是说，每个结点除了知道自己是谁以外，还知道他的双亲在哪里。他的结点结构为表6-4-1所示。 双亲表示法第一示意图其中datas是数据域，存储结点的数据信息。而parent是指针域，存储该结点的双亲在数组中的下标。有了这样的结构定义，我们就可以来实现双亲表示法了。由于跟结点是没有双亲的，所以我们约定跟结点的位置域s设置为-1，这也就意味着，我们所有的结点都存有它双亲的位置。 双亲表示法示意图这样的存储结构，我们可以根据结点的parent指针很容易的找到他的双亲结点，所有的时间复杂度为O(1)，直到parent为-1时，表示找到了数结点的根。可如果我们要知道结点的孩子是什么，对不起，请遍历整个结构才行。这真是麻烦，能不能改进一下呢？当然可以。我们增加一个结点最左边孩子的域，不妨叫他长子域，这样就可以很容易得到结点的孩子。如果没有孩子的结点，这个长子域就设置为-1. 长子域示意图对于有0个或一个孩子结点来说，这样的结构是解决了要找结点孩子的问题了。甚至是有两个孩子，直到长子是谁，另一个当然就是次子了。另一个问题场景，我们很关注个兄弟之间的关系，双亲表示法无法体现这样的关系，那我们怎么办？嗯，可以增加一个右兄弟域来体现兄弟关系，也就是说，每个节点如果他存在右兄弟，则记录下右兄弟的下标。同样的，如果右兄弟不存在，则复制为-1. 右兄弟示意图但如果结点的孩子很多，超过了2个。我们有关注结点的双亲，有关注结点的孩子，还关注结点的兄弟，而且对时间遍历要求还比较高，那么我们还可以把此结构扩展为有双亲域，长子域，再有右兄弟域。存储结构的设计是一个非常灵活的过程。一个存储结构设计的是否合理，取决于基于该春初结构的运算是否适合，方便，时间复杂度好不好等。 注意也不是越多越好，有需要时在设计相应的结构。 H3 孩子表示法换一种完全不同的考虑方法。由于树中每个节点可能有多颗子树，可以考虑用多重链表，即 每个节点都有多个指针域，其中每个指针指向一个子树的跟结点，我们就把这种放啊，叫做多重链表表示法。 不过，树的每个节点的树，也就是他的孩子格式视图不同的，所以可以设计两种方案来解决。方案一一种时指针域的个数就等于输的度，复习一下，树的度时各个节点度的最大值。结构如下 指针域树的结构其中data是数据域，child到childd是指针域，用来只想该结点的孩子结点。对于图6-4-1来说，树的度是3，所以我们的指针域的个数是3，这种方法实现如下所示。 链表指针域这种方法对于树中各结点的度差异很大时，显然是浪费空间的，因为有很多的结点，他的指针域时空的。不过如果书的各结点度相差很小时，那就意味着开辟的空间被充分利用了，这是存储结构的缺点反而变成了优点。既然很多指针域都可能为空，为什么不按需分配空间呢。于是我们有了第二种方案。方案二第二种方案每个节点指针域的个数等于该结点的度，我们专门去一个位置来存储结点指针域的个数 指针域个数等结点的度其中data为数据域，degree为度域，也就是存储该结点的孩子结点的个数，child1到childd为指针域，只想该结点各个孩子的结点。 指针域等于度示意图这种方法克服了浪费空间的缺点，对空间利用率很高了，但是由于每个节点的链表是不相同的结构，加上要维护结点的度的数值，在运算上就会带来时间上的损耗。能否有更好的方法，既可以减少控制真的浪诶又能使结点结构相同。仔细观察，我们为了要遍历政客书，把每个节点放在一个舒徐存储结构的数组是合理的，但每个结点的孩子的有多少是不确定的，所以我们在对每个节点的孩子建立一个单链表体现他们的关系。这就是我们要将的孩子表示法。具体实现办法是，把每个节点的孩子结点排序起来，以单链表做存储结构，则n个结点有n个孩子链表，如果是叶子结点则此单链表为空。然后n个头指针又组成一个线性表，采用顺序排序规则，存放斤一个一维数组中。 孩子表示法示意图为此，设计两种结点结构，一种是孩子链表的孩子结构。 孩子表示法孩子结构示意图其中child是数据域，用来存储某个节点在表头数组中的下标。next是指针域，用来存储只想某结点的下一个孩子结点的指针。另一个是表头数组的表头结构。 孩子表示法表头结构示意图其中data是数据域，存储某结点的数据信息，firstchild 是头指针域，存储钙及诶单孩子链表的头指针。这样的结构对于我们要茶渣某个节点的某个孩子，或者找某个节点的兄弟，只徐耀查找这个结点的孩子单链表即可。对于遍历政客书也是很方便的，对头结点的数组循环即可。但是，这也存在着问题，我如何知道某个节点的双亲是谁呢？比较麻烦，徐耀整合树遍历才行，难道就不可以把双亲表示法和孩子表示法综合一下吗？当然是可以的 双亲表示法孩子表示法结合示意图我们把这种方法称为双亲孩子表示法，应该算是孩子表示法的改进。 H3 孩子兄弟表示法刚才分别从双亲的角度和从孩子的角度研究书的存储结构，如果我们从树结点的兄弟的角度又会如何呢？当然，对于树这样的层级结构来说，只研究结点的兄弟是不行的，我们观察后发现。任意一棵树，他的结点的第一个孩子如果存在就是唯一的，它的右兄弟如果存在也是唯一的。因此，我们设置两个指针，分别指向该结点的第一个孩子和此结点的右兄弟。 存储示意图其中data是数据域，firstchild为指针域，存储该结点的第一个孩子结点的存储地址，rightsib是指针域，存储该结点的右兄弟结点的存储地址。 孩子兄弟表示法示意图这种表示法，给查找某个节点的某个孩子带来了方便，只需要通过firstchild找到该结点的长子，然后再通过的长子结点的rightsib找到他的二弟，接着一直下去，直到找到具体的孩子。当然，如果想要找到某个结点的双亲，这个表示法也是有缺陷的。怎么办呢啊你？嗯，如果真的有必要，完全可以再增加一个parent指针域来解决快速查找双亲的问题。其实这个表示法的最大好处是它把一个复杂的树变成了一个二叉树 孩子兄弟表示法二叉树 H2 二叉树的定义对于在某个阶段都是两种结果的情形，比如开和关，0和1，真和假，上和下等，都适合用树状结构来建模，而这种书是一种很特殊的树状结构，叫做二叉树。 二叉树（Binary Tree）是n(n&gt;=0)个基点的有限集合，该集合或者为空集（称为空二叉树），或者有一个根结点和两个互不相交的，分别称为跟结点的左子树和右子树的二叉树组成。 图6-5-2就是一颗二叉树，而图6-2-1的树，因为D结点有三个子树，所以他不是二叉树。 二叉树示意图 H3 二叉树的特点二叉树的特点有： 每个节点最多有两颗子树，所以二叉树中不存在度大于2的结点。注意不是只有两个子树，而是最多有。没有子树或者有一颗子树都是可以的。 左子树和右子树是有顺序的，次序不能任意颠倒。就像人是双手，双脚，但是左手和右手 左脚和右脚是不一样的 。 即使树中的某个及诶单只有一个子树，也要区分他们是左子树还是右子树。 二叉树具有五种基本形态： 空二叉树 只有一个跟结点 根结点只有左子树 根结点只有右子树 根结点既有左子树又有右子树 应该说这五种状态还是比较好理解的。接下来我们来考虑下只有三个结点的二叉树会有几种形态呢？若只从形态上考虑，三个节点的树只有两种情况，那就是图6-5-4中的有两层的树1和有三层的后四种的任意一种，但是对于二叉树来说由于区分左右，所以就演变了五种形态 只有三个结点的五种形态 H3 特殊二叉树我们再来介绍一些特殊的二叉树。这些书可能暂时你不能理解他有什么用处，但先了解一下，以后会提到他们的实际用途。 斜树 顾名思义，斜树一定要斜的，但是往哪儿斜是有讲究的。所有的及诶单都只有左子树的二叉树叫做左斜树。所有结点都是只有右子树的二叉树叫右斜树。这两者统称为斜树。 图6-5-4中的树2就是左斜树。树5就是右斜树。斜树有很明显的特点，就是每一层都只有一个及诶单，结点的个数和二叉树的深度是相同的。 有人会想这还叫树呀，与我们的线性结构不是一样吗。对的其实线性结构就可以理解为树的一种及其特殊的表现形式 满二叉树 苏东坡曾有诗云：“人有悲欢离合，月有阴晴圆缺，此事古难全”。意思就是说完美是理想，不完美才是人生。我们通过通常的例子也都是左高右低，参差不齐的二叉树，那是否存在完美的二叉树呢？ 在一棵二叉树中，如果所有分之结点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树被称为满二叉树 满二叉树 但是每个节点都存在左右子树，不能算是满二叉树，还比徐耀所有的叶子都在同一层，这就能做到整颗树的平衡。因此，满二叉树的特点有： 叶子只能出现在最下一层，出现在其他层就不可能达到平衡了。 非叶子结点的度一定是2，否则就是缺胳膊少腿了 在同样深度的二叉树中，满二叉树的结点个数最多，叶子树最多 完全二叉树 对一棵树具有n个结点的二叉树按层序编号，如果编号为i（1&lt;=i&lt;=n）的结点于同样深度的满二叉树的编号为i的结点的在二叉树中位置完全相同，则这颗二叉树被称为完全二叉树。 完全二叉树 这是一种有些理解难度的特殊二叉树。 首先要从字面上区分，“完全”和“满”的差异，满二叉树一定是一颗完全二叉树，但完全二叉树不一定是满的 其次，完全二叉树的所有节点与同样深度的满二叉树，他们按层序编号相同的结点，是一一对应的。这里有个关键词是按层序编号，像图6-5-7中的树1，因为5结点没有左子树，却又右子树，那就使得按层序编号的第10个编号空荡了 分析完全二叉树特点 从这里我也可以得出一些完全二叉树的特点： 叶子结点只能出现在最下两层 最下层的叶子一定集中在左部连续位置 倒数二层，如有叶子结点，一定都在右部连续位置 如果结点度为1，则该结点只有左孩子，既不存在只有右子树的情况。 同样结点的二叉树，完全二叉树的结点最小从上面的例子，也给了我们一个判断某二叉树是否是完全二叉树的办法，那就是看着书的示意图，心中默默给每个节点按照满二叉树的结构储层编号，如果编号出现空档，就书评不是完全二叉树，否则就是。 H2 二叉树的性质二叉树有一些徐耀并记住的特性，以便于我们更好的使用它。 H3 二叉树性质1性质1: 在二叉树的第i层至少有2i-1个结点(i&gt;=1)。这个性质很好记忆，观察一下图6-5-5。第一层是跟结点，只有一个，所以2^{1-1}即2^{0}=1。第二层有两个…通过数据归纳法的论证，可以很容易地得出在二叉树第i层上至少有2^{i-1}个结点(i&gt;=1)的结论。 H3 二叉树性质2性质2: 深度为k的二叉树至少有2^{k}-1个结点(k&gt;=1)注意这里一定要看清楚，是2^{k}后在减去1，而不是2^{k-1}。以前很多同学不能完全戒，这样去记忆，就容易把性质1和2弄混淆了。深度为k的意思就是k有两层树。我们先来看简单的如果有一层，至多1=2^{0}-1个结点如果有两层，至多1+2=3=2^{2}-1各结点….通过数据归纳法的论证，可以得出，如果有k层，此二叉树之多有2^{k}-1个结点。 H3 二叉树性质3性质3:对任何一颗二叉树T，如果其终端结点树为n{0},度为2的结点n{2},则n{0}=n{2}+1。终端结点其实就是叶子结点树，而一颗二叉树，除了叶子结点树，剩下的就是度1或2的几点输了，我们设n{1}为度是1的结点树。则树T的结点总数n=n{0}+n{1}+n{2}。比如图6-6-1的例子，结点总数为10，他是由A，B，C，D等度为2结点，F，G，H，I等度为0的叶子结点和E这个度为1的及诶单组成。综合为4+1+5=10. 二叉树性质3我们换个角度，再数一数他的链接线数，由于跟结点只有分支出去，没有分支进来，所以分之嫌总数为结点总数减去1.图6-6-1就是9个分支。对于ABCD结点来说，他们都有两个分支线出去，而E结点只有一个分支线出去。所以总分支线为4x2+1x1=9.用袋鼠表达就是分支线总数=n-1=n{1}+2n{2}结论就是n{0}=n_{2}+1. H3 二叉树性质4性质4:具有n个结点的完全二叉树的深度为[Log_{2n}]+1([x]表示不大于x的最大整数)。由二叉树的定义我们可以知道，深度为k的满二叉树的结点n一定是Sk-1.因为这个是最多的结点个数。那么对于n=2k-1倒退得到满二叉树的度数为k=log2（n+1），比如说结点为15的满二叉树，度为4.完全二叉树我们已经提到，它是一颗觉有n个结点的二叉树，若按层序编号，与其同样深度的满二叉树编号几点在二叉树位置完全相同，那他就是完全二叉树。也就是说，它的叶子结点只会出现爱着妳最下面的两层。它的结点树一定少雨等于同样读书的满二叉树的结点树2k-1但一定不会多余2k-1-1， H3 二叉树性质5性质5:如果对一颗由n个结点的完全而二叉树（其深度为[log2n]+1）的结点按层序变化 …. 性质这里蒙蔽了。。有时间再说 H2 二叉树的存储结构H3 二叉树的顺序存储结构前面我们已经谈到了树的存储结构，并且谈到顺序存储结构对树这种一对多的关系结构实现起来是比较困难的。但是二叉树是一种特殊的树，由于它的特殊性，使得用顺序存储结构也可以实现。二叉树的顺序存储结构就是用一位数组存储二叉树中的结点，并且结点的存储位置，也就是鼠标的下标要能体现节点之间的逻辑关系，比如双亲与孩子的关系，左右兄弟的关系等。先来看看完全二叉树的顺序存储，一颗完全二叉树如6-7-1所示。 完全二叉树顺序存储示意图将这颗二叉树村入数组中，相应的下标对应起同样的位置。 完全二叉树顺序存储结构这些看出俄安全二叉树的优越性来了吗。由于它定义的严格，所以用顺序结构也可以表现出二叉树的结构来，当然对于一般的二叉树，筋骨按层序编号不能反映逻辑关系，但是可以按前完全二叉树编号只不过，把不存在的结点设置为“^”而已。如图6-7-3.注意浅色结点表示不存在 非完全二叉树顺序存储考虑一种极端的情况，一颗深度为k的右斜树，他只有k各结点，却要分配2k-1个存储但愿空间，这显然是对存储空间的浪费。所以顺序存储结构一般只用于完全二叉树。 特殊情况对于存储空间的浪费 H3 二叉链表既然顺序存储适用性不强，我们就要考虑链式存储结构。二叉树每个节点最多有两个孩子，所以为她设计一个数据域和两个指针域是比较自然的想法，我们成这样的链表叫做二叉链表。 二叉链表结构示意图其中data是数据域，ichild和richild都是指针域，分别存放左孩子和右孩子的指针。 二叉链示意图就如同树的存储结构中讨论的一样，如果有徐耀，还可以再增加一个只想起双亲的指针域，那样我们称之为s三叉链表，由于与树的存储结构类似，这里就不详述了。 H2 遍历二叉树H3 二叉树遍历原理假设，我手头头20长100元和2000张1元的奖券，同时撒向了空中，大家比赛开谁最终见得最多。如果是你你会怎么办？相信所有的同学都会说鲜见100原单额。 二叉树的遍历(Traversing binary tree)是指从很结点出发，按照某种需一次访问二叉树中所有节点，使得每个节点被访问一次且仅访问一次。 这里有两个关键词，访问和次序。访问其实要跟根据实际的需要来确定具体做什么，比如每个结点哦度进行相关计算，输出打印等，它算作是一个抽象操作。在这里我们可以简单的嘉定就是输出结点的数据信息。二叉树的遍历次序不同于线性结构，最多也就是从头至尾，循环，双向等见扽遍历方式。树的结点之间不存在唯一的前驱和后继的关系，在访问一个节点后，下一个被访问的结点面临着不同的选择。就像你人生的道路上。由于选择方式的不同，遍历的次序就完全不同了。 H3 二叉树遍历方法二叉树遍历方式恶意很多，如果我们限制了从左到右的习惯方式，那么主要就分为四种。 前序遍历 规则是若二叉树为空，则空操作返回，否则先访问跟结点，在遍历左子树，在前序遍历右子树。遍历的舒徐是ABDHCEIF。 前序遍历示意图 中序遍历 规则是若树为空，则空操作返回，否则从跟结点开始（注意并不是先访问跟结点），中序遍历跟结点的左子树，然后是访问跟结点，最后中序遍历右子树。所以遍历的顺序是 GDHBAEICF。 中序遍历示意图 后序遍历 规则是若树为空，则空操作返回，否则就从左到右先叶子后结点的方式遍历访问左右子树，最后访问跟结点。遍历的顺序是GHDBIEFCA。 后序遍历示意图 层序遍历 规则是若树为空，则空操作返回，否则丛书的第一层，也就是跟结点开始访问，从上而下储层便利。从左到右顺序对结点出个访问。ABCDEFGHI。 层序遍历示意图 我们同图形的方式来表现书的结构，应该说是非常直观和容易理解，但是对于计算机来说，她只有循环，判断等方式来处理，也就是说，他只会处理线性序列，而我们刚才提到的四种变方法，其实就是把树中的结点变成某种意义的线性序列，这就给程序的实现带来了好处。另外不同的遍历提供了对结点一次护理的分不同方式，可以在遍历过程中对结点进行各种处理。 H2 排序算法在排序之前，先让我们建立一些数据 class TreeNode{ /// 存储的值 var value:String /// 左子树和右子树 var leftTreeNode:TreeNode? var rightTreeNode:TreeNode? private init(value:String) { self.value = value } private func setLeft(treeNode:TreeNode?) -> TreeNode { self.leftTreeNode = treeNode return self } private func setRight(treeNode:TreeNode?) -> TreeNode { self.rightTreeNode = treeNode return self } /// 初始化后的数据源 单例 static let rootTreeNode: TreeNode = { let AtreeNode = TreeNode(value: \"A\") let BtreeNode = TreeNode(value: \"B\") let CtreeNode = TreeNode(value: \"C\") let DtreeNode = TreeNode(value: \"D\") let EtreeNode = TreeNode(value: \"E\") let FtreeNode = TreeNode(value: \"F\") let GtreeNode = TreeNode(value: \"G\") let HtreeNode = TreeNode(value: \"H\") let ItreeNode = TreeNode(value: \"I\") AtreeNode.setLeft(treeNode: BtreeNode).setRight(treeNode: CtreeNode) BtreeNode.setLeft(treeNode: DtreeNode) CtreeNode.setLeft(treeNode: EtreeNode).setRight(treeNode: FtreeNode) DtreeNode.setLeft(treeNode: GtreeNode).setRight(treeNode: HtreeNode) EtreeNode.setRight(treeNode: ItreeNode) return AtreeNode }() } 我们通过上面的代码获取到的rootTreeNode 就是图 6-8-2 掩饰的数据结构了。接下来让我们一次实验这些不同的排序算法把 H3 前序遍历算法/// 前序遍历算法 extension TreeNode { func preOrderTraverse(){ print(self.value) self.leftTreeNode?.preOrderTraverse() self.rightTreeNode?.preOrderTraverse() } } print(\"-----preOrderTraverse-------\") TreeNode.rootTreeNode.preOrderTraverse() 打印结果 -----preOrderTraverse------- A B D H K E C F I G J 前序算法，其实就是先遍历所有的左子树，在遍历了左子树没有了之后，就前往上一层的遍历右子树，之后继续循环 H3 中序遍历方法/// 中序遍历算法 extension TreeNode { func inOrderTraverse(){ self.leftTreeNode?.inOrderTraverse() print(self.value) self.rightTreeNode?.inOrderTraverse() } } print(\"-----inOrderTraverse-------\") TreeNode.rootTreeNode.inOrderTraverse() 打印结果 -----inOrderTraverse------- H K D B E A F I C G J 中序就是顺序错开一点，循环遍历直到找到最左叶开始打印，之后遍历回来 H3 后序遍历方法/// 后序遍历算法 extension TreeNode { func postOrderTraverse(){ self.leftTreeNode?.postOrderTraverse() self.rightTreeNode?.postOrderTraverse() print(self.value) } } print(\"-----postOrderTraverse-------\") TreeNode.rootTreeNode.postOrderTraverse() 打印结果 -----postOrderTraverse------- K H D E B I F J G C A H3 层序遍历算法 /// 层序遍历算法 extension TreeNode{ func cengOrderTraverse(){ var treeNodes = [self] while treeNodes.count > 0 { guard let selfNode = treeNodes.last else { return } if let rn = selfNode.leftTreeNode { treeNodes.insert(rn, at: 0) } if let ln = selfNode.rightTreeNode { treeNodes.insert(ln, at: 0) } print(selfNode.value) treeNodes.removeLast() } } } print(\"-----cengOrderTraverse-------\") TreeNode.rootTreeNode.cengOrderTraverse() 打印结果 -----cengOrderTraverse------- A B。 C D E F G H I J K H2 二叉树的创建…… 暂时搁置 H2 线索二叉树H3 线索二叉树原理我们现在提倡节约型社会，一切都应该节约为本。对待我们的程序也不例外，能不浪费的时间或空间偶应该考虑节省，我们再来考虑6-10-1，会发现指针域并不是都充分的利用了，有许许多多的”^”，也就是空指针域的存在，这实在不是好现象，应该要想办法利用起来。 二叉树利用率低示意图首先我们要来看看这空指针有多少个呢？对于一个有n个绩点的二叉链表，每个节点有志向左右孩子的两个指针域，所以一共是2n个指针域，而n个结点的二叉树一共有n-1条分支线数，也就是说，其实是存在2n-（n-1）=n+1个空指针域。这些空间不怒出任何事物，白白地浪费着内存的资源。另一方面，我们左遍历时，遍历了之后，我们可以知道。可以这是建立过的基础之上的，在二叉链表上，我们只能知道每个节点只想起左右 大话数据结构-树.md","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/tags/数据结构/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://blog.msiter.com/tags/计算机基础/"}],"keywords":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}]},{"title":"大话数据结构 - 串 （5）","slug":"大话数据结构-串","date":"2018-01-03T10:07:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"d,thsjjg-c-20180103.html","link":"","permalink":"http://blog.msiter.com/d,thsjjg-c-20180103.html","excerpt":"串栈的定义早先的计算机在被发明是，只要作用是做一些科学和工程的计算工作，也就是现在我们理解的计算器，只不过它比小小计算器功能更强大，速度更快一些。后来发现，在计算机上做的非数值处理的工作越来越多，使得我们不得不需要引入对字符的处理。于是就有了字符串的概念。比如我们现在常用的搜索引擎，当我们在文本框中输入“数据”时，他已经把我们想要的“数据结构”列在下面了。显然网站这里做了一个字符串查找匹配的工作。","text":"H2 串H3 栈的定义早先的计算机在被发明是，只要作用是做一些科学和工程的计算工作，也就是现在我们理解的计算器，只不过它比小小计算器功能更强大，速度更快一些。后来发现，在计算机上做的非数值处理的工作越来越多，使得我们不得不需要引入对字符的处理。于是就有了字符串的概念。比如我们现在常用的搜索引擎，当我们在文本框中输入“数据”时，他已经把我们想要的“数据结构”列在下面了。显然网站这里做了一个字符串查找匹配的工作。今天我们就来研究“串”这样的数据结构。 串（String）是由零个或者多个字符组成的优先序列，又名叫字符串。 一般记为s=”a1a2…..an”(n&gt;=0),其中，s是串的名称，用双引号（有些书中也有单括号）扩起来的字符序列是串的值，注意单引号不属于串的内容。ai(1&lt;=i&lt;=n)也可以字母，数字或其他字符，i就是该在字符在传中的位置。串中的字符数目n称为串的长度， 定义中谈到“有限”是指长度n是一个有限的数值。零个字符的串称为空串（null string），他的长度为零，可以直接用两双引号““””表示，也可以用希腊文字“Φ”表示。所谓的序列，说明穿的相邻字符之间具有前驱后继的关系。还有一些概念徐耀解释。空格穿，只包含空格的串。注意他与空串的区别，空格串是有内容和长度的，而且可以不止一个空格。子串和主串，串中任意个数的连续字符组成的子序列成为该串的子串，相应的，包含子串的串称为主串。子串在主串的位置就是子串的第一个字符在主串中的序号。开头我提到的“over”，“end”,”lie”其实可以认为是“lover”，“friend”，“believe”这些单词字符串的子串。 H2 串的比较两个数字，很容易比较大小。2比1大，这完全正确，可是两个字符串如何比较？比如“silly”,“stupid”这样的同样表达“愚蠢”的字符串，他们在计算机的大小其实取决与他们挨个字母的前后顺序。它们的第一个字母都是“s”，我们认为不存在大小差异，而第二个字母，由于“i”字母比“t”字母要靠前，所以“i”&lt;”t”,于是我们说“silly”&lt;“stupid”。事实上，串的比较是通过组成串的子复之间的编码来进行的，而字符的编码指的是字符在对应字符集中的序号。计算机的额常用字符串使用标准的ASCII编码，更准确一点，有7为二进制表示一个字符，总共可以表示128个字符。后来由于一些特殊字符的出现，128个不够用，于是扩展ASCII编码由8为二进制表示一个字符，总共可以表示256个字符，这已经足够满足以英语为主的语言和特殊字符进行输入和输出等操作的字符需要了。可以，但我们国家就有除汉语外的满，回，藏，蒙古，维吾尔等多个少数民族文字，换做全世界估计要有成百上重语言和文字，显然这个256个字符是不够的，因此后来就有了 Unicode 编码，比较常用的是由 16位的二进制数表示一个字符，这样总共就可以表示216个字符，约是65万多个字符，足够表示世界上搜有的语言的所有字符了。当然，为了和ASCII码兼容，Unicode的前256个字符和ASCII码完全相同。所以如果我们要在C语言中比较两个串是否相等，必须是他们串的长度以及它们各个位置相等是。那么对于来两个串不相等是，如何判定它们的大小呢，我们这样定义：给定两个串：s=“a1,a2…an”,t=“b1,b2,…bm”,当满足以下条件之一时，s&lt;t n&lt;m,切ai=bi(i=1，2..n)。 例如当s=“hap”，t=“happy”，就有s&lt;t.因为t比s又多出了两个字符 存在某个k&lt;=min(m,n),使得ai=bi(i=1,2….,k-1),ak&lt;bk 例如当s=“happen”，t=“happy”，因为两串的前4个字母均相同，而两川的第五个字母（k值），字母e的ASCII是101，而字母y的ASCII码是121，显然e&lt;y，所以s&lt;t。 H2 串的抽象数据类型串的逻辑结构和线性表很相似，不同之处在于串针对的是字符集，也就是传中的元素都是字符，哪怕是传中的字符是“123”这样的数字组成，或者“2010-10-10”这样的日期组成的，他们只能理解为长度为3和长度为10 的字符串，每个元素都是字符而已。因此对于串的基本操作与线性表还是有很大差别的。线性表更关注的是但个元素的操作，比如查找一个元素，插入或删除一个元素，但串中更多的是出查找子串位置，得到指定位置的子串，替换子串的操作。 protocol String{ /// __, /// ( o /) _/_ /// `. , , , , // / /// (___)(_(_/_(_ //_ (__ /// /) /// (/ func StrAssign(chars:[Character]) -> String // 。。。。略 } H2 串的存储结构穿的存储结果与线性表相同，分为两种。 H3 串的顺序存储结构串的顺序春初结构是用一组地址连续的存储单元来存储串中的字符序列的。按照预定义的大小，为每个定义的串变量分配一个固定长度的存储区。一般是用给定长数组来定义。既然是定长数组，就存在一个与定义的最大字符串，一般可以讲世纪的串长度值保存在数组的0下标位置，由的书中也会定义存储在数组的最后一个小婊位置。但也有些编程语言不这么干，觉的存个数组占个空间嫌麻烦。它规定在串值后面加一个不计入串长度的结束标记字符，比如“\\0”来表示串值的中介，这个时候，你要想知道此时的串长度，就需要遍历计算一下才知道了，其实这还是需要占用一个空间，何必呢。刚才讲的串的顺序存储方式其实是有问题的，因为字符串的操作没比如两川的链接Concat，新串的插入StrInsert，以及字符串的替换Replace，都有可能是德川序列的长度超过了数组的长度MaxSize。 H3 串的链式存储结构对于串的链式存储结构，与线性表是相思的，但由于串结构的特殊性，结构中的每个元素数据是一个字符，如果也简单的应用链表春初船只，一个节点对应一个字符，就会存在很大的空间浪费。因此，一个节点可以存放一个字符，也可以考虑存放多个字符，最后一个节点若是未被占满时，可以用“#”或者其他非传旨字符不全。 串链式存储结构示意图当然，这里一个节点存多少字符才合适就变得很重要，这会直接影响着串处理的效率，需要根据实际情况做出选择。单穿的链式存储结构在链接串与串操作时有一定方便之外，总的来说不如顺序存储灵活，性能也不如顺序存储结构好。 H2 朴素的模式匹配算法记得我在刚做软件开发的时候，徐耀阅读一些英文的文章或帮助。此时才发现学习英语不只是为了过四六级，工作中他还是挺重要的。而我哪只为应付考试的英语，早已经忘记的差不多了。于是我想在短时间内突击一下，很明显，找一本词典从头开始被不是什么好的办法。要被也得被那些最常用的，最少是计算机文献中长哟过的，于是我就想自己写一个程序，只要输入一些英文的文档，就可以计算出这当中所用频率最高的词汇是哪些。那他们都备好了，基本上阅读就不成问题了。当然说说容易，要实现这一个需求，还是有不少困难的，有兴趣的同学，不妨去试试看。不过这里面最重要的就是找一个单词在一篇文章（相当于一个大字符串）中的定位问题。这种子串的定位操作通常称为串的模式匹配。应该是串中最重要的操作之一。假设我们要从下面的主串S=”goodgoodle”中，找到T=”google”这个子串的位置。我们通常需要下面的步骤。 extension String{ /// 朴素方式 查询字符串是否包含 另一个字符串 并且给出第一个 匹配的位置 /// /// - Parameters: /// - string: 另一个字符串 /// - pos: 偏移量 默认为 0 /// - Returns: 返回 元组 (是否存在,偏移量) func contain_N(str:String,pos:Int=0) -> (contain:Bool,index:Int){ // 偏移量 是否超过了 最后剩下位数还没有找到 那么就放弃查找 // 例如 \"abc\" \"ac\" 当偏移量 为 2 时 大于了 那么没有寻找下去的必要了 if pos > (self.count - str.count) { return (false,0) } // 挨个匹配 for (index,chat) in str.enumerated() { if let result = self.char(byIndex: pos+index) , result == chat{ continue } return self.contain_N(str: str, pos: pos+1) } // 完成匹配 返回 争取已经返回 pos 偏移量 return (true,pos) } /// 返回 字符串的 个数，方便查看 var count:Int{ return self.lengthOfBytes(using: String.Encoding.utf8) } /// 提取 String Index 中的 字符 func char(byIndex index:Int) -> Character? { if index >= self.count { return nil } return self[self.index(self.startIndex, offsetBy: index)] } } ///// 测试 let mainString = \"aixabc\" let subString = \"abc\" mainString.contain_N(str: subString) /// Log: (contain true, index 3) 简单说就是，就是对主串的每一个字符作为子串开头，与要匹配的字符串进行匹配。对主串做大循环，每个字符串开头做T的长度的小循环，知道匹配成功或者全部遍历完成。 这种方法的时间复杂度是O(mn) m和n分别为字符串的长度。 所以有没有办法可以更快的解决这个匹配呢？ H2 KMP模式匹配算法你可以忍受朴素模式的滴小阿妹？也许不可以，也许无所谓。但在很多年前我们的科学家，觉的像这种有多个0和1重复字符的字符串，却要挨个遍历的算法是非常糟糕的事情，于是就有三位前辈，D.E.Knuth、J.H.Morris和V.R.Pratt(其中Knuth和Pratt共同研究，Morris独立研究)发表 一个模式匹配算法，可以大大避免重复便利的情况，我们把它称为克努特-莫里斯-普拉特算法，简称KMP算法。 H3 KMP模式匹配算法原理为了能讲清楚KMP算法，我们不直接讲带啊吗，那样很容易造成理解困难，还是从这个算法的研究角度来理解为什么他比朴素算法要好。如果主串 S=”abcdefghab”，其实还可以更长一些，我们就省略掉只保留前9位，我们要匹配的T=”abcdex”，那么如果用前面的算法的话，前5个字母，两个字符串完成相同，知道第6个字木，f与x不等。 朴素算法示意图 算法以后会补上，目前没有看懂 大话数据结构-串.md","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/tags/数据结构/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://blog.msiter.com/tags/计算机基础/"}],"keywords":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}]},{"title":"大话数据结构 - 栈与队列 4","slug":"大话数据结构-栈与队列","date":"2018-01-02T13:12:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"d,thsjjg-zydl-20180102.html","link":"","permalink":"http://blog.msiter.com/d,thsjjg-zydl-20180102.html","excerpt":"栈与队列栈的定义 栈(Stack)是限定尽在表为进行插头和删除操作的线性表 我们把允许插入和删除的一段称为栈顶(top),另一端称为栈底(bottom),不含有任何元素的栈称为空栈。栈又称为后进先出(Last In First Out)的线性表，建成LIFO结构。理解栈的定义需要注意：首先它是一个线性表，也就是说，栈元素具有线性关系，继前驱后继关系。只不过它是一种特殊的线性表而已。定义中说是在线性表的表为进行插入和删除操作，这里表为是指栈顶，而不是栈底。栈的插入操作，叫做进栈，也称压栈，入栈。类似子弹入弹夹。栈的删除操作，也叫出栈，也有的叫做弹栈。如同弹夹中的子弹出夹。","text":"H2 栈与队列H3 栈的定义 栈(Stack)是限定尽在表为进行插头和删除操作的线性表 我们把允许插入和删除的一段称为栈顶(top),另一端称为栈底(bottom),不含有任何元素的栈称为空栈。栈又称为后进先出(Last In First Out)的线性表，建成LIFO结构。理解栈的定义需要注意：首先它是一个线性表，也就是说，栈元素具有线性关系，继前驱后继关系。只不过它是一种特殊的线性表而已。定义中说是在线性表的表为进行插入和删除操作，这里表为是指栈顶，而不是栈底。栈的插入操作，叫做进栈，也称压栈，入栈。类似子弹入弹夹。栈的删除操作，也叫出栈，也有的叫做弹栈。如同弹夹中的子弹出夹。 进栈与出栈示意图 H3 进栈出栈变化形式现在我要问问大家，这个要最先进栈的元素，是不是就只能最后出栈呢？答案是不一定的，要看什么元素。栈对线性表的掺入和删除的位置进行了限制，并没有对元素进出的时间进行限制，也就是说，在不是所有元素都见栈的情况下，事先进去的元素也可以出栈，只要保证栈顶元素出栈就可以了。举例来说，如果我们现在是有3个整型数字元素1，2，3依次进栈，会有哪些出栈次序呢？ 第一种： 1，2，3进，再3，2，1出。这是最简单的最好理解的一种，出栈次序为 321. 第二种： 1进，1出，2进，2出，3进，3出。也就是进一个就出一个，出栈次序为 123 第三种： 1进，2进，2出，1出，3进，3出。出栈次序为213. 第四种： 1进，1出，2进，3进，3出，2出。出栈次序132 第五种： 1进，2进，2出，3进，3出，1出。出栈次序为231.有没有可能是312这样的出栈舒徐呢？答案是肯定不会。因为3先出栈就意味着，3曾经进栈，既然3都进栈了，那就意味着，3曾经进栈，既然3都进栈了，那也就意味着，1和2都已经进栈了。从这个简单的例子就可以看出，只是三个元素，就有5中可能的出栈次序，如果元素量大，其实出栈的次序将会更多的，这个知识点一定要弄明白 H2 栈的抽象数据类型对于栈来讲，理论上线性表的操作他都具有，可由于她的特殊性，素以这对他对于操作会有些变化。特别是插入和删除操作，我们改名为push和pop，英文直译的话是压和弹，更容易理解。你就把它当成是弹夹的子弹压入和弹出就好了，我们一般叫进栈和出栈。 protocol Stack{ static func InitStack() -> Stack // 初始化操作，建立一个空栈 func DestroyStack() // 若栈存在，则销毁它。 func ClearStack() // 将栈清空 func StackEmpty() -> Bool // 若栈为空，返回true，否则返回false func GetTop() -> Any // 如果存在非空，返回栈顶元素 func Push(object:Any) // 若栈存在，插入新元素 func Pop() -> Any // 删除栈顶元素，并返回其值 func StackLength() -> Int // 获取栈的元素的个数 } H2 栈的顺序存储结构及实现H3 栈的顺序存储结构既然展示线性表的特例，那么栈的顺序存储其实也是线性表顺序存储的简称，我们称为 顺序栈。线性表是用数组来实现的，想想看，对于栈这种只能一头插入和删除的线性表来说，用数组那一段作为栈顶和栈底比较好？没错，下标为0的一段作为栈顶比较好，因为首元素都存在栈底，变化最小，所以让它做栈底。我们来定一个Top变量来只是栈顶元素在数组中的位置，这top就如同我们中学物理学习到的游标卡尺的游标，他来回移动，意味着栈顶的top可以变大变小，但无论如何游标不能超过尺的长度。同理，入展的长度为StackSize，则栈的top碧霄小雨StackSize。当栈存在一个元素时，top等于0，因此我们通常把空栈的判定条件定位top等于-1。若现在有一个栈，StackSize是5，则栈普通情况，空栈和沾满的是情况示意图： 普通空栈满栈示意图 H2 栈的链式存储结构及实现H3 栈的链式存储结构讲完了栈的顺序存储结构，我们来看看栈的链式存储结构，建成链栈。想想看，栈只是栈顶来做插入和删除操作，栈顶放在链表的头部还是尾部呢？由于单链表头头指针，而栈顶指针也是必须的，那么干嘛不让他俩合二为一呢，所以比较好的办法是吧栈顶放在单链表的头部。另外，都已经有了孩子安定在头部了，单链表中比较畅通的头结点也就失去了意义，通常对于链栈连锁，是不徐耀头结点。 链栈示意图对于链栈来说，基本不存在栈满的情况，除非内存已经没有可以使用的空间，如果真的发生，那次是的计算机系统，已经面临司机崩溃的情况，而不是这个链栈溢出的问题。但对于空栈来说，链表原定义是头指针指像空，那么链栈的空就是top=NULL的时候。 H2 顺序栈和链栈对比一下，顺序栈和链栈，他们在时间复杂度上是一样的，均为O(1)。对于空间性能，顺序栈需要实现确认一个固定的长度，可能会存在内存空间浪费的问题。但他的优势存取是时定位很方便，而链栈则要求每个元素都有指针与，这同时也正价了一些嫩村开销，但对于栈的长度无限制，所以他们的区别和线性表中的讨论一样，如果栈的使用过程中元素变化不可预料，有时很小，有时非常大，那么最好是用链栈，反之，如果他的变化在可控范围内，建议使用顺序栈会更好一些。 H2 栈的作用有的同学可能会觉的，用数组和链表不直接实现不就行了吗？干嘛要引入栈这种的额数据结构呢？其实这和我们明明有两只脚走路，干嘛还要成汽车或者飞机一样。理论上，陆地上的任何地方，你都是可以靠双脚走到的，可那徐耀多少时间和精力呢？我们更关注的是到达而不是如何去的过程。栈的引入简化程序设计的问题，话费了不同关注层次，使得思考范围缩小，更加聚焦于我们要结局的问题。反之想数组等，因为要分散经理去考虑数组下标增减的等下接问题，范围掩盖了问题的本质。所以现在很多高级语言，比入Java，C#等都有对栈结构的封装，你可以不用关注他的实现细节，就可以直接使用Stack的push和pop方法，非常方便。 H2 栈的应用-递归栈有一个很重要的应用：在程序设计语言中实现了递归。那么什么是递归呢？当你往镜子面前一站，镜子里面就有你的像，但你试过两面镜子一起照吗？如果A,B两面镜子相互面对面放着，你往中间一站，嘿，两面镜子都有你的“化身”。为什么会有这么奇妙的现象呢？这是一种递归现象 镜子递归现象示意图我们先来看一个经典的递归例子：斐波那契数列(Fibonacci)。为了说明这个数列，这位斐老还举了一个很形象的例子。 H3 斐波纳切数列实现说如果兔子在出生两个月后，就有繁殖能力，一对兔子每个月能生一对小兔子。假设所有兔子都不死，那么一年以后可以繁殖多少对兔子呢？我们那新出生的一对小兔子分析一下：第一个月小兔子每有繁殖能力，所以还是一对，第二个月，剩下一堆小兔子共有两对；三个月后老兔子又剩下一堆，因为小雨还每有繁殖能力，所以一共是3对…依次类推可以列出下表 兔子月份和兔子对数示意图表中数字1，1，2，3，5，8，13…构成了一些序列，这个数列有一个十分明显的特点，那是：前面相邻两项之和构成了后一项假设我们要打印出前40为斐波纳切烈数。先考虑下我们如何使用迭代的方式实现打印前40位斐波纳切列数。 var numbers:[Int] = [0,1] for i in 1...40{ numbers.append(numbers[i]+numbers[i-1]) } print(numbers) 代码很简单，几乎不用做什么解释。但其实我们的代码，如果用递归来实现，还可以更简单。 func Fbi(i:Int) -> Int{ if i &lt; 2 { return i == 0 ? 0 : 1 } return Fbi(i: i-1) + Fbi(i: i-2) } for i in 0...40 { print(i,\":\",Fbi(i: i)) } 怎么样，相比较迭代的代码，是不是赶紧很多。嘿嘿，过要弄懂他得费点脑子。函数怎么可能调用自己呢？听其实有些难以理解，不过你可以不要把递归函数中看作是在调用自己，而是把它当作在调另一个函数。只不过，这个函数和自己长的不一样而已。 ps: 不过这个迭代的执行，，次数也太夸张了？ 递归函数异常执行次数 我们来模拟代码中Fbi(i)函数i=5的执行函数过程。 模拟迭代示意图 H3 递归定义在高级语言中，调用自己和其他函数并没有本质的不同。我们把 一个直接调用自己或通过一系列的调用的语句简洁的调用自己的函数，成为递归函数。当然，写递归函数最怕的就是陷入永不结束的无穷递归中，所以，每个递归必定义必须至少有一个条件，满足时递归不再进行，即不再引用自身而返回值推出。 比如刚才的例子会使得i&lt;2的，这样就可以执行return爹语句而不用继续递归了。对比了两种实现斐波纳切的代码。递归和迭代的区别是：迭代使用的是循环结构，递归使用的是选择结构，递归能使程序的解雇更清晰，更简洁，更容易让人理解，从而减少读懂代码的时间。但是大量的递归调用会建立函数的副本，会消耗大量的时间和内存。迭代则不需要反复调用函数和占用额外的内存。因此我们应该是不同情况选择不同的实现方式。 H2 栈的应用–四则运算表达式求值H3 后缀(逆波兰)表示法定义栈的现实应用也很多，我们再来重点讲一个比较常用的应用：数学表达式的求值。我们小学学数学的时候，有一句话是老师反复强调的，“先乘除，后加减，从左算到右，先括号内后括号外”。这个大家都不陌生。那么如何使用代码的方式来实现数学表达式的求值呢？这里面的困难在于乘除在加减的后面，却要先运算，而加入括号后，就变的更加的复杂。不知道该如何处理。单仔细观察后发现，括号都是成对出现的，有左括号就定义会有右括号，对于多重括号，最终也是完全嵌套匹配的。这用栈结构正好合适，只要碰到左括号，就将此左括号进栈，不管多少表达式多少充括号，反正遇到左括号就进栈，而后面遇到的有括号，就让栈顶的左括号出栈，期间让数字运算，这样，最终又阔的表达式从左导游巡查一边，应该由空岛有元素，最终在印全部匹配成功后成为空栈的结果。但对于四则元算，括号也只是当中的一部分，先乘除后加减是的问题依然复杂，如何有效的处理它们嗯？20世纪50年代，波兰罗辑学家Jan Lukasiewicz，当时也和我们现在的同学们一样，困惑与如何才可以搞定这个四则运算，不知道他是否像牛顿被苹果砸到头而想到万有引力的原理，或者还是阿基米德在浴缸中洗澡想到判断皇冠是否纯碱的办法，总之他也是灵感凸显，想到了 一种不徐耀括号的后缀表达法，我们也把它称为逆波兰（Reverse Polish Nonation，RPN）表示。 我想可能他的名字太复杂了，所以后人只用它的国籍而不是姓名来命名，是在可惜。我们先来看看，对于”9+(3-1)×3+10÷2”，如果要启用护椎表示法应该是什么样子：”9 3 1 - 3 * + 10 2 / +”，叫后缀的有原因在于所有的符号都要在运算数字的后面出现。显然这里没有了括号。对于从来没有接触过后缀表达式的同学来讲，这样的表述很难受。 H3 后缀表达式计算结果为了解释后缀表达式的好处，我们先来看看，计算机如何应用后缀表达式计算出最终的结果20 的。后缀表达式：9 3 1 - 3 * + 10 2 / +规则：从左到右便利表达式的每个数字和符号，遇到数字就进栈，遇到是符号，就将栈顶的两个数字出栈，进行计算，运算结果进栈，长一智到最终获得结果 初始化一个空栈。此栈用来对要运算的数字进出使用 后缀表达式中的前三个都是数字，所以9，3，1进栈 逆波兰运算第二步 接下来是“-”，所以将栈1出栈作为减数，3出栈作为被减数，并运算3-1得到2，再将2进栈 逆波兰运算第三步 接着是数字3进栈 逆波兰运算第四步 后面是 “* ”号，也就意味着占中的3和2出栈2与3相乘，得到6。再把6进栈 下面是“+”，所以占中的6和9出栈，9与6想家，得到15，将15进栈 逆波兰运算第六步 接着是10与2两数字进栈 接下来是符号“/”，因此，栈顶的2与10出栈，10与2相处，得到5，将5进栈 逆波兰运算第八步 最后一个符号是“+”，所以15与5出栈并想家，得到20，20进栈 计算结果20出栈，栈变为空 逆波兰运算第十步 果然，后缀表达法可以很顺利的解决计算的问题。但是这个后缀表达式是如何出来的呢？就让我们来推导 H3 中缀表达式转后缀表达式。。。。 略 H2 队列的定义操作系统和客服系统中，都应用了一种疏解后来实现干柴的先进先出的排队功能，这就是队列。 队列（queue）是只允许在一端进行插入操作，而在另一端进行删除操作的线性表。 队列是一种先进后出(First In First Out)的线性表，简称FIFO。允许插入的一段为队尾，允许删除的一段为队头。 假设队列是 q=(a1,a2,a3…an),那a1就是队头元素，而an就是队尾元素。这样我们就可以删除时，总是从a1开始，而插入式，总是在最后。这就符号我们通常生活的习惯，排在第一个的有限出列，最后来的当然要排在队伍后面。 队列示意图 H3 队列的抽象数据类型同样是线性表队列也有类似线性表的操作，不同的就是插入数据只能在队尾进行，删除数据只能在队头进行。 H3 循环队列线性表有顺序存储和链式存储，栈是线性表，所以有两种存储方式。同样，队列作为一种特殊的线性表，也同样存在这两种存储方式。我们先来看队列的顺序存储结构。 H2 总结栈(Stack)是限定在表尾进行插入和删除的线性表队列（Queue）是只允许在一段进行插入操作，另一段进行删除操作的线性表他们均可以用现新表的顺序存储结构来实现，但都存在着顺序结构的一些弊端。因此他们有各自自由的技巧来解决这个问题。对于栈来说，如果是两个相同类型的栈，则可以用数组的两端作为占地的方法来让两个栈共享数据，这就可以最大化的利用数组的空间。对于列来说，为了避免数组插入和删除时需要移动数据，于是就引入了循环队列，使得对头和队尾可以在数组中循环变化。解决了移动数据的时间损耗，使得本来插入和删除是O(n)的时间复杂度变成了O(1).他们都可以通过链式存储结构，实则上与线性表基本相同 大话数据结构-栈与队列.md","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/tags/数据结构/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://blog.msiter.com/tags/计算机基础/"}],"keywords":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}]},{"title":"大话数据结构 - 线性表 3","slug":"大话数据结构-线性表","date":"2017-12-29T17:15:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"d,thsjjg-xxb-20171229.html","link":"","permalink":"http://blog.msiter.com/d,thsjjg-xxb-20171229.html","excerpt":"线性表的定义线性表，从名字你就能感觉到，是具有像线一样的性质的表。在广场上，有很多人分散在各处，当中有些是小朋友，可能有很多大人甚至有不少宠物，这些小朋友的数据对于整个广场来说不是线性表的结构。但像刚才提到的那样，一个班级的小朋友，一个牵着一个排着队，有一个打头，有一个收尾，当中的小朋友每一个都知道他前面的一个是谁，他后面一个是谁，这样如同有一根线把他们串联起来。就称之为线性表。 线性表(List)：零个或者多个数据元素的有限序列","text":"H2 线性表的定义线性表，从名字你就能感觉到，是具有像线一样的性质的表。在广场上，有很多人分散在各处，当中有些是小朋友，可能有很多大人甚至有不少宠物，这些小朋友的数据对于整个广场来说不是线性表的结构。但像刚才提到的那样，一个班级的小朋友，一个牵着一个排着队，有一个打头，有一个收尾，当中的小朋友每一个都知道他前面的一个是谁，他后面一个是谁，这样如同有一根线把他们串联起来。就称之为线性表。 线性表(List)：零个或者多个数据元素的有限序列 这里需要强调几个关键的地方。 开始写代码了，，，，总觉的这里的代码 有种画蛇添足的感觉，好吧～ 咱们也就是模仿一下～ 看看就好～ 首先它是一个序列。也就是说，元素之间是有顺序的，如元素存在多个，则第一个元素无前驱，最后一个元素无后继，其他每个元素都有且只有一个前驱和后继。如果一个小朋友去那两个小朋友后面的衣服，就不可以拍成一对了，同样，如果一个小朋友后面的衣服，被两个甚至多个小朋友拉扯这其实是打架，而不是有序排队。然后，线性表强调的是 有限的，小朋友班级人数有限，元素个数当然也是有限的。事实上，在计算机中处理的对象都是有限的，那种无限的数列，只存在于数学的概念中。如果用数学语言来定义。可如下：若将线性表记为（A1,…,Ai-1,Ai,Ai+1,…,An）则表中Ai-1领先于Ai,Ai领先于Ai+1，称Ai-1是Ai的直接前驱元素，Ai+1是Ai的直接后继元素。当i=1，2，…*n-1，ai有且仅有一个直接后继，当i=2,3,…n时，ai有且仅有一个直接前驱。 线性表前驱后继示意图所以线性表元素的个数n(n&gt;=0)定义为线性表的长度，当n=0时，称为空表。在非空表中的每一个元素都有一个确定的位置，如A1是第一个数据元素，An时最后一个数据元素，Ai是第i个数据元素，称i为线性表中的位序。我现在说一些数据集，大家来判断一下是否是线性表。先来一个大家感兴趣的，一年里的星座列表，是不是线性表呢？ 线性表星座举例示意图当然是，星座通常都是白羊大头，双鱼座首位，当中的星座都要前驱和后继，而且一泓也只有十二个，所以他完全符合线性表的定义。公司的组织架构，总经理管理几个总监，没个总监管理几个经理，没个经理都有各自的下属和员工。这样的组织架构是不是一个线性关系呢？不是为什么不是呢？哦，因为每一个元素，都有不止一个后继，所以他不是新型表。那种一个总经理只管一个总监，一个总监只管一个经历，一个经历只管一个员工的公司，俗称皮包公司岗位设置等于在忽悠外人。 H2 线性表的抽象数据类型前面我们已经给了线性表的定义，现在我们来分析以西啊，线性表应该有一些什么样的操作呢？还是回到刚才幼儿园小朋友的例子，老师为了让小朋友有秩序的出入，所以就考虑给他们拍一个对，并且是长期使用的顺序，这个考虑和安排的过程其实就是一个线性表的创建和初始化过程。一开始没经验，把小朋友排好队后，发现有的高有的爱，队伍很难看，于是就让小朋友解散重新拍—这是一个线性表表重置为空表的操作。拍好了对，我们随时可以叫队伍某一个小朋友的名字一踏的具体情况。比如有家长问，队伍里的第五个孩子，怎么这么调皮，他叫什么名字呀？傲视可以很快的告诉这位家长，这就是风清扬的儿子，叫做风云变。我在旁边就非常扭捏，看来是我给儿子的名字没取好，儿子让班级风云突变了。这种可以根据位序得到数据元素也是一种很重要的线性表操作。还有什么呢，有时我们想知道，某个小朋友，比如麦兜是否是班里的小朋友，老师会告诉我说，不是，麦兜在春天花花幼儿园，不在我们幼儿园。这种查找某个元素是否存在的操作很常用。而后有家长问老师，办理现在到底有多少个小朋友呀，这种获得线性表长度的问题也很普遍。显然对于一个幼儿园来说，加入一个新的小朋友到队列中，或因某个小朋友生病，徐耀一处某个位置，都是很正常的情况，对于一个线性表来说，插入数据和删除书句都是必须的操作。所以线性表的抽象数据类型定义如下： protocol List{ /// 初始化操作，建立一个空的线性表 /// /// - Returns: List 对象 static func InitList() -> List /// 若线性表为空，返回true，否则返回false /// /// - Returns: 是否 func ListEmpty() -> Bool /// 将线性表清空 func ClearList() /// 将线性表数据的第i个元素位置返回 /// /// - Parameter i: 位序 /// - Returns: 数据元素 func GetElem(i:Int) -> Any? /// 在线性表中查重和e相同的元素，如果查找成功，返回该元素在表中序号表示成功；否则返回-1表示失败。 /// /// - Parameter e: 数据元素 /// - Returns: 位序 -1 为无数据 func LocateElem(e:Any) -> Int /// 在线性表L中的第i个位置插入新元素e /// /// - Parameters: /// - i: 位序 /// - e: 数据元素 /// - Returns: &lt;#return value description#> func ListInsert(i:Int,e:Any) /// 删除线性表中的第i个位置元素，并用返回其值 /// /// - Parameter i: 位序 /// - Returns: 返回被删除的元素 func ListDelete(i:Int) -> Any? /// 返回线性表的元素个数 /// /// - Returns: 元素个数 func ListLength() -> Int } 对于不同的应用，线性表的基本操作是不同的，上述操作是最基本的，对于实际问题中涉及到的关于线性表的更复杂操作，完全可以用这些基本操作的组合来实现。比如，要实现两个线性表集合A和B的并集操作。即使要使得集合A=A∪B。说白了，就是把存在集合B中的但并不存在A中的元素插入到A中即可。仔细分析一下这个操作，发现我们只要循环集合B中的每一个元素，判断当前元素是否存在A中，如不存在，则插入到A中即可。思路是很容易想到的。 /// 其中 ListClass 为 List 协议的实现 func union(la: ListClass,lb: ListClass){ let lalen = la.ListLength() let lblen = la.ListLength() let list = ListClass.InitList() for i in 0...lblen{ let e = lb.GetElem(i: i) if la.LocateElem(e: e) == -1 { la.ListInsert(i: lalen+i, e: e) } } } 这里，我们对于union操作，用到前面线性表基本操作 ListLength,GetElem,LocateElem,ListInsert等，可见对于复杂的个性化的操作，其实就是把基本操作组合起来实现的。 H2 线性表的顺序存储结构H3 顺序存储定义说这么多的线性表，我们来看看线性表的两种物理结构的第一种–顺序存储结构。 线性表的顺序存储结构，指的是用一顿地址连续的存储单元一次存储线性表的数据元素。 线性表（A1，A2，…，An）的顺序存储示意图如下： 线性表顺序存储示意图我们在第一节课时，已经讲过顺序暑促存储结构。今天我们再举一个例子。记得大学时，我们同宿舍的有一个同学，热特别老实，热心，我们时常会让他帮我们去图书馆占座，他总是答应，你想想，我们一个宿舍连她一起共有几个人，这其实明白这是欺负人的事。他每次一吃完早饭就冲去图书馆面条一个好地儿，把它的书包里的书，一本本的按座位放好，若书包里的树不够，他会把它的饭盒，水杯，水笔都用上，常常一排，九个座硬是被他占了，后来又一次因占座的事儿差点都要打架。 占位说明示意图 H3 顺序存储方式线性表的顺序存储结构说白了，和刚才的例子一样，就是在内存中找了块地儿，通过占位的方式，吧一定内存空间给占了，然后把相同数据类型的数据元素一次存放在这块空地种。既然线性表的每个数据元素的类型，都相同，所以可以用C的以为数组来实现顺序存储结构，即把第一个元素存到数组下表为0的位置，就表示从这开始，这地方归我了。为了建立一个线性表，要在内存中找一块地儿，于是这块地额第一个位置就非常关键，他是存储空间的其实位置。接着，因为我们一共几个人，所以它需要占九个座，在线性表中，我们估算这个线性表的最大存储容量，建立一个数组，数组的长度就是这个最大存储容量。可现实中，我们宿舍总有那么几个不是很好学的人，为了游戏没了恋爱，就不去图书馆自习了。假设我们就个人，去了六个，真正被使用的座位，也就只是六个，另外三个是空的。同样的，我们已经有了其实的位置，也有了最大的容量，于是我们就可以在里面增加数据了，随着数据的插入，我们线性表的长途开始变大，不过线性表的当前长度不能超过存储容量，即数组的长度。想想也是，如果我们有10个人，只占了九个组，自然是坐不下的来看线性表的顺序存储的结构代码 struct ListClass: List { /// 数组元素类型根据实际情况而定，这里假设为 Int typealias T = Int /// 存储空间初始化分配量 var MAXSIZE = 20 /// 数组存储数据元素，最大值为MAXSIZE var data:[T] = [] /// 线性表的长度 var length = 0 } 这里，我们就发现描述顺序存储结构需要三个属性： 存储空间的起始位置： 数组 data，他的存储位置就是存储空间的存储位置。 线性表的最大存储容量： 数组长度MAXSIZE 线性表的当前长度： length H3 数据长度与线性表长度区别注意哦，这里有两个概念，“数组的长度”和“线性表的长度”徐耀区分一下。数组的长度是春芳线性表存储空间的长度，存储分配后这个粮食一般不变的。有个别的同学可能会问，数组的大小一定不可以变吗？我怎么看到有书中谈到可以动态分配一组数组。是的，一般高级语言，比如C，VB都可以用编程手段实现动态分配数组，不过这会带来性能上的损耗。线性表的长度是线性表中元素的个数，随着闲心表插入和删除操作的进行，这个是变化的。在任一时刻，线性表的长度应该小于等于数组的长度。 H3 地址计算方法由于我们数数都是从1开始树数的，线性表的定义也不能免俗，其实也是1，可C语言中的数组却是从0开始作为第一个下表的，于是线性表的第i个元素要存储在数组下表为i-1de位置。即数据元素的需要和存放他的数组下表之间存在对应关系 数组长度关系示意图用数组存储顺序表意味着要分配固定长度的数字空间，由于线性表中可以进行插入和删除操作，因此分配的数组空间,由于线性表中可以进行插入和删除操作，因此分配的数组空间大于等于当前性表的长度。其次，内存中的地址，就喝图书馆和电影院的祖伟一样，都是有编号的。存储器中的每个存储但愿都有自己的编号，这个编号成为地址。当我们占座后，占多的第一个位置确定后，后面的位置都是可以计算的。试想一下，我们班级成绩第五名，我们后面的10名同学成绩名次是多少呢？当然是6，7.。。15，因为5+1，+5+2，，，+5+10.由于每个数据元素，不管他是整型，实型还是字符型，他都需要一定的存储空间的。假设占用的是C个存储单元，那么线性表中第i+1个数据元素的存储位置和第i个数据元素的存储位置满足下列关系(LOC表示获得存储位置的函数)。 LOC(ai+1) = LOC(ai)+c 所以对于第i个数据元素Ai的存储位置可以有A1推送得出： LOC(Ai)=LOC(Ai)+(i-1)*c 从图来理解: 元素位置示意图通过这个公式，你可以随时酸楚线性表中任意位置的地址，不管他是第一个还是最后一个，都是相同的时间。那么我们对每个线性表位置的存入和去除数据，对于计算机来说都是相等的时间，也就是一个常数，因此用我们算法中学到的时间复杂度的感念来说，她的去存时间性能为O(1).我们通常把具有这一特点的存储结构称为随机存取结构。 H2 顺序存储结构的插入与删除H3 获得元素操作对于线性表的顺序存储结构来说，如果我们要实现GetElem操作，即将线性表第i个位置元素返回，其实是非常简单的。就程序而言，只要i的树枝在数组下标范围内，就是把数组第i-1下表的只返回即可。来看代码： func GetElem(i:Int) -> Any?{ if self.data.count == 0 || i &lt; 0 || i >= self.data.count { return nil } return self.data[i] } H3 插入操作刚才我们也谈到，这里的时间复杂度为O(1)。我们现在来考虑，如果我们要实现 ListInsert(i,e),即在线性表中的第i个位置插入新元素，应该如何操作？举个例子，本来我们在春运是去买火车票，大家都排队排的好好的。这时来了一个咩女，对着队伍中排在第三位的你说，“大哥，求求你帮帮忙，我家母亲有病，我得急着回去看她，着队伍这么长，你可否让我排在你的前面嫩？”你心一软，就同意了。这是你必须后退一步。否则他是没法进到队伍来的这可不得了，后面的人像蠕虫一样，全部都得退后一步没否则他就没法进到队伍来的。这可不得了，后面的人像蠕虫一样没全部都得退一步。骂声四起。但后面的人，也不清楚这加塞是怎么回事儿，没什么办法。 数据结构插入操作示意图插入算法的思路： 如果插入位置不合理，抛出异常； 如果线性表长度大于等于数组长度，则抛出异常或动态增加容量； 从最后一个元素开始向前编导第i个位置，分别将他们向后移动一个位置； 将要插入元素填入位置i处； 表长加1 H3 删除操作接着刚才的例子。此时后面排队的人群y一件都很大，都说怎么可以这样，不管什么原因，插队就是不行，有本事，找火车站开后门去。就在这时，远处跑来一胖子，对着这么美女喊，可找到你了，你这个骗子，还我钱。只见这女子，二话没说门突然就冲出了对了，胖子追在其后，消失在人群中。哦，原来他是倒卖火车票的黄牛，刚才还装可怜，于是排队的人群，又像蠕虫一样，均相亲移动了一步，骂声渐息，队伍又恢复了平静。这就是线性表的顺序存储结构删除元素的过程。 线性表删除操作示意图删除算法的思路： 如果删除位置不可理，抛出异常 去除删除元素 从删除元素位置开始便利到最后一个元素位置，分别将他们都向前移动一个位置 表长减1 现在我们来分析一下，插入和删除的时间复杂度。 先来看最好的情况，如果元素要插入到最后一个位置，或者删除最后一个元素，此次时间复杂度为O(1),因为不徐耀移动元素的，就如同来了新人要正常排队，当然是排在最后，如果此时他又不想排了，那么他一个人离开就好了，不影响任何人。最坏的情况呢，如果元素要插入到第一个位置或者删除第一个元素，此时时间复杂度是多少呢？那就意味着要移动所有的元素向后或者向前，所以这个时间复杂度为O(n)。至于平均的情况，由于元素插入到第i个位置或删除地i个元素，徐耀移动n-i个元素。根据概率远离，没个位置插入或删除元素的可能性是相同的，也就说位置靠前，移动元素多，位置考后，移动元素少，最终移动次数为 （n-1）/2。我们前面的讨论过时间复杂度的推导，可以得到，平均时间复杂度还是O(n)。这说明什么？线性表的顺序存储结构，在存，度数据时，不管是那个位置，时间复杂度都是O(1)；在插入或删除时，时间复杂度都是O(n).这都说说明，他比较适合元素个数不太变化，而更多的是存取数据的应用。当然，它的优缺点还不止这些…. H3 线性顺序存储结构的优缺点 我就一展示数据的表格 优点 缺点 无须为表示表中元素之间的逻辑关系而增加额外的存储空间 插入和删除操作需要移动大量元素 可以快速的存取表中任一位置的元素 当线性表长度变化较大时。难以确定存储空间的容量 - 造成存储空间的“碎片” H2 线性表的链式存储结构H3 顺序存储结构不足的解决办法前面我们讲的线性表的顺序存储结构。他是有缺点的，最大的缺点就是插入和删除时需要移动大量元素，这显然就需要耗费时间。能不能想办法解决呢？要解决这个问题，我们就得考虑一下导致这个问题的原因。为什么当插入和删除时，就徐耀大量元素，仔细分析后，发现原因在于相邻的两元素的存储位置也具有邻居关系。他们编号是1，2，3…，n，他们在内存中的位置也是挨着的，中间没有空隙，当然就无法快速介入，而删除后，当中就会滤除空隙，自然需要弥补。问题就出在这里。我们反正也是要让相邻元素留有足够余地，干脆所有的元素都不要考虑相邻位置了，哪有空位就到哪里，而只是让每一个元素都知道他的下一个元素位置在哪里，这样我们可以在找到，这样，我们可以在第一个元素时，就知道第二个元素的位置，而找到他。 H3 线性表链式存储结构定义在解释这个思路之前，我们先来谈另一个话题。前几年，有一本书风靡了全世界，他叫《达芬奇密码》，成为世界上最畅销的小说之一，树的内容集合了侦探，惊悚和阴谋论等多种风格，很好看。我犹豫看的时间太贵于救援，情节都忘的差不多了，不过这本书和绝大部分侦探小说一样，都是同一种处理办法。那就是，作者不会让你实现知道整个过程的全部，而是在一步步的到达某个环节，才根据现场的信息，获得或推断出下一步是什么，也就说，每一步出了对侦破的信息进一步确定外（之前信息也不一定都是对的，有时就是证明某个信息不正确），还有就是对下一步如何操作或行动的指引。不过这个例子也不完全与线性表相符合。因为侦破的限速可能是错综复杂的，有点像我们之后要讲到的树和图的数据结构。今天我们要谈的就是单线索，五分制的情况，即线性表的链式存储结构。线性表的链式存储结构的特点是用一组人以的存储单元存储线性表的数据元素，这组存储单元可以是连续的，也可以是不连续的。不就意味着这些数据元素可以存在内存未被占用的任意位置 线性表链式存储结构示意图以前在顺序结构中，每个数据元素只徐耀村数据元素信息就可以了。现在链式结构中，除了窑村数据元素信息外，还要存储他的后即元素的存储地址。因此，为了表示每个数据元素A1与其直接后需数据元素Ai+1之间的逻辑关系，对数据元素A1来说，除了存储其本身的信息之外，还徐耀存储一个指示器直接后需的信息（即直接后即的存储位置）。我们把存储数据信息的域成为数据域，把存储直接后继位置的域成为指针域。指针域存储的信息被称为指针或链。这两部分信息组成数据Ai的存储印象，成为结点（Node）。n个结点（A1的存储印象）连接成一个链表，即为线性表的链式存储结构，因为次链表的每个节点斗志包含一个指针与，所以叫做 单链表。单链表正是通过每个节点的指针域将线性表的数据元素按期逻辑次序连接在一起。 线性表链式结构存储示意图对于线性表来说，但得有个头有个尾，链表也不例外。我们把链表中第一个节点存储位置叫做头指针，那么整个链表的存储就必须是从头指针开始进行了。之后的每一个结点，他的指针指向哪里？最后一个，当然就意味着直接后继不存在了，所以我们桂东，线性链表的最后一个结点指针为“空”（通常用NULL或”^”符号来表示） 线性表链式存储头指针和空指针示意图有时，我们为了更加方便的对链表进行操作，会在单链表的第一个节点前附设一个结点，成为头结点。头节点的数据域可以不存储任何信息，谁脚踏实地一个呢，有这个特权。也可以存储如线性表的长度等附加信息，头结点的指针与存储只想第一个节点的指针。 头结点示意图 H3 头指针与头节点的异同 我就一展示数据的表格 头指针 头结点 头指针是指链表指向第一个结点的指针，若链表有头结点，则是指向头结点的指针 头结点是为了操作的统一和方便而设立的，放在第一个元素结点之前，其数据与一般无意义（也可存放链表的长度） 头指针具有表示作用，所以常用头指针冠以链表的名字 有了头结点，对在第一元素结点钱插入结点和删除第一结点，其操作与其结点的额操作就统一了 无论链表是否为空，头指针均不为空。头指针是链表的必要元素 头结点不一定是链表必须要素 H3 线性表链式存储结构代码描述若线性表为空表，则头结点的指针域为“空” 不好的空链示意图这里我们大概的用图示表达了内存中单链表的存储状态。看着满途的省略号“…… ”，你就知道是多么不方便。而我们真正关心的额：他是在内存中的实际位置吗？不是的，这只是他所表示的线性表中的数据元素雨数据元素之间的逻辑关系，所以我们该用更方便的存储示意图来表示单链表 链表新的存储示意图如带有头结点的单链表表示为： 头结点链表表示示意图空链表表示为： 空链表表示示意图 H2 单链表的读取在线性表的顺序存储结构中，我们要计算任意一个元素的存储位置是很容易的。但在单链表中，由于第i个元素到底咋哪儿？没办法一开始就知道，必须得从头开始找。因此，对于单链表实现第i个元素的数据操作getElem，在算法上相对于要麻烦一些。获得链表地第i个数据的算法思路： 声明一个结点p指向链表第一个节点，初始化j从1开始 当j&lt;i时，就便利链表，让p的指针向后移动，不断指向下一个结点，j累加1 若是链表末尾p为空，则说明第i个元素不存在 否则查找成功，返回结点p的数据 说白了，就是从头开始找，知道第i个元素为止。由于这个算法时间复杂度取决于i的为止，当i=1，则不需要遍历，第一个就去除数据了，而当i=n是则遍历n-1次。因此最最坏情况的额时间复杂度是O(n)。由于单链表的结构中没有定义表厂，所以不能实现知道要循环多少次，因此也就不方便是哟个for循环来控制循环。其主要核心思想就是“工作指针后移”，这其中也是很多算法的常用技术。此时就有人说，这么麻烦，这数据结构有什么意思！还不如顺序存储结构呢？哈，世界万物总是有两面的，有好自然有不足，有差自然就有优势。下面我们来看以下单链表中的如何实现“插入”和“删除”的吧。 H2 单链表的插入与删除H3 单链表的插入算法思路 声明一结点P只想链表第一个节点，初始化j从1开始 当j&lt;i时，就遍历链表，让p的指针向后移动，不断指向下一结点，j累加1 若到链表末尾p为空，则说明第i个元素不存在 否则查找成功，在系统生成一个空结点s 将数据元素e赋值到s的数据域 单链表的插入标准语句 s-&gt;next=p-&gt;next p-&gt;next=s 返回成功 H3 单链表的删除算法思路 声明一结点P只想链表第一个节点，初始化j从1开始 当j&lt;i时，就遍历链表，让p的指针向后移动，不断指向下一结点，j累加1 若到链表末尾p为空，则说明第i个元素不存在 否则查找成功，将要删除的结点p-&gt;next复制给q 单链表的删除标准语句 p-&gt;next=q-&gt;next 将q结点的数据复制给e，作为返回 释放q结点 返回成功 分析一下刚才我们讲解的单链表的插入和删除算法，我们发现，他们其实都是由两部分组成的。第一部分就是遍历查第i个元素；第二个部分就是插入和删除元素。从整个算法来说，我们很容易就推导处，他的时间复杂度都是O(n)。如果在我们不知道第i个元素的指针为止，单链表数据结构在插入和删除操作上，与线性表的顺序存储结构没有什么太大的有时。但如果我们希望从i为止插入10个元素，对于顺序结构存储就意味着，每一次插入都需要移动n-1个元素每次都是O(n)。而单链表，我们只需要第一次是，找到第i个位置的指针，此时为O(n)，接下来只是简单的通过复制移动指针而已，时间复杂度都是O(1).显然对于插入或删除数据越频繁的操作。单链表的效率优势越是明显。 H2 单链表的正表创建回顾一下，顺序存储结构的创建了其实就是一个个数组的初始化，即声明一个类型和大小的数组并复制的过程。而单链表和顺序存储结构就不一样，他不像顺序存储结构那么集中，它可以很散，是一种动态结构。对于每个链表来说，他所占用的空间的大小和位置是不是需要预先分配划定的，可以根据俄系统的情况和实际的需求即时生成。所以创建单链表的过程就是一个动态生成链表的过程。即从“空表”的初始状态其，依次建立个元素结点，并出个插入链表。单链表正表创建的算法思路： 声明一结点p和计数器变量i 初始化一空链表L 让L的头结点的指针指向NULL，即建立一个戴头结点的单链表 循环： 生成一新结点复制给P 随机生成艺术字复制给P的数据域p-&gt;data 将p插入到头结点与新结点之间H2 单链表的正表删除 声明一结点配合q 将第一个节点复制给p 循环： 将下一结点复制给q 释放p 将q复制给pH2 单链表的结构与顺序结构的优缺点 我就一展示数据的表格 存储分配方式 时间性能 空间性能 顺序存储结构用一段连续的存储单元依次存储线性表的数据元素 查找1.顺序存储结构O(1) 2.单链表O(n) 顺序存储结构需要预分配存储空间，分大了，浪费，分销了易发生上溢 单链表采用链式存储结构，用一组人以的存储单元存放线性表的元素 插入和删除1.顺序存储结构徐耀平均移动表长一半的元素，时间为O(n) 2.单链表再找出某位置的指针后，插入和删除时间为O(1) 单链表不徐耀分配存储空间，只要有就可以分配，元素个数也不受限制 通过上面的对比，我们可以得出一些经验性的结论： 若线性表需要频发查找，很少进行插入和删除操作时，宜采用顺序存储结构。如需要频繁插入和删除时，宜采用单链表结构。比如说游戏开发中，对于用户注册的个人信息，除了注册时插入数据外，绝大属情况都是读取，所以应该考虑用顺序存储结构，而游戏中的玩家的武器或者装备列表，随着玩家的游戏过程中，可能会随时增加或删除，此时在用顺序存储就不太合适了，单链表结构就可以大展拳脚。当然，这只是简单的类比，现实中的软件开发，要考虑的问题会复杂的多。 当线性表中的元素个数变化较大或者根本不知道有多大时，最好用单链表结构，这样就不徐耀考虑存乎空间的大小问题。而如果实现知道线性表的大大只长度，比如一年12个月，一周就是星期一至星期日共七天，这种用顺序存储结构效率会高很多。 总之，线性表的顺序存储结构和单链表结构各有其优缺点，不能简单的说哪个好，那个不好，需要根绝实际情况，来综合平和采用哪种数据结构更能满足和达到需求和性能。 H2 静态链表其实C语言真是好东西，它具有的指针能力，使得它可以非常容易的操作内存中的地址和数据，这比其他高级语言更加灵活方便。后来的面向对象语言，虽不是用指针，但因为启用对象引用机制，从中角度也间接的实现了指针的某些作用。但对于一些语言，早起的高级语言，由于没有指针，链表结构按照咱们前面的讲法，就诶发实现了，怎么办呢？有人就想出来用数组来代替指针，来描述单链表。真是不得不佩服他们的智慧，我们来看看他是怎么做到的。首先我们让数组的元素都是由两个数据域组成，data和cur。也就是说，数组的每个下表都对应一个data和一个cur。数据域data，用来存放数据元素，也就是通常我们要处理的数据；而游标cur相当于单链表中的next 指针，存放钙元素的后继在数据的下标。我们把这种用数组描述的链表称为静态链表，这种描述方法还有起名叫做游标实现法。为了方便我们插入数据，我们通常会把数组建立的大一些，一边有一些空闲空间可以边鱼插入时不至于溢出。 另外我们对数组第一个和最后一个元素作为特殊元素处理，不村数据。我们通常把未被使用的数组元素成为备用链表。而数组第一个元素，记下标为0的元素的cur就存放备用链表的第一个结点的下标。而数组的最后一个元素的cur则存放第一个有数据的元素的下标，相当于单链表中的头结点作用，当整个链表为空时，则为0。 加入我们已经讲数据存入静态链表，比如分别存放着“甲”，“乙”，“丁”，“戊”，“己”，“庚”等数据，则如下： 静态链表演示图此时，“甲”这里就存又有下一个元素的“乙”的游标2，“乙”则存有下一个元素“丁”的游标3。而“庚”作为最后一个有值元素，所以他的cur设置为0.而最后一个元素的cur，则因为前七个都有值，设置为 第一个无值的游标 7. H3 静态链表的插入操作个人理解： 首先检测是否还有空闲的数组位置，如果没有数组已经满了 根据最后一个元素的cur获取到一个可以被赋值的游标位置 获取cur为0的游标的数据 将cur 设置为 可以被复制的游标 赋值 并且将cur 设置为 0 H3 静态表的删除操作 首先找到到需要删除的位置数据 将头结点的的cur 设置为 该数据的 cur 将该值的cur 设置为 第一个可复制的cur 并将可以被赋值的cur 设置为该游标 H3 静态链表优缺点 我就一展示数据的表格 优点 缺点 在插入和删除的操作时，只需要修改游标，不徐耀移动元素，从而改进了在顺序存储结构中的插入和删除操作需要移动大量的缺点 没有解决连续存储空间带来的表长难以确定的问题 失去了顺序存储结构随机存取的特性 总的来说，静态链表其实是为了给没有指针的高级语言设置的一种实现单链表能力的方法。尽管大家不一定会用得上，但这样的额思考方式是非常巧妙的，应该理解其思想，以备不时之需。 H2 循环链表对于单链表，由于每个节点只存储了向后的指针，到了为标志就停止了向后脸的操作，这样，当中某一结点就无法找到他的前驱结点了，就像我们刚才说的，不能回到从前。 将单链表中终端结点的指针短有空指针改为指向头结点，就是整个单链表形成一个环，这种头尾想接的单链表成为但循环链表，建成循环链表（circular linked list）。 头指针单循环链表 尾指针单循环链表 H2 双循环链表双循环链表就是，每一个数据不仅知道他的后继是什么，还知道自己的前驱是什么。 头指针双循环链表 H2 总结回顾这一章，我们主要讲的是线性表。先谈了他的定义，线性表是零个或多个具有相同类型的数据元素的有限序列。然后谈了线性表的抽象数据类型，如他的一些基本操作。之后我们就线性表的两大结构做了讲述，先讲了是比较容易的顺序存储结构，值的是用一顿地址连续的存储单元依次存储线性表的数据元素。通常我们都是用数组来实现这一结构。后来是我们的重点，有舒徐存储结构的插入和删除操作不方便，引出了链式存储结构，它具有不受古丁的存储空间限制，可以比较快捷的插入和删除操作的特点。然后我们分别就链式存储结构的不同形式，进行了讲解。另外我们还讲解了 如何不是用指针来实现链表的 静态链表。 总结 大话数据结构-线性表.md","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/tags/数据结构/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://blog.msiter.com/tags/计算机基础/"}],"keywords":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}]},{"title":"大话数据结构 - 算法 2","slug":"大话数据结构-算法","date":"2017-12-28T15:27:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"d,thsjjg-sf-20171228.html","link":"","permalink":"http://blog.msiter.com/d,thsjjg-sf-20171228.html","excerpt":"算法 算法： 算法是解决特定问题求解步骤的描述，在计算机中表现为指令的有限序列，并且每条指令表示一个或多个操作。 数据结构与算法关系我们这门课程叫做数据结构，但很多时候我们会讲到算法，以及它们之间的关系，市场上也有不少书叫“数据结构与算法分析”这样的名字。有人可能就要问了，那你到底直降数据结构，还是算法一起讲？它们之间是什么关系呢？干嘛要放在一起？这个问题怎么回答。打个比方，今天是你女友生日，你打算请女友去看爱情音乐剧，到了戏院，抬头一看—《梁山伯》18:00开眼。嗯？怎么会这样？一问才知道，今天饰演祝英台的演员生病，所以梁山伯唱独角戏。真是搞笑了，这还有什么看头？事实上，数据结构和算法也是类似的关系。只谈数据结构，当然也可以，我们可以在很短的时间就把几种重要的数据结构介绍完。听完后，很可能你没什么感觉，不知道这些数据结构有啥用处，但如果我们再把响应的算法拿出来讲一讲，你就会发现，深刻开始感慨：哦计算机界的前辈们，的确是一些很牛很牛的人，他们是很多看似难以解决或者没法解决的问题，变得如此的美妙和神奇。","text":"H2 算法 算法： 算法是解决特定问题求解步骤的描述，在计算机中表现为指令的有限序列，并且每条指令表示一个或多个操作。 H3 数据结构与算法关系我们这门课程叫做数据结构，但很多时候我们会讲到算法，以及它们之间的关系，市场上也有不少书叫“数据结构与算法分析”这样的名字。有人可能就要问了，那你到底直降数据结构，还是算法一起讲？它们之间是什么关系呢？干嘛要放在一起？这个问题怎么回答。打个比方，今天是你女友生日，你打算请女友去看爱情音乐剧，到了戏院，抬头一看—《梁山伯》18:00开眼。嗯？怎么会这样？一问才知道，今天饰演祝英台的演员生病，所以梁山伯唱独角戏。真是搞笑了，这还有什么看头？事实上，数据结构和算法也是类似的关系。只谈数据结构，当然也可以，我们可以在很短的时间就把几种重要的数据结构介绍完。听完后，很可能你没什么感觉，不知道这些数据结构有啥用处，但如果我们再把响应的算法拿出来讲一讲，你就会发现，深刻开始感慨：哦计算机界的前辈们，的确是一些很牛很牛的人，他们是很多看似难以解决或者没法解决的问题，变得如此的美妙和神奇。 H3 两种算法的比较大家都已经学过一门计算机语言，不管学的哪一种，学的好不好，好歹都是可以写点小程序的了。现在我要求大家写一个1+2+3…+100 结果的程序，你应该怎么写呢？ 大多数人会马上写出如下的代码(以下为Swift代码)： var sum = 0 for i in 1...100 { sum = sum + i } print(\"结果:\",sum) 这是最简单的计算机程序之一，他就是一种算法，我不缺解释这段代码的额含义了。问题在于，你的第一直觉就是这样子写的，但是这样子写真的好吗？是不是最高效呢？此时我们不得不吧伟大数学家 高斯的童年故事拿出来说一遍，也许你们在已经听过，但是不妨感受一下，天才当年是如何才华和天分的。据说18世界的德国小村庄的高斯，上小学的一天，课堂很乱，就像我们平时在下面窃窃私语摆弄手机的同学一样，老师非常生气，后果也很严重。在临放学前，要求每个学生都要计算 1+2+3…+100的结果，谁先算出来谁先回家。天才当然不会被这种问题难道，告诉很快就有了记过，是 5050.老师非常惊讶，因为他相比也是花了大功夫通过 1+2=3 3+3=6 6+4=10 计算出来的。为什么这个少年这么快就算出来了了高斯解释道： sum = 1+ 2+ 3+... +99 +100 sum = 100+ 99+ 98+... +2 +1 2xsum = 101+ 101+ 101+...101+ 101 如果使用程序表示就是 var i = 1 var n = 100 var sum = 0 sum = (i + n)*n/2 print(\"结果:\",sum) 神通就是神通，他用的方法相当于另一种求等差数列的算法，不仅仅可以用于100，也可以加到1千，一万，一亿，也都是瞬间的事情。但如果用刚才的程序，显然计算机要循环 一千，一万，一亿次的加法运算。人脑比电脑算得快，似乎成为了现实。 H3 算法的定义什么是算法呢？算法是描述解决问题的方法。算法（Algorithm）这个单词最早出现在波斯数学家阿勒 花刺子密在公寓825年（相当于我们中国的唐朝）缩写的《印度数学算法》中。如今普遍任何的对算法的定义式： 算法是解决特定问题步骤的描述，在计算机中表现为指令的有限序列，并且每条指令表示一个或多个操作 刚才的例子我们也看到，对于给定的问题，是可以有多种算法来解决的。那我就要问问你们，有没有通用的算法呀。这个问题其实很弱鸡，就相当于问，有没有包治百病的药一样。现实世界的问题千奇百怪，算法当然也就千变万化，没有通用的算法可以解决所有的问题。甚至解决一个小问题，很优秀的算法不一定适合他算法定义中，提到了指令，指令能被人或及其等计算装置执行。它可以是计算机指令，也可以是我们平时的语言文字。为了解决某个或者某类问题，徐耀吧指令表示称一定的操作序列，操作序列包含了一组操作，每一个操作都完成特定的功能，这就是算法了。 H3 算法的特性算法由五个基本特性： 输入，输出，有穷性，确定性和可行性。 H4 输入输出输入和输出特性比较好理解，算法具有零个或多个输入。尽管对于绝对数算法来说，输入参数都是必要的，但是对于个别情况，如打印“Hello World”。这样的代码不徐耀任何擦输入参数，依次算法的输入可以是零个。算法具有至少一个或多个输出。算法是一定有输出的，不需要输出，你用这个算法干嘛，输出的形式可以是打印输出，也可以是返回一个或多个值等。 H4 有穷性有穷性：只算法在执行有限的步骤之后，自动结束而不会出现无限循环，并且每个步骤都在可接受的时间范围内完成。 现实中经常会写出死循环的代码，这就不满足有穷性。当然这里有穷的概念并不是纯粹数学意义的，而是在实际应用中应当合理的，可以接受的“有边界”。你说你写一个算法，计算机要算上二十年，一定会结束，他在数学意义是有穷了，但是媳妇熬成婆了，算法的意义也就不大了 H4 确定性确定性：算法的每一步骤都具有确定的含义，不会出现二义性。 算法在一定条件下，只有一条执行路径，相同的输出只有唯一的输出结果。算法的每个步骤都被精确的定义而无歧义。 H4 可行性可行性：算法的每一步骤都必须是可行的，也就是说，每一步都能够通过执行有限次数完成。 可行性意味着算法可以转换为程序上级运行，并得到正确的结果。尽管在目前计算机界也存在那种没有实现的极为复杂的算法，不是说理论上不能实现，而是因为过于复杂，我们目前的编程方法，工具和大脑限制了这个工作，不过这都是理论研究领域的问题，不属于我们现在要考虑的范围。 H3 算法设计的要求刚才我们谈到了，算法不是唯一的。也就是说，同一个问题，可以有多种解决问题的算法，这可能让那些长年只左右标准答案题目的学生失望了，他们多么希望存在标准答案的，只有一个是正确的，把它背下来，需要的时候套用就可以了。不过话说回来，尽管算法不唯一，相对好的算法确实存在的。掌握好的算法，对我们解决问题很有帮助，否则前任的智慧我们不能利用，就都得自己从头研究了。那么什么才叫好的算法呢？ H4 正确性正确性：算法的正确性是指算法至少应该具有输入输出和加工处理无歧义性，能正确反映文日的雪球，能够得到答案的正确答案但是算法的“正确”通常在用法上有很大的茶杯，大体分为以下四个层次。 算法程序没有语法错误。 算法程序对于合法的输入数据能够产生满足徐耀的输出结果。 算法程序对于非法的输入数据能够给出满足规格说明的结果。 算法程序对于精心选择的，甚至刁难的测试数据都有满足需求的输出结果。对于这四层含义，层次1要求最低，但是仅仅没有语法错误实在谈不上是好算法，这就如同仅仅解决温饱，不能算是胜过幸福一样。而层次4是最困难的，我们几乎不能初一验证所有的输入都得到正确的结果。因此算法的正确性在大部分情况下都不能用程序来证明，而是用数学方法证明的。证明一个复杂算法在所有层次上都是正确的，代价非常昂贵。所一般情况下，我们把层次3作为一个算法是否正确的标准。H4 可读性可读性：算法设计的另一目的是为了便于阅读，交流和理解。可读性高有助于人们理解算法，晦涩难懂的算法往往因含错误，不易被发现，并且南与调试和修改。我在很久以前曾经看到一个网友写的代码，它号称这程序是‘用史上最少代码实现俄罗斯方块’。因为我也写过了类似的小程序，所以项研究以下他是如何写的。由于他追求的是最少代码这样的极致，使得他的代码真的不好理解。也许除了计算机和他自己，绝大多数人是看不懂他的代码的。我们写代码的目的，一方是为了让计算机执行，但还有一个重要的目的是为了便与他人阅读，让人理解和交流，自己也可能阅读，如果可读性不好，时间长了，自己都不知道写了些什么。可读性是算法好坏很重要的标志。H4 健壮性一个好的算法还应该能对输入数据不合法的请款做合适的处理。比如输入的时间或者距离不应该是负数等。健壮性：当输入数据不合法事，算法也能做出相关处理，而不是产生异常莫名其妙的结果。H4 时间效率高和存储量低最后好的算法，还应该具备时间效率高和存储量低的特点。时间效率值得是算法的执行时间，对于同一个问题，如果有多个算法能够解决，执行时间短的算法效率高，执行时间长的效率低。存储量需求指的是算法在执行时间需要的最大存储空间，主要只算法程序运行时算占用的内存和外部硬盘存储空间。设计算法应该满足时间效率高和存储连最低的需求。 在生活中人们都希望或最少的钱，用最短的时间，班最大的是，算法也是一样的方法，用最少的存储空间，花最少的时间。半城同样的事儿就是好算法。求100个人的平均分，羽球全省的所有考生的成绩的平均分在占用时间和内存有非常大的差异的，我们自然视锥可以高效率和第存储量的算法来解决问题。 综上，好的算法，应该具有正确性，可读性，健壮性，高效率和低存储量的特征。 H3 算法效率的度量方法刚才我们提到设计算法要提高效率。这里的效率大都是只算法的执行时间。那么我们如何度量一个算法的执行时间呢。正所谓“是骡子是马，拉出来溜溜”。比较容易想到的方法就是。我们通过对算法的数据测试，利用计算机的即使功能，来计算不同算法的效率是高还是低。 H4 事后统计方法事后统计方法：这种方法主要是通过设计好的测试程序和数据，利用计算机计时器对不同的算法编制的程序的运行时间进行比较，从而确定算法效率的高低。但是这种方法显然有很大的缺陷的： 必须依据算法事先便只好程序，这通常需要花费大量的时间和经理。如果编织出来发现他根本是糟糕的算法，不是竹篮打水一场空吗？ 时间的比较依赖于计算机硬件和软件等环境因素，有时会掩盖算法本身的优劣。要知道，现在的一台四核处理器的计算机，跟当年的 286 386 486 等老爷爷辈的机器相比，在处理算法的运算速度上，是不能相提并论的；而所用的操作系统，编译器，运行框架等软件的不同，也可以影响他们的结果；就算是同一台计算器，CPU的使用率和内存占用情况不一样，也会造成席位的差异。 算法的测试数据设计困难，并且程序的运行时间往往还与测试数据的规模有很大的关系，效率高的算法在小的测试数据还得不到体现。比如10个数字的排序，不管用什么算法，差异几乎为0 ，而我们如果由一百万个随机数字的排序，那不同算法的差异就非常大了。那么我们为了比较算法，到底用多少数据来测试，这是很难判断的问题。 基于时候统计方法有这样那样的缺陷，我们考虑不予采纳。 H4 事先分析估算方法我们的计算机前辈们，为了对算法的评判更科学，研究出了一种叫做事前分析估算的方法。事前分析估算方法：在家算计程序编制前，一句统计方法对算法进行估算。经过分析，我们发现，一个用高级程序语言编写的程序在计算机上运行时消耗的时间取决于下列因素： 算法采用的策略，方法 便意产生的代码质量 问题的输入规模 机器执行指令的速度 第一条当然是算法好坏的根本，第二条要有软件来支持，第四条要看硬件性能。也就是说抛开这些与计算机硬件，软件有关的因素，一个程序的运算时间，依赖于算法的好坏和问题的输入规模，所谓问题输入规模是指输入量的多少。我们来看看今天刚上课觉的例子，两种求和的算法：第一种算法： var sum = 0 // 执行1次 for i in 1...100 { // 执行100次 sum = sum + i // 执行100次 } print(\"结果:\",sum) // 执行一次 第二种算法： var i = 1 // 执行1次 var n = 100 // 执行1次 var sum = 0 // 执行1次 sum = (i + n)*n/2 // 执行1次 print(\"结果:\",sum) // 执行1次 显然第一种算法执行了1+(n+1)+n+1次即2n+3次；而第二种算法，是1+1+1+1+ =5次。事实上第二种算法的第一条和最后一条是一样的，所以我们关注的代码其实中间的部分，我们把循环看作一个整体，忽略头尾循环判断的开销，那么这两个算法其实就是n次和1次的差距。悬法好坏显而易见我们再来延伸一下例子： var x = 0 var sum = 0 var n = 100 for i in 0...n { for j in 0...n { x = x+1 // 执行了nxn次 sum = sum + x } } print(\"结果:\",sum,\"，执行了:\",x,\"次.\") ps:这个例子，我使用了 Playground 书写的，在写完之后居然产生了卡顿感，甚至Xcode一度不可操作，出现了 小彩虹圈。所以算法消耗非常大。 这个例子中，i从1到100，每次都让j在执行100次，而当中的x++和sum = sum+x，其实就是1+2+3+…+10000,也就是100平方次，所以这个算法当中，循环部分的代码整体需要执行 n平方（忽略循环体头尾的开销）次。显然这个算法的执行次数对于同样输入规模n=100，要多与前面两种算法，这个算法执行时间随着n的增加也将远远多与前面两个。此时你会看到，测定运行时间最可靠的方法就是计算对运行时间由小号的基本操作的执行次数。运行时间与这个计数成正比。我们不关心编写程序所用的程序设计语言是什么，和不管这些程序泡在什么样的计算机中，我们只关心他所事先的算法。这样，不记那些循环索引的递增和循环终止条件，变量生病，打印结果等操纵。最终，在分析程序的运行时间时，最重要的是把程序看成独立于程序设计语言的算法或一系列步骤。可以从问题描述中得到启示，同样问题的输入模式是n，求和算法的第一种，求1+2+…n徐耀一段代码执行n次。那么这个问题的输入规模是的操作数量是f(n)=n,显然运行100次的同一段代码规模是运行10次的10倍。而第二种，无论n为多少，n的运行次数都是1，即f(n)=1 ，第三种，运算100次是运算10次的100倍。因为他是f(n)=n*n。我们在分析一个算法的运行时间时，重要的是把基础操作的数量和输入规模关联起来，即基础操作的数量必须表示称输入规模的函数。 算法 效率比较示意图我们可以这样认为，随着n值的越来越大，他们在时间效率上的差异也越来越大，好比你们当中有些人每天都在学习，我指的是有用的学习，而不是只为考试的死读书，每天都在进度，而另一些人，打打游戏，谁睡大觉，入校时大家都一样，但毕业结果可能就大不一样，前者名气争抢着要，后者求职无门。 H3 函数的渐进增长我们现在来判断一下，两个算法 A和B那个更好，假设两个算法的输入规模都是n，算法A要做2n+3此操作，你可以裂解现有一个n次的循环，执行完成后，在做依次n的循环，最后还有三次的复制或运算。共2n+3次操作。算法B要做3n+1次操作。你觉的他们谁更快呢？准确来说，答案是不一定的 函数渐进增长示意图当n=1时，算法A效率不如算法B（次数要比算法b多一次）。而当n=2时候，两者的效率相同；当n&gt;2时i算法，算法A就开始由于算法B了，随着n的增加，算法A比算法B越来越好了。于是我们可以得出结论，算A总体上好过与算法B。此时我们给出这样的定义，输入规模n在没有限制的情况下，只要超过一个数值N，这个函数就是总大雨量一个函数，我们成函数时渐进增长的。 函数的渐进增长：定给两个函数f(n)和g(n)，如果存在一个整数N，使得对于所有的n&gt;N，f(n)总是比g(n)大，那么，我们就说f(n)的增长渐进快于g(n)。 从中我们发现，随着n的增加，后面的+3还是+1 其实不影响最终的算法变化的，例如算法 A‘和算法B’，所以我门可以胡恶略这些假发常数。后面的例子，这样的成熟忽略的意义可能会更加明显。 后面的例子也就不再多说了。判断一个算法的效率时，函数的常熟和其他次要项常常可以忽略，而更应该关注主项（最高阶项）的阶数。 判断一个算法好不好，我们只通过少量的数据是不能精确判断的。根据刚才几个阳历，我们发现，如果我们可以对比这几个算法的关键执行次数函数的渐进增长型，基本就可以分析处：某个算法，随着n的增加，他越来越有一另一算法，或者越来越差于另一个算法。 这其实就是事前估计算法的理论依据，通过算法时间复杂度来估算算法时间效率。 H3 算法时间复杂度H4 算法时间复杂度定义 在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)岁n的变化情况并确定T(n)的数量级。算法的时间复杂度，也就是算法的时间量度，几座：T(n)=O(f(n))。他表示岁问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同，乘坐算法的渐近时间复杂度，简称为时间复杂度。其中f(n)是问题规模n的某个函数。 这样用大写O()来体现算法时间复杂度的记法，我们称之为大O记法。一般情况下，随着n的增大，T(n)增加最慢的算法为最有算法。显然，由此算法时间复杂度的定义可知，我们分别给他们去了非官方的名字，O(1) 叫常数阶，O(n)叫线性阶，O(n平方)叫平方阶，当然，还有其他的一些阶，我们之后会介绍。 H4 推导大O阶方法那么我们如何分析一个算法的时间复杂度呢？即如何推导大O阶呢？我们给出了下面的推导方法，基本上，这也是我们总结我们前面觉的例子。 推导大O阶: 用常数1取代运行时间所有的加法常数 在修改后的运行次数函数中，只保留最高项阶 如果最高阶项存在且不是1，则去除与这个项想成的常数。得到的结果就是大O阶。 哈，仿佛是得到了游戏攻略一样，我们好像已经得到了一个推导算法时间复杂度的万能公式。可事实上，分析一个算法的时间复杂度，没有那么简单，我们还徐耀多看几个自己。 H4 常数阶首先顺序结构的时间复杂度。下面这个算法，也就是刚才的第二种算法(高斯算法)，为什么时间复杂度不是O(5),而是O(1). var i = 1 // 执行1次 var n = 100 // 执行1次 var sum = 0 // 执行1次 sum = (i + n)*n/2 // 执行1次 print(\"结果:\",sum) // 执行1次 这个算法的运行次数函数是f(n)=5.根据我们推导大O阶的方法，第一步就是把常数项5换成1.在保留最高位项阶时，他根本没有最高阶项，所以这个算法时间复杂度为O(1)。另外，我们是试想以下，如果这个算法当中的次数sum = (i + n)*n/2由10句，即： var i = 1 // 执行1次 var n = 100 // 执行1次 var sum = 0 // 执行1次 sum = (i + n)*n/2 // 执行1次 NO.1 sum = (i + n)*n/2 // 执行1次 NO.2 sum = (i + n)*n/2 // 执行1次 NO.3 sum = (i + n)*n/2 // 执行1次 NO.4 sum = (i + n)*n/2 // 执行1次 NO.5 sum = (i + n)*n/2 // 执行1次 NO.6 sum = (i + n)*n/2 // 执行1次 NO.7 sum = (i + n)*n/2 // 执行1次 NO.8 sum = (i + n)*n/2 // 执行1次 NO.9 sum = (i + n)*n/2 // 执行1次 NO.10 print(\"结果:\",sum) // 执行1次 事实上无论n为多少，上面两段代码就是3和12次执行的差异。这种与问题大小无关（n的多少），执行时间恒定的算法，我们称之为具有O(1)的时间复杂度，又叫常数阶。注意：不管这个常数是多少，我们都记做O(1)，而不能是O(3),O(12)等其他任何数字，这也是初学者常常犯的错误。对于分支结构而言，无论真，还是家，执行的次数都是恒定的，不会随着n的变大而发生变化，所以单纯的分支结构（不包含在循环结构中），其时间复杂度也是O(1)。 H4 线性阶线性阶的循环结构会复杂很多。要确定某个算法的阶次，我们常常需要确定某个特定语句或某个语句集运行的次数。因此，我们要分析算法的复杂度，关键就是要分析循环结构的运行情况。下面这段代码，他的循环的时间复杂度为O(n)，因为循环体重的代码徐耀执行n次。 var sum = 0 for i in 1...100 { // 时间复杂度为O(1)的程序步骤序列 } H4 对数阶下面的代码，时间复杂度又是多少呢？ var count = 1 while(count &lt; n){ count = count*2 // 时间复杂度为O(1)的程序步骤序列 } 由于每次count乘以2之后，就距离n更近了一分。也就是说，有多少个2相乘后大于n，则会推出循环。由2的X平方等到x=log2n。所以说这个循环的时间复杂度为O(logn)。 H4 平方阶下面例子是一个循环嵌套，他的内循环我们已经分析过，时间复杂度为O(n). for i in 0...n { for j in 0...n { // 时间复杂度为O(1)的程序步骤序列 } } 而对于外层的循环，不过是内部循环这个时间复杂度为O(n)的语句，再循环n次。所以这段代码的时间复杂度为O(n平方)如果外循环的循环次数改为了m，其时间复杂度就为o(mxn)。 for i in 0...m { for j in 0...n { // 时间复杂度为O(1)的程序步骤序列 } } 所以我们可以总结得出，循环的时间复杂度等于循环体的复杂度乘以该循环运行的次数。 H4 常见的时间复杂度常见的复杂度如表 常见的时间复杂度示意图 H4 最坏情况与平均情况你早上上班出门后突然想起来，手机忘记带了，这年头，钥匙，钱包手机三大件，出门那样都不能少呀，于是回家找。打开门一看，手机就在门口玄关的台子上，原来是出门穿鞋时忘记拿了。这当然是比较好，基本没花什么时间寻找。可如果不是放在哪里，你就得进去到处找。找东西有运气好的时候，也有怎么找也找不到情况。但在现实中，通常我们碰到的绝大多数既不是最好的也不是最坏的，所以算下来平均情况居多。最坏情况运行时间是一种保证，那就是运行时间将不会再坏了。在应用中，这是一种最重要的需求，通常，除非特别制定，我们提到的运行时间都是情况的运行时间。平均运行时间是所有情况中最有意义的，因为它是预期的运行时间。也就是说，我们运行一段程序代码时，是希望看到平均运行时间的。可现实中，平均运行时间很难通过分析得到，一般都是通过运行一定数量的实验数据后估算出来的。对算法的分析，一种方法是计算所有情况的平均值，这种时间复杂度的计算方法成为平均时间复杂度。另一种方法是计算最坏情况下的时间复杂度，这种方法成为最坏时间复杂度。一般没有特殊说明的情况下，都是指最坏时间复杂度。 H4 算法空间复杂度我们在写代码时，完全可以用空间来换取时间，比如说，要判断某某年是不是闰年，你可能会花一点心思写一个算法，而且由于是一个算法，也就意味着，每次给一个年份，都是要通过计算得到是否是闰年的结果。还有两一个办法就是通过，实现建立又2050个元素的数组，然后把所有的年份都按照用下表的数字对应。这样所谓的判断某一年是否为闰年，就变成了查找数组某一项的值又少的问题。此时我们的算法是最小化了，但是硬盘或内存中需要存储这个2050个0和1.这是通过一笔空间上的开销来换取计算时间的小技巧。到底哪一个好，其实要卡你用在什么地方。算法的空间复杂度通过计算算法所需的存储空间时间，算法空间复杂度的计算公式记做：S(n)=O(f(n)),其中，n为问题的规模，f(n)为语句关于n所占空间的函数。一般情况下，一个程序在机器上执行时，除了需要存储程序本身的指令，常数，变量和输入数据外，还徐耀存储对数据操作的存储单元。如输入数据所占空间只取决于问题本身，和算法无关，这样只需要分析该算法在实现时所需的辅助但愿即可。若算法执行时所需的辅助空间相对于输入数据量而言是个常数，则成为次算法为原地工作，空间复杂度为O(1)。通常，我们都是用“时间复杂度”来之运行时间的需求，使用“空间复杂度”指空间需求。当不用限定词地来使用“复杂度”时，通常都是指时间复杂度。现在我们这本书的重点还是在 时间复杂度。 H4 总结回顾算法的定义：算法是解决特定问题求解步骤的描述，在计算机中为指令的的有限序列，并且每条指令表示一个或多个操作。算法的特性：有穷性，确定性，可行性，输入和输出算法的设计的要求：正确性，可读性，健壮性，高效率和低存储需求算法特性和算法设计需求容易混，需要对比记忆。算法的度量方法：事后统计方法（不科学，不准确），事前分析估算方法。在讲解如何用时间分析估算方法之前，我们先给出了函数渐进增长的定义。函数的渐进增长：给定两个函数f(n)和g(n)，如果存在一个整数N，当n&gt;N的事后，f(n)始终大于g(n)。那么我们就说f(n)的渐进增长比g(n)快。 于是我们得处一个结论，判断一个算法好不好，我们只通过少量的数据是不能作出准确判断的，如果我们可以对比算法的关键执行次数函数的渐进增长性，基本就可以分析出：某个算法，随着N的变大，他会越来越优于另一个算法，或者越来越差于另一个算法。然后给出了算法时间复杂度的定义和推导大O阶的步骤。推导大O阶: 用常数1取代运行时间所有的加法常数 在修改后的运行次数函数中，只保留最高项阶 如果最高阶项存在且不是1，则去除与这个项想成的常数。得到的结果就是大O阶。通过这个步骤，我们可以在得到算法的运算次数表达式后，很快就得到他的时间复杂度，即大O阶。同时我也提醒了大家，其实推导大O阶很容易，但如何得到运行次数的表达式确实很徐耀数学功底的。 大话数据结构-算法.md","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/tags/数据结构/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://blog.msiter.com/tags/计算机基础/"}],"keywords":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}]},{"title":"大话数据结构 - 数据结构绪论 （1）","slug":"大话数据结构-数据结构绪论","date":"2017-12-27T14:22:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"d,thsjjg-sjjgxl-20171227.html","link":"","permalink":"http://blog.msiter.com/d,thsjjg-sjjgxl-20171227.html","excerpt":"数据结构绪论 数据结构： 是相互之间存在一种或多种特定关系的数据元素的集合。 数据结构起源早起人们都把计算机理解为数值计算工具，就是感觉计算机当然是用来计算的，所以计算机额解决问题，应该先从具体问题抽象成一个适当的数据模型，设计出一个借此数据模型的算法，然后在编写程序，得到一个实际的软件。","text":"H2 数据结构绪论 数据结构： 是相互之间存在一种或多种特定关系的数据元素的集合。 H3 数据结构起源早起人们都把计算机理解为数值计算工具，就是感觉计算机当然是用来计算的，所以计算机额解决问题，应该先从具体问题抽象成一个适当的数据模型，设计出一个借此数据模型的算法，然后在编写程序，得到一个实际的软件。 可现实中，我们更多的不是解决数值计算的问题，而是需要一些更可可续有效的手段（比如表，树和图等数据结构）的帮助，才能更好的处理问题。所以 数据结构是一门研究非数值计算的程序设计问题中的操作对象，以及它们之间关系和操作等相关问题的学科 H3 基础概念和术语说到数据结构是什么，我们得先来谈谈什么是数据。正所谓“巧妇难为无米之炊”，在强大的计算机，也是要有“米”下锅才可以干活儿的，否则就是一堆破铜烂铁，这个“米”就是数据 H4 数据数据：是描述客观事物的符号，是计算机中可以操作的对象，是能被计算机识别，并输入给计算机处理的符号集合。 数据不仅仅包括整型，实型等数值类型，还包括字符以及声音 图像 视频等非数值类型 比如我们现在常用的搜索引擎，一般会有网页，MP3，图片，视频等分类。MP3就是声音数据，图片当然是图像数据，视频就不用说了，而网页其实指的就是全部数据的搜索，包括最重要的数字和字符等文字数据 也就是说，我们这里说的数据，其实就是符号，而且这些符号必须具备两个前提： 可以输入到计算器中 能被计算机程序处理对于整型，实型等数值类型，可以进行数值计算。对于字符数据类型，就需要进行非数值的处理。而声音，图像，视频等其实可以通过编码的手段变成字符数据来处理的。 H4 数据元素数据元素: 是组成数据的，有一定意义的基本单位，在计算机中通常作为整体处理，也被称为记录。比如，在人类中什么事数据元素呀？当然使人了畜类呢？牛 吗 羊 鸡 猪 够 等动物当然就是畜类的数据元素。 H4 数据项数据项：一个数据元素可以有若干个数据项组成比如人这样的数据元素，可以有眼，耳朵，鼻子，嘴巴，手脚这些数据项，也可以有姓名，年龄，性别出生地址，联系电话等数据项，具体有哪些数据项那个，要是你做的系统来决定。 数据项是数据不可分割的最小单位。 在数据机构这门课程中，我们把数据项定义为最小单位，是有助于我们更好的解决问题。所以，记住了，数据形式数据的最小单位。但是真正讨论问题的时候，数据元素才是数据结构建立数据模型的着眼点，就像我们讨论一部电影时，是要论这部电影角色这样的数据元素，而不是针对这个角色的姓名或者年龄这样的“数据项”去研究分析。 H4 数据对象数据对象：是性质相同的数据元素的集合，是数据的子集什么叫性质相同呢。是指数据元素具有相同数量和类型的数据项，比如，还是刚才的例子，人都有姓名，生日，性别等相同的数据项。既然数据对象是数据的子集，在实际应用中，处理的数据元素通常具有相同性质，在不产生混淆的情况下，我们都将数据对象简称为数据。好了，有了这些感念的铺垫，我们的主角登场了。说了数据的定义，那么数据结构中的结构又是什么呢？ H4 数据结构结构，简单的理解就是关系，比如分子结构，就是说组成分子的原子之间的排列方式。严格点说，结构是指各个组成部分相互搭配和排序的方式。在现实生活中 不同数据元素之间不是独立的，而是存在特定的关系的，我们将这些关系成为结构。 那数据结构是什么？ 数据结构：是相关之间存在一种或者多种特定关系的数据元素的集合。 在计算机中，数据元素并不是孤立，杂乱无序的，而是具有内在联系的数据集合。数据元素之间存在的一种或多种特定关系，也就是数据的组织形式。为编写好一个“好”的程序，必须分析待处理对象的特性及个处理对象之间存在的关系。这也就是研究数据结构的意义存在。 定义中提到的一种或多种特定关系，具体是什么样的关系，这正是我们下面要讨论的问题。 H4 个人理解与总结 数据-数据对象-数据元素-数据项之间的关系我们首先学习了什么是数据，之后说明了一些名词。那么他们是什么关系呢 数据 +--------------------|------------------+ | | 数据对象 数据对象 +---------|---------+ +---------|----------+ | | | | 数据元素 数据元素 数据元素 数据元素 +-----|-----+ +-----|-----+ +-----|-----+ +-----|-----+ | | | | | | | | 数据项1 数据项2 数据项1 数据项2 数据项1 数据项2 数据项1 数据项2 简单就是说，“耳朵 ，鼻子 嘴巴 ”这些 数据项，组成了“人”这些 数据元素，而人又组成了人类这个 数据对象，而人类是 又是 生物的一个子集，也就是包含 那么生命就是 数据 数据项组成了数据元素，而数据对象是性质相同的数据元素的集合，是数据的子集~~ H3 逻辑结构与物理结构按照视点的不同，我们把数据结构分为逻辑结构和物理结构 H4 逻辑结构逻辑结构：是指数据对象之间的相互关系。 其实这也是我们今后最徐耀关注的问题。逻辑结构分为以下4种： 集合结构集合结构： 集合结构中的元素除了同属于一个集合外，他们之间没有其他关系。各个数据元素是“平等”的，他们的共同属性是“同属于一个集合”。数据结构中的数据关系就类似于数学中的集合 集合结构示意图 线性结构线性结构：线性结构中的数据元素之间是一对一的关系 线形结构示意图 树形结构树形结构：树形结构中的数据元素存在一种一对多的层次关系 树形结构示意图 图形结构图形结构：图形结构中的数据元素存在多对多的关系 图形结构示意图我们在用示意图表示数据的逻辑机构是，要注意两点： 将每一个数据元素看作一个节点，永远泉表示 元素之间的逻辑关系用节点之间的连线表示，如果这个关系是有方向的，那么用带箭头的连线表示 从之前的例子也可以看出，逻辑机构是针对具体问题的，是为了解决某个问题的，在对问题理解的基础上，选择一个合适的数据结构表示数据元素之间的逻辑关系。 H4 物理结构说完了逻辑结构，我们再来看看物理结构（很多书中也叫存储结构，你只要理解上把他们当作一回事就好了）。物理结构： 是指数据的逻辑结构在计算机的存储形式数据是数据元素的集合，那么根据物理结构的定义，实际上就是如何把数据存储到计算机的存储器中，存储器主要是针对内存而言，像硬盘，软盘，光盘等外部的存储器数据组织通常用文件结构来描述。数据的存储结构应正确反应数据元素之间的逻辑关系，这才是最关键的，如何存储数据元素之间的逻辑关系，是实现物理结构的重点和难点。 数据元素的存储结构形式有两种： 顺序存储和链式存储。 顺序存储结构顺序存储结构： 是把数据元素存储在地址连续的存储单元里，其数据见的逻辑关系与物理关系是一致的。 顺序存储结构示意图这种存储结构其实很简单，说白了，就是排队占位。大家都按顺序排好，每个人，占一小段空间，大家谁也别插谁的队。我们之前学计算机语言时，数组就是这样的顺序存储结构。当你告诉计算机，你要建立一个又9个整型数组时，计算机就在内存找了一片空地，按照一个模型所占的位置乘以9，开辟一段连续的空间，于是第一个就放在第一个位置，第二个数据就放在第二个，这样依次摆放。 链式存储结构如果就是这么简单和有规律，一切就都好办了。可实际上，又会有人插队，也会有人要上厕所，有人放弃排队。所以这个队伍当中会添加新成员，也有可能会去掉老成员，整个结构时刻都处于变化中。显然，面对这样市场要变化的结构，顺序存储是不科学的。那怎么办呢？现在如银行，医院等地方，设置了排队系统，也就是每个人去了，限领一个号，等着叫号，叫到时去办理业务或看病。在等待的时候，你爱在哪儿在哪儿，可以坐着，站着或者走动，甚至出去逛一圈，只要及时赶回来就行。你关注的是前一个号有没有被叫到，叫到了，下一个就轮到了。链式存储结构：是把数据元素存放在任意的存储单位中，这组存储单元可以是连续的，也可以是不连续的。 数据元素的春初关系并不能反映其逻辑关系，但是需要用一个指针存放数据元素的地址，这样通过地址就可以找到相关数据元素的位置 链式存储结构示意图显然，链式存储就灵活多了，数据存放哪里不重要，只要有一个指针，存放了相应的地址就能找到他了。 逻辑结构是面向问题的，而物理结构是面向计算机的，其基础的目标就是将数据及其逻辑关系存到计算机的内存中。 先说说，逻辑结构和物理结构。书上总结的已经很好了。 逻辑结构是面向问题的，而物理结构是面向计算机的。 其实简单来说就是, 如果把人类存储起来，那么 按照他们的籍贯。还是年龄大小。还是之间的亲戚关系。这种叫做 逻辑结构。如果是把人放到 放在广场。是排队还是随便走动，这个是物理结构。。。感觉解释的还是不行。。。 顺序结构和 链式结构的区别和相同 我就一展示数据的表格 名称 不同点 顺序存储结构 顺序结构是连续的内存地址，所以数量必须提前定好。 链式存储结构 链式存储是非连续内存地址，只需要知道下一个数据元素在那里就好了，所以理论上在内存不满之前是无限个个数的 H3 抽象数据类型H4 数据类型数据类型：是指一组性质相同值的集合及定义在此集合上的一些操作的总称数据类型是按照值的不同进行划分的。在高级语言中，每个变量，常量和表达式都有各自的取值范围。类型就用来说明变量或表达式的取值范围和所能进行的操作。当年那些设计计算机语言的人，为什么会考虑到数据类型呢？比如，大家都需要住房子，也都希望房子越大越好。很显然，没有钱，考虑房子没啥意义。于是商品房就出现了各种各样的方形，有别墅的，有错层的，有单间的。有一百多平的，也有几十平的，甚至北京还出了胶囊公寓。这眼就满足了不同人的需求。同样，在计算机中，内存也不是无限大的，你要计算一个1+1=2，3+5=8的这样的整型数字的减价运算，显然不徐耀开辟很大的适合小数甚至字符运算的内存空间。于是计算机的研究者门就考虑，要对数据进行分类，分出来多种数据类型。 在C语言中，按照取值的不同，数据可以分为两类 原子类型： 是不可以在分解的基本类型，包括 整型，实型，字符型等。 结构类型： 是由若干各类型组合而成，是可以在分解的。例如，整型数组是有若干整型数据组成。 比如，在C语言中变量生变int a,b ，这就意味着，再给变量a和b复制时不能超出 int 的取值范围，变量a和b之间的运算也只能是int类型所允许的运算。因为不同的计算机有不同的硬件系统，这就要求程序语言最终通过编译器或者解释器转换成底层语言，如汇编语言甚至是通过机器语言的数据类型来实现的。可事实上，高级语言的编程者不管最终程序原型在什么计算机上，他的目的就是为了实现两个整型数字的运行，如 a+b，a-b，axb，a/b等，他才不关系证书在计算机内部是如何表示的，也不需要知道，CPU为了实现1+2进行了几次开关操作，这些操作是如何实现的，对高级语言开发者来讲根本不重要。于是我们就会考虑，无论什么计算机，什么计算机语言，大都会面临着 整数运算，实数运算，字符运算等操作我们可以考虑把他们抽象出来 抽象是指抽取出食物具有的普遍性的本质。 它是抽出问题的特征而忽略非本质的细节，是对具体事物的一个概括。抽象是一种思考问题的方式，它隐藏了繁杂的细节，只保留了实现目标所需的信息。 H4 抽象数据类型我们对已有的数据类型进行抽象，就有了抽象数据类型。抽象数据类型（Abstract Data Type,ADT）：是指一个数据模型以及定义在该模型的一组操作。 抽象数据类型的定义仅取决于他的一组逻辑特性，而与其在计算机内部如何表示和实现无关。比如刚才的例子，各个计算机，不管是大型机，小型机，PC，平板电脑，PDA甚至智能手机都有“整数”类型，也需要整数间的运算，那么整形其实就是一个抽象数据类型，尽管他在上面提到的这些不同计算机中实现方法不一样，但是由于其定义的数学特性相同，在计算机编程者看来，他们都是相同的。因此，“抽象”的意义在于数据类型的数学抽象特性而且，抽象数据类型不仅仅指那些已经定义并实现的数据类型，还可以是计算机编程者在设计软件程序时自己定义的数据类型，比如我们便携计算机绘图或者地图累的软件系统，经常会用到坐标，也就是说，总是有成对出现的X和Y，在3D的软件中甚至会出现Z。既然这三个整型数字是始终出现在在一起出现，我们就定一个叫 point的抽象属类型，他有XYZ三个整型变量，这样我们很方的操作一个point数据变量就能知道这一点的坐标了。 根据抽象数据类型的定义，它还包括定义在该模型的一组操作。就像“超级玛丽”这个经典的任天堂游戏，里面的游戏主角是马里奥（Mario）。我们给他定义了几个基本操作，走（前进，后退，上，下）跳，打子弹等。一个抽象数据类型定义了：一个数据对象，数据对象中个数据元素之间的关系及数据元素的操作。至于，一个抽象数据类型到底需要那些操作，这就只能由设计者根据实际需要来定。像马里奥，可能开始只有两种操作，走和跳，后来发现应该要增加一种打子弹的操作，再后来发现有些玩家希望他可以走的快一点，就有了按住子弹后前进就会“跑”的操作。这些都是根据实际情况来设计的 事实上，抽象数据类型体现了程序设计中问题分解，抽象和信息隐藏的特性。抽象数据类型把实际生活中的问题分解为多个规模小且容易处理的问题，然后建立一个计算机能处理的数据模型，并把每个功能模块的实现细节都作为一个独立的单位，从而使具体的实现过程隐藏起来。 为了便于我们在之后的讲解中对抽象数据进行规范的描述，我们给出了描述对象书库类型的标准格式： /// 抽象数据类型 Class ADT{ /// 数据元素之间的逻辑关系的定义 let data1 let data2 /// 操作 func oper1{} func oper2{} } H3 总结回顾数据结构的相关结构 数据结构概念图 由这些概念，给出了数据结构的定义：数据结构是相互之间存在的一种或多种特定关系的数据元素的集合。 同样是结构，从不同的角度讨论会有不同的分类。 结构分类示意图 总结： 数据 是有数据元素 或者 数据对象构成，数据对象是由特性一样的一群数据元素构成，一个或者多个数据项构成了数据元素 数据结构按照 分类有两种结构，逻辑结构和物理结构。 逻辑结构多表示数据见的逻辑关系，包含（1.集合机构（无关系）2.线性关系（一对一）3.树性关系（一对多）4.图形关系（多对多））等。而物理结构，则是其存储在计算机的存储器中的无力位置来定的。（比如：必须在连续的内存地址中的 顺序存储结构，以及相对应的 不要再连续地址中的 链式存储结构） 计算器的数据存储器是内存，硬盘等存储，存储的是文件结构。 抽象数据类型是为了规定某一种数据元素的 取值 以及 操作。这个还不是非常明白。但是大概就是 目前我们所学的对象。比如 人抽象承认，那么他就是一个人，需要由消化系统等变量，当然还需要拥有，呼吸，眨眼等操作 大话数据结构-数据结构绪论.md","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/tags/数据结构/"},{"name":"计算机基础","slug":"计算机基础","permalink":"http://blog.msiter.com/tags/计算机基础/"}],"keywords":[{"name":"数据结构","slug":"数据结构","permalink":"http://blog.msiter.com/categories/数据结构/"}]},{"title":"RxSwift Moya 实际项目实践","slug":"RxSwift Moya 实际项目实践","date":"2017-12-26T14:45:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"RxSwift Moya sjxmsj-20171226.html","link":"","permalink":"http://blog.msiter.com/RxSwift Moya sjxmsj-20171226.html","excerpt":"在公司最近贷款项目被国家管控的原因，这几天一直在学习。今天就开始说说 rXswift 吧。 以前也写过一篇 RxSwift 教程，后来慢慢的因为项目实际开发的时候为了所以小包的大小，都改为了Objective-c 所以一直也没有什么机会使用Swift。 首先完整项目的地址在这里 DouyuTool 可以查看我的Commit 来看看我的修改路程","text":"在公司最近贷款项目被国家管控的原因，这几天一直在学习。今天就开始说说 rXswift 吧。 以前也写过一篇 RxSwift 教程，后来慢慢的因为项目实际开发的时候为了所以小包的大小，都改为了Objective-c 所以一直也没有什么机会使用Swift。 首先完整项目的地址在这里 DouyuTool 可以查看我的Commit 来看看我的修改路程 好的坏的都是风景 我目前学习的主要在这。RxSwift 中文文档 · RxSwift 中文文档非常感谢 @beeth0ven 翻译了并且根据自己的理解，所编写的文档，让我看到受益匪浅。 代码没有经过处理，所以可能会有一些意想不到的问题，以后慢慢整理。 以下是 预览的 Gif (大小 12.85M). RxSwift Moya 实际项目实践.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"RxSwift","slug":"RxSwift","permalink":"http://blog.msiter.com/tags/RxSwift/"},{"name":"Moya","slug":"Moya","permalink":"http://blog.msiter.com/tags/Moya/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"IOS 绘制 录音波形图","slug":"IOS 绘制 录音波形图","date":"2017-12-22T05:38:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"IOS hz lybxt-20171222.html","link":"","permalink":"http://blog.msiter.com/IOS hz lybxt-20171222.html","excerpt":"最近工作不是非常的忙，前段时间在研究 Objective-c 的Runtime，Runloop，这些知识实在是太杂多，搞的很乱。今天忽然想起来，以前想做波形图。那今天就来试试吧。","text":"最近工作不是非常的忙，前段时间在研究 Objective-c 的Runtime，Runloop，这些知识实在是太杂多，搞的很乱。今天忽然想起来，以前想做波形图。那今天就来试试吧。 楼下一个男人病的要死，隔壁的一家唱着留音机。&lt;br/&gt;对面是哄孩子，楼上有两个人狂笑，还有打牌声。&lt;br/&gt;河边的船上有女人哭着她死去的母亲。&lt;br/&gt; 人类的悲喜并不相通，我只觉得他们吵闹。——鲁迅《而已集》 H2 首先要先准备一个 录音器收集声音的框架，我是用的是 AVFoundation 框架的 AVAudioRecorder首先导入 -&gt; #import &lt;AVFoundation/AVFoundation.h&gt;. H3 设置info.plist 文件权限请求在Info.plist 增加一个 节点 NSMicrophoneUsageDescription 请求录音 H3 创建一个 声音收集器创建一个 AVAudioRecorder 对象用于录音的动作 AVAudioSession *session = AVAudioSession.sharedInstance; [session setCategory:AVAudioSessionCategoryPlayAndRecord error:nil]; NSURL *url = [NSURL fileURLWithPathComponents:@[ [NSSearchPathForDirectoriesInDomains(NSDocumentDirectory, NSUserDomainMask, YES) lastObject], @\"MyAudioMemo.m4a\"]]; self.recorder = [[AVAudioRecorder alloc] initWithURL: url settings:@{ AVFormatIDKey: @(kAudioFormatMPEG4AAC), AVSampleRateKey: @(44100.0f), AVNumberOfChannelsKey: @(2), } error:NULL]; self.recorder.delegate = self; self.recorder.meteringEnabled = YES; [self.recorder prepareToRecord]; H3 按钮点击 开始录音 结束录音用户点击按钮的时候 开始录音和结束录音的操作 - (IBAction)clickRecordButtonMethod:(id)sender { if (!self.recorder.recording) { /// 正在录音 [AVAudioSession.sharedInstance setActive:true error:nil]; [self.recorder record]; [self.recorderButton setTitle:@\"停止录音\" forState:(UIControlStateNormal)]; }else{ // 暂停 录音 [self.recorder stop]; [AVAudioSession.sharedInstance setActive:false error:nil]; [self.recorderButton setTitle:@\"开始录音\" forState:(UIControlStateNormal)]; } } 这个时候我们已经可以录音了，并且实际上已经完成了录音了，但是我们看不到效果。接下来我们开始获取接下来的事情吧 H2 监听声音的大小在我们完成了录音的代码之后，接下来就需要我们绘制波形图了和监听声音的音量的大小了 监听的远离非常简单，就是我们使用 NSTimer 通过AVAudioRecorder averagePowerForChannel 获取音量值。 修改的代码如下 - (IBAction)clickRecordButtonMethod:(id)sender { if (!self.recorder.recording) { /// 正在录音 [AVAudioSession.sharedInstance setActive:true error:nil]; [self.recorder record]; [self.recorderButton setTitle:@\"停止录音\" forState:(UIControlStateNormal)]; self.timer = [NSTimer scheduledTimerWithTimeInterval:0.02 target:self selector:@selector(timeHandleMethod) userInfo:nil repeats:true]; }else{ // 暂停 录音 [self.recorder stop]; [AVAudioSession.sharedInstance setActive:false error:nil]; [self.recorderButton setTitle:@\"开始录音\" forState:(UIControlStateNormal)]; [self.timer invalidate]; } } -(void)timeHandleMethod{ /// 监听数据 ...more... } H3 关于录音和Audio Session Categories如果AVAudioRecorder的averagePowerForChannel和peakPowerForChannel方法总是返回-160的话，那么很有可能是当前的Audio Session Categories不允许进行音频输入（也就是麦克风输入）。如：AVAudioSessionCategorySoloAmbient/kAudioSessionCategory_SoloAmbientSound，AVAudioSessionCategoryPlayback/kAudioSessionCategory_MediaPlayback。 如果这样的话，我们需要把当前Audio Session Categories设置成 AVAudioSessionCategoryRecord/kAudioSessionCategory_RecordAudio，或者AVAudioSessionCategoryPlayAndRecord/kAudioSessionCategory_PlayAndRecord。 可以使用两套API 来修复这个问题 一种是AVFoundation Framework中的API。如下： NSError *setCategoryError = nil; BOOL success = [[AVAudioSession sharedInstance] setCategory: AVAudioSessionCategoryRecord //或者AVAudioSessionCategoryPlayAndRecord error: &amp;setCategoryError]; 另一种是使用AudioToolbox Framework，它是基于C的API.如下： UInt32 sessionCategory = kAudioSessionCategory_RecordAudio; OSStatus result = AudioSessionSetProperty(kAudioSessionProperty_AudioCategory, sizeof(sessionCategory), &amp;sessionCategory); H3 分贝数据的处理根据Apple文档，AVAudioRecorder的averagePowerForChannel和peakPowerForChannel方法返回的是分贝数据，数值在-160 - 0之间（可能会返回大于0的值如果超出了极限）。在实际测试中，比如我在办公室（不算吵也不算特别安静的环境下）我测试averagePowerForChannel的返回值平均在-35左右徘徊。 有很多方法可以把这个原始的分贝数据转化成更可读或者更可用的形式。如Apple SpeakHere Sample。或者自己手动设置一个分贝的范围，然后根据比例输出自己需要的分贝范围：比如下段代码： -(void)timeHandleMethod{ [self.recorder updateMeters]; float power = [self.recorder averagePowerForChannel:0]; CGFloat progress=(1.0/160.0)*(power+160.0)-0.3; ...more... } 还有另外一种 大神总结的计算方法 //用于监控AVAudioRecorder数据的Timer回调方法。 //注意设置AVAudioRecorder的meteringEnabled属性为YES。 //recorder变量是AVAudioRecorder对象。 //http://stackoverflow.com/questions/9247255/am-i-doing-the-right-thing-to-convert-decibel-from-120-0-to-0-120/16192481#16192481 - (void)levelTimerCallback:(NSTimer *)timer { [recorder updateMeters]; float level; // The linear 0.0 .. 1.0 value we need. float minDecibels = -80.0f; // Or use -60dB, which I measured in a silent room. float decibels = [recorder averagePowerForChannel:0]; if (decibels &lt; minDecibels) { level = 0.0f; } else if (decibels >= 0.0f) { level = 1.0f; } else { float root = 2.0f; float minAmp = powf(10.0f, 0.05f * minDecibels); float inverseAmpRange = 1.0f / (1.0f - minAmp); float amp = powf(10.0f, 0.05f * decibels); float adjAmp = (amp - minAmp) * inverseAmpRange; level = powf(adjAmp, 1.0f / root); } NSLog(@\"平均值 %f\", level * 120); } 这个时候我们已经可以获取到 声音的大小了 H2 绘制波形图我们主要使用一个 栈 来保存声音的大小数据。先进后出 大概的代码如下 [self.heightArray removeObjectAtIndex:0]; // 移除第一个 [self.heightArray addObject:@(height)]; // 增加一个 绘制就是用 Graphics Context是图形上下文 来绘制图形 -(void)drawRect:(CGRect)rect{ /// 获取当前的高度 float rectHeight = CGRectGetHeight(rect); // 获取初始化 左方的位置 保证 波形图 水平垂直 float initX = (CGRectGetWidth(rect)-(self.heightArray.count*LineWidth+(self.heightArray.count-1)*SpaceWidth))/2; // 配置上下文 CGContextRef context = UIGraphicsGetCurrentContext(); CGContextSetStrokeColorWithColor(context, UIColor.redColor.CGColor); CGContextSetLineWidth(context, LineWidth); /// 增加线条 for (int i=0; i&lt;self.heightArray.count; i++) { float height = [self.heightArray[i] floatValue]; float x = initX + i*LineWidth + (i+1)*SpaceWidth; CGContextMoveToPoint(context, x, (rectHeight-height)/2); CGContextAddLineToPoint(context, x, (rectHeight-height)/2+height); } CGContextStrokePath(context); } H2 岩石项目完整项目 IOS 绘制 录音波形图.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/tags/IOS/"},{"name":"Waver","slug":"Waver","permalink":"http://blog.msiter.com/tags/Waver/"},{"name":"AVFoundation","slug":"AVFoundation","permalink":"http://blog.msiter.com/tags/AVFoundation/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"执子之手 与子偕老","slug":"执子之手 与子偕老","date":"2017-12-14T11:00:00.000Z","updated":"2018-08-29T10:33:16.506Z","comments":true,"path":"zzzs yzxl-20171214.html","link":"","permalink":"http://blog.msiter.com/zzzs yzxl-20171214.html","excerpt":"我这个人不怎么会说话，我只想过自己想过的日子和你在一起很开心 但是也有很多烦恼","text":"我这个人不怎么会说话，我只想过自己想过的日子和你在一起很开心 但是也有很多烦恼 我们会看到最美的太阳 努力！💪！ 如果我玩游戏的时候我知道你很不喜欢我玩游戏不怎么理你 你问我话 我也有可能没听见但是 如果这个时候你在旁边 看看视频看到好玩的找我聊天的时候多喊我几下 大声点 荆文征！你不让我去玩，我心里一直痒痒的 就会很难受 就想去玩但是真的去玩了真的玩不了太久 我就会到床上 去陪你 如果我们出去吃饭的时候我知道你很不喜欢我们出去吃饭喝酒 说些有的没的 经常说胡话 还花很多钱但是 这个是我们的生活寄托 独自在北京 你可以依靠我 我去依靠谁心里很多事情 没有地方去诉说 说胡话 有可能是心里的悲哀 不甘自己一个人在北京 谁都靠不上 我有些时候就是单纯的想说说话喝酒 只是给我要说的话 如果不太着调 找个理由 如果你有什么不高兴的事儿我知道 不善于表达 会一直闷着自己 自己去思考琢磨但是 我们就是一个人 你不开心 你就说 我就哄你你很多的话 如果连我都不说 谁可以说你直接告诉我 很多事情可以迎刃而解我们两个人在 全世界这么多人相遇 相识 相爱 相恨我们遇到了别人一辈子都遇到的事儿我们经过很多 我们开心过 伤心过 如果这样子你都不愿意跟我说 那跟谁说 如果那些以前的事儿我知道 你会一直想 我以前的那些事儿 就像梦魇 不自觉的就进入脑子我知道 你也不想想 毕竟那些事儿 对谁来说都是一种折磨 谁都不好受但是有些事情 真的是以前的如果我小时候 没偷东西 就好了 那次偷东西我被我妈打的很厉害 追的满村跑如果我小时候 没有学我哥 倒着下梯子 就好了 那次我鼻子被担到梯子上 呼呼流血但是在那之后 再也没拿过别人的东西但是在那之后 我姨家修了 楼梯 我的鼻子也挺挺的了时间 是一支箭 只能往前 不可以回头 我们在一起 10年了 好的坏的都体验过了即使 你如何 我都会一直爱你 即使 我如何 你也会一直爱我我们还有什么过不去的现在 确实很不好 我们的婚礼 在买房的同一年的举行你现在独自一个人在家里 准备生产 家里没有一个熟人想说话 也觉的尴尬 跟我说 我很多时候 也不怎么会说话 其实最开始 我想的是 等咱们搬到临沂 咱们站稳脚步在盛大的教堂 邀请亲朋好友 牵着你的手很多朋友的见证下 亲吻你但是 孩子的出现 什么都打乱了在没有钱的时候 我们定亲 婚纱照 举办婚礼什么都没有我想的样子 我觉的很不好意思 但是看到你没有什么不满我当时真的很欣慰 我觉的你好完美 其实最开始 也是 会到临沂 咱们稳定工作我开车接送你上下班 把你扶到车上 因为你的大肚子实在太大了我每天晚上拍照 记录独自一点点的打起来 最后剪辑成一个 动态图 一定很有意思看着你 慢慢的变重 我们现在 23岁家里没有钱 我只能在北京回到临沂 我们的房子没有下来 没有工作什么地方都需要钱 我们真的需要努力，我知道我对不起你 我真的很努力 老婆 希望你也不要生气相信我 我爱你 我们在一起这么久 没有什么东西抵过我们驾着一叶小舟 刚刚起航 三个人在船上 摇摇晃晃但是 我们一起努力 扶住船帆 很快就会稳起来的 我们一定要活成别人都羡慕的样子 执子之手 与子偕老.md","categories":[{"name":"生活","slug":"生活","permalink":"http://blog.msiter.com/categories/生活/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://blog.msiter.com/tags/生活/"},{"name":"希望","slug":"希望","permalink":"http://blog.msiter.com/tags/希望/"},{"name":"家庭","slug":"家庭","permalink":"http://blog.msiter.com/tags/家庭/"}],"keywords":[{"name":"生活","slug":"生活","permalink":"http://blog.msiter.com/categories/生活/"}]},{"title":"天通苑地铁 - 安检方式改变","slug":"生活随处可见一斑20171123","date":"2017-11-23T09:18:00.000Z","updated":"2018-08-29T10:33:16.506Z","comments":true,"path":"shsckj,xyb20171123-20171123.html","link":"","permalink":"http://blog.msiter.com/shsckj,xyb20171123-20171123.html","excerpt":"今天早上来到天通苑地铁站发现安检方式改变了，以前是一个口安检，在大门口存在一个可以供没带包乘客进入的通道，由于这个口离安检人员较远甚至存在一个弯道，所以根本没人会管带包乘客进入该通道。后来通道干脆封掉了，这样一来，带包不带包都需要在一个地方排队等待安检了。现在在原本通道的地方放置了两个安检门把有包无包区分开来。我只是觉得这样子挺好的，本着生活处处皆学问的心理自己觉得大概有几种心理导致了以上描述","text":"今天早上来到天通苑地铁站发现安检方式改变了，以前是一个口安检，在大门口存在一个可以供没带包乘客进入的通道，由于这个口离安检人员较远甚至存在一个弯道，所以根本没人会管带包乘客进入该通道。后来通道干脆封掉了，这样一来，带包不带包都需要在一个地方排队等待安检了。现在在原本通道的地方放置了两个安检门把有包无包区分开来。我只是觉得这样子挺好的，本着生活处处皆学问的心理自己觉得大概有几种心理导致了以上描述 最开始人们在没有人注意的时候会走通道，另外就是当一个带包的人走之后。所有的人都会出现这种情况，这种情况就类似一个很干净的地方，被一个人丢了垃圾，那里就会不断被人丢垃圾，直到变成垃圾桶。这种心理很多，从众，羊群，我觉得最好的是 破窗定律。 破窗效应，是关于环境对人们心理造成暗示性或诱导性影响的一种认识。指如果有人打坏了一幢建筑物的窗户玻璃，而这扇窗户又得不到及时的维修，别人就可能受到某些暗示性的纵容去打烂更多的窗户。一个房子如果窗户破了，没有人去修补，隔不久，其它的窗户也会莫名其妙地被人打破；一面墙，如果出现一些涂鸦没有被清洗掉，很快的，墙上就布满了乱七八糟、不堪入目的东西；一个很干净的地方，人们不好意思丢垃圾，但是一旦地上有垃圾出现之后，人就会毫不犹豫地抛，丝毫不觉羞愧。一幢有少许破窗的建筑为例，如果那些窗不被修理好，可能将会有 破坏者 破坏更多的窗户。最终他们甚至会闯入建筑内，如果发现无人居住，也许就在那里定居或者纵火。一面墙，如果出现一些涂鸦没有被清洗掉，很快的，墙上就布满了乱七八糟、不堪入目的东西；一条人行道有些许纸屑，不久后就会有更多垃圾，最终人们会视若理所当然地将垃圾顺手丢弃在地上。这个现象，就是犯罪心理学中的破窗效应。 而现在的处理方式则是利用的是，自我焦点效应，在众目睽睽之下，尤其是在安检人员和乘客不太出现那种无视规则的人，除非… 自我焦点效应,spotlight effect ，也叫做社会焦点效应，是人们 高估 周围人对自己外表和行为关注度的一种表现。焦点效应意味着人类往往会把自己看作一切的中心，并且直觉地高估别人对我们的注意程度。焦点效应其实是 每个人都会 有的体验，这种心理状态让我们过度关注自我，过分在意聚会或者工作集会时周围人们对我们的关注程度。国外有实验和结论的,大体就是除非你不穿衣服,或者在讲和做那些引人注意的事(通常跟性,死亡有关)即使你穿的像只猴子或者漂亮的像只孔雀,也么有几个人会留意你，大家都是看的自己,同时希望别人看自己. 生活处处皆学问，不得不说其实厉害的人无处不在。 很多人有仇视社会，自己如何努力都能做到一些事情，而觉得社会不公，觉得自己就是基于不到，以下是我辍学工作这么多年体会得到一些点可以一起分享下 在互联网看到的内容来源于你想看到的内容。 上学有没有用我不知道，我只知道学历比我高的人他看问题比我快准狠，我指的是“学成” 楼下一个男人病得要死，那间壁的一家唱着留声机，对面是弄孩子。墙上有两个人狂笑，还有打牌声。河中的船上有女人哭着她死去的母亲。人类的悲欢并不相通，我只是觉得他们吵闹。 鲁迅 - 《而已集》 当你老了，回顾一生，就会发觉：什么时候出国读书，什么时候决定做第一份职业、何时选定了对象而恋爱、什么时候结婚，其实都是命运的巨变。只是当时站在三岔路口，眼见风云千樯，你作出选择的那一日，在日记上，相当沉闷和平凡，当时还以为是生命中普通的一天。 陶杰-《杀鹌鹑的少女》 一下再也想不起来这么多了 以后慢慢补充吧。 热爱生活，有时候等待回报的时候不要自暴自弃，在这段时间不如多学习！🎉🎉🎉🎉 生活随处可见一斑20171123.md","categories":[{"name":"生活","slug":"生活","permalink":"http://blog.msiter.com/categories/生活/"}],"tags":[{"name":"无趣，心理学","slug":"无趣，心理学","permalink":"http://blog.msiter.com/tags/无趣，心理学/"}],"keywords":[{"name":"生活","slug":"生活","permalink":"http://blog.msiter.com/categories/生活/"}]},{"title":"使用 NodeJS APNS 给你的应用发消息","slug":"使用 NodeJS APNS 给你的应用发消息","date":"2017-11-22T17:02:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"sy NodeJS APNS g,jndyyfxx-20171122.html","link":"","permalink":"http://blog.msiter.com/sy NodeJS APNS g,jndyyfxx-20171122.html","excerpt":"用到了小米的 MiPushSDK 今天出现了问题，总之无论如何就吃错误。在跟他们的开发人员进行交流的同时，我想看看是谁的问题，所以有了以下的经历。Demo Github 地址","text":"用到了小米的 MiPushSDK 今天出现了问题，总之无论如何就吃错误。在跟他们的开发人员进行交流的同时，我想看看是谁的问题，所以有了以下的经历。Demo Github 地址 H2 创建推送证书创建推送证书 这个步骤省略 H2 导出 证书.p12 和 key.p12推送证书安装在本地之后 打开 应用 钥匙串访问 找到自己的证书 在需要导出的证书上右键点击 导出 这个东西就是证书.p12 有没有密码都可以 密码会用来一会 openssl 的时候输入 点击这个证书 展开之后会看到一个 Key 右键导出 这个导出的 p12 就是 key.p12 密码设置同上 H2 将导出的 p12 生成为 pemopenssl pkcs12 -clcerts -nokeys -out cert.pem -in cert.p12 # 导出 cert.pem openssl pkcs12 -in key.p12 -out key.pem -nodes # 导出 key.pem 在转换过程中 p12 设置了密码就输入密码 没有输入直接回车就可以在设置 key.pem 的过程中 会向你询问是否设置密码，设置密码需要输入两次 分别是密码和确认密码 H2 开始创建 Nodejs APNS 服务H3 创建 NodeJs项目创建一个 NodeJS 项目 mkdir APNS cd APNS npm init 按照步骤填写信息，之后在生成的package.json 文件中 引入 对于 apn 的支持 \"dependencies\": { \"apn\": \"\" } 总体上看起来是这个样子的 { \"name\": \"apn\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\" }, \"author\": \"\", \"license\": \"ISC\", \"dependencies\": { \"apn\": \"\" } } H3 完成创建一个 index.js 文件 var apn = require(\"apn\"); var tokens = [\"&lt;&lt;you want push device token>>\"]; var service = new apn.Provider({ \"cert\": \"push/cert.pem\", // 根目录下创建 push 文件夹 将文件放置在内，当然你可以放在自己喜欢的位置 \"key\": \"push/key.pem\", \"production\":false }); var note = new apn.Notification({ \"alert\":\"Hello World!\", \"sound\":\"default\" }); // The topic is usually the bundle identifier of your application. note.topic = \"&lt;&lt;you bundle identifier>>\"; note.badge = 0; console.log(`Sending: ${note.compile()} to ${tokens}`); service.send(note, tokens).then( result => { console.log(\"sent:\", result.sent.length); console.log(\"failed:\", result.failed.length); console.log(result.failed); }); // For one-shot notification tasks you may wish to shutdown the connection // after everything is sent, but only call shutdown if you need your // application to terminate. service.shutdown(); 这里面只进行了一些基本的设置，只设置了标题关于消息内容等设置 可以查阅文档或者直接在 apn/lib/notification/ 目录下查看 设置 目前的版本是存在这些的 [\"payload\", \"expiry\", \"priority\", \"alert\", \"body\", \"locKey\", \"locArgs\", \"title\", \"subtitle\", \"titleLocKey\", \"titleLocArgs\", \"action\", \"actionLocKey\", \"launchImage\", \"badge\", \"sound\", \"contentAvailable\", \"mutableContent\", \"mdm\", \"urlArgs\", \"category\", \"threadId\"] H3 测试node index.js 大功告成 使用 NodeJS APNS 给你的应用发消息.md","categories":[{"name":"服务器","slug":"服务器","permalink":"http://blog.msiter.com/categories/服务器/"}],"tags":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"NodeJS","slug":"NodeJS","permalink":"http://blog.msiter.com/tags/NodeJS/"},{"name":"APNs","slug":"APNs","permalink":"http://blog.msiter.com/tags/APNs/"}],"keywords":[{"name":"服务器","slug":"服务器","permalink":"http://blog.msiter.com/categories/服务器/"}]},{"title":"IOS10前 UITextFiled 的 placeholder 的问题","slug":"IOS10前 UITextFiled 的 placeholder 的问题","date":"2017-11-16T01:16:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"IOS10q UITextFiled d placeholder dwt-20171116.html","link":"","permalink":"http://blog.msiter.com/IOS10q UITextFiled d placeholder dwt-20171116.html","excerpt":"The styled string that is displayed when there is no other text in the text field.This property is nil by default. If set, the placeholder string is drawn using system-defined color and the remaining style information (except the text color) of the attributed string. Assigning a new value to this property also replaces the value of the placeholder property with the same string data, albeit without any formatting information. Assigning a new value to this property does not affect any other style-related properties of the text field 这是官方的一片解释，看着都很不错的～","text":"The styled string that is displayed when there is no other text in the text field.This property is nil by default. If set, the placeholder string is drawn using system-defined color and the remaining style information (except the text color) of the attributed string. Assigning a new value to this property also replaces the value of the placeholder property with the same string data, albeit without any formatting information. Assigning a new value to this property does not affect any other style-related properties of the text field 这是官方的一片解释，看着都很不错的～ 然而 今天我们的巨头设计师来找我，说我的输入框不居中.我不以为然，怎么可能～因为我的设备上是好的拿来手机一看，还真是，，，好吧 赶紧找原因吧，因为我的设备是IOS11 所以我怀疑是不是IOS10的问题。之后找了一些资料发现 Vertically centering a UITextField’s attributedPlaceholderuitextfield attributedplaceholder center Google 发觉这个问题还是普遍存在的 有不少人给处理自己的做法比如： kean在 Stackflow中的回答 NSMutableParagraphStyle *style = [self.addressBar.defaultTextAttributes[NSParagraphStyleAttributeName] mutableCopy]; style.minimumLineHeight = self.addressBar.font.lineHeight - (self.addressBar.font.lineHeight - [UIFont fontWithName:@\"Gotham-BookItalic\" size:14.0].lineHeight) / 2.0; self.addressBar.attributedPlaceholder = [[NSAttributedString alloc] initWithString:@\"Placeholder text\" attributes:@{ NSForegroundColorAttributeName: [UIColor colorWithRed:79/255.0f green:79/255.0f blue:79/255.0f alpha:0.5f], NSFontAttributeName : [UIFont fontWithName:@\"Gotham-BookItalic\" size:14.0], NSParagraphStyleAttributeName : style } ]; 另外他也给出了另一种方法 You could also override a - (CGRect)placeholderRectForBounds:(CGRect)bounds; method in UITextField subclass. It’s messy, but it works :) 还有很多搜到的方法 我就不一一赘述了。他们的方法或多或少的都没很麻烦，而且需要进行适配，比如这种调整位置的是可以的。但是IOS11 位置又好了怎么办呢？最终找到如下的方法，特此记录一下 - (CGRect)placeholderRectForBounds:(CGRect)bounds { return CGRectMake(0, 0 , self.bounds.size.width, self.bounds.size.height); } - (void)drawPlaceholderInRect:(CGRect)rect { [super drawPlaceholderInRect:CGRectMake(0, 0 , self.bounds.size.width, self.bounds.size.height)]; } IOS10前 UITextFiled 的 placeholder 的问题.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/tags/IOS/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"WebView 与 Html Input File 以及 Upload File 出现的问题","slug":"WebView 与 Html Input Bug","date":"2017-10-26T04:10:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"WebView y Html Input Bug-20171026.html","link":"","permalink":"http://blog.msiter.com/WebView y Html Input Bug-20171026.html","excerpt":"在项目中使用了WebView来显示一些内容，之后就遇到了一些问题。总结了一下","text":"在项目中使用了WebView来显示一些内容，之后就遇到了一些问题。总结了一下 你还很年轻,将来你会遇到很多人,经历很多事,得到很多,也会失去很多&lt;br/&gt;&lt;br/&gt;但无论如何,有两样东西,你绝不能丢弃,一个叫良心,另一个叫理想 H2 遇到 Input File 出现的 崩溃问题这个问题其实还是比较好解决 无非就是权限问题 具体的key值 请直接访问 Cocoa Keys H2 Model 的ViewController 在上传文件后 会直接 dismiss掉解决办法 在 Model 出来的 ViewController 加入 UINavigationController 之后重写 UINavigationController 的方法 -(void)dismissViewControllerAnimated:(BOOL)flag completion:(void (^)(void))completion{ if (self.presentedViewController) { [super dismissViewControllerAnimated:flag completion:completion]; } } H3 自己重写pan dismiss 方法的障碍解决在我们想重写dismiss的方法时，会绑定一个手势。但是在 WebView中已经存在了很多手势了。其中就包括 两个 UIScreenEdgePanGestureRecognizer，一个进行前进操作 一个进行后退操作 我们想重写pan方法进行前进后退dismiss的话，暂时只有两种办法，接下来我们看看那种方法可以使用吧 H4 第一种 自己去写 WebView 中的 pan 手势首先想到的就是这个方法，因为这个方法很省事儿，可定义程度高，当然这是可行的情况下 事实证明，我们在第一个问题就被拌住了，我们没有办法去渐进式的 前进网页 和 后退 所以这个问题不得不放弃 H4 第二种 使用 UIGestureRecognizerDelegate 来暂时关闭 webview中的手势这个方法最终实践是可以的 首先我们获取到 后退的手势 在创建 WebView 之后，我们这样获取 H5 获取到 手势 并且设置 delegatefor (UIGestureRecognizer *reconizer in self.wkWebView.gestureRecognizers) { /// 如果获取的 手势 类型是 ScreenEdgePanGestureRecognizer 类型 if ([reconizer isKindOfClass:UIScreenEdgePanGestureRecognizer.class] ) { /// 如果手势对象是 返回的收视对象 作出以下处理 if (((UIScreenEdgePanGestureRecognizer*)reconizer).edges == UIRectEdgeLeft) { reconizer.delegate = self; } /// 该手势就是 前进手势 if (((UIScreenEdgePanGestureRecognizer*)reconizer).edges == UIRectEdgeRight) { } } } H5 根据WebView 是否可以返回 控制手势是否可用获取到 delegate之后我们就可以进行操作了 接下来实现 delegate 的方法 /// 当WebView 不可以返回到时候，我们不让该手势触发 -(BOOL)gestureRecognizerShouldBegin:(UIGestureRecognizer *)gestureRecognizer{ return self.wkWebView.canGoBack; } H5 写 推出视图的方法-(instancetype)initWithRootViewController:(UIViewController *)rootViewController{ self = [super initWithRootViewController:rootViewController]; if (self) { _presentdAnimation = [[BaseViewControllerPresentdAnimation alloc] init]; _dismissedAnimation = [[BaseViewControllerDismissedAnimation alloc] init]; _interactiveTransitioning = [[BasePresentdAnimationInteractiveTransition alloc]init]; self.navigationBarHidden = true; self.transitioningDelegate = self; self.modalPresentationCapturesStatusBarAppearance = true; /// 在获取到 RootViewController 完成 手势的绑定 这样在 Wkwebview 手势不可用的时候 该手势就可以使用了 _panGestureRecognizer = [[UIScreenEdgePanGestureRecognizer alloc] initWithTarget:self action:@selector(handlePanGestureRecognizerMethod:)]; _panGestureRecognizer.edges = UIRectEdgeLeft; [rootViewController.view addGestureRecognizer:_panGestureRecognizer]; } return self; } -(id&lt;UIViewControllerAnimatedTransitioning>)animationControllerForPresentedController:(UIViewController *)presented presentingController:(UIViewController *)presenting sourceController:(UIViewController *)source{ return _presentdAnimation ; } -(id&lt;UIViewControllerAnimatedTransitioning>)animationControllerForDismissedController:(UIViewController *)dismissed{ return _dismissedAnimation; } -(id&lt;UIViewControllerInteractiveTransitioning>)interactionControllerForDismissal:(id&lt;UIViewControllerAnimatedTransitioning>)animator{ if (_dismissedAnimation.isInteraction) { return _interactiveTransitioning; } return nil; } -(void)handlePanGestureRecognizerMethod:(UIPanGestureRecognizer *)pan{ CGPoint point = [pan translationInView:self.view]; switch (pan.state) { case UIGestureRecognizerStateBegan: self.dismissedAnimation.isInteraction = true; [self.viewControllers.firstObject dismissViewControllerAnimated:true completion:nil]; break; case UIGestureRecognizerStateChanged: [_interactiveTransitioning updateInteractiveTransition: (CGFloat)point.x/CGRectGetWidth(self.view.frame)]; break; default: _dismissedAnimation.isInteraction = false; CGFloat locationX = ABS(point.x); CGFloat velocityX = [pan velocityInView:self.view].x; if (velocityX >= 500 || locationX >= CGRectGetWidth(self.view.frame)/2) { [_interactiveTransitioning finishInteractiveTransition]; }else{ [_interactiveTransitioning cancelInteractiveTransition]; } break; } } 效果如下： WebView 与 Html Input Bug.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"WKWebView","slug":"WKWebView","permalink":"http://blog.msiter.com/tags/WKWebView/"},{"name":"WebView","slug":"WebView","permalink":"http://blog.msiter.com/tags/WebView/"},{"name":"UIWebView","slug":"UIWebView","permalink":"http://blog.msiter.com/tags/UIWebView/"},{"name":"Input","slug":"Input","permalink":"http://blog.msiter.com/tags/Input/"},{"name":"File","slug":"File","permalink":"http://blog.msiter.com/tags/File/"},{"name":"Bug","slug":"Bug","permalink":"http://blog.msiter.com/tags/Bug/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"IOS shadowColor 动画 卡顿","slug":"IOS shadowColor 动画 卡顿","date":"2017-10-12T18:00:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"IOS shadowColor dh q,kd-20171012.html","link":"","permalink":"http://blog.msiter.com/IOS shadowColor dh q,kd-20171012.html","excerpt":"最近开发的时候遇见了一件怪事儿，做了一个 UIViewControllerContextTransitioning,在同事的手机上跳转会卡顿。在此之前写的跳转动画都没有卡顿的现象。最终终于发现了问题的所在在于 shadowColor ，在跳转的时候我设置了一个阴影增加层级层次效果。","text":"最近开发的时候遇见了一件怪事儿，做了一个 UIViewControllerContextTransitioning,在同事的手机上跳转会卡顿。在此之前写的跳转动画都没有卡顿的现象。最终终于发现了问题的所在在于 shadowColor ，在跳转的时候我设置了一个阴影增加层级层次效果。 @implementation BaseViewControllerPresentdAnimation -(NSTimeInterval)transitionDuration:(id&lt;UIViewControllerContextTransitioning>)transitionContext { return 0.5; } -(void)animateTransition:(id&lt;UIViewControllerContextTransitioning>)transitionContext{ UIViewController *toViewController = [transitionContext viewControllerForKey:(UITransitionContextToViewControllerKey)]; UIView *containerView = [transitionContext containerView]; UIView *coverView = [UIView.alloc initWithFrame:containerView.bounds]; coverView.backgroundColor = [UIColor.blackColor colorWithAlphaComponent:0]; [containerView addSubview:coverView]; toViewController.view.transform = CGAffineTransformTranslate(toViewController.view.transform, CGRectGetWidth(toViewController.view.frame), 0); [containerView addSubview:toViewController.view]; [self makeShadowMethod:toViewController]; [UIView animateWithDuration:[self transitionDuration:transitionContext] animations:^{ toViewController.view.transform = CGAffineTransformIdentity; coverView.backgroundColor = [UIColor.blackColor colorWithAlphaComponent:0.3]; } completion:^(BOOL finished) { [coverView removeFromSuperview]; [transitionContext completeTransition:true]; }]; } -(void)makeShadowMethod:(UIViewController *)toViewController{ toViewController.view.clipsToBounds = false; /// 需要添加这句话，可以使动画不再卡顿 toViewController.view.layer.shadowPath = [UIBezierPath bezierPathWithRect:toViewController.view.bounds].CGPath; toViewController.view.layer.shadowRadius = 2; toViewController.view.layer.shadowColor = [UIColor.blackColor colorWithAlphaComponent:0.4].CGColor; toViewController.view.layer.shadowOffset = CGSizeMake(-3.0f,0); toViewController.view.layer.shadowOpacity = 0.4; } @end 知道这个解决方案是看到了 Lu_Ca的博客 之后就很好奇为什么这个代码会有这么神奇的作用呢？ SpeedBoy007的专栏 只要你提前告诉CoreAnimation你要渲染的View的形状Shape,就会减少离屏渲染计算 [myView.layer setShadowPath：[[UIBezierPath bezierPathWithRect：myView.bounds] CGPath]; 加上这行代码，就减少离屏渲染时间，大大提高了性能 IOS shadowColor 动画 卡顿.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"Objective-C","slug":"Objective-C","permalink":"http://blog.msiter.com/tags/Objective-C/"},{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"一杯敬自由，一杯敬死亡","slug":"2017-9-4 有感","date":"2017-09-04T03:25:00.000Z","updated":"2018-08-29T10:33:16.494Z","comments":true,"path":"2017-9-4 yg-20170904.html","link":"","permalink":"http://blog.msiter.com/2017-9-4 yg-20170904.html","excerpt":"","text":"一杯敬自由，一杯敬死亡 &lt;br/&gt;&lt;br/&gt;宽恕我的平凡，驱散了迷惘&lt;br/&gt;&lt;br/&gt;好吧天亮之后总是潦草离场&lt;br/&gt;&lt;br/&gt;清醒的人最荒唐&lt;br/&gt;&lt;br/&gt;好吧天亮之后总是潦草离场&lt;br/&gt;&lt;br/&gt; 转眼二十多年过去了，今年22岁，身高178，体重145斤。这两年，体重没有变高，但是体重和年龄确实变大了不少，身体变弱了很多，出去玩的时候，稍微运动下，第二天身体就会给出非常明显的反应，酸痛感十足 可怕的不是变大了，身体变差了，而是默默的接受了这各种设定，给自己一个改变不了的理由了。 这些年，在北京，从最开始的创业公司遍天下，到现在的寥寥数几个。看惯了，失败，看惯了，别人的成功。看惯了以前看不惯的 变老的不只是身体，更多的是那份心。 以前不知道的知道，但是少了的是，时间，拼，劲儿，其实归根结底还是对于目前的不敢放弃，从头来，也许会更好，但是不敢再去试验了。 当你走进这欢乐场背上所有的梦与想各色的脸上各色的妆没人记得你的模样三巡酒过你在角落固执的唱着苦涩的歌听他在喧嚣里被淹没你拿起酒杯对自己说一杯敬朝阳，一杯敬月光唤醒我的向往，温柔了寒窗于是可以不回头的逆风飞翔不怕心头有雨，眼底有霜一杯敬故乡，一杯敬远方守着我的善良，催着我成长所以南北的路从此不再漫长灵魂不再无处安放一杯敬明天，一杯敬过往支撑我的身体，厚重了肩膀虽然从不相信所谓山高水长人生苦短何必念念不忘一杯敬自由，一杯敬死亡宽恕我的平凡，驱散了迷惘好吧天亮之后总是潦草离场清醒的人最荒唐好吧天亮之后总是潦草离场清醒的人最荒唐 是对还是错，其实你知道的，只是不敢 2017-9-4 有感.md","categories":[{"name":"牢骚","slug":"牢骚","permalink":"http://blog.msiter.com/categories/牢骚/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://blog.msiter.com/tags/生活/"},{"name":"悲观","slug":"悲观","permalink":"http://blog.msiter.com/tags/悲观/"}],"keywords":[{"name":"牢骚","slug":"牢骚","permalink":"http://blog.msiter.com/categories/牢骚/"}]},{"title":"AsyncDisplayKit 2.1 Gif错误，以及解决方法","slug":"AsyncDisplayKit 2.1 Gif错误","date":"2017-08-22T14:45:00.000Z","updated":"2018-08-29T10:33:16.494Z","comments":true,"path":"AsyncDisplayKit 2.1 Gifcw-20170822.html","link":"","permalink":"http://blog.msiter.com/AsyncDisplayKit 2.1 Gifcw-20170822.html","excerpt":"在使用 AsyncDisplayKit 遇到了一些问题，因为工作需要必须支持IOS7，所以选择了 AsyncDisplayKit 2.1版本。但是在使用 其中的 展示gif的时候出现了一些问题。","text":"在使用 AsyncDisplayKit 遇到了一些问题，因为工作需要必须支持IOS7，所以选择了 AsyncDisplayKit 2.1版本。但是在使用 其中的 展示gif的时候出现了一些问题。 目前的 修改库 版本为 在使用的时候出现了 GIF 有的时候出现，有的是不出现，有的时候出现了，却不动的情况。 最终找到解决方案在。 AsyncDisplayKit Pull Request 3057 代码在于 AsyncDisplayKit commit d270577f23dca63c69bc6cd0e4cea6652733a376 但是现在 AsyncDisokayKit 已经开始支持 IOS8版本以上了。并且已经移动到了 Texture 所以我们只能手动自己创建了一个版本了。 解决方案 自己本地 local 库 修改 2.1 版本的代码 使用我已经修改好的代码库 引入 pod AsyncDisplayKitFix —————————————— 2017年9月4号 再次修复了，两个问题，当然只是我的项目中的。记录一下 第一个. 关于 ASTableNode 刷新某一个section或者某一个行的时候，会启动一个验证方法，但是这个方法是验证所有的section，我分别控制第一个或者第二个secrion就会出现刷新前和刷新后的数量对不上，而导致报错。 在文件 _ASHierarchyChangeSet.mm _validateUpdate 修改验证 第二个. 在ASTextNode赋值的时候，我记得没错误的话。官方的例子是 可以判断 ASTextNode的attritedString 是否为空，来做一些布局的变化。但是在实际使用中，发现了它的方法，写的确实 - (void)setAttributedText:(NSAttributedString *)attributedText { if (attributedText == nil) { attributedText = [[NSAttributedString alloc] initWithString:@\"\" attributes:nil]; } // Don't hold textLock for too long. { ASDN::MutexLocker l(__instanceLock__); if (ASObjectIsEqual(attributedText, _attributedText)) { return; } 这种问题就是会一直都不能为nil。故而修复为 - (void)setAttributedText:(NSAttributedString *)attributedText { if (attributedText == nil) { return; } // Don't hold textLock for too long. { ASDN::MutexLocker l(__instanceLock__); if (ASObjectIsEqual(attributedText, _attributedText)) { return; } AsyncDisplayKit 2.1 Gif错误.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"Objective-C","slug":"Objective-C","permalink":"http://blog.msiter.com/tags/Objective-C/"},{"name":"AsyncDisplayKit","slug":"AsyncDisplayKit","permalink":"http://blog.msiter.com/tags/AsyncDisplayKit/"},{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"约束教程","slug":"约束教程","permalink":"http://blog.msiter.com/tags/约束教程/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"Spring boot Mybatis 学习","slug":"Spring boot Mybatis 学习","date":"2017-07-21T18:25:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Spring boot Mybatis xx-20170721.html","link":"","permalink":"http://blog.msiter.com/Spring boot Mybatis xx-20170721.html","excerpt":"开始前的闲聊一直都想回家，北京呆不起。想回家，却发现，家里的开发职位都是java的，，，那没办法，捡起来吧","text":"我年华虚度，空有一身疲倦 H2 开始前的闲聊一直都想回家，北京呆不起。想回家，却发现，家里的开发职位都是java的，，，那没办法，捡起来吧 H2 基本设置在创建项目的时候，我们使用了最基本的配置，所以项目没有目录等。我们需要使用maven默认的文件配置 src main -- 开发包 java -- 代码包 resources -- 资源包 test -- 测试包 java -- 代码包 resources -- 资源包 H2 gradle 配置在idea 创建一个 gradle 项目。但是本来在本地安装了一个 4.0 版本的 gradle，我在idea设置了一个 local gradle，但是却出现了一个问题。 启动服务器的时候，出现了莫名的问题最后在statckflow中发现了解决办法就是使用默认的gradle。 之后配置 gradle 安装信息 group &#39;Farrom&#39; version &#39;1.0-SNAPSHOT&#39; apply plugin: &#39;java&#39; apply plugin: &#39;war&#39; apply plugin: &#39;idea&#39; sourceCompatibility = 1.8 repositories { jcenter() maven { url &quot;http://repo.spring.io/snapshot&quot; } maven { url &quot;http://repo.spring.io/milestone&quot; } } dependencies { // 阿里巴巴 durid 数据源 compile group: &#39;com.alibaba&#39;, name: &#39;druid&#39;, version: &#39;1.1.1&#39; // 数据 链接 compile group: &#39;mysql&#39;, name: &#39;mysql-connector-java&#39;, version: &#39;6.0.6&#39; // Spring Boot compile group: &#39;org.springframework.boot&#39;, name: &#39;spring-boot-starter-web&#39;, version: &#39;1.5.4.RELEASE&#39; // Mybatis compile group: &#39;org.mybatis&#39;, name: &#39;mybatis&#39;, version: &#39;3.4.4&#39; compile group: &#39;org.mybatis&#39;, name: &#39;mybatis-spring&#39;, version: &#39;1.3.1&#39; compile group: &#39;org.mybatis.spring.boot&#39;, name: &#39;mybatis-spring-boot-starter&#39;, version: &#39;1.3.0&#39; } H3 创建 Spring 配置文件name: Demo server: port: 8090 datasource: url: jdbc:mysql://localhost:3306/parrom?autoReconnect=true&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=utf8 username: root password: 123456 driverClassName: com.mysql.jdbc.Driver mybatis: typeAliasesPackage: com.farrom.domain package com.farrom.config; import com.alibaba.druid.pool.DruidDataSourceFactory; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionFactoryBean; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.transaction.annotation.EnableTransactionManagement; import javax.sql.DataSource; import java.util.Properties; @Configuration @EnableTransactionManagement public class MybatisConfig { @Value(\"${datasource.url}\") private String url; @Value(\"${datasource.driverClassName}\") private String driverClassName; @Value(\"${datasource.username}\") private String username; @Value(\"${datasource.password}\") private String password; @Value(\"${mybatis.typeAliasesPackage}\") private String typeAliasesPackage; /** * 创建数据源 * @Primary 该注解表示在同一个接口有多个实现类可以注入的时候，默认选择哪一个，而不是让@autowire注解报错 */ @Bean public DataSource getDataSource() throws Exception{ Properties props = new Properties(); // props.put(\"driverClassName\", this.driverClassName); ##Loading class `com.mysql.jdbc.Driver'. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver'. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary. props.put(\"url\", this.url); props.put(\"username\", this.username); props.put(\"password\", this.password); return DruidDataSourceFactory.createDataSource(props); } /** * 根据数据源创建SqlSessionFactory */ @Bean(name=\"sqlSessionFactory\") public SqlSessionFactory sqlSessionFactory() throws Exception { SqlSessionFactoryBean sqlSessionFactory = new SqlSessionFactoryBean(); sqlSessionFactory.setDataSource(this.getDataSource()); return sqlSessionFactory.getObject(); } } H4 数据库 emoji mysql 适配。在根目录下的etc创建一个文件,my.cnf。在文件中设置配置 [client] default-character-set=utf8mb4 [mysql] default-character-set=utf8mb4 [mysqld] character-set-client-handshake=FALSE character-set-server=utf8mb4 collation-server=utf8mb4_unicode_ci init-connect=&#39;SET NAMES utf8mb4&#39; 创建Database的时候选择 对一个的编码 该配置不需要设置任何代码。这个时候 sqlsession就已经创建好了 目前就学习了这点。。。 Spring boot Mybatis 学习.md","categories":[{"name":"服务器","slug":"服务器","permalink":"http://blog.msiter.com/categories/服务器/"}],"tags":[{"name":"java","slug":"java","permalink":"http://blog.msiter.com/tags/java/"},{"name":"spring boot","slug":"spring-boot","permalink":"http://blog.msiter.com/tags/spring-boot/"},{"name":"mybatis","slug":"mybatis","permalink":"http://blog.msiter.com/tags/mybatis/"}],"keywords":[{"name":"服务器","slug":"服务器","permalink":"http://blog.msiter.com/categories/服务器/"}]},{"title":"Charles version 4.1 破解 以及 Https 的破译","slug":"charles 4.1 破解","date":"2017-07-10T13:26:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"charles 4.1 pj,x-20170710.html","link":"","permalink":"http://blog.msiter.com/charles 4.1 pj,x-20170710.html","excerpt":"Charles 限时优惠Charles 4 正版限时优惠优惠活动（限时：2016 年 8 月 8 日 - 15 日），优惠 30 元，点击领取优惠券。 简介 Charles 是在 Mac 下常用的网络封包截取工具，在做移动开发时，我们为了调试与服务器端的网络通讯协议，常常需要截取网络封包来分析。","text":"后来我终于知道,它并不是我的花,我只是恰好途径了它的盛放。 H2 Charles 限时优惠Charles 4 正版限时优惠优惠活动（限时：2016 年 8 月 8 日 - 15 日），优惠 30 元，点击领取优惠券。 H2 简介 Charles 是在 Mac 下常用的网络封包截取工具，在做移动开发时，我们为了调试与服务器端的网络通讯协议，常常需要截取网络封包来分析。 Charles 通过将自己设置成系统的网络访问代理服务器，使得所有的网络访问请求都通过它来完成，从而实现了网络封包的截取和分析。 除了在做移动开发中调试端口外，Charles 也可以用于分析第三方应用的通讯协议。配合 Charles 的 SSL 功能，Charles 还可以分析 Https 协议。 Charles 是收费软件，可以免费试用 30 天。试用期过后，未付费的用户仍然可以继续使用，但是每次使用时间不能超过 30 分钟，并且启动时将会有 10 秒种的延时。因此，该付费方案对广大用户还是相当友好的，即使你长期不付费，也能使用完整的软件功能。只是当你需要长时间进行封包调试时，会因为 Charles 强制关闭而遇到影响。 Charles 主要的功能包括： 截取 Http 和 Https 网络封包。 支持重发网络请求，方便后端调试。 支持修改网络请求参数。 支持网络请求的截获并动态修改。 支持模拟慢速网络。 Charles 4 新增的主要功能包括： 支持 Http 2。 支持 IPv6。 H2 安装 Charles去 Charles 的官方网站（http://www.charlesproxy.com）下载最新版的 Charles 安装包，是一个 dmg 后缀的文件。打开后将 Charles 拖到 Application 目录下即完成安装。 H2 将 Charles 设置成系统代理之前提到，Charles 是通过将自己设置成代理服务器来完成封包截取的，所以使用 Charles 的第一步是将其设置成系统的代理服务器。 启动 Charles 后，第一次 Charles 会请求你给它设置系统代理的权限。你可以输入登录密码授予 Charles 该权限。你也可以忽略该请求，然后在需要将 Charles 设置成系统代理时，选择菜单中的 “Proxy” -&gt; “Mac OS X Proxy” 来将 Charles 设置成系统代理。如下所示： 之后，你就可以看到源源不断的网络请求出现在 Charles 的界面中。 需要注意的是，Chrome 和 Firefox 浏览器默认并不使用系统的代理服务器设置，而 Charles 是通过将自己设置成代理服务器来完成封包截取的，所以在默认情况下无法截取 Chrome 和 Firefox 浏览器的网络通讯内容。如果你需要截取的话，在 Chrome 中设置成使用系统的代理服务器设置即可，或者直接将代理服务器设置成 127.0.0.1:8888 也可达到相同效果。 H2 Charles 主界面介绍 Charles 主要提供两种查看封包的视图，分别名为 “Structure” 和 “Sequence”。 Structure 视图将网络请求按访问的域名分类。 Sequence 视图将网络请求按访问的时间排序。 大家可以根据具体的需要在这两种视图之前来回切换。请求多了有些时候会看不过来，Charles 提供了一个简单的 Filter 功能，可以输入关键字来快速筛选出 URL 中带指定关键字的网络请求。 对于某一个具体的网络请求，你可以查看其详细的请求内容和响应内容。如果请求内容是 POST 的表单，Charles 会自动帮你将表单进行分项显示。如果响应内容是 JSON 格式的，那么 Charles 可以自动帮你将 JSON 内容格式化，方便你查看。如果响应内容是图片，那么 Charles 可以显示出图片的预览。 H2 过滤网络请求通常情况下，我们需要对网络请求进行过滤，只监控向指定目录服务器上发送的请求。对于这种需求，以下几种办法： 方法一：在主界面的中部的 Filter 栏中填入需要过滤出来的关键字。例如我们的服务器的地址是：http://yuantiku.com , 那么只需要在 Filter 栏中填入 yuantiku 即可。 方法二：在 Charles 的菜单栏选择 “Proxy”-&gt;”Recording Settings”，然后选择 Include 栏，选择添加一个项目，然后填入需要监控的协议，主机地址，端口号。这样就可以只截取目标网站的封包了。如下图所示： 通常情况下，我们使用方法一做一些临时性的封包过滤，使用方法二做一些经常性的封包过滤。 方法三：在想过滤的网络请求上右击，选择 “Focus”，之后在 Filter 一栏勾选上 Focussed 一项，如下图所示： 这种方式可以临时性的，快速地过滤出一些没有通过关键字的一类网络请求。 H2 截取 iPhone 上的网络封包Charles 通常用来截取本地上的网络封包，但是当我们需要时，我们也可以用来截取其它设备上的网络请求。下面我就以 iPhone 为例，讲解如何进行相应操作。 H3 Charles 上的设置要截取 iPhone 上的网络请求，我们首先需要将 Charles 的代理功能打开。在 Charles 的菜单栏上选择 “Proxy”-&gt;”Proxy Settings”，填入代理端口 8888，并且勾上 “Enable transparent HTTP proxying” 就完成了在 Charles 上的设置。如下图所示: H3 iPhone 上的设置首先我们需要获取 Charles 运行所在电脑的 IP 地址，Charles 的顶部菜单的 “Help”-&gt;”Local IP Address”，即可在弹出的对话框中看到 IP 地址，如下图所示： 在 iPhone 的 “ 设置 “-&gt;” 无线局域网 “ 中，可以看到当前连接的 wifi 名，通过点击右边的详情键，可以看到当前连接上的 wifi 的详细信息，包括 IP 地址，子网掩码等信息。在其最底部有「HTTP 代理」一项，我们将其切换成手动，然后填上 Charles 运行所在的电脑的 IP，以及端口号 8888，如下图所示： 设置好之后，我们打开 iPhone 上的任意需要网络通讯的程序，就可以看到 Charles 弹出 iPhone 请求连接的确认菜单（如下图所示），点击 “Allow” 即可完成设置。 H2 截取 Https 通讯信息H3 安装证书如果你需要截取分析 Https 协议相关的内容。那么需要安装 Charles 的 CA 证书。具体步骤如下。 首先我们需要在 Mac 电脑上安装证书。点击 Charles 的顶部菜单，选择 “Help” -&gt; “SSL Proxying” -&gt; “Install Charles Root Certificate”，然后输入系统的帐号密码，即可在 KeyChain 看到添加好的证书。如下图所示： 需要注意的是，即使是安装完证书之后，Charles 默认也并不截取 Https 网络通讯的信息，如果你想对截取某个网站上的所有 Https 网络请求，可以在该请求上右击，选择 SSL proxy，如下图所示： 这样，对于该 Host 的所有 SSL 请求可以被截取到了。 H3 截取移动设备中的 Https 通讯信息如果我们需要在 iOS 或 Android 机器上截取 Https 协议的通讯内容，还需要在手机上安装相应的证书。点击 Charles 的顶部菜单，选择 “Help” -&gt; “SSL Proxying” -&gt; “Install Charles Root Certificate on a Mobile Device or Remote Browser”，然后就可以看到 Charles 弹出的简单的安装教程。如下图所示： 按照我们之前说的教程，在设备上设置好 Charles 为代理后，在手机浏览器中访问地址：http://charlesproxy.com/getssl，即可打开证书安装的界面，安装完证书后，就可以截取手机上的 Https 通讯内容了。不过同样需要注意，默认情况下 Charles 并不做截取，你还需要在要截取的网络请求上右击，选择 SSL proxy 菜单项。 H2 模拟慢速网络在做移动开发的时候，我们常常需要模拟慢速网络或者高延迟的网络，以测试在移动网络下，应用的表现是否正常。Charles 对此需求提供了很好的支持。 在 Charles 的菜单上，选择 “Proxy”-&gt;”Throttle Setting” 项，在之后弹出的对话框中，我们可以勾选上 “Enable Throttling”，并且可以设置 Throttle Preset 的类型。如下图所示： 如果我们只想模拟指定网站的慢速网络，可以再勾选上图中的 “Only for selected hosts” 项，然后在对话框的下半部分设置中增加指定的 hosts 项即可。 H2 修改网络请求内容有些时候为了调试服务器的接口，我们需要反复尝试不同参数的网络请求。Charles 可以方便地提供网络请求的修改和重发功能。只需要在以往的网络请求上点击右键，选择 “Edit”，即可创建一个可编辑的网络请求。如下所示： 我们可以修改该请求的任何信息，包括 URL 地址、端口、参数等，之后点击 “Execute” 即可发送该修改后的网络请求（如下图所示）。Charles 支持我们多次修改和发送该请求，这对于我们和服务器端调试接口非常方便，如下图所示： H2 给服务器做压力测试我们可以使用 Charles 的 Repeat 功能来简单地测试服务器的并发处理能力，方法如下。 我们在想打压的网络请求上（POST 或 GET 请求均可）右击，然后选择 「Repeat Advanced」菜单项，如下所示： 接着我们就可以在弹出的对话框中，选择打压的并发线程数以及打压次数，确定之后，即可开始打压。 悄悄说一句，一些写得很弱的投票网站，也可以用这个办法来快速投票。当然，我也拿 Charles 的 Repeat 功能给一些诈骗的钓鱼网站喂了不少垃圾数据，上次不小心还把一个钓鱼网站的数据库打挂了，嗯，请叫我雷锋。 H2 修改服务器返回内容有些时候我们想让服务器返回一些指定的内容，方便我们调试一些特殊情况。例如列表页面为空的情况，数据异常的情况，部分耗时的网络请求超时的情况等。如果没有 Charles，要服务器配合构造相应的数据显得会比较麻烦。这个时候，使用 Charles 相关的功能就可以满足我们的需求。 根据具体的需求，Charles 提供了 Map 功能、 Rewrite 功能以及 Breakpoints 功能，都可以达到修改服务器返回内容的目的。这三者在功能上的差异是： Map 功能适合长期地将某一些请求重定向到另一个网络地址或本地文件。 Rewrite 功能适合对网络请求进行一些正则替换。 Breakpoints 功能适合做一些临时性的修改。 H3 Map 功能Charles 的 Map 功能分 Map Remote 和 Map Local 两种，顾名思义，Map Remote 是将指定的网络请求重定向到另一个网址请求地址，Map Local 是将指定的网络请求重定向到本地文件。 在 Charles 的菜单中，选择 “Tools”-&gt;”Map Remote” 或 “Map Local” 即可进入到相应功能的设置页面。 对于 Map Remote 功能，我们需要分别填写网络重定向的源地址和目的地址，对于不需要限制的条件，可以留空。下图是一个示例，我将所有 ytk1.yuanku.ws（测试服务器）的请求重定向到了 www.yuantiku.com（线上服务器）。 对于 Map Local 功能，我们需要填写的重定向的源地址和本地的目标文件。对于有一些复杂的网络请求结果，我们可以先使用 Charles 提供的 “Save Response…” 功能，将请求结果保存到本地（如下图所示），然后稍加修改，成为我们的目标映射文件。 下图是一个示例，我将一个指定的网络请求通过 Map Local 功能映射到了本地的一个经过修改的文件中。 Map Local 在使用的时候，有一个潜在的问题，就是其返回的 Http Response Header 与正常的请求并不一样。这个时候如果客户端校验了 Http Response Header 中的部分内容，就会使得该功能失效。解决办法是同时使用 Map Local 以下面提到的 Rewrite 功能，将相关的 Http 头 Rewrite 成我们希望的内容。 H3 Rewrite 功能Rewrite 功能功能适合对某一类网络请求进行一些正则替换，以达到修改结果的目的。 例如，我们的客户端有一个 API 请求是获得用户昵称，而我当前的昵称是 “tangqiaoboy”，如下所示： 我们想试着直接修改网络返回值，将 tangqiaoboy 换成成 iosboy。于是我们启用 Rewrite 功能，然后设置如下的规则： 完成设置之后，我们就可以从 Charles 中看到，之后的 API 获得的昵称被自动 Rewrite 成了 iosboy，如下图所示： H3 Breakpoints 功能上面提供的 Rewrite 功能最适合做批量和长期的替换，但是很多时候，我们只是想临时修改一次网络请求结果，这个时候，使用 Rewrite 功能虽然也可以达到目的，但是过于麻烦，对于临时性的修改，我们最好使用 Breakpoints 功能。 Breakpoints 功能类似我们在 Xcode 中设置的断点一样，当指定的网络请求发生时，Charles 会截获该请求，这个时候，我们可以在 Charles 中临时修改网络请求的返回内容。 下图是我们临时修改获取用户信息的 API，将用户的昵称进行了更改，修改完成后点击 “Execute” 则可以让网络请求继续进行。 需要注意的是，使用 Breakpoints 功能将网络请求截获并修改过程中，整个网络请求的计时并不会暂停，所以长时间的暂停可能导致客户端的请求超时。 H2 反向代理Charles 的反向代理功能允许我们将本地的端口映射到远程的另一个端口上。例如，在下图中，我将本机的 61234 端口映射到了远程（www.yuantiku.com）的80端口上了。这样，当我访问本地的 61234 端口时，实际返回的内容会由 www.yuantiku.com 的 80 端口提供。 H2 设置外部代理，解决与翻墙软件的冲突Charles 的原理是把自己设置成系统的代理服务器，但是在中国，由于工作需要，我们常常需要使用 Google 搜索，所以大部分程序员都有自己的翻墙软件，而这些软件的基本原理，也是把自己设置成系统的代理服务器，来做到透明的翻墙。 为了使得两者能够和平共处，我们可以在 Charles 的 External Proxy Settings 中，设置翻墙的代理端口以及相关信息。同时，我们也要关闭相关翻墙软件的自动设置，使其不主动修改系统代理，避免 Charles 失效。 H2 破解 下载特定的版本的Charles以及破解文件 charles.jar 在应用程序中右键Charles，选择“显示包内容”。 依次打开目录：Contents -&gt; Java 用下载的charles.jar替换目录中的charles.jar。 重新打开后还是破解失败的所以需要 点击 Help -&gt; Register Charles 随便输入即可破解完成 H2 总结通过 Charles 软件，我们可以很方便地在日常开发中，截取和调试网络请求内容，分析封包协议以及模拟慢速网络。用好 Charles 可以极大的方便我们对于带有网络请求的 App 的开发和调试。 愿本文帮助大家成为 Charles 的专家，祝大家玩得开心～ 本文全部引用自 唐巧的 Charles 从入门到精通 charles 4.1 破解.md","categories":[{"name":"开发帮助","slug":"开发帮助","permalink":"http://blog.msiter.com/categories/开发帮助/"}],"tags":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"约束教程","slug":"约束教程","permalink":"http://blog.msiter.com/tags/约束教程/"},{"name":"破解","slug":"破解","permalink":"http://blog.msiter.com/tags/破解/"},{"name":"抓包","slug":"抓包","permalink":"http://blog.msiter.com/tags/抓包/"}],"keywords":[{"name":"开发帮助","slug":"开发帮助","permalink":"http://blog.msiter.com/categories/开发帮助/"}]},{"title":"travis-ci 来维护 Cocoapods","slug":"travis-ci 来维护 Cocoapods","date":"2017-05-25T18:54:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"travis-ci lwh Cocoapods-20170525.html","link":"","permalink":"http://blog.msiter.com/travis-ci lwh Cocoapods-20170525.html","excerpt":"","text":"人的一切痛苦，本质上都是对自己的无能的愤怒。——王小波 H2 教程开始前的废话连篇我们公司的app，是在是火不聊了。那么办法了，我们抽象出来一个sdk给别人接吧。这样子的话，我们怎么也可以有些量啊。 最开始使用的Cocoapods 全部代码开发的方式来制作的，在跨过一个又一个的大坑之后，终于到了，要把代码达成 .a 包地步，其实是可以达成 .framework 的。主要是还是因为代码需要兼容 ios 7 。所以必须要使用 达成 static 的方式。 H3 打包首先使用的打包命令，肯定是 xcodebuild 不要问我，如何使用，google吧。 我们使用的命令时 xcodebuild build -project Pods/Pods.xcodeproj -target OddityOcUI 这样子打下来是默认 Iphone sdk版本+realese 版本的，这样子只在真机上运行肯定是没问题啦～ 但是你怎么都得做到可以在模拟器上跑吧。所以就需要接下来的这一句了。 xcodebuild build -project Pods/Pods.xcodeproj -target OddityOcUI -sdk iphonesimulator10.3 后面的是 sdk 版本，不知道版本的可以运行命令 xcodebuild -showsdks H3 现在开始整合 travis-ci既然都找到这里了，我就不跟你bb那么多了。其实我们最多不会写 yml文件嘛。 因为 budild 会遇见非常多的log，我为了解决，尝试使用了。xcpretty 事实证明…… 没啥用处。先放着吧。 language: objective-c osx_image: xcode8.3 os: - osx branches: only: - master before_install: - gem install xcpretty install: - pod install --repo-update before_script: - git config --global user.name \"\" - git config --global user.email \"\" - git clone ${CocoaPodsRepo} script: - set -o pipefail &amp;&amp; xcodebuild build -project Pods/Pods.xcodeproj -target OddityOcUI | xcpretty -c - set -o pipefail &amp;&amp; xcodebuild build -project Pods/Pods.xcodeproj -target OddityOcUI -sdk iphonesimulator10.3 | xcpretty -c - lipo -create build/Release-iphoneos/OddityOcUI/libOddityOcUI.a build/Release-iphonesimulator/OddityOcUI/libOddityOcUI.a -output libOddityOcUI.a after_success: - bash operation.sh - cd OddityUI - git add . - git commit -m '更新通用静态包' - git push --force --quiet \"https://${PersonalAccessTokens}@${GtiHubUrlRepo}\" master:master - git tag ${GtiHubTagVersion} - git push --force --quiet \"https://${PersonalAccessTokens}@${GtiHubUrlRepo}\" ${GtiHubTagVersion}:${GtiHubTagVersion} env: global: - GtiHubTagVersion: 0.3.2 - GtiHubUrlRepo: github.com/OddityUI/OddityUI.git - CocoaPodsRepo : https://github.com/OddityUI/OddityUI travis-ci 来维护 Cocoapods.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"travis-ci","slug":"travis-ci","permalink":"http://blog.msiter.com/tags/travis-ci/"},{"name":"cocoapods","slug":"cocoapods","permalink":"http://blog.msiter.com/tags/cocoapods/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"奇怪的 unrecognized selector sent to instance 问题","slug":"奇怪的 unrecognized selector sent to instance 问题","date":"2017-05-18T15:39:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"q,jgd unrecognized selector sent to instance wt-20170518.html","link":"","permalink":"http://blog.msiter.com/q,jgd unrecognized selector sent to instance wt-20170518.html","excerpt":"","text":"&quot;Nuts！&quot; —— 101空降师副师长麦考里夫将军 我做了一个 黑夜模式 和 白天模式的切换。在ios8.3 的设备上发现了一个问题，会导致崩溃。控制台打出各种奇怪的问题…… unrecognized selector sent to instance 各种对象的 包括 NSURL,UIView,_FCString… 等等，我当时就蒙了，，我到底写出了什么样子的代码…… 他最终报错的地方我发送 NSnotifition的地方，也不具体跳到某一个崩溃的位置。 后来想了一下 unrecognized selector sent to instance 是由于已经销毁了，还调用。并且我的崩溃对象千奇百怪的。崩溃在发送通知的地方。那么问题大概就是出现在这里了吧。我尝试在每一个地方都进行了 dealloc移除通知的方法。果然，问题消失。其实我只移除了一个我自定义的UIView的通知，其他的UIViewControoler，没有移除也是没问题。只是为了保证百分之百…… 猜测： ios8.3的问题，在销毁后没有移除我的通知 引起各种对象的崩溃的原因，估计是因为新的对象占据了理论上销毁的对象的 物理地址 奇怪的 unrecognized selector sent to instance 问题.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"error","slug":"error","permalink":"http://blog.msiter.com/tags/error/"},{"name":"奇怪的问题","slug":"奇怪的问题","permalink":"http://blog.msiter.com/tags/奇怪的问题/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"八爪鱼 获取用户鼠标悬浮层级","slug":"八爪鱼 获取用户鼠标悬浮层级","date":"2017-05-17T14:40:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"bzy hqyhsbxfcj-20170517.html","link":"","permalink":"http://blog.msiter.com/bzy hqyhsbxfcj-20170517.html","excerpt":"公司一直再做新闻聚合，导致我们公司一直在爬取新闻，爬取各种软件的新闻资讯。 后来老板突发奇想，我们不如做一个八抓鱼把…… 那么找了两个同事，预言了一下。那就做吧，之后同时qt开发，紧锣密鼓的展开了。","text":"公司一直再做新闻聚合，导致我们公司一直在爬取新闻，爬取各种软件的新闻资讯。 后来老板突发奇想，我们不如做一个八抓鱼把…… 那么找了两个同事，预言了一下。那就做吧，之后同时qt开发，紧锣密鼓的展开了。 只有强者才懂得斗争，弱者甚至失败都不够资格，他们生来就是被征服的 中途，我们一起聊天的时候，就说到了八抓鱼，是小白用户使用的，所以他们想爬取的内容层级，都是鼠标选中的。所以想做一个鼠标选择dom的js。跟我吐了一会苦水。那个时候不太忙，再加上那会儿我刚做完 新闻详情页的js，觉的有些经验。立马拍胸脯，我来。就有了接下来的代码。 /** * Created by Administrator on 2016/11/2. */ /* 方法说明 * @method 方法名 * @for 所属类名 * @param {参数类型} 参数名 参数说明 * @return {返回值类型} 返回值说明 */ // window.onload=function(){ // // var p = CreateShowDomXmlLabel(); // // document.body.onmousemove = function(e) { // // var dom = e.target; // // HandleSuspendViewMethod(dom); // // p.innerText = GetDomObjectAllFatherDomName(dom); // // RemoveSuspendView(); // 移除之前的显示遮挡层 // // var div = CreateSuspendView(dom); // 创建现在的遮挡层 // // document.body.insertBefore(div,p); // } // } var p = CreateShowDomXmlLabel(); document.body.onmousemove = function (e) { var dom = e.target; HandleSuspendViewMethod(dom); RemoveSuspendView(); // 移除之前的显示遮挡层 var div = CreateSuspendView(dom) document.body.insertBefore(div, p); updateLabelLocationMethod(GetDomObjectAllFatherDomName(dom), div) } /// 用户当前操作的 dom 结构体 var CurrentDomXML; /// 用户创建的遮挡层的id 名称 var SuspendViewID = \"OddityUISuspendView\"; /* * 处理用户滑动时间的开始，如果用户更换了鼠标的对象则 进行接下来的操作。否则就直接返回 * @method HandleSuspendViewMethod * @param {HTMLElment} e 用户当前滑动位置的dom结构对象 */ function HandleSuspendViewMethod(e) { if (e == CurrentDomXML) { return } CurrentDomXML = e }; /* 移除之前创建的 SuspendView * @method RemoveSuspendView */ function RemoveSuspendView() { var removeStr = document.getElementById(SuspendViewID); if (removeStr != null) { removeStr.parentNode.removeChild(removeStr); } }; //获取控件左绝对位置 function getAbsoluteLeft(o) { oLeft = o.offsetLeft while (o.offsetParent != null) { oParent = o.offsetParent oLeft += oParent.offsetLeft o = oParent } return oLeft } //获取控件上绝对位置 function getAbsoluteTop(o) { oTop = o.offsetTop; while (o.offsetParent != null) { oParent = o.offsetParent; oTop += oParent.offsetTop; o = oParent } return oTop } /* 创建遮挡层 根据 传入的 对象的 绝对定位 设置 遮挡层的 位置。以及 遮挡层的 透明度。穿透属性 * @method CreateSuspendView * @param {HTMLElment} e 用户当前滑动位置的dom结构对象 */ function CreateSuspendView(dom) { var div = document.createElement(\"div\"); div.id = SuspendViewID; /// 设置div的 黑色 和透明 div.style.opacity = 0.4; div.style.backgroundColor = \"black\"; div.style.display = \"block\"; div.style.position = \"absolute\"; div.style.borderColor = \"red\" div.style.width = dom.offsetWidth + \"px\"; div.style.height = dom.offsetHeight + \"px\"; div.style.zIndex = 99999 div.style.borderStyle = \"solid\" div.style.top = getAbsoluteTop(dom) + \"px\"; div.style.left = getAbsoluteLeft(dom) + \"px\"; /// 设置鼠标的穿透 效果 div.style.pointerEvents = \"none\"; return div } /// 创建 显示 DOM 结构的 Label function CreateShowDomXmlLabel() { var p = document.createElement(\"p\"); p.innerText = \"\"; p.style.textAlign = \"center\"; p.style.backgroundColor = \"black\"; p.style.lineHeight = \"30px\"; p.style.color = \"white\"; p.style.opacity = 1; p.style.position = \"absolute\"; p.style.height = \"30px\"; p.style.zIndex = 999991 p.style.top = \"0px\"; /// 设置鼠标的穿透 效果 p.style.pointerEvents = \"none\"; document.body.appendChild(p); return p } /// 根据传入的 dom 返回 dom 树 字符串 function GetDomObjectAllFatherDomName(dom) { var domName = \"[ - \" + dom.nodeName; while (dom.parentNode) { domName = dom.parentNode.nodeName + \" > \" + domName; dom = dom.parentNode; } return domName.toLocaleLowerCase() + \" - ]\" } function updateLabelLocationMethod(str, div) { p.innerText = str; var topLocation = div.offsetTop-40 var leftLocation = div.offsetLeft if (topLocation &lt; 10) { topLocation = div.offsetHeight + div.offsetTop + 10 } p.style.top = topLocation + \"px\"; p.style.left = leftLocation + \"px\"; return div } 测试方法，找到任意浏览器，打开开发者模式。在console控制台，复制粘贴这些代码就可以看到效果了。 其实真的是为了凑博客数的…… 八爪鱼 获取用户鼠标悬浮层级.md","categories":[{"name":"Web 前端","slug":"Web-前端","permalink":"http://blog.msiter.com/categories/Web-前端/"}],"tags":[{"name":"八爪鱼","slug":"八爪鱼","permalink":"http://blog.msiter.com/tags/八爪鱼/"},{"name":"html","slug":"html","permalink":"http://blog.msiter.com/tags/html/"},{"name":"js","slug":"js","permalink":"http://blog.msiter.com/tags/js/"},{"name":"Javascript","slug":"Javascript","permalink":"http://blog.msiter.com/tags/Javascript/"},{"name":"鼠标悬浮","slug":"鼠标悬浮","permalink":"http://blog.msiter.com/tags/鼠标悬浮/"}],"keywords":[{"name":"Web 前端","slug":"Web-前端","permalink":"http://blog.msiter.com/categories/Web-前端/"}]},{"title":"WKWebView IOS8 下 loadHtmlString错误","slug":"WKWebView IOS8 下 loadHtmlString错误","date":"2017-05-17T14:40:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"WKWebView IOS8 x loadHtmlStringcw-20170517.html","link":"","permalink":"http://blog.msiter.com/WKWebView IOS8 x loadHtmlStringcw-20170517.html","excerpt":"","text":"不是现实支撑的梦想，而是梦想支撑了现实。——星空日记 做项目的时候，需要展示新闻详情。经过一系列的调研，最终选定为使用 webview。因为需要支持ios7，所以我在详情页就需要同时具备 UIWebView 和 WKWebView，两种。由于IOS8才开始出现的WKWebView，所以自然而然的我当然想从ios8就是用WkwebVIew。毕竟性能好，，，各种夸但是很快就遇见一个问题，本来呢，在ios9，ios10 ，我直接调用方法就可以。 [_wkWebView loadHTMLString:htmlStr baseURL:[NSBundle oddity_shareBundle].bundleURL]; 在htmlStr 里面，我有设置的 本地图片，本地js，本地css。在 ios9-10 一切OK。但是偏偏ios8不行，加载出来本地图片，但是本地js本地css加载不出来…… 一顿谷歌，没找到…… 最终心思，那成，放弃吧…… 直接ios7-8 都是用 UIWebView吧。 找到了一些参考 但是，后来有次无聊的时候，想到了，把js和css全部放在html字符串不就好了吗？ 于是乎，有了这样子的一段代码 if ([[[UIDevice currentDevice] systemVersion] floatValue] >= 8.0 &amp;&amp; [[[UIDevice currentDevice] systemVersion] floatValue] &lt; 9.0) { NSString *file1 = [[NSBundle oddity_shareBundle] pathForResource:@\"jquery\" ofType:@\"js\"]; NSString *file2 = [[NSBundle oddity_shareBundle] pathForResource:@\"bootstrap.min\" ofType:@\"css\"]; NSString *file3 = [[NSBundle oddity_shareBundle] pathForResource:@\"content\" ofType:@\"css\"]; if (file1 &amp;&amp; file2 &amp;&amp; file3) { NSString *fileStr1 = [NSString stringWithContentsOfFile:file1 encoding:(NSUTF8StringEncoding) error:nil]; NSString *fileStr2 = [NSString stringWithContentsOfFile:file2 encoding:(NSUTF8StringEncoding) error:nil]; NSString *fileStr3 = [NSString stringWithContentsOfFile:file3 encoding:(NSUTF8StringEncoding) error:nil]; topHeader = [NSString stringWithFormat:@\"&lt;script type=\\\"text/javascript\\\">%@&lt;/script>&lt;style type=\\\"text/css\\\">%@&lt;/style>&lt;style type=\\\"text/css\\\">%@&lt;/style>\",fileStr1,fileStr2,fileStr3]; } } 其实还可以优化的，比如这个文件其实礼物上只需要读取一次就可以的，但是我现在会每次都读取，这个时候就可以做一个缓存。或者其他云云。 我这里只是提供一个思路。。。 WKWebView IOS8 下 loadHtmlString错误.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"WKWebView","slug":"WKWebView","permalink":"http://blog.msiter.com/tags/WKWebView/"},{"name":"Systematic distinction","slug":"Systematic-distinction","permalink":"http://blog.msiter.com/tags/Systematic-distinction/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"Html 字符串转换成 AttributedString ios版本下的错误","slug":"Html 字符串转换成 AttributedString ios版本下的错误","date":"2017-05-17T14:31:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Html zfczhc AttributedString iosbbxdcw-20170517.html","link":"","permalink":"http://blog.msiter.com/Html zfczhc AttributedString iosbbxdcw-20170517.html","excerpt":"在ios中想要把html字符串转换成 AttributedString ，需要使用以下方法","text":"在ios中想要把html字符串转换成 AttributedString ，需要使用以下方法 请勇敢地向黑夜里走去&lt;br/&gt;&lt;br/&gt;虽然你没有什么成功的机会，虽然你刚上路便可能横死&lt;br/&gt;&lt;br/&gt;但我依然祝福你，并诅咒你。——猫腻 NSMutableAttributedString *attributedString = [[NSMutableAttributedString alloc] initWithData:[title dataUsingEncoding:NSUnicodeStringEncoding] options:@{ NSDocumentTypeDocumentAttribute: NSHTMLTextDocumentType } documentAttributes:nil error:nil]; 这样子的话,html字符串就可以转换为 NSMutableAttributedString 对象，可以展示在可以展示 AttributedString的空间上，但是这个东西是有一定时间的耗时的。尤其是在 tableview上会消耗很大的计算时间，使滑动出现问题。那么我们就需要进行一个一步计算，并且为了更好的节省性能，我们最好做一个缓存。接下来就是我的制作方式 @interface OddityHtmlTitleCache() @property(nonatomic,strong) NSCache *sharedCache; @end @implementation OddityHtmlTitleCache // 创建一个 单利的 管理器 +(OddityHtmlTitleCache *)sharedCache{ static OddityHtmlTitleCache *sharedManager; static dispatch_once_t onceToken; dispatch_once(&amp;onceToken, ^{ sharedManager = [[OddityHtmlTitleCache alloc]init]; sharedManager.sharedCache = [[NSCache alloc] init];; }); return sharedManager; } // 根据 html字符串获取 NSAttributedString -(NSAttributedString *)htmlTitleByString:(NSString *)title{ // 在cache 提取 id viewController = [self.sharedCache objectForKey:title]; if ( viewController) { return viewController; } NSMutableAttributedString *attributedString = [[NSMutableAttributedString alloc] initWithData:[title dataUsingEncoding:NSUnicodeStringEncoding] options:@{ NSDocumentTypeDocumentAttribute: NSHTMLTextDocumentType } documentAttributes:nil error:nil]; [attributedString addAttributes:@{ NSFontAttributeName:[UIFont oddity_font3], } range:[attributedString.string fullRange]]; if (attributedString) { [self.sharedCache setObject:attributedString forKey:title]; } return attributedString; } @end 最开始，我是在ios10，测试的，没有问题，但是我的同时反馈给我。他有崩溃。最终我查到了,在stackoverflow，这个转的方法，在ios9.2之前，异步执行该方法都会错误的。且行且珍惜把…… Html 字符串转换成 AttributedString ios版本下的错误.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"AttributedString","slug":"AttributedString","permalink":"http://blog.msiter.com/tags/AttributedString/"},{"name":"iOS8 html2AttributedString error","slug":"iOS8-html2AttributedString-error","permalink":"http://blog.msiter.com/tags/iOS8-html2AttributedString-error/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"WebKit WkwebView dealloc Crash错误","slug":"WebKit WkwebView dealloc Crash错误","date":"2017-05-17T14:19:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"WebKit WkwebView dealloc Crashcw-20170517.html","link":"","permalink":"http://blog.msiter.com/WebKit WkwebView dealloc Crashcw-20170517.html","excerpt":"","text":"生活总是让我们遍体鳞伤，但到后来，那些受伤的地方一定会成为我们最强壮的地方。——海明威 今天遇到一个奇怪的问题，在我 dismiss UIViewController后，我的UIViewController没有销毁，这导致内存在慢慢的增长，没有销毁。查了一会儿，把问题锁定在了 WKWebView上了，我开始慢慢的注释，调试，最后发现。是我的以下代码的问题。 self.configuration = [[WKWebViewConfiguration alloc] init]; [self.configuration.userContentController addScriptMessageHandler:self name: OddityWkWebViewConfiguration]; _wkWebView = [[OddityCustomWkWebView alloc]initWithFrame:(CGRectZero) configuration:self.configuration]; 在我注释了，addScriptMessageHandler方法之后，dealloc调用了。那么就知道了问题了。在 ViewDidDisapper 方法，removeScriptMessageHandlerForName 就好了 -(void)viewDidDisappear:(BOOL)animated{ [super viewDidDisappear:animated]; [self.configuration.userContentController removeScriptMessageHandlerForName: OddityWkWebViewConfiguration]; } 再后来我发现在ios的测试机上，我推出去之后会直接崩溃。控制台打印出，野指针的问题，最后确认为野指针就是 WkWebView。后来在 stackoverflow找到了这个问题的解决。最后更新为 -(void)viewDidDisappear:(BOOL)animated{ [super viewDidDisappear:animated]; self.wkWebView.scrollView.delegate = nil; [self.configuration.userContentController removeScriptMessageHandlerForName: OddityWkWebViewConfiguration]; } 好了，不崩溃了。 WebKit WkwebView dealloc Crash错误.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"Systematic distinction","slug":"Systematic-distinction","permalink":"http://blog.msiter.com/tags/Systematic-distinction/"},{"name":"WebKit","slug":"WebKit","permalink":"http://blog.msiter.com/tags/WebKit/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"Autolayout 和 size-class 简明教程","slug":"Autolayout 和 size-class 简明教程","date":"2016-11-21T03:25:00.000Z","updated":"2018-08-29T10:33:16.494Z","comments":true,"path":"Autolayout h size-class jmjc-20161121.html","link":"","permalink":"http://blog.msiter.com/Autolayout h size-class jmjc-20161121.html","excerpt":"教程开始前的废话连篇在iphone5出现之后，也就是ios6的时候。约束(autolayout)出现了，其实最开始的时候，ios dever们都还是坚持手写代码，毕竟自己用了好几年了，你说换就换，现在的需求你帮我写啊？所以导致当时使用约束的少之又少，直至后来出现了横屏和竖屏之类适配，而且屏幕更多繁多的时候，手写代码已经越来越不太能担任这个任务的时候，才开始慢慢的进入了这个大潮","text":"让你难过的事情，有一天，你一定会笑着说出来。 H2 教程开始前的废话连篇在iphone5出现之后，也就是ios6的时候。约束(autolayout)出现了，其实最开始的时候，ios dever们都还是坚持手写代码，毕竟自己用了好几年了，你说换就换，现在的需求你帮我写啊？所以导致当时使用约束的少之又少，直至后来出现了横屏和竖屏之类适配，而且屏幕更多繁多的时候，手写代码已经越来越不太能担任这个任务的时候，才开始慢慢的进入了这个大潮而我比较幸运，在iphone5的时候第一次拥有了iphone手机，在我学习ios的时候，iphone6和swift这两个东西出现了。所以我最开始学习的时候就是使用 storyboard和约束一起学习的好了废话不多说了。约束到底是什么东西呢？其实说白了他是一种描述性的布局方式。什么是描述？比如说。“咳咳，这个图片距离这个按钮的右边10像素，距离屏幕上方10像素！图片的大小是80x80”。这就叫做描述，这样我们的前辈们(apple的开发人员们)，就会把我们的描述解析成相对应的布局方式，完成图片位置的放置。其实说到布局，无论手写代码还是xib,sb(storyboard)都可以进行约束的编码的。 我们教程首先学习 sb,xib这一类的布局，因为这样咱们可以很直观的看到约束对于view的布局影响。当我们足够熟悉布局的时候，再转入手写布局会方便很多这篇教程将以这几个方面进行讲解 XIB StoryBoard 约束设置 NSLayoutConstraint 约束设置 VFL 约束设置 NSLayoutAnchor 约束设置 第三方约束设置 例子总结 － 实例 总结 H2 XIB StoryBoard 约束设置在我们学习之前，请你们自己建立一个项目。打开storyboard的预览界面，咱们在界面的最下方 storyboard的预览界面 下方有三个button，分别是 align pin resole auto layout issues H3 align:英文解释的意思为排序，那么我们即可以理解为，排序…点击展开选项，我会挨个解释一下。 align 展开示例 ps选项一共有4个类别。第一类和第二类是需要选中两个或者多个的view的时候，才可以操作 Leading Edges 选中的views们 左 对齐 Trailing Edges 选中的views们 右 对齐 Top Edges 选中的views们 上 对齐 Bottom Edges 选中的views们 下 对齐 Horizontal Centers 选中的views们 水平方向 中心对齐 Vertical Centers 选中的views们 垂直方向 中心对齐 Baselines 选中的views们基于 基线 对齐 Horizontally in Container 选中的视图 相对于 父视图 进行 水平方向 对齐 Vertical in Container 选中的视图 相对于 父视图 进行 垂直方向 对齐 Update Frames None 再设置了这些约束之后不进行Frame的更改 Update Frames Items of New Constraints 设置了这些约束之后 只更改选中的这些views的Frame Update Frames All Frames in Container 更改该 vc 里所有View的约束 (慎用!!!!!!) H3 pin:英文解释为 大头针，其实我们就可以为，这个展开项内的所有的现象都是为了将视图订在某一个位置的。那么我们再次展开选项 pin 展开示例 上方的输入框 这个输入框时表示当前选中的views或者view距离父视图的上方距离为多少，左右下同理，不一一赘述了 而点击这个倒三角开启的选项中 User Standard Value 是说使用标准的的值，而且这个值只有在是设置上下方向的时候才有用。默认的值其实就是距离 Bottom Layout Guide，也就是上下基线。下基线就是距离视图最底部。上基线就是距离StatusView下方的位置。而这里的默认值其实是8 User Current Canvas Value 使用当前位置设置。默认为当前设置方向最近的一个VIew，且没有覆盖遮挡的视图 剩下的选项，会根据当前视图的布置情况有所不同，但是道理相当，这个选项是让你设置你要根据那个视图进行当前位置距离的设置的 Width 和 Height 这个不需要我赘述了吧。分别是 宽度和高度 的设置 Constarain to Margins. 这个是否需要外边距 默认为 8 。一般没啥卵用，都会去掉 Equal Widths 和 Equal Heights 这两个选项需要选择两个视图。比如选中View1和View2，那么可以分别设置这个两个视图宽度和高度相等 Aspect Ratio 这个属性是设置选中View的比例。当你点击设置的时候，默认他会设置当前视图的比例。比如你的View高度为40宽度为30。那么你的比例就将设置为3:4. 如果你希望修改这个比例的属性，咱们在讲完这三个东西之后，我会讲解 Align 这个东西你不得不承认这个东西和咱们学习的第一个Align重复的… 在这里就不赘述了 Update Frames 这个查看上面 Align选项的这个属性就好了 H3 resole auto layout issues他的这个解释已经很好理解了，自动布局问题的解决。就是如果你在布局的时候出现了一些问题。比如，咱们再设置约束之后，出现黄色或者红色的的颜色的时候。就需要使用以下方式修改。红色说明咱们设置的约束有缺失或者有冲突的问题，黄色则说明，约束正确，但是当前View的Frame和约束描述的Frame不一致 resole auto layout issues 展开示例 看到以上视图咱们可以看出它分为两个而且这两种除了名字不一样，选项是一摸一样的额。Selected Views 这个说的就是你要处理的约束问题是当前你选中的View，而All Views in View Controller，则是说明要解决的约束问题是这个ViewController所有的VIew的(这个可得慎重的)。 Update Frames 修改Frame，当你的约束设置正确但是Frame不对的时候使用者选项可以讲View的Frame展示成为约束所描述的样子 Update Constaints 而这个选项，说实话我没用过。他的意思咱们也可以知道他是通过Frame 去修改 约束…… Add Missing Constraints 添加缺失的约束，这个选项我也没使用过，因为这个方法添加的缺失的约束不一定就是正确的约束，在实际运行中肯定会出现问题所以尽量自己把缺失的约束自己添加了。 Reset to Suggested Constaints 重新设置建议的约束？没使用过，不知道什么意思 Clear Constraints 清除约束，会删除选中的视图的所有的约束。在All Views in View Controller 你要是做这个选项的时候可得慎重，使用了就说明你要删除当前VC所有的约束。当然你可以 ctrl-z H3 后面的话在说了这些之后，其实咱们应该已经可以进行约束的设置了，但是还有很多问题，其中我现在说一下快速设置的问题。当你在这个层次view选择器中（图1）。 图一 图二 图三 快速设置的问题。我们可以在View上按住Ctrl 键之后左键拖拽到view本身或者其他View来快速的设置一些属性，具体的属性，咱们自己看吧。他只是一种快捷方式，在属性设置上没有任何区别的，这里就不一一赘述了 快速解决约束问题的快捷键。当我们的View的约束正确的而fram没有显示正确的位置的时候我们可以使用 resole auto layout issues 进行修改，但是每次都要打开这选项实在是太麻烦了。所以我们可以选择一个快捷键。就是 osx ： comment+alt+= 而window 则为 window+alt+= 快速修改约束 设置UIScrollView的时候，因为牵扯到要设置ScrollView ContainView 的高度宽度的问题，所以再设置 ScrollView 子View 的时候一定要明确一个道理！ 就是比如保证 子视图的约束结合起来之后可以让 containView知道自己的高度和宽度，如果缺失，将导致约束失败。 修改约束的问题，咱们在修改约束的时候也是在view的选择器中。选中你要修改的VIew之后在最左侧的工具箱中（图2）。可以看到我们黄框标注出的约束。点击Edit就可以修改咱们约束的属性了 Constant 这个输入框就是约束的值，而大于等于，小于等于以及等于需要咱们根据实际情况进行自己分辨设置 Priority 优先级别，这个分别为 1000(最高)， 750(中),250(低)。三个选项，这个我没有使用过，不过估计是想两个约束发生实际运行中的冲突的时候 进行优先级显示的方法吧 Multiplier 这个就是设置比例的地方，就是咱们之前说的。而这个设置是非常好玩的一个设置，当然他也有使用的局限，在设置视图的宽度和高度的时候这个是用不了的，是设置比如 距离四周的位置？居中，或者两个视图的宽度高度相等的时候,或者比例设置的时候，才会可以设置。这个我还没有很多疑问。所以在我测试完成后，会进行修改 H2 NSLayoutConstraint 约束设置使用NSLayoutConstraint是Apple在出约束的时候出现的，也就是官方推荐用户使用这个东西，或者sb和xib。至少当时是这样的额。但是…这个东西的费事儿成都超出你的想象 H3 方法介绍public enum NSLayoutAttribute : Int { case left case right case top case bottom case leading case trailing case width case height case centerX case centerY case lastBaseline @available(iOS 8.0, *) case firstBaseline @available(iOS 8.0, *) case leftMargin @available(iOS 8.0, *) case rightMargin @available(iOS 8.0, *) case topMargin @available(iOS 8.0, *) case bottomMargin @available(iOS 8.0, *) case leadingMargin @available(iOS 8.0, *) case trailingMargin @available(iOS 8.0, *) case centerXWithinMargins @available(iOS 8.0, *) case centerYWithinMargins case notAnAttribute } 在网上看到一张图可以很好的说明问题。 NSLayoutAttribute 示例 以上的属性很多大家肯定都自己可以看懂，我也就不说了。我这里就说几个比较让人觉的不解的地方。 有 Margins 和 没有 Margins 的区别在于，咱们在SB 和 xib 中设置的 Constarain to Margins 是一个效果 Leading 在习惯从右至左看的地区，相当于NSLayoutAttributeRight; Trailing: 在习惯由左向右看的地区，相当于NSLayoutAttributeRight；在习惯从右至左看的地区，相当于NSLayoutAttributeLeft lastBaseline 文字的下基线 firstBaseline 文字的上基线 首先他的方法如下： /// 获得一个约束 /// /// - parameter view1: 第一个对象，通常就是咱们要设置的用户的View /// - parameter attr1: 你要是设置他的那个属性 查阅上方 NSLayoutAttribute 解释 /// - parameter relation: 一个Enum对象， 大于等于 小于等于 等于，自己看看吧， 不赘述了 /// - parameter view2: 第二个对象 一般是你要设置的View的SuperView。如果你只设置View的宽度或者高度这些只需要一个VIew就可以做的这个参数就为nil /// - parameter attr2: 第二个对象的 属性。 如果第二个对象为 nil。则该对象为 notAnAttribute /// - parameter multiplier: 倍数。 这里不赘述了，查看 SB xib 教程就好了 /// - parameter constant: 约束的值 /// /// - returns: NSLayoutConstraint public convenience init(item view1: Any, attribute attr1: NSLayoutAttribute, relatedBy relation: NSLayoutRelation, toItem view2: Any?, attribute attr2: NSLayoutAttribute, multiplier: CGFloat, constant c: CGFloat) 或者这样说可能更好理解一点view1.attr1 [= , &gt;= , &lt;=] view2.attr2 * multiplier + constant 在获取约束完成之后使用每个View 提供的方法 extension UIView { @available(iOS 6.0, *) open var constraints: [NSLayoutConstraint] { get } @available(iOS 6.0, *) open func addConstraint(_ constraint: NSLayoutConstraint) // This method will be deprecated in a future release and should be avoided. Instead, set NSLayoutConstraint's active property to YES. @available(iOS 6.0, *) open func addConstraints(_ constraints: [NSLayoutConstraint]) // This method will be deprecated in a future release and should be avoided. Instead use +[NSLayoutConstraint activateConstraints:]. @available(iOS 6.0, *) open func removeConstraint(_ constraint: NSLayoutConstraint) // This method will be deprecated in a future release and should be avoided. Instead set NSLayoutConstraint's active property to NO. @available(iOS 6.0, *) open func removeConstraints(_ constraints: [NSLayoutConstraint]) // This method will be deprecated in a future release and should be avoided. Instead use +[NSLayoutConstraint deactivateConstraints:]. } 这些大家根据名字就可以看懂的我就不解释了。还需要注意的一点就是，一定要设置View的 translatesAutoresizingMaskIntoConstraints 属性为false。否则会出现问题。人家说的也很明白。我要不要自己给你调整位置呢？如果你想自己调整约束来调整位置，就把我设置为false吧。默认为true H2 VFL 约束设置终于还是到了这里了，之前学习这个的时候真是千难万难，这个东西真心的不怎么友好……废话不多说了 VFL（Visual Format Language）被称为 “可视化格式语言”，是苹果公司为了简化autolayout的编码而推出的抽象语言。 我就一展示数据的表格 功能 写法 含义 水平方向 H: 或 V: H 说明之后的句子都是在水平方向设置约束的 V 则是垂直方向。默认方向为 H 水平方向 Views [view] 要设置的view们 SuperView &#124; view们所在的父视图 关系 &gt;=,==,&lt;= NSLayoutRelation 空间，间隙 - -30- 说明之间的空隙为30 优先级 @ 为250 750 1000 三个级别，之前咱们说过了 设置宽度高度 () [view(30)] 配合方向 水平方向就是为宽度 垂直则为高度 下面咱们来举几个例子： 我就一展示数据的表格 代码 含义 &#124;[view]&#124; 和父视图的左右对齐 &#124;-(&gt;=100)-[view] 距父视图的左边距离大于等于100 [view] 宽度大于等于100 V:&#124;-(&gt;=100)-[view(&gt;=100)] 距父视图的上边距离大于等于100并且高度度大于等于100 H3 约束类型public struct NSLayoutFormatOptions : OptionSet { public init(rawValue: UInt) public static var alignAllLeft: NSLayoutFormatOptions { get } public static var alignAllRight: NSLayoutFormatOptions { get } public static var alignAllTop: NSLayoutFormatOptions { get } public static var alignAllBottom: NSLayoutFormatOptions { get } public static var alignAllLeading: NSLayoutFormatOptions { get } public static var alignAllTrailing: NSLayoutFormatOptions { get } public static var alignAllCenterX: NSLayoutFormatOptions { get } public static var alignAllCenterY: NSLayoutFormatOptions { get } public static var alignAllLastBaseline: NSLayoutFormatOptions { get } @available(iOS 8.0, *) public static var alignAllFirstBaseline: NSLayoutFormatOptions { get } public static var alignmentMask: NSLayoutFormatOptions { get } /* choose only one of these three */ public static var directionLeadingToTrailing: NSLayoutFormatOptions { get } // default public static var directionLeftToRight: NSLayoutFormatOptions { get } public static var directionRightToLeft: NSLayoutFormatOptions { get } public static var directionMask: NSLayoutFormatOptions { get } } 不讲解了，我不是用这个VFL所以不会就不解释了。默认使用 ，init(0). 就好了。 H3 方法解释/// 获得一组约束 /// /// - parameter format: vfl 格式化string /// - parameter opts: NSLayoutFormatOptions Opt /// - parameter metrics: 数据的数据 比如 [view(height)] 那么此时 metrics 就为 [\"height\":100]. 不需要则为 nil /// - parameter views: views [\"view1\":self.backView] /// /// - returns: NSLayoutConstraints open class func constraints(withVisualFormat format: String, options opts: NSLayoutFormatOptions = [], metrics: [String : Any]?, views: [String : Any]) -> [NSLayoutConstraint] 如果没有声明方向默认为水平H:（原文写的V:） 妈的，真心不能使用vfl，简直反人类。而且很多问题。比如等于父视图的宽高，剧中问题…… 等到这些问题解决了，我在用吧，现在还是尽量不使用…… 而且为了使用vfl，还得是用其他方式约束去约束他不能约束，或者我不会约束的地方，真心了累。而且他的宽高问题在横屏的时候也是一个坑。 H2 NSLayoutAnchor 约束设置在ios9 之后，也许是受到了第三方约束框架的鼓舞，咱们的苹果公司更新了对于 autolayout的布局api。 NSLayoutAnchor 。每一个UIView都会有自己的这些属性 extension UIView { /* Constraint creation conveniences. See NSLayoutAnchor.h for details. */ @available(iOS 9.0, *) open var leadingAnchor: NSLayoutXAxisAnchor { get } @available(iOS 9.0, *) open var trailingAnchor: NSLayoutXAxisAnchor { get } @available(iOS 9.0, *) open var leftAnchor: NSLayoutXAxisAnchor { get } @available(iOS 9.0, *) open var rightAnchor: NSLayoutXAxisAnchor { get } @available(iOS 9.0, *) open var topAnchor: NSLayoutYAxisAnchor { get } @available(iOS 9.0, *) open var bottomAnchor: NSLayoutYAxisAnchor { get } @available(iOS 9.0, *) open var widthAnchor: NSLayoutDimension { get } @available(iOS 9.0, *) open var heightAnchor: NSLayoutDimension { get } @available(iOS 9.0, *) open var centerXAnchor: NSLayoutXAxisAnchor { get } @available(iOS 9.0, *) open var centerYAnchor: NSLayoutYAxisAnchor { get } @available(iOS 9.0, *) open var firstBaselineAnchor: NSLayoutYAxisAnchor { get } @available(iOS 9.0, *) open var lastBaselineAnchor: NSLayoutYAxisAnchor { get } } 大家看看这些单词就应该知道什么意思了吧。 咱们可以看到这里大概有三个类型。 NSLayoutXAxisAnchor , NSLayoutYAxisAnchor , NSLayoutDimension 分别左右边距上下边距，以及最后的 宽度和高度 而这些类型都实现 NSLayoutAnchor,他们有共同的方法 /* These methods return an inactive constraint of the form thisAnchor = otherAnchor. */ open func constraint(equalTo anchor: NSLayoutAnchor&lt;AnchorType>) -> NSLayoutConstraint open func constraint(greaterThanOrEqualTo anchor: NSLayoutAnchor&lt;AnchorType>) -> NSLayoutConstraint open func constraint(lessThanOrEqualTo anchor: NSLayoutAnchor&lt;AnchorType>) -> NSLayoutConstraint /* These methods return an inactive constraint of the form thisAnchor = otherAnchor + constant. */ open func constraint(equalTo anchor: NSLayoutAnchor&lt;AnchorType>, constant c: CGFloat) -> NSLayoutConstraint open func constraint(greaterThanOrEqualTo anchor: NSLayoutAnchor&lt;AnchorType>, constant c: CGFloat) -> NSLayoutConstraint open func constraint(lessThanOrEqualTo anchor: NSLayoutAnchor&lt;AnchorType>, constant c: CGFloat) -> NSLayoutConstraint 而 针对于高度会有比例这一个约束，所以在 NSLayoutDimension有自己的方法 /* These methods return an inactive constraint of the form thisVariable = constant. */ open func constraint(equalToConstant c: CGFloat) -> NSLayoutConstraint open func constraint(greaterThanOrEqualToConstant c: CGFloat) -> NSLayoutConstraint open func constraint(lessThanOrEqualToConstant c: CGFloat) -> NSLayoutConstraint /* These methods return an inactive constraint of the form thisAnchor = otherAnchor * multiplier. */ open func constraint(equalTo anchor: NSLayoutDimension, multiplier m: CGFloat) -> NSLayoutConstraint open func constraint(greaterThanOrEqualTo anchor: NSLayoutDimension, multiplier m: CGFloat) -> NSLayoutConstraint open func constraint(lessThanOrEqualTo anchor: NSLayoutDimension, multiplier m: CGFloat) -> NSLayoutConstraint /* These methods return an inactive constraint of the form thisAnchor = otherAnchor * multiplier + constant. */ open func constraint(equalTo anchor: NSLayoutDimension, multiplier m: CGFloat, constant c: CGFloat) -> NSLayoutConstraint open func constraint(greaterThanOrEqualTo anchor: NSLayoutDimension, multiplier m: CGFloat, constant c: CGFloat) -> NSLayoutConstraint open func constraint(lessThanOrEqualTo anchor: NSLayoutDimension, multiplier m: CGFloat, constant c: CGFloat) -> NSLayoutConstraint 大家自己看看方法就知道了，如果不知道就去文章下方例子，下载查看。 H2 第三方约束设置 Masonry (github地址)[https://github.com/SnapKit/Masonry] SnapKit (github地址)[https://github.com/SnapKit/SnapKit] Cartography (github地址)[https://github.com/robb/Cartography] 具体的用法查看他们的教程吧，我就不献丑了。 H2 例子总结 － 实例 那么我们来做一个个人主页的布局吧，因为这里包含的知识点比较多。而且比较好实现…… H3 XIB StoryBoard 方式那么首先我们做一个个人主页的背景视图，让他距离上左右方为0。而高度则为整个VC的view的1/3，我录制为了动态图了。 个人中心背景视图设置紧接着我们在个人中心的背景视图设置头像以及名字的布局约束 用户头像，用户姓名约束设置一个tag分栏视图的约束 分栏View约束设置 设置UISCrollView的约束,以及运行效果 UISCrollView 约束设置完成滑动Progress修改约束实现 切换ViewControoller的假象 UISCrollView 修改约束这样我们就完成了 xib的 布局 H2 总结除了第三方的约束框架，我都写了一份代码，实现同一个效果。大家有需要的可以查看github上的项目。 (Github 地址)[https://github.com/AimobierExample/AutoLayout] 这是案例的github地址，我把这个例子分为了4个分支。可以按个查看实现的约束。 写到最后才发觉其实并没有将到 size－class。有机会补上吧～ Autolayout 和 size-class 简明教程.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"约束教程","slug":"约束教程","permalink":"http://blog.msiter.com/tags/约束教程/"},{"name":"swift","slug":"swift","permalink":"http://blog.msiter.com/tags/swift/"},{"name":"autolayout","slug":"autolayout","permalink":"http://blog.msiter.com/tags/autolayout/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"制作一个自己的 Cydia 源","slug":"制作一个自己的 Cydia 源","date":"2016-11-12T02:05:43.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"zzygzjd Cydia y-20161112.html","link":"","permalink":"http://blog.msiter.com/zzygzjd Cydia y-20161112.html","excerpt":"大家肯定都知道 Cydia 吧， iPhone、iPod touch、iPad等设备上的一种破解软件，类似苹果在线软件商店iTunes Store 的软件平台的客户端，在越狱的过程中被装入到系统中的，其中多数为iPhone、iPod Touch、ipad的第三方软件和补丁，主要都是弥补系统不足用。是由Jay Freeman（Saurik）领导，Okori Group以及UCSB大学合作开发。 之前用了很多好用的源，但是很好奇的是，他们是怎么制作的呢？为什么越狱之后就可以这么厉害呢？那么怎么制作这么一个东西","text":"夜里不睡的人，白天多多少少总有什么逃避掩饰的吧。白昼解不开的结黑夜慢慢耗 大家肯定都知道 Cydia 吧， iPhone、iPod touch、iPad等设备上的一种破解软件，类似苹果在线软件商店iTunes Store 的软件平台的客户端，在越狱的过程中被装入到系统中的，其中多数为iPhone、iPod Touch、ipad的第三方软件和补丁，主要都是弥补系统不足用。是由Jay Freeman（Saurik）领导，Okori Group以及UCSB大学合作开发。 之前用了很多好用的源，但是很好奇的是，他们是怎么制作的呢？为什么越狱之后就可以这么厉害呢？那么怎么制作这么一个东西 H2 制作自己的 Cydia源Cydia 说白了启示就是一个云盘，你们需要的呢，只是需要几个文件，来告诉过来访问这个云盘的Cydia程序，我这个源叫啥？谁制作的这个源？这个源里都有什么软件？这些源的放置位置都是啥？那么如何制作自己的云盘呢？ 几种办法 第一种就是自己做一个服务器，本地跑起来。 github 任何一个直接访问的文件存储地方 比如 七牛云。 Cydia 源的文件结构 +- / +- Release +- Packages +- CydiaIcon.png +- debs +- *.deb H3 文件讲解/ 服务器根目录/Release 文件记录软件源本身的相关信息 ，例如作者 之类的/Packages 记录具体软件包的存放位置和安装信息等数据/CydiaIcon.png ICON 显示的ICON图片/debs 存放所有deb包的目录/debs/*.deb deb包…… H4 Release 文件讲解必须Origin: 软件源名称，可以使用中文（Cydia的软件源列表中显示的标题）Label: 同上，也可以使用中文Suite: 软件源的类型，比如正式源，测试源等，可以分别用stable, beta, unstable等来表示，一般填stable就可以了Version: 版本号，这个其实不重要，随便填，一般都是写1.0Codename: 代码代号，比如BigBoss的就写BigBoss，威锋的就写WeiPhone，也没什么限制，只能用英文Architectures: 结构。iPhone平台统一写iphoneos-armComponents: mainDescription: 软件介绍，可以使用中文和html代码，具体能使用哪些代码在下面会介绍。 可选Support: 支持，没什么作用，除非特别需要，否则可以不要这个。MD5Sum: 不是必须的，但如果Packages文件位置不与Release文件在同一目录下，则必须有此项。另外，如果需要签名Release文件，也必须有这个。关于MD5Sum的格式，在下文也会介绍。 Description格式 显示在Cydia中每个软件页面最下方。 不能直接换行，如果要实现显示换行显示，可以使用代码。 要加粗显示，可以使用代码 可以使用html代码设置字体颜色。 不能使用超链接代码。 代码： Description: WeiPhone-威锋网为您提供iPhone所需软件/补丁。&lt;br&gt;联系我们: &lt;strong&gt;weip.com@ gmail.com&lt;/strong&gt;; H4 生成Packages文件 将 deb 文件放在一个文件夹下，比如说debs下 命令行里进入到debs目录的上级目录 Packages存放于当前目录 执行命令 dpkg-scanpackages debs &gt; Packages 执行命令 bzip2 -zfk Packages 生成 Packages.bz2 执行命令 gzip -fk Packages 生成 Packages.gz ps 4.5.6 可以使用 dpkg-scanpackages debs &gt; Packages &amp;&amp; bzip2 -zfk Packages &amp;&amp; gzip -fk Packages 这样会自动将debs文件夹下的所有 deb文件信息 打印至 Packages 文件里 H2 (旧) 制作 自己deb 文件H3 总结 先把文件夹结构弄好 在 Applications 文件夹下面放入自己的 .app 文件 在 DEBIAN 文件夹下面放入 control描述文件，以及根据自己的需求放入脚本文件 使用 chmod -R 0755 Directory 设置权限 使用 dpkg-deb -b Directory a.deb 命令打包 使用 dpkg-name a.deb 规范命名 H4 各个文件讲解先生成如下的文件目录结构： +- Directory +- Applications | +- Example.app | | +- Info.plist | | +- Example | | +- icon.png +- DEBIAN +- control +- preinst/postinst/prerm/postrm/extrainst_ /Directory : 任意的一个文件夹放置主要的文件/Directory/Applications : 放置.app文件夹/Directory/Applications/Example.app : .app文件夹 /DEBIAN : 放置描述的文件/DEBIAN/control : 记录了软件包标识，软件名，介绍，作者，冲突软件等信息，用来标识一个软件包 H4 DEBIAN/control 文件描述以下为必须项 Package : 软件包标识符，类似于*，一个软件包必须要有一个唯一的标识符。通常是用com.xxx.abc这样的形式来命名。Architecture: 架构，用于标识运行的系统，iPhone上为iphoneos-armVersion: 版本号，不能用下划线和逗号和空格。格式有（以逗号分隔） 1.0，1.0f，0-1，1:1.0，其中1:1.0这种格式比较特殊，在Cydia中，1:1.0仍然会显示为1.0，但版本号实际是高于1.0的。 以下为可选项Name: 软件包在Cydia中的显示名称，中英文不限，也可以用空格，但不宜过长（长了显示不完全）。Author: 软件作者。Maintainer: 维护者，一般是软件源的拥有者。Sponsor: 负责人，可以是个人也可以是网站。 Author，Maintainer，Sponsor 的格式相同，均为 名称+空格+&lt;邮件地址或网址&gt;，经测试，如果名称为中文的话，即使写了邮件地址和网址，在Cydia中点击也不会跳转。 示例： WEIP.Tech &#119;&#x65;&#105;&#112;&#46;&#99;&#x6f;&#109;&#x40;&#x67;&#x6d;&#x61;&#x69;&#108;&#44;&#99;&#x6f;&#x6d; 或 WeiPhone.com http://www.weiphone.com 如果没有邮件地址或网址，则不需要 &lt;&gt; 及&lt;&gt;中的内容。中文名或未提供邮件/网址，无 &gt; 符号 Icon: 指定软件包的图标显示。当无Icon设定时，Cydia会显示该软件包所在的分类的图标。 格式： 在线地址，如 http://www.abc.com/abc.png 本地地址：file://+路径，如file:///Applications/Cydia.app/Sources/app.weiphone.com.png注：在软件页面（非列表页面），自定义的图标是不会显示的，显示的是分类图标。 Section: 软件分类，中英文无限制，排列顺序是 英文-&gt;中文。Installed-Size: 解包后的文件大小，可以有小数位，以kb为单位，不需要注明kb，这个不需要很精确，而且小数位在Cydia里显示不出来（不是四舍五入，全部舍了）。至于文件大小是否包含DEBIAN目录中的内容就随意了。Priority: 优先级，可填 Required，Important，Standard，Optional，Extra，依次为 必须，重要，一般，可选，次要。虽然没有什么实际作用，但优先级为Required和Important的软件包在卸载时会有警告，这样可以避免删除一些系统必须的软件。但Required和Important不要滥用，一般用Standard，Optional或Extra即可。优先级在Cydia中是不会显示的Essential: 是否必须软件包，可填 yes 和 no， 填yes则为必须软件包，卸载时Cydia会有警告。卸载Essential标记为yes的软件包可能会导致系统问题。当然此功能需慎用，不要因为不希望用户删除自己的软件而加入Essential: yes。如果没有Essential这项的话默认就是非必须的，相当于Essential: no。Depends: Depends 字段应该包含您的软件包正常工作绝对必需的任何软件包的名称。Pre-Depends: “Pre-Depends”是为特例而保留的。当某个软件包被作为”Pre-Depends”列出时，它强制系统在试图安装您的软件包之前完全安装所指定的软件包。Conflicts: 冲突软件包。比如软件包A和B有冲突，不能同时安装。比如说A和B冲突，当系统已经安装了A的时候尝试安装B，则不能继续。Provides: 提供的软件包，比如说软件包A包含B的全部功能，那么则是A provides B，因此可以在安装了A的前提下不安装B。但此功能在非Cydia的软件管理工具中可能会无法识别（实际是这些软件不合deb标准）Replaces: 替换软件包，安装A会替换B。 以上5项的格式相同，直接填软件包的Package标识即可，如果需要加入版本号，则为 软件表标识+空格+(判断符号 版本号).比如 Depends: apt-key, firmware (&gt;=3.0)， 这表示依赖于apt-key，不限版本，firmware，且版本大于或等于3.0。 判断符号：远远低于（&lt;&lt;）、低于(&lt;)、低于或等于（&lt;=）、仅等于（=）、等于或高于（&gt;=）、大于（&gt;）以及远远高于（&gt;&gt;）。 表示多个软件包，以英文逗号分隔。 表示“或”关系，用 | 分隔。比如软件包C依赖于A或B，可写Depends: A | B。 但“或”关系要慎用。原因是，当不存在“或”关系的时候，假设B依赖于A，且系统并未安装A，那么在Cydia中安装B的时候会自动下载安装A。而假如说C依赖于A或B，且A与B都未安装，那么在安装C的时候就会失败，因为系统无法判断是应该下载A还是B。除非系统已经安装了A或B，否则C不能安装。 一个特殊的依赖：firmware。这个Package记录了固件版本，在对固件版本有要求的软件包上特别重要。 假设B依赖于A，那么在卸载A的时候也会一起卸载B Description: 软件描述，不能在control里直接换行，如果需要实现换行显示，可以使用代码。当指定了Depiction时，在软件查看页面不会显示Description。Depiction: 功能类似于软件描述，链接到一个网页，以网页的内容代替软件描述。只在软件查看页面显示，在软件包列表页面不显示。 可以使用本地网页，格式同Icon。 注意：此功能可能会消耗大量网络流量。Homepage: 链接到页面，Cydia中显示为More Information。 页面不会主动加载。Tag: 可选项有 commercial, console, daemon, extension, library, uikit, x，对应图标文件在 /Applications/Cydia.app/Purposes 目录下。也可以自行添加 purpose 分类，并加入同名图标即可。 role:: 软件包使用者归类。developer开发者，hacker骇客，enduser普通用户，该标签用于Cydia中软件包显示过滤。 cydia::commercial Cydia Store软件。 例子如下: Package: com.weiphone.source Name: WeiPhone威锋中文源 Version: 1.0 Essential: no Icon: file:///Applications/Cydia.app/Sources/app.weiphone.com.png Installed-Size: 133.7 Replaces: con.weiphone.logo Conflicts: con.weiphone.logo Provides: con.weiphone.logo Depends: cydia Priority: Standard Maintainer: WEIP.Tech Author: WEIP.Tech Section: Repositories Architecture: iphoneos-arm Description: WeiPhone Chinese Repository威锋中文源 HomePage: http://www.weiphone.com/ Sponsor: WeiPhone.com Tag: purpose::repository, role::enduser H4 DEBIAN/preinst/postinst/prerm/postrm/extrainst_ 文件描述很多时候deb安装并不是把文件复制到iPhone里就可以了，还需要执行一些命令，比如设置权限，备份文件，加载启动进程等等，那么这时候就需要一些脚本来实现这些操作。 标准的deb脚本有4个preinst,postinst,prerm和 postrmpre是表示XX之前的前缀，post是表示XX之后的前缀，inst是install（安装）的缩写，rm是remove（移除）的缩写，所以这4个脚本的功能很明显： preinst: 在复制文件前执行的脚本 postinst: 在复制文件之后执行的脚本 prerm: 在卸载前执行的脚本 postrm: 在卸载之后执行的脚本 在Cydia中还存在一个独立的脚本,extrainst_,从字面上来讲就是额外的安装脚本。这个脚本是Cydia的作者Saurik为解决某些脚本只需要在安装时执行，在升级时不执行而专门引入的一个脚本，功能跟postinst差不多，和Installer时代的“ahhhh”比较相似。关于extrainst_的详情可以看看这个：http://www.telesphoreo.org/piper … ptember/000252.html 5个脚本的编写方法基本是一样的，但为了适应Cydia的安装，在某些情况下需要进行特定的配置。 查看某些deb可能会发现这样的语句： if [[ $1 == install || $1 == upgrade ]]; then 这种语句是为了区别安装/升级/卸载而准备的脚本。$1是一个外部变量，将这个外部变量传入脚本来执行，而这个外部变量是由Cydia软件自身生成的。 简单来说，如果是安装，则是 $1 == install ；如果是升级，则是$1 == upgrade；如果是卸载则是 $1 == remove。 if 是个判断语句，当满足if后[ ]中的指定条件时，if中的内容就会执行。那么这里就可以通过设定install/upgrade/remove来控制在不同操作时执行的命令。 但要注意的是，这个功能只能在Cydia中使用，其它的apt软件管理工具，如Icy，Rock等，不能识别这个命令，因此无法执行if中的语句，所以在写脚本的时候到底需不需要用这种格式，就看自己的需要了。 总体来说，Unix的脚本（Shell Script）有其固定的格式。 文件顶头为 #!/bin/bash 表示调用bash这个shell 之后就是运行的命令了。 脚本中如果需要注释，可以使用 # 符号。 以 # 开头的行会被当作注释，里面的内容在执行过程中没有意义。 通配符： * 最常用的两个命令自然是设置属性/权限/用户/组 设置属性/ H4 会使用到的系统命令操作H5 权限chmod 【-R】 属性 文件名 由于deb的脚本执行都是在root用户下，因此不需要提升权限，即不需要使用sudo命令。 -R参数：表示递归，加上此参数会将指定的目录及其子目录的全部目录和文件的属性改变。 属性：有多种写法。具体可以看 http://baike.baidu.com/view/1229012.htm?fr=ala0_1 比较常用的几种属性： chmod +x XXXXX 为文件增加可执行权限 chmod 0644 XXXXX 不可执行文件最常使用的权限 chmod 0755 XXXXX 可执行文件最常使用的权限 实例： chmod -R 0755 /Applications/Cydia.app H5 设置用户/组chown 【-R】 用户:组 文件名 同样不需要sudo来提示权限。-R也是表示递归。 比如要将文件A设为root用户，wheel组，可以使用命令 chown -R mobile:mobile /var/mobile/Documents H5 复制文件/文件夹cp 【参数】 原始文件 目的文件 参数列表： -l（小写字母L）：创建硬链接，相当于一个镜像，而不是实际创建两个文件cp -l abc def -f：强行复制，如果目的文件已存在，覆盖之且不提示cp -f abc def -p：保留文件的属性、用户、组、时间戳等信息 cp -p abc def -r和-R：作用都是递归，将文件夹下的全部子文件和子文件夹一起复制 cp -r abc/ def/ -s：创建符号链接而不是创建双份文件 cp -s abc/ def/ -n：如果目的文件已存在，则不覆盖且不提示 cp -n abc def -a：相当与-dR，保留文件自身的属性等数据，一并复制子文件/文件夹 cp -a abc/ def/ H5 移动文件/文件夹 &amp; 重命名mv 【参数】 源文件 目的文件 -f：强行移动，如果目的文件已存在，覆盖之且不提示 其实 mv 命令就是复制之后再删除，但 mv 命令会自动保留文件的属性等数据，移动文件夹时会自动移动子文件/子文件夹，因此都不需要另外的参数。 重命名是由mv命令来实现的，mv 就是将 源文件 移动到 目标文件的位置并以目标文件的文件名保存。 H5 显示语句echo &quot;Some Thing&quot;; 示例：显示语句 “测试echo命令”。 echo &quot;测试echo命令&quot;; H5 管理自启动服务launchctl load或unload -w plist文件路径 实例： 让wefit3自启动 launchctl load -w /System/Library/LaunchDaemons/com.weiphone.fitx.plist 禁用iPhone日志记录syslogd launchctl unload -w /System/Library/LaunchDaemons/com.apple.syslogd.plist PS: 记录自启动进程的plist文件保存在以下两个目录： /System/Library/LaunchDaemons/ 和 /Library/LaunchDaemons/ H5 杀死进程killall 进程名 示例：关闭Safari进程 killall safari H5 判断基本格式是 if [ 判断条件一 ]; then 执行命令 else 执行命令 fi 实例： 如果文件abc存在，则备份为abc.bak，否则将文件def重命名为abc if [ -f abc]; then mv -f abc abc.bak else mv def abc fi 其中[ -f abc ]可以由[ -e abc]取代 如果目录abc不存在，则新建一个目录abc if [ ! -e abc ]; then mkdir abc fi H5 获取固件系统版本号sw_vers -productVersion H5 获取设备型号uname -i uname -m H5 Cydia中安装完之后重新启动SpringBoarddeclare -a cydia cydia=($CYDIA) if [[ ${CYDIA+@} ]]; then eval &amp;quot;echo &amp;#39;finish:reboot&amp;#39; &amp;gt;&amp;amp;${cydia[0]}&amp;quot; fi H5 几个比较有用的实例 备份 preinst（安装之前就要把原始文件备份，不能等到安装完已经覆盖以后才备份） if [ ! -f 原始文件备份 ]; then echo &amp;quot;原始文件的备份已存在，跳过备份&amp;quot; else cp -p 原始文件 原始文件备份 echo &amp;quot;原始文件已备份&amp;quot; fi postrm（还原备份） echo &quot;还原备份&quot;; mv -f 原始文件备份 原始文件 备份操作在制作补丁的时候，尤其是替换类型的补丁时特别有用 判别具体固件版本 在control里可以通过Depends来设置依赖的固件版本，但有时候需要在某个特定固件版本下进行操作 比如说一个软件，要求固件版本大于或等于3.0，但在固件版本为3.1的时候必须删除某一个文件才能运行，那么脚本可以这样写： firmware=$(sw_vers -productVersion) if [[ $firmware == 3.1 ]]; then 删除文件 fi 判别设备型号 当设备型号为iPod Touch时删除某个文件platform=$(uname -i) if [[ $platform == &amp;quot;N45AP&amp;quot; || $platform == &amp;quot;N72AP&amp;quot; || $platform == &amp;quot;N18AP&amp;quot; ]]; then 删除文件 fi 或platform=$(uname -m) if [ $platform == iPod* ]; then 删除文件 fi 更多关于Shell Script的信息请见 http://www.hack base.com/tech/2009-10-10/56808.html H4 打包如果在DEBIAN中有脚本存在，则需要将整个DEBIAN文件夹及子文件属性设为0755,如果没有脚本的话保留0644属性即可，0755属性也没问题。 chmod -R 0755 DEBIAN 打包命令 dpkg-deb -b PATH FILENAME 其中PATH是打包deb的工作目录，DEBIAN文件夹需位于PATH指定的目录下 FILENAME是deb的文件名，这个可以自己决定。 以上命令打包deb默认是采用gz格式压缩，压缩率有限，如果要获得更改的压缩率（更小的文件体积），可以使用bzip2和lzma格式。 压缩为bzip2格式 dpkg-deb -bZ bzip2 PATH FILENAME 压缩为bzip2格式 dpkg-deb -bZ lzma PATH FILENAME 默认的gz格式压缩率最低，bzip2格式居中，lzma格式压缩率最高。（当然也会有例外） PS: 压缩率越高，压缩时间越长，在iPhone上使用较高的压缩率有更大概率导致失去响应。 iPhone OS 2.x无lzma组件，因此无法安装lzma压缩的deb。iPhone OS 3.x可以解压lzma压缩。 如果deb包含的文件文本量比较大，那么一般可以获得不错的压缩率。但如果是像铃声，jpg/png图片这样文件本身就是压缩格式的情况，继续压缩的可能性就不高了，这类情况很难获得比较好的压缩率 H4 【可选】deb文件规范命名dpkg-name abc_1.0.deb 如果想指定文件名格式，可以使用 dpkg-name --help 图形界面的deb制作工具 Debian Package Maker 网址： http://code.google.com/p/debianpackagemaker/ 个人感觉不如直接在命令行里来的直观，有兴趣的朋友可以自己试试。 ［ 需要翻墙 ］ H2 (新) 制作自己的deb文件H3 安装theos安装方法 选择theos的安装目录，官方建议放在默认的 /opt/theos.然后执行 export THEOS=/opt/theos 为了验证设置成功没有 echo $THEOS 如果打印 /opt/theos 说明摄制完成 Using git: git clone --recursive git://github.com/DHowett/theos.git /opt/theos Alternatively, you can use svn, if you prefer: svn co http://svn.howett.net/svn/theos/trunk $THEOS git clone -b stableversion https://github.com/haorenqq/theos/ $THEOS不要执行上面的语句，用上面的方法替换 特别感谢网名为逍遥笛子 的热心朋友 提供的分支，由于原theos最新的版本不兼容iosopendev，所以用15年的老版本 以上操作，如果出现任何关于权限的错误。使用sudo就可以了。 H3 安装idld其实我不知道这个是干什么的？但是呢，说是签名的。。。但是我没用到过，但是还是记录一下毕竟有不少坑 按照官方的教程是如此的说的。 git clone git://git.saurik.com/ldid.git cd ldid git submodule update --init ./make.sh cp -f ./ldid $THEOS/bin/ldid 但是通常发生错误，第一个错误就是 引入了 #include &lt;openssl/err.h&gt; ，默认是不存在 这个文件夹的额。第二个错误就是 make.sh中的代码默认是只匹配Xcode5-1-1的名称，所以需要修改 make 文件。 下载 文件 修复 接下来使用命令。生成 ldid 文件./make.sh . 反正我是生成失败了 你可以直接下载别人已经编译完成的文件 ldid文件 之后将文件拷贝到 /opt/theos/bin 下就可以了 H3 安装iOSOpenDevgit clone https://github.com/AimobierExample/iOSOpenDevInstallFix cd iOSOpenDevInstallFix sh repair.sh 之后打开 iOSOpenDev-1.6-2.pkg 按照提示就可以安装完成了 打开xcode就可以看见越狱的项目了 选择 Logos TWeak 按照xm文件内的提示，libsubstrate.dylib添加到工程中(在安装好的/opt/iOSOpenDev/lib 目录下)，然后把xm中的内容清空。mm文件的内容会根据xm文件中的内容编译后自动生成。 %hook SpringBoard - (void)applicationDidFinishLaunching:(id)application{ %orig; UIAlertView * alert = [[UIAlertView alloc]initWithTitle:@&quot;Welcome&quot; message:@&quot;HelloWorld!&quot; delegate:nil cancelButtonTitle:@&quot;Thanks&quot; otherButtonTitles:nil]; [alert show]; } %end 点击菜单 Product - Build For - Profiling 这个时候通常会报错，因为真机调试会出现问题 Failed to create directory /var/root/iOSOpenDevPackages on device 你的iOS设备IP地址 但是此刻已经在项目根目录下出现了 变已完成的 deb文件了，你可以直接添加到咱们的源服务器中，按照之前的教程生成 packages 完成安装。 H3 真机调试现在调试越狱设备，在已经越狱的手机上打开Cydia，搜索下列插件如果搜索不到，打开软件源-编辑 删除BigBos和ModMyi，再回到首页，点击更多软件源，重新添加这两个即可搜索到下列插件 Core Utilities Core Utilities(/bin) diskdev-cmds file-cmds system-cmds Mobileterminal openSSH sshpass toggle ssh preferencdloader substrate safe mode syslogd to /var/log/syslog 再在Xcode中的Target的Build Settings中的Code Signing中，改为Don’t Code Sign.最后打开Target-Build Settings 找到iOSOpenDevDevice选项，填入越狱手机的本地ip 之后打开终端创建key iosod sshkey -h 192.168.23.71（换成你的iOS设备IP地址） 创建完成 点击菜单 Product - Build For - Profiling 就可以安装到设备，安装完成之后，设备回自己重启，之后就会弹出了一个alertView。 H2 Theos 创建 Cydia 应用H3 首先安装 Theos安装方法 选择theos的安装目录，官方建议放在默认的 /opt/theos.然后执行 export THEOS=/opt/theos 为了验证设置成功没有 echo $THEOS 如果打印 /opt/theos 说明摄制完成 Using git: git clone --recursive git://github.com/DHowett/theos.git /opt/theos H3 使用Theos创建应用安装完成之后 使用： /opt/theos/bin/nic.pl 调用之后 msiter:~ jingwenzheng$ /opt/theos/bin/nic.pl NIC 2.0 - New Instance Creator ------------------------------ [1.] iphone/activator_event [2.] iphone/application_modern [3.] iphone/cydget [4.] iphone/flipswitch_switch [5.] iphone/framework [6.] iphone/ios7_notification_center_widget [7.] iphone/library [8.] iphone/notification_center_widget [9.] iphone/preference_bundle_modern [10.] iphone/tool [11.] iphone/tweak [12.] iphone/xpc_service Choose a Template (required): 2 Project Name (required): Demo Package Name [com.yourcompany.demo]: com.demo Author/Maintainer Name [荆文征]: jwz [iphone/application_modern] Class name prefix (two or more characters) [XX]: demo Instantiating iphone/application_modern in demo/... Done. msiter:~ jingwenzheng$ 这样就创建完成了 H3 运行到真机首先要确保震级上面安装 openssh ssh root@ip地址 密码。默认为 alpine 这样连接上就说明安装完成，可以调用的到～ 之后设置环境变量THEOS_DEVICE_IP 为 真机 IP。 之后 cd 目录。 使用命令安装到真机上 make package install H4 第一个问题 ldid你可以直接下载别人已经编译完成的文件 ldid文件 之后将文件拷贝到 /opt/theos/bin 下就可以了 默认是没有权限的 所以可能需要 sudo. 复制完成之后赋予权限sudo chmod 777 /opt/theos/bin/ldid H4 第二个问题 dpkg没有安装文件工具 brew install dpkg H4 dpkg 1.18.14 版本问题在 1.18.14 版本，dpkg lzma 不能使用了，必须使用 xz H4 这个时候需要修改 /opt/theos/makefiles/package/deb.mk 文件ifeq ($(_THEOS_PACKAGE_FORMAT_LOADED),) _THEOS_PACKAGE_FORMAT_LOADED := 1 _THEOS_DEB_PACKAGE_CONTROL_PATH := $(or $(wildcard $(THEOS_PROJECT_DIR)/control),$(wildcard $(THEOS_PROJECT_DIR)/layout/DEBIAN/control)) _THEOS_DEB_CAN_PACKAGE := $(if $(_THEOS_DEB_PACKAGE_CONTROL_PATH),$(_THEOS_TRUE),$(_THEOS_FALSE)) _THEOS_DEB_HAS_DPKG_DEB := $(call __executable,dpkg-deb) ifneq ($(_THEOS_DEB_HAS_DPKG_DEB),$(_THEOS_TRUE)) internal-package-check:: @echo \"$(MAKE) package requires dpkg-deb.\"; exit 1 endif ifeq ($(_THEOS_DEB_CAN_PACKAGE),$(_THEOS_TRUE)) # Control file found (or layout/ found.) THEOS_PACKAGE_NAME := $(shell grep -i \"^Package:\" \"$(_THEOS_DEB_PACKAGE_CONTROL_PATH)\" | cut -d' ' -f2-) THEOS_PACKAGE_ARCH := $(shell grep -i \"^Architecture:\" \"$(_THEOS_DEB_PACKAGE_CONTROL_PATH)\" | cut -d' ' -f2-) THEOS_PACKAGE_BASE_VERSION := $(shell grep -i \"^Version:\" \"$(_THEOS_DEB_PACKAGE_CONTROL_PATH)\" | cut -d' ' -f2-) $(_THEOS_ESCAPED_STAGING_DIR)/DEBIAN: $(ECHO_NOTHING)mkdir -p \"$(THEOS_STAGING_DIR)/DEBIAN\"$(ECHO_END) ifeq ($(_THEOS_HAS_STAGING_LAYOUT),1) # If we have a layout/ directory, copy layout/DEBIAN to the staging directory. $(ECHO_NOTHING)[ -d \"$(THEOS_PROJECT_DIR)/layout/DEBIAN\" ] && rsync -a \"$(THEOS_PROJECT_DIR)/layout/DEBIAN/\" \"$(THEOS_STAGING_DIR)/DEBIAN\" $(_THEOS_RSYNC_EXCLUDE_COMMANDLINE) || true$(ECHO_END) endif # _THEOS_HAS_STAGING_LAYOUT $(_THEOS_ESCAPED_STAGING_DIR)/DEBIAN/control: $(_THEOS_ESCAPED_STAGING_DIR)/DEBIAN $(ECHO_NOTHING)sed -e '/^[Vv]ersion:/d' \"$(_THEOS_DEB_PACKAGE_CONTROL_PATH)\" > \"$@\"$(ECHO_END) $(ECHO_NOTHING)echo \"Version: $(_THEOS_INTERNAL_PACKAGE_VERSION)\" >> \"$@\"$(ECHO_END) $(ECHO_NOTHING)echo \"Installed-Size: $(shell du $(_THEOS_PLATFORM_DU_EXCLUDE) DEBIAN -ks \"$(THEOS_STAGING_DIR)\" | cut -f 1)\" >> \"$@\"$(ECHO_END) before-package:: $(_THEOS_ESCAPED_STAGING_DIR)/DEBIAN/control _THEOS_DEB_PACKAGE_FILENAME = $(THEOS_PACKAGE_DIR)/$(THEOS_PACKAGE_NAME)_$(_THEOS_INTERNAL_PACKAGE_VERSION)_$(THEOS_PACKAGE_ARCH).deb internal-package:: $(ECHO_NOTHING)COPYFILE_DISABLE=1 $(FAKEROOT) -r dpkg-deb -Zgzip -b \"$(THEOS_STAGING_DIR)\" \"$(_THEOS_DEB_PACKAGE_FILENAME)\" $(STDERR_NULL_REDIRECT)$(ECHO_END) # This variable is used in package.mk after-package:: __THEOS_LAST_PACKAGE_FILENAME = $(_THEOS_DEB_PACKAGE_FILENAME) else # _THEOS_DEB_CAN_PACKAGE == 0 internal-package:: @echo \"$(MAKE) package requires you to have a layout/ directory in the project root, containing the basic package structure, or a control file in the project root describing the package.\"; exit 1 endif # _THEOS_DEB_CAN_PACKAGE endif # _THEOS_PACKAGE_FORMAT_LOADED 这样按理就可以运行了 制作一个自己的 Cydia 源.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"越狱","slug":"越狱","permalink":"http://blog.msiter.com/tags/越狱/"},{"name":"cydia","slug":"cydia","permalink":"http://blog.msiter.com/tags/cydia/"},{"name":"制作源","slug":"制作源","permalink":"http://blog.msiter.com/tags/制作源/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"WKWebView 制作详情页的一些经验","slug":"WKWebView 制作详情页的一些经验","date":"2016-09-21T03:25:00.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"WKWebView zzx,yqydyx,sjy-20160921.html","link":"","permalink":"http://blog.msiter.com/WKWebView zzx,yqydyx,sjy-20160921.html","excerpt":"Hello World好久好久没有更新过博客了，今天去面试了一家公司。被询问到关于资讯类App的详情页问题，想到了很多之前做详情页时候遇见的问题和解决的问题，所以心血来潮的想记录下来。","text":"H2 Hello World好久好久没有更新过博客了，今天去面试了一家公司。被询问到关于资讯类App的详情页问题，想到了很多之前做详情页时候遇见的问题和解决的问题，所以心血来潮的想记录下来。 只有一种英雄主义，就是在认清这个世界之后依然热爱他。 ——罗曼罗兰。 H2 如何去展示一个详情页呢那么废话少说，亮剑吧！ H3 如何去显示一个WKWebView呢其实怎么说呢，我觉的其实吧。每个人都大同小异。无非就是如何将数据转换成Html并且将字符串传递给WebView。之后展示出来而已。那么我们很快就会遇到第一个问题。如何将数据转换成Html格式的字符串呢？ H4 搞定我们的模板君我不清楚其他开发者们遇见的数据结构，但是我的数据结构如下/ // // NewContent.swift // Journalism // // Created by Mister on 16/5/30. // Copyright © 2016年 aimobier. All rights reserved. // import RealmSwift /// 频道的数据模型 open class Content: Object { /// 用于获取评论的 docid dynamic var txt: String? = nil /// 新闻Url dynamic var img: String? = nil /// 新闻标题 dynamic var vid: String? = nil } /// 频道的数据模型 open class NewContent: Object { /// 新闻ID dynamic var nid = 1 // 新闻的详情 let content = List&lt;Content>() // Should be declared with `let` // More …… } 详情页对象包含三个字段 img,txt,vid。也就是图片，文字，视频三种类型。那这样就简单了。把他们拼装成一个Html 还不简单~ String += String // ????? 这样子？ 我是拒绝的…… 之后想起来之前做服务的时候 jsq，ejs… 这些视图模板都是可以完成现在的需求的，不知道IOS 有没有呢？ 所以说！ 废话！ 当然有啊！ MGTemplateEngine 这就是了~ 但是！！！ 问题这个大神没有使用那个第三方的管理插件来让别人导入自己的框架~ 难道我又要回归到 之前那段 被拖拽引入所支配的恐惧吗？ ???? 我还是拒绝的~~~ 那么接下来就有两种方式来引入这个框架了~ 当然了 全都是 Cocoapods的…… 第一种使用 本地引入的方式： 如果你想本地引入的话，那很简单的 在你的项目根目录下建立一个文件夹 取名字呢~ 就叫做 MGTemplateEngine ，之后 把 clone 下来的 MGTemplateEngine 项目放入一个新建的Classes 目录下。之后再classes 同级目录中新建一个 文件 MGTemplateEngine.podspec 里面的代码呢，大概写成这样子 # # Be sure to run `pod lib lint SwaggerClient.podspec' to ensure this is a # valid spec and remove all comments before submitting the spec. # # Any lines starting with a # are optional, but encouraged # # To learn more about a Podspec see http://guides.cocoapods.org/syntax/podspec.html # Pod::Spec.new do |s| s.name = \"MGTemplateEngine\" s.version = \"1.0.0\" s.summary = \"奇点资讯\" s.description = &lt;&lt;-DESC if you～ Shabi Boom Sha Ga la ga DESC s.platform = :ios, '7.0' s.requires_arc = true s.framework = 'SystemConfiguration' s.homepage = \"https://github.com/swagger-api/swagger-codegen\" s.license = \"MIT\" s.source = { :git => \"https://github.com/swagger-api/swagger-codegen.git\", :tag => \"#{s.version}\" } s.author = { \"Swagger\" => \"apiteam@swagger.io\" } s.source_files = 'Classes/**/*' s.public_header_files = 'Classes/**/*.h' end 所有说大概的目录分布呢~ 是这个样子的~ ── 项目根目录 ├ MGTemplateEngine ├──────├ MGTemplateEngine.podspec ├──────├ Classes │ └──── MGTemplateEngine 所有的文件 └ 你的其他文件 之后呢，在你项目中的Podfile 写下这样的代码~ pod 'MGTemplateEngine', :path => 'MGTemplateEngine/' ## MGTemplateEngine组件 运行完成 pod install~ Woooooo~ 搞定~ 第二种呢 pod 'JMGTemplateEngine' 这个东西是我自己做的为了方便……………… 运行完成 pod install~ Woooooo~ 搞定~ H4 显示出来我们的详情吧~没什么好说的直接上代码吧 import MGTemplateEngine extension MGTemplateEngine{ static var shareTemplateEngine:MGTemplateEngine!{ let templateEngine = MGTemplateEngine() templateEngine.matcher = ICUTemplateMatcher(templateEngine: templateEngine) return templateEngine } } func getHtmlResourcesString() -> String{ let variables = [\"title\":self.title,\"source\":self.pname,\"ptime\":self.ptime,\"theme\":\"normal\",\"body\":body] let result = MGTemplateEngine.shareTemplateEngine.processTemplateInFile(atPath: templatePath, withVariables: variables) return result! } 这样子我们就得到了Html 的String 对象，在这个时候，我们只要 使用WkWebView的 loadHTMLString 方法就OK了啊～ 是的我们很快的就发现了～ 我们真的可以展示了～ 但是，行高怎么办呢？ 那我们很快就遇到了我们的几个坎 H2 遇到的坎坷虽然展示完成了，但是接下来我们就遇到了几个问题。 接下来针对这几个问题，我来给你说说，我是怎么解决的 H3 WebView和JS的交互在看接下来的之前咱们需要知道一个知识点就是WKWebVIew和js的交互 let configuration = WKWebViewConfiguration() configuration.userContentController.add(self, name: \"JSBridge\") self.webView = WKWebView(frame: CGRect(origin: CGPoint.zero, size: CGSize(width: 600, height: 1000)), configuration: configuration) 这个JSBridge就是我们自定义的桥连对象，使用这个桥连对象就可以实现交互了 WKWebView -&gt; javaScript的操作 self.webView.evaluateJavaScript(\"js 语句\") { (data, _) in // data 就是反回的数据 } javaScript –&gt; WKWebView的操作 var message = { \"type\": 0 } window.webkit.messageHandlers.JSBridge.postMessage(message); 之后再咱们的项目中实现WKScriptMessageHandler代理方法 public func userContentController(_ userContentController: WKUserContentController, didReceive message: WKScriptMessage) { guard let bodyData = message.body as? Dictionary&lt;String,AnyObject> else { return } /// bodyDaya 就是咱们的传入的对象 这里根据自己传入的类型机型 options 判断即可 } 其中JSBridge 对象就是咱们的自定义桥连对象 这样就可以实现交互了 H3 高度的计算问题相信很朋友也都查阅了很多东西，知道了 调用 JS的 高度计算方法 . document.getElementById(&#39;section&#39;).offsetHeight 我的主要内容都是显示在一个 section的Div里的，你们各位也请进行自己的计算。 那好吧，我们就来做吧~~~ 首先我们先监听 WebView 加载完成页面之后的事件，那么我们先实现它的Delegate吧。 /// 加载完成 public func webView(_ webView: WKWebView, didFinish navigation: WKNavigation!) { // 执行方法 self.webView.evaluateJavaScript(\"document.getElementById('section').offsetHeight\") { (data, _) in if let height = data as? CGFloat{ if self.webView.frame.size.height != height+35 { self.webView.layoutIfNeeded() self.webView.frame.size.height = height+35 self.tableView.tableHeaderView = self.webView } } } } 这样我们会发觉，好了啊~ 那么接下来咱们就遇到了，咱们的第二个坎 H3 图片LazyLoad的问题可能在这里很多用户就会察觉到这个，当咱们的新闻详情很多图片的时候，咱们就会出现加载时间巨长的问题。主要是因为Html界面呢，他不是咱们的tableView,ios的加载机制，是快要显示了开始准备渲染Cell，而Html是全部渲染完成，之后你爱怎么滑怎么滑。所以当图片过大的时候。就会出现加载时间很长的问题了那么自然而然的想到了使用咱们的lazyload。也就是俗称的 懒加载。 现在世面上的懒加载，都是一个样子的，给你提供一个自定义的额属性。比如lazysrc，设置成咱们需要加载的网络图片，而src设置成咱们的没有加载出来的占位图片。之后检测页面的滑动情况，当检测到快或者需要显示&lt;img&gt;标签的时候，进行吧 lazysrc赋值src的这么一个操作。 &lt;script src=\"jquery-1.11.0.min.js\">&lt;/script> &lt;script src=\"jquery.lazyload.js?v=1.9.1\">&lt;/script> 在网上随便找了一个测试发觉没用还是慢啊，之后抓包，发现图片还是一起加载的。即使没有滑动…… 这是怎么回事儿呢？ 其实不难理解，咱们的懒加载计算的是通过偏移位置来计算的，什么事偏移位置呢。。其实这个地方用图的方式更好，但是我不知道用什么画…… 那么咱们给webView的设置的就是咱们的所有的html的高度，他根本就不需要偏移就可以显示所有的内容了，这也就是我们的lazyload.js 没有效果的原因了。那么我们怎么解决这个问题呢？ 我是这样做的，因为我的WebView是tableView的表视图，那么我就实现了 scrollView的代理方法 /** 主要是为了针对于党图片延时加载之后的webvView高度问题 - parameter scrollView: 滑动视图 */ public func scrollViewDidScroll(_ scrollView: UIScrollView) { let height = UIScreen.main.bounds.height+scrollView.contentOffset.y self.webView.evaluateJavaScript(\"scrollMethod(\\(height))\", completionHandler: nil) self.adaptionWebViewHeightMethod() } 通过这个方法不断检测页面的偏移量 function scrollMethod(offesty) { $(\"img\").each(function(index, img) { // &lt;!-- 更多的操作> }) } 在这个操作里进行图片的循环跟我们传入的便宜量对比，如果快要展示了，那么咱们就把咱们设置的 属性替换成图片的src ，这个子就实现了图片的懒加载了 H3 关于图片点击问题这个点击问题，相信大家看到这里就应该已经知道该怎么做了。对了………… 当然是使用js方法桥连了 $(\"#body_section img\").click(function() { var index = $(\"img\").index(this); window.webkit.messageHandlers.JSBridge.postMessage({ \"type\": 1, \"index\": index }); }) public func userContentController(_ userContentController: WKUserContentController, didReceive message: WKScriptMessage) { guard let bodyData = message.body as? Dictionary&lt;String,AnyObject> else { return } guard let type = bodyData[\"type\"] as? Int else{return} if type == 1 { /// 图片展示 } } 但是这就又有了一个问题，就是咱们的webview和咱们的图片展示VC的图片加载的方式是不一样的。我这里先讲讲我的，之前找到使用 webview的缓存？还是什么的，还没有研究…… H3 关于图片重复加载的问题。其实这里的问题，就难点了，我是想了很久，该怎么解决，因为这样还涉及到一个问题，就是给图片添加进度条的问题。 先说说解决办法吧，心路历程就不说了。首先咱们的不是可以控制图片的何时加载了吗？那么咱们可不可以更厉害一点呢？让我们的图片该要加载的时候把请求链接传给我们，我们进行我们的缓存策略。SD PIN 随便了就。 答案是肯定的。 $(\"img\").each(function(index, img) { var datasrc = $(this).attr(\"data-src\") if ($(this).offset().top &lt; offesty + 200 &amp;&amp; ajaxUrl.indexOf(index) == -1) { ajaxUrl.push(index) window.webkit.messageHandlers.JSBridge.postMessage({ \"type\": 3, \"index\": index, \"url\": datasrc }); } }) 其中 ajaxurl存储了已经添加的 index 如果，没有这个东西的话，我们只要一滑动，那就蹭蹭蹭的传递给我们url，我们就有的加载了…… 这可不是我们想要的。 那么在我们接收到URL的加载的请求，那么我们就开始加载吧~~ fileprivate func HandlePinDownLoadResult(_ finish:@escaping (String) -> Void,result:PINRemoteImageManagerResult){ /// 含有静态图片 if let img = result.image ,let base64 = UIImageJPEGRepresentation(img, 0.9)?.base64EncodedString(options: NSData.Base64EncodingOptions.init(rawValue: 0)){ DispatchQueue.global(qos: .background).async { let string = \"data:image/jpeg;base64,\\(base64)\".replaceRegex(\"&lt;\", with: \"\").replaceRegex(\">\", with: \"\") DispatchQueue.main.async(execute: { finish(string) }) } } /// 含有动态图片 if let img = result.animatedImage { DispatchQueue.global(qos: DispatchQoS.QoSClass.background).async { let base64 = img.data.base64EncodedString(options: NSData.Base64EncodingOptions.init(rawValue: 0)) let string = \"data:image/gif;base64,\\(base64)\".replaceRegex(\"&lt;\", with: \"\").replaceRegex(\">\", with: \"\") DispatchQueue.main.async(execute: { finish(string) }) } } } 这样我们就实现了图片的本地缓存策略了~但是问题又来了…… 首先就是遇到大的图片尤其是gif那个base64解析真是慢啊…… 而且每次重新打开 webview 就算是已经下载好了，光是base64解析也要小一会儿了…… H3 base64的问题那还真没好的办法，，缓存吧……………… fileprivate func DownloadImageByUrl(_ progress:@escaping (Int) -> Void,finish:@escaping (String) -> Void){ /// 先读缓存 没有咱们再进行后续工作 if let str = PINCache.shared().object(forKey: \"hanle\\(self)\") as? String { return finish(str) } guard let url = URL(string: self) else { return } PINRemoteImageManager.shared().downloadImage(with: url, options: PINRemoteImageManagerDownloadOptions(), { (result) in self.HandlePinDownLoadResult(finish,result:result) } } /** 处理PINRemoteImage下载完成的结果哦 - parameter finish: 处理完成化后的回调 - parameter result: Result to PINRemoteImageManagerResult */ fileprivate func HandlePinDownLoadResult(_ finish:@escaping (String) -> Void,result:PINRemoteImageManagerResult){ /// 含有静态图片 if let img = result.image ,let base64 = UIImageJPEGRepresentation(img, 0.9)?.base64EncodedString(options: NSData.Base64EncodingOptions.init(rawValue: 0)){ DispatchQueue.global(qos: .background).async { let string = \"data:image/jpeg;base64,\\(base64)\".replaceRegex(\"&lt;\", with: \"\").replaceRegex(\">\", with: \"\") DispatchQueue.main.async(execute: { finish(string) PINCache.shared().setObject(string as NSCoding, forKey: \"hanle\\(self)\") /// 缓存 }) } } /// 含有动态图片 if let img = result.animatedImage { DispatchQueue.global(qos: DispatchQoS.QoSClass.background).async { let base64 = img.data.base64EncodedString(options: NSData.Base64EncodingOptions.init(rawValue: 0)) let string = \"data:image/gif;base64,\\(base64)\".replaceRegex(\"&lt;\", with: \"\").replaceRegex(\">\", with: \"\") DispatchQueue.main.async(execute: { finish(string) PINCache.shared().setObject(string as NSCoding, forKey: \"hanle\\(self)\") /// 缓存 }) } } } H3 图片加载进度条这个需要html配合，首先咱们每个图片也就是&lt;img&gt;标签上都生成一个进度条。无论什么样子的都行。反正你得保证我把进度传递回去了，你找的到你的空间，那么唯一标识是。index还是其他的随你了。 fileprivate func DownloadImageByUrl(_ progress:@escaping (Int) -> Void,finish:@escaping (String) -> Void){ if let str = PINCache.shared().object(forKey: \"hanle\\(self)\") as? String { return finish(str) } guard let url = URL(string: self) else { return } PINRemoteImageManager.shared().downloadImage(with: url, options: PINRemoteImageManagerDownloadOptions(), progressDownload: { (min, max) in if url.absoluteString.hasSuffix(\".gif\") { let process = Int(CGFloat(min)/CGFloat(max)*100) progress((process-5 &lt; 0 ? 0 : process-5)) } }) { (result) in self.HandlePinDownLoadResult(finish,result:result) } } 这样咱们就获取到了进度了。 /** 根据提供的 URL 和 需要加载完成的 Index - parameter url: 图片URL - parameter index: 图片所在的Index */ fileprivate func HandleUrlAndIndex(_ url:String,index:Int){ url.DownloadImageByUrl({ (pro) in DispatchQueue.main.async(execute: { let jsStr = \"$(\\\"div .customProgressBar\\\").eq(\\(index)).css(\\\"width\\\",\\\"\\(pro)%\\\")\" self.webView.evaluateJavaScript(jsStr, completionHandler: nil) }) }, finish: { (base64) in let jsStr = \"$(\\\"img\\\").eq(\\(index)).attr(\\\"src\\\",\\\"\\(base64)\\\")\" self.webView.evaluateJavaScript(jsStr, completionHandler: nil) if url.hasSuffix(\".gif\") { let display = \"$(\\\"div .progress\\\").eq(\\(index)).css(\\\"visibility\\\",\\\"hidden\\\")\" self.webView.evaluateJavaScript(display, completionHandler: nil) } }) } 我的进度条class都叫做customProgressBar，之后我根据 index 进行的唯一性标识。之后传入过去进度条。进行进度条的显示。 对了提醒一句 进度条特别占内存。咱们还是只给 gif 做做就算了，其他的没必要啊………… 谢谢 WKWebView 制作详情页的一些经验.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"WKWebView","slug":"WKWebView","permalink":"http://blog.msiter.com/tags/WKWebView/"},{"name":"swift","slug":"swift","permalink":"http://blog.msiter.com/tags/swift/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"RxSwift 学习 未完待续","slug":"RxSwift 学习","date":"2016-07-06T21:16:43.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"RxSwift xx-20160706.html","link":"","permalink":"http://blog.msiter.com/RxSwift xx-20160706.html","excerpt":"简介为什么使用 RxSwift其实这个问题就是在问，RxSwift它可以做什么呢？在他们编写程序的时候，总是会牵涉到需要检测某些值的变化。比如。textFiled Text变化？数据请求完成失败的变化？键盘弹起隐藏的变化，而我们需要做很多不一样的操作，去检测这些东西的变化情况，可能会是delegate，Notifinotion，KVO等等。 于是乎就有人想到了，为什么不设计一种处理机制来统一处理这些东西呢？所以 reactivex 这种机制出现了，而这里的 RxSwift 就是这么一个机制下的一个扩展。所以RxSwift 为什么用它？你可以理解了吗？","text":"H2 简介H3 为什么使用 RxSwift其实这个问题就是在问，RxSwift它可以做什么呢？在他们编写程序的时候，总是会牵涉到需要检测某些值的变化。比如。textFiled Text变化？数据请求完成失败的变化？键盘弹起隐藏的变化，而我们需要做很多不一样的操作，去检测这些东西的变化情况，可能会是delegate，Notifinotion，KVO等等。 于是乎就有人想到了，为什么不设计一种处理机制来统一处理这些东西呢？所以 reactivex 这种机制出现了，而这里的 RxSwift 就是这么一个机制下的一个扩展。所以RxSwift 为什么用它？你可以理解了吗？ 学校里还是相对单纯的地方，找不到女朋友，基本还是因为你丑。 H3 RxSwift 概念每一个Observable 的实例相当于一个Swift中的Sequence。 但是区别在于，Swift中的SequenceType是同步的循环，而 Observable 是异步的。 一个 Observable (ObservableType) 相当于一个序列Sequence(SequenceType) . ObservableType.subscribe(_:) 方法其实就相当于 SequenceType.generate() Observable 对象会在有任何 Event 时候，将把 observer (ObserverType) 作为一个参数通过 ObservableType.subscribe(_:) 自动发出。并不需要 observer (ObserverType) 调用 Next()方法 如果一个 Observable 发送了一个 (Event.Next(Element)) 下一步指令的时候，它将会继续发送后续更多的 Event ，然而如果它发出的是一个 (Event.Error(ErrorType)) 错误动作，或者是一个 (Event.Completed) 正常结束完成动作的话。它将通知不在发出任何动作。 序列的语法可以很明显的表达这一点: Next* (Error | Completed)? 图表可以直观的解释这一切 --1--2--3--4--5--6--|----> // \"|\" = 正常终止 --a--b--c--d--e--f--X----> // \"X\" = 错误终止 --tap--tap----------tap--> // \"|\" = 继续进行, 如同一个按钮点击事件的一个序列 这些图表被称为marble diagrams。你可以学习更多关于他们在 rxmarbles.com。 H3 Observables 和 observers (又名 subscribers)Observables 观测数据将不会执行除非有用户用户订阅了它。在下面的示例中，观察到的关闭将永远不会被执行，因为没有订阅observers： example(\"Observable with no subscribers\") { _ = Observable&lt;String>.create { observerOfString -> Disposable in print(\"This will never be printed\") observerOfString.on(.Next(\"😬\")) observerOfString.on(.Completed) return NopDisposable.instance } } 在下面的示例中, 在结束之前会调用 subscribe(_:): example(\"Observable with subscriber\") { _ = Observable&lt;String>.create { observerOfString in print(\"Observable created\") observerOfString.on(.Next(\"😉\")) observerOfString.on(.Completed) return NopDisposable.instance } .subscribe { event in print(event) } } 不用担心这些创建 Observable 的细节，马上就要学习了 在以上的栗子中，我们返回的都是一个 NopDisposable.instance ，而在实际的情况中是需要 返回一个 DisposeBag 的实例的，来妥善的处理这些代码。 至于为什么？嗯。 …… practice makes permanent 🙂 熟能生巧？ 你可以查看更多介绍 Disposing ， Getting Started guide. H3 创建和订阅一个 Observables有以下这几种方法来创建和订阅一个 Observables H4 never创建一个 Observables ，不发出任何项目，不终止 就是任性！！！！ example(\"never\") { let disposeBag = DisposeBag() let neverSequence = Observable&lt;String>.never() let neverSequenceSubscription = neverSequence .subscribe { _ in print(\"This will never be printed\") } neverSequenceSubscription.addDisposableTo(disposeBag) } H4 empty创建一个只发送完成动作的 Observables 对象。 老子不问过程，只看结果！！！ example(\"empty\") { let disposeBag = DisposeBag() Observable&lt;Int>.empty() .subscribe { event in print(event) } .addDisposableTo(disposeBag) } 这个实例还介绍了创建和订阅一个 Observables 对象，其实就是执行了 subscribe 这个方法。 H4 just创建一个发送制定动作的的 Observables 对象。 example(\"just\") { let disposeBag = DisposeBag() Observable.just(\"🔴\") .subscribe { event in print(event) } .addDisposableTo(disposeBag) } 这个实例还介绍了创建和订阅一个 Observables 对象，其实就是执行了 subscribe 这个方法。 H4 of创建一个具有固定数量的 Observables 对象 example(\"of\") { let disposeBag = DisposeBag() Observable.of(\"🐶\", \"🐱\", \"🐭\", \"🐹\") .subscribeNext { element in print(element) } .addDisposableTo(disposeBag) } 这个例子还介绍了 subscribeNext(:) 这种简单的方法不像 subscribe(:),它是定语了所有的动作 包括 （Next, Error, and Completed）subscribeNext 将会忽略所有的 (Error and Completed )动作，只会生产出一个 Next 动作、我们这里同样也有 完成 和 失败 对应的简单方法。 subscribeError(:) and subscribeCompleted(:)，当你只想检测是对应的动作的时候如果你想订阅所有的动作的你可以使用 subscribe(onNext:onError:onCompleted:onDisposed:)` 就像下面的例子 👇看了以下自己写的。不知道怎么说！ 草 ！subscribe 就是拦截所有的操作！ 比如 next error 和 complted。而这些检测都有单独的简便方法 subscribeNext subscribeError subscribeCompleted Example someObservable.subscribe( onNext: { print(&quot;Element:&quot;, $0) }, onError: { print(&quot;Error:&quot;, $0) }, onCompleted: { print(&quot;Completed&quot;) }, onDisposed: { print(&quot;Disposed&quot;) } ) H4 toObservable将一个 sequence(SequenceType),转换成为一个 Observable ,可以是任何实现了(SequenceType)协议的对象，比如Array, Dictionary, or Set example(\"toObservable\") { let disposeBag = DisposeBag() [\"🐶\", \"🐱\", \"🐭\", \"🐹\"].toObservable() .subscribeNext { print($0) } .addDisposableTo(disposeBag) } 该例子使用了 $0 这一种参数，而不是显式命名的参数 H4 create创建一个 Observable 序列 example(\"create\") { let disposeBag = DisposeBag() let myJust = { (element: String) -> Observable&lt;String> in return Observable.create { observer in observer.on(.Next(element)) observer.on(.Completed) return NopDisposable.instance } } myJust(\"🔴\") .subscribe { print($0) } .addDisposableTo(disposeBag) } H4 range创建一个 可以发射一系列的连续整数，然后终止 的 Observable对象 example(\"range\") { let disposeBag = DisposeBag() Observable.range(start: 1, count: 10) .subscribe { print($0) } .addDisposableTo(disposeBag) } H4 repeatElement创建一个无限地发射给定的元素 Observable。 豌豆君？？ example(\"repeatElement\") { let disposeBag = DisposeBag() Observable.repeatElement(\"🔴\") .take(3) .subscribeNext { print($0) } .addDisposableTo(disposeBag) } 该栗子中使用 take 方法来限制发射给定元素的次数 H4 generate创建一个只有当提供的所有的判断条件都为 true 的时候，才会给出动作的 Observable ! 老子 刚正不阿 example(\"generate\") { let disposeBag = DisposeBag() Observable.generate( initialState: 0, condition: { $0 &lt; 3 }, iterate: { $0 + 1 } ) .subscribeNext { print($0) } .addDisposableTo(disposeBag) } H4 deferred创建一个全新的 Observable ，你TM才是搬运工，老子是大自然的创造者！ example(\"deferred\") { let disposeBag = DisposeBag() var count = 1 let deferredSequence = Observable&lt;String>.deferred { print(\"Creating \\(count)\") count += 1 return Observable.create { observer in print(\"Emitting...\") observer.onNext(\"🐶\") observer.onNext(\"🐱\") observer.onNext(\"🐵\") return NopDisposable.instance } } deferredSequence .subscribeNext { print($0) } .addDisposableTo(disposeBag) deferredSequence .subscribeNext { print($0) } .addDisposableTo(disposeBag) } H4 error创建一个不做任何操作，直接丢一个错误给你的 Observable. 对方不想和你 BB，并丢给你一个错误 😐 example(\"error\") { let disposeBag = DisposeBag() Observable&lt;Int>.error(Error.Test) .subscribe { print($0) } .addDisposableTo(disposeBag) } H4 doOn为每一个发出的事件和返回的执行制定操作。 收费站？ example(\"doOn\") { let disposeBag = DisposeBag() Observable.of(\"🍎\", \"🍐\", \"🍊\", \"🍋\") .doOn { print(\"Intercepted:\", $0) } .subscribeNext { print($0) } .addDisposableTo(disposeBag) } 这里也有。 doOnNext(:), doOnError(:), and doOnCompleted(:) 简便方法。 也有 doOn(onNext(:)onError(:)onCompleted(:)) 这样的方法 H2 Working with Subjects使用 Subjects 进行工作，一个 Subject 可以理解为一个中间人，他既可以观察者观察，向观察者提供动作。也可以当作观察者去观察，来接受对象。 大概的意思。可攻可受？？？ H3 PublishSubject向所有订阅者发布动作。在他们订阅之后。这个时间是有关系的哦。从下图也可以看到，第二个订阅的用户，已经错过了接受红绿的时间。所以他只接受到了，蓝色和错误动作 let disposeBag = DisposeBag() let subject = PublishSubject&lt;String>() subject.subscribe{print(\"第一次订阅\",$0)}.addDisposableTo(disposeBag) subject.onNext(\"🐶\") subject.onNext(\"🐱\") subject.subscribe{print(\"第二次订阅\",$0)}.addDisposableTo(disposeBag) subject.onNext(\"🅰️\") subject.onNext(\"🅱️\") 在这份代码中第一个订阅可以展示4个？而第二次，就只能接收到 小猫和小狗。 在这份例子中，使用的是 onNext(:) 简便的方法，当然也有 错误 和 完成的简便方法 onError(:) , onCompleted() . 你也可以直接食用 on(.Error(:)) on(.Completed(:)) on(.Next(:)) 这和之前的如出一辙 (:) H3 ReplaySubject咱们之前创建的 PublishSubject ，如果在订阅之前的时间是不会接收到的，而这个呢 可以指定，缓存的个数，比如 2 ，那么咱们就可以接受订阅时间之前两次的 动作事件。 let disposeBag = DisposeBag() let subject = ReplaySubject&lt;String>.create(bufferSize: 1) subject.subscribe{print(\"第一次订阅\",$0)}.addDisposableTo(disposeBag) subject.onNext(\"🐶\") subject.onNext(\"🐱\") subject.subscribe{print(\"第二次订阅\",$0)}.addDisposableTo(disposeBag) subject.onNext(\"🅰️\") subject.onNext(\"🅱️\") 在这份代码中，第二次的额订阅的时候 就会 是 小猫 A 和 B了～ H3 BehaviorSubject向所有的订阅者广播新的事件，并且传递 当前 的最新值，初始值。 怎么感觉就是 ReplaySubject 之后 buffSize 是 1 的变形呢。。。。除了多了一个初始值。。。 let disposeBag = DisposeBag() let subject = BehaviorSubject(value: \"🔴\") subject.subscribe{print(\"第一次订阅\",$0) }.addDisposableTo(disposeBag) subject.onNext(\"🐶\") subject.onNext(\"🐱\") subject.subscribe{ print(\"第二次订阅\",$0)}.addDisposableTo(disposeBag) subject.onNext(\"🅰️\") subject.onNext(\"🅱️\") 在第二次订阅出现的时候会多出现一次。最新值。而第一次订阅则会出现一个 初始值。 看了这三个例子有没有好像遗漏了什么 ，一个 Completed 事件。 PublishSubject, ReplaySubject, 和 BehaviorSubject 不会在自动发出 完成事件的。 H3 VariableBehaviorSubject 变种。。。 就是说呢，BehaviorSubject 不是不会自动发送 Completed 事件吗？ Variable 会。没了。 let variable = Variable(\"🔴\") subject.subscribe{print(\"第一次订阅\",$0) }.addDisposableTo(disposeBag) variable.value = \"🐶\" variable.value = \"🐱\" subject.subscribe{ print(\"第一次订阅\",$0)}.addDisposableTo(disposeBag) variable.value = \"🅰️\" variable.value = \"🅱️\" Variable 对象 调用 asObservable() 方法可以获取他变种前的 BehaviorSubject 对象。 Variable 对象 不能实现 onNext 方法，但是你可以调用他的 value 参数，来 get 和set 它的值。 RxSwift 学习.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"swift","slug":"swift","permalink":"http://blog.msiter.com/tags/swift/"},{"name":"RX","slug":"RX","permalink":"http://blog.msiter.com/tags/RX/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"reactivex 学习","slug":"reactivex 学习","date":"2016-06-21T23:22:00.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"reactivex xx-20160621.html","link":"","permalink":"http://blog.msiter.com/reactivex xx-20160621.html","excerpt":"散记好久没有学习到新的东西了，之前一直想学习 ReactiveCocoa,但是看了一点之后，觉的很是繁琐，而且感觉很多api方法，再加上项目很紧迫没有时间去学习新的东西了。我就暂时搁置了，现在项目做的也差不多了，觉得这个学习进度是时候提上进程。 再开始学习的时候，发现了RxSwift.在之后发现了 reactivex 。进入了官网发现自己可能，找到了一个 类似于 Realm和swagger 的庞然大物， 绝对要好好学习，在加上自己学习的本身就是swift。自然选择了 RXswift。 好了，废话不多说了，开始学习吧，请耐心看下去。因为我也是翻译，所以如果有任何觉得不应该的地方，可以提醒我。","text":"庆幸你来自远方不清楚我的过往。 H3 散记好久没有学习到新的东西了，之前一直想学习 ReactiveCocoa,但是看了一点之后，觉的很是繁琐，而且感觉很多api方法，再加上项目很紧迫没有时间去学习新的东西了。我就暂时搁置了，现在项目做的也差不多了，觉得这个学习进度是时候提上进程。 再开始学习的时候，发现了RxSwift.在之后发现了 reactivex 。进入了官网发现自己可能，找到了一个 类似于 Realm和swagger 的庞然大物， 绝对要好好学习，在加上自己学习的本身就是swift。自然选择了 RXswift。 好了，废话不多说了，开始学习吧，请耐心看下去。因为我也是翻译，所以如果有任何觉得不应该的地方，可以提醒我。 H3 ReactiveX在进入ReactiveX的官方网站后，就看到了它对自己的评价 ReactiveX is a combination of the best ideas fromthe Observer pattern, the Iterator pattern, and functional programming reactivex组合是观察者模式，迭代器模式和函数式编程最好的想法。 ok ~ 好吧，算你吊。什么意思！ H3 Observable 观察者模式H4 简介在reactivex 观察者 订阅 可观察对象。然后，观察者 会对 可观察对象 以任意顺序发出的任何项目丢回作出反应。这种模式有利于并发操作，他不需要创建一个阻塞对象来等待 可观察者 发出任何指令,而是创建一个哨兵的形式的观察员，随时准备作出适当的反应针对于 可观察对象 发出的项目。 See Also Single — 一个针对于可观察对象只发出一次项目的专门版本 Rx Workshop: Introduction Introduction to Rx: IObservable Mastering observables (来自 Couchbase 服务器的文档) 2 minute introduction to Rx 作者: Andre Staltz(“Think of an Observable as an asynchronous immutable array.”) (把一个可观察对象认作为一个异步不可改变的数组) Introducing the Observable by Jafar Husain (JavaScript Video Tutorial) Observable object (RxJS) by Dennis Stoyanov Turning a callback into an Rx Observable by @afterecho H4 Background在许多编程项目中，人们往往更倾向于在一个时间执行一个指令执行或者完成一个增量操作。但是在reactivex中，许多指令可以并行执行。其结果会在后来以任意顺序被观察者抓获。而不是定义一个方法完成数据的转换等操作方法，然后以一个 被观察者的身份去订阅了一个观察者。 这种方法的一个优点是，当你有一堆不依赖于彼此的任务时，你可以同时启动它们，而不是等待每一个完成之前开始下一个-这样，你的总执行时间就是你一堆任务执行时间最长的那一个，就像是木板组成水桶，装的水多少在于最短的那块木板一样的道里。 有许多术语用来描述这种异步编程和设计模型。本文档将使用以下术语：一个观察者订阅观察。一个可观察的发射项目或通过调用观察员的方法发送通知给它的观察员。 在其他情况下，有时也称观察员为“用户”“观看的人”或“堆”。这种模式一般是通常被称为“反应模式” H4 建立观察员在一个普通的方法调用是异步的，没有排序，并行调用典型的reactivex -流程是这样的： 调用方法。 将该方法的返回值存储在一个变量中 使用这个变量和它的新值来做一些有用的事情。 或者，像这样的： // 打电话，把它的返回值 赋值给` returnval ` returnval =方法（参数）； // returnval 去做点有用的事儿 在异步模型中，流程会像这样： 定义一个方法，做一些有用的从异步调用返回值；该方法是观察者的一部分。也就是 A 调用方法做出一些调整后 反悔 A 定义异步调用方法本身作为一个可观察的对象 附加的观测器，通过订阅它观察（这也导致可观察到的开始行动） 继续你的业务；每当调用返回时，观察者的方法将开始操作它的返回值或值-所观察到的项目。 看起来像这样： // 定义，但不调用，用户 onNext 处理 // 在这个例子中，观察者是非常简单的，只有一个`onNext`处理 def myOnNext = { it -&gt; do something useful with it }; // 定义，但不调用，可观察到的 def myObservable = someObservable(itsParameters); // 订阅用户可见，并调用观察 myObservable.subscribe(myOnNext); // 继续我的业务 H5 onNext, onCompleted, and onError您的观察者实现以下方法的一些订阅方法子集可以将一个观察者连接到一个可观察到的： H6 onNext无论任何时候，一个可观察对象调用这个方法发出一个项目，这个方法会把 被观察者发出的这个项目作为一个参数继续传递下去 H6 onError一个被观察者遇到非预期的数据和一些错误，就会调用这个方法，接下来它不会调用 onCompleted 或者 onNext 方法，这个方法将错误的指示作为参数 H6 onCompleted没有发生错误的情况下，完成操作后，调用的方法。 通过对观察到的条款，它可以调用OnNext零次或更多次，然后可以根据调用结果调用 最后一次 onCompleted或OnError。按照惯例，在这个文件中，调用OnNext通常被称为“排放”的项目，而叫onCompleted或onError被称为“通知”。 参见： Introduction to Rx: IObserver H5 注销 Unsubscribing在一些reactivex实现，有一个专门的观察者接口，签约者，实现一个Unsubscribing的方法。你可以调用这个方法来表明，用户不再对目前任何订阅感兴趣。这些观测可以（如果他们没有其他感兴趣的观察员）选择停止产生新的物品发出。 这一结果将级联退订通过运营商，适用于观察，观察者订阅的链，这将导致在产业链的各个环节停止发射项目。这不保证立即发生，但是，它是可能的一个观察到的产生和尝试发射一段时间，即使没有观察者仍然观察这些排放量。 H5 关于命名约定的一些注释reactivex每个语言的具体实现有自己的命名习惯。有没有规范的命名标准，虽然有许多共性之间的实现 此外，这些名称中的一些在其他上下文中有不同的含义，或在一个特定的实现语言的成语中显得有些尴尬。 例如有事件的命名模式（例如OnNext，OnCompleted，OnError）。在某些情况下，这样的名称将表示方法，通过该事件处理程序的注册。然而，他们的名字reactivex，事件处理器。 H4 “热”和“冷”的 被观测者什么时候被观察者会发出信息？这取决于被观察者。“热”的观察可能当他刚被创建没多久就发出信息，所以后来订阅的观察者观察到的信息就是中间的某些地方。“冷”的观察，直到一个订阅者观察他的变化，他才开始发生信息。所以观察者就看到他的整个信息过程 在reactivex一些实施方案中，也有一些称为“连接”的观察。除非一个观察者订阅了这个连接对象并且调用它的 Connect 方法，否则被观察者不会发出信息 H4 通过可观察算子的合成观察者和被观察者仅仅只是 ReactiveX的开始。由他们自己，他们只不过是一个轻微的扩展的标准观察者模式，更适合处理一系列的事件，而不是一个单一的回调。 真正的力量来自于reactive extensions（即reactivex）-运营商可以变换，结合，操纵，并与发射的观测值序列的工作项目。 这些接收运营商允许你一起构成异步序列在声明的方式与所有的回调函数的效率效益但没有嵌套的回调处理程序通常与异步系统相关的问题。 This documentation groups information about the various operators and examples of their usage into the following pages: Creating ObservablesCreate, Defer, Empty/Never/Throw, From, Interval, Just, Range, Repeat, Start, and TimerTransforming Observable ItemsBuffer, FlatMap, GroupBy, Map, Scan, and WindowFiltering ObservablesDebounce, Distinct, ElementAt, Filter, First, IgnoreElements, Last, Sample, Skip, SkipLast, Take, and TakeLastCombining ObservablesAnd/Then/When, CombineLatest, Join, Merge, StartWith, Switch, and ZipError Handling OperatorsCatch and RetryUtility OperatorsDelay, Do, Materialize/Dematerialize, ObserveOn, Serialize, Subscribe, SubscribeOn, TimeInterval, Timeout, Timestamp, and UsingConditional and Boolean OperatorsAll, Amb, Contains, DefaultIfEmpty, SequenceEqual, SkipUntil, SkipWhile, TakeUntil, and TakeWhileMathematical and Aggregate OperatorsAverage, Concat, Count, Max, Min, Reduce, and SumConverting ObservablesToConnectable Observable OperatorsConnect, Publish, RefCount, and ReplayBackpressure Operators执行特定的流量控制策略的各种运营商 H5 连锁运营商大多数操作符在可观察到的和返回一个可观察到的。这允许你应用这些操作符一个接一个，在一个链中。链中的每个操作符都修改了可观察到的结果，从以前的操作的操作。还有其他模式，如生成器模式，其中一个特定类的各种方法通过修改该对象的操作来修改该类的一个类上的一个项目。这些模式也允许你以类似的方式链的方法。但在生成器模式中，在链中出现的方法的顺序通常不重要，与可观察到的运营商的订单事宜。观察到的操作符的链不独立于原始观察到的起源链，但他们反过来操作，每一个操作上的观察所产生的运营商立即在外链。 reactivex 学习.md","categories":[{"name":"开发帮助","slug":"开发帮助","permalink":"http://blog.msiter.com/categories/开发帮助/"}],"tags":[{"name":"reactiv","slug":"reactiv","permalink":"http://blog.msiter.com/tags/reactiv/"},{"name":"rxswift","slug":"rxswift","permalink":"http://blog.msiter.com/tags/rxswift/"}],"keywords":[{"name":"开发帮助","slug":"开发帮助","permalink":"http://blog.msiter.com/categories/开发帮助/"}]},{"title":"Realm-cocoa 学习","slug":"realm-cocoa 学习","date":"2016-03-03T20:53:35.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"realm-cocoa xx-20160303.html","link":"","permalink":"http://blog.msiter.com/realm-cocoa xx-20160303.html","excerpt":"PS:以下内容均为项目为Swift的基础，如果需要Object－c请查阅Realm的Object－c文档。 前些日子在看第一届《中国Swift开发者大会》的时候，听到了realm这个数据库，说到了运行速度方面，相较于CoreData可以有很大的提升。再加上之前在做项目的时候，觉的coredata的很多配置让我觉的不爽，很是繁琐。所以就想看一看realm到底如何，学习了一天觉的很好，固决定记录一下。因为也不知道怎么讲解，所以我会尝试翻译realm官网的文档，再加上我的理解进行解释。 Realm is a mobile databasehundreds of millions of people rely on","text":"如果没有见过光明，我本可以忍受黑暗。 PS:以下内容均为项目为Swift的基础，如果需要Object－c请查阅Realm的Object－c文档。 前些日子在看第一届《中国Swift开发者大会》的时候，听到了realm这个数据库，说到了运行速度方面，相较于CoreData可以有很大的提升。再加上之前在做项目的时候，觉的coredata的很多配置让我觉的不爽，很是繁琐。所以就想看一看realm到底如何，学习了一天觉的很好，固决定记录一下。因为也不知道怎么讲解，所以我会尝试翻译realm官网的文档，再加上我的理解进行解释。 Realm is a mobile databasehundreds of millions of people rely on H2 散记这是Realm官网的对于自己的解释。 realm可以快速有效的编写应用程序的本地持久化，它的代码大概就是下面这个样子： // 先创建一个你想要持久化的对象的模型，Object 是 Reaml 自己定义的对象 class Dog: Object { dynamic var name = \"\" dynamic var age = 0 } class Person: Object { dynamic var name = \"\" dynamic var picture: NSData? = nil // 这是一个可选类型 let dogs = List&lt;Dog>() } // 这是实例化一个Realm对象的时候，就像咱们平时创建Class对象一样的 let myDog = Dog() myDog.name = \"Rex\" myDog.age = 1 print(\"name of dog: \\(myDog.name)\") // 得到一个Realm对象 let realm = try! Realm() // 查询这个狗小于两岁的，其实咱们看着代码就可以理解了，它使用了链式代码结构，很容易看懂 let puppies = realm.objects(Dog).filter(\"age &lt; 2\") puppies.count // => 0 比如现在的到的数目是0，因为现在咱们还没有添加任何数据 // 把咱们的上面创建的狗的对象，添加到数据库中 try! realm.write { realm.add(myDog) } // 再次查看数量的时候，不需要再进行一次查询，Realm会自动的为你完成更新 puppies.count // => 1 // 你也可以更新你的数据内容在任何线程 dispatch_async(dispatch_queue_create(\"background\", nil)) { let realm = try! Realm() let theDog = realm.objects(Dog).filter(\"age == 1\").first try! realm.write { theDog!.age = 3 } } H2 教程H3 项目中如何添加 Realm 框架主要有下面的三种集成方式 H4 使用Dynamic Framework： 下载Realm安装包最新版本 根据你的需要，将你下载文件解压后， 从/ios/swift-2.1.1（IOS设备） 或者 tvos/（Apple电视设备） 再或者 osx/swift-2.1.1/（mac电脑设备） 这三个目录中，选择自己需要的文件，将其拖入项目中，并且要选中“如果需要请勾选”选项 在你的项目中 Build Settings ，为Framework Search Paths 设置ealmSwift.framework 路径 如果使用Realm 在 IOS，watchOS或者TvOS，在Build Phase 创建一个新的 “Run Script Phase”，下面写上bash &quot;${BUILT_PRODUCTS_DIR}/${FRAMEWORKS_FOLDER_PATH}/Realm.framework/strip-frameworks.sh&quot;这一步是需要解决应用程序商店提交bug时存档通用二进制文件。H4 使用CocoaPods 安装CocoaPods0.39.0 版本或者更新的版本. 在你的Podfile文件中添加use_frameworks! 和 pod &#39;RealmSwift&#39; 在终端中运行 pod install 打开 ＊.xcworkspace 项目H4 使用Carthage 安装 Carthage 0.9.2 或者更新的版本 在你的Cartfile文件中添加&quot;realm/realm-cocoa&quot; 运行 carthage update. 从 Carthage/Build/ 拖拽RealmSwift.framework 和 Realm.framework 到 General 下面的“Embedded Binaries” iOS/watchOS/tvOS: 在你的项目targets的 “Build Phases”设置项中，点击“＋”好按钮，添加一个新的“New Run Script Phase”，内容如下/usr/local/bin/carthage copy-frameworks和路径添加到框架下您想要使用“输入文件”,如$(SRCROOT)/Carthage/Build/iOS/Realm.framework,$(SRCROOT)/Carthage/Build/iOS/RealmSwift.framework这个脚本是在应用程序商店提交错误引发了普遍的二进制文件。确保这一阶段后,“嵌入框架”阶段。 H3 创建数据模型 H4 方便快捷的创建Realm模型首先需要安装Alcatraz,在终端里面执行以下命令.如果执行失败，请翻墙后在尝试 curl -fsSL https://raw.githubusercontent.com/supermarin/Alcatraz/deploy/Scripts/install.sh | sh 安装完成之后，重启xcode就可以在菜单window选项下面看到一个Package Manager 选项，点击 安装package ，搜索 Xcode Plugin ，之后，再重启。创建创建文件，就可以文件类型中有一个Realm选项，点击创建。之后生成文件！ 你会发现！！SHIT！！！！！我不如自己写了！！！！！！！ H4 创建Realm 数据模型其实创建Realm数据模型的方法超级简单，就和咱们平时创建Class是一样一样的。 import RealmSwift // 狗的数据模型 class Dog: Object { dynamic var name = \"\" dynamic var owner: Person? // 狗的主人是可以为空的 } 但是，在们必须知道他都允许咱们创建什么类型的数据。 这样子咱们创建数据模型的时候就没有问题了吧。当然Realm是支持绑定关系的。一对一，一对多之类的，都可以的。 H3 数据的操作 H4 向Realm插入数据终于迎来了，咱们的增删改查了。 当你定义一个模型你可以实例化对象子类和新实例添加到域。考虑一下这个简单的模型: class Dog: Object { dynamic var name = \"\" dynamic var age = 0 } 我们可以以下几个方式创建对象: // (1) 先创建狗的对象，然后在给予其赋值 var myDog = Dog() myDog.name = \"Rex\" myDog.age = 10 // (2) 使用字典创建 let myOtherDog = Dog(value: [\"name\" : \"Pluto\", \"age\": 3]) // (3) 使用一个Array创建y。 let myThirdDog = Dog(value: [\"Fido\", 5]) 1.最显而易见的就是 直接创建对象，并且赋值2.也可以使用字典实例化对象，但是！要使用数据模型中对应的！的键和值。3.最后,可以使用数组实例化对象。但是要注意！数组中的值，必须和数据模型中的属性的顺序保持一致 创建完成对象之后就是把它放入数据库里面了，你可以像下面的方法一样放进数据库 // 创建一个用户对象，并且赋值 let author = Person() author.name = \"David Foster Wallace\" // 得到默认的Realm对象 let realm = try! Realm() // 你只需要这么做一次 // 添加这个对象到Realm try! realm.write { realm.add(author) } 这样就在数据库中，添加了一个对象了。 H4 Realm修改数据Realm 提供很多方式去修改数据，请选择适合自己的方式进行修改 H5 Typed Updates你可以修改任何对象的属性，在write进程中 // Update an object with a transaction try! realm.write { author.name = \"Thomas Pynchon\" } H5 根据数据的主键进行修改重写数据模型的Object.primaryKey()方法可以设置模型的主键，声明一个主键，允许对象可以通过主键进行有效的查询和修改，并强制每个值的唯一性。一旦一个对象添加到Realm，主键就不能更改 class Book: Object { dynamic var id = 0 dynamic var price = 0 dynamic var title = \"\" override static func primaryKey() -> String? { return \"id\" } } 因为这个数据模型含有主键，所以再向Realm添加一个对象时，如果已经存在同样主键的对象时，Realm会自动更新前一个数据的其它不一样的属性。而如果不存在这个主键的对象，Realm会创建一个新的对象 // 假设Realm中存在一个主键为1的对象的时候 let cheeseBook = Book() cheeseBook.title = \"Cheese recipes\" cheeseBook.price = 9000 cheeseBook.id = 1 // id==1，修改这个书的属性 try! realm.write { realm.add(cheeseBook, update: true) } 你也可以通过一个字典的方式，指定主键和你要修改的属性，来进行修改用户 // 假设数据库中已经存在一个主键为1的Book时 try! realm.write { realm.create(Book.self, value: [\"id\": 1, \"price\": 9000.0], update: true) // the book's `title` property will remain unchanged. } H5 修改大批量数据可以获取一群数据后，指定这些数据其中的某些数据，或者全部数据。 的某一歇属性值。 let persons = realm.objects(Person) try! realm.write { // 设置第一个人的 isFirst对象为True persons.first?.setValue(true, forKeyPath: \"isFirst\") // 把每个人的所居住的行星，设置为地球 persons.setValue(\"Earth\", forKeyPath: \"planet\") } H4 Realm删除数据当用户想删除某一个对象的时候，查询出来，之后～ // let cheeseBook = ... Book stored in Realm //删除一个对象，在Wirte交易中。 try! realm.write { realm.delete(cheeseBook) } 你也可以删除Realm中的全部数据，这很快速 // 删除Realm中所有的对象 try! realm.write { realm.deleteAll() } H4 Realm查询数据Realm称为这么受欢迎的数据库的原因来了！咱们看她们官方的解释。 Queries return a Results instance, which contains a collection of Objects. Results have an interface very similar to Array and objects contained in a Results can be accessed using indexed subscripting. Unlike Arrays, Results only hold Objects of a single subclass type. 查询返回一个结果实例，它包含一个对象集合。结果类似于Array一样的东西，可以使用下标来进行每一个数据的访问。和Arrays不一样的地方在于,查询结果只持有一种类型的对象。 All queries (including queries and property access) are lazy in Realm. Data is only read when the properties are accessed. 在Realm中，所有的查询（这里面包括了查询和属性的访问）都是懒加载的。数据仅仅在数据访问的时候再进行唯一的一次读取 那么就让我们来试试吧。 let dogs = realm.objects(Dog) // 这样子就查询了Realm数据库中所有的狗 H4 条件筛选如果你熟悉nspredicate，那么你已经到了指导如何查询的境界。对象、Realms，列表，和结果都提供了方法，查询一个结果Arrays 可以传递一个nspredicate实例，谓词字符串，或谓格式字符串。例如，检索所有狗的颜色棕褐色和名字首“B”从默认的境界： // 查询使用谓词字符串 var tanDogs = realm.objects(Dog).filter(\"color = 'tan' AND name BEGINSWITH 'B'\") // 查询使用 NSPredicate 实例 let predicate = NSPredicate(format: \"color = %@ AND name BEGINSWITH %@\", \"tan\", \"B\") tanDogs = realm.objects(Dog).filter(predicate) 看到苹果的谓词编程指南建立谓词的更多信息和使用我们的nspredicate列表。领域支持许多共同的谓词： 比较操作数可以是属性名称或常量。至少一个操作数必须是一个属性名。 比较运算符= =，&lt;，&gt; =，&gt;，！=，支持Int, Int8, Int16, Int32, Int64, Float, Double 和 NSDate 属性类型。如: age == 45 身份比较 == ，!= ，Results&lt;Employee&gt;().filter(&quot;company == %@&quot;, company) 比较运算符 = 和 != 需要Bool属性的支持。 字符串和NSData性质，我们我们支持 ==, !=,BEGINSWITH,CONTAINS, andENDSWITH ，如名称中 CONTAINS ‘Ja’ 不区分大小写的比较字符串，如:CONTAINS[c] ‘Ja’。请注意只有字符A-Z和a-z会被忽略。 Realm支持以下复合操作：: AND, OR, and NOT. 例如：name BEGINSWITH ‘J’ AND age &gt;= 32 包含操作符号 IN， 如 名字 name IN {‘Lisa’, ‘Spike’, ‘Hachi’} 我们可以比较属性是否为空，如：Results&lt;Company&gt;().filter(&quot;ceo == nil&quot;).注意，境界把Nil作为一个特殊的值而不是一个属性的缺失，所以不像SQL零等于本身。 任何的比较，如有 student.age＜21 聚合表达式@count, @min, @max, @sum 和 @avgRealm都支持。例如：realm.objects(Company).filter(&quot;employees.@count &gt; 5&quot;)。找到所有员工在五个以上的公司 子查询的限制和支持： @count在子查询表达式是唯一的。 SUBQUERY(…).@count必须和一个常量进行比较 相关子查询现在还不支持 H5 排序结果允许您在一个或多个属性的基础上指定一个排序标准和顺序。例如，下面的例子中狗按照名字来进行排序返回： let sortedDogs = realm.objects(Dog).filter(\"color = 'tan' AND name BEGINSWITH 'B'\").sorted(\"name\") H5 链式查询Realm 和其它的查区别在于，他每一个查询结果都拥有继续查询的能力，这样用户就可以对自己查询的结果进行进一步的询问。例如：我们先查找了一群棕色的狗，之后又想查询处其中名字以“B”开头的狗。 let tanDogs = realm.objects(Dog).filter(\"color = 'tan'\") let tanDogsWithBNames = tanDogs.filter(\"name BEGINSWITH 'B'\") H3 Realm版本迁移其实一般的版本迁移有两种情况，第一种。删除了某些字段 class Person: Object { dynamic var firstName = \"\" dynamic var lastName = \"\" dynamic var age = 0 } To: class Person: Object { dynamic var fullName = \"\" dynamic var age = 0 } 接下来，你将进行 // 在你的(application:didFinishLaunchingWithOptions:) let config = Realm.Configuration( // 设置一个新的版本，如果你从来没有设置过版本，那么默认版本就是0 schemaVersion: 1, /// 设置一个找到不一样版本的回调方法 migrationBlock: { migration, oldSchemaVersion in // 因为我们没有设置过版本，所以 oldSchemaVersion &lt; 1 if (oldSchemaVersion &lt; 1) { // 什么都不用做 // Realm 将自动检测新的属性和删除的属性 // 并会自动更新磁盘模式 } }) // 告诉Realm 使用这个新的配置作为默认配置 Realm.Configuration.defaultConfiguration = config // 接下来就让我们获得默认的对象吧 let realm = try! Realm() 而如果你添加了一些字段，比如咱们不想要FirstName和LastName了，我们希望他变成一个字段！fullName！ // 在你的(application:didFinishLaunchingWithOptions:) Realm.Configuration.defaultConfiguration = Realm.Configuration( schemaVersion: 1, migrationBlock: { migration, oldSchemaVersion in if (oldSchemaVersion &lt; 1) { // 枚举所有的属性 migration.enumerate(Person.className()) { oldObject, newObject in // 从旧的对象中获取之前存储的东西 let firstName = oldObject![\"firstName\"] as! String let lastName = oldObject![\"lastName\"] as! String // 设置到新的对象中的属性上去 newObject![\"fullName\"] = \"\\(firstName) \\(lastName)\" } } }) 还有一种情况：从版本0 直接 升到 版本2 Realm.Configuration.defaultConfiguration = Realm.Configuration( schemaVersion: 2, migrationBlock: { migration, oldSchemaVersion in // The enumerateObjects:block: method iterates // over every 'Person' object stored in the Realm file migration.enumerate(Person.className()) { oldObject, newObject in // Add the `fullName` property only to Realms with a schema version of 0 if oldSchemaVersion &lt; 1 { let firstName = oldObject![\"firstName\"] as! String let lastName = oldObject![\"lastName\"] as! String newObject![\"fullName\"] = \"\\(firstName) \\(lastName)\" } // Add the `email` property to Realms with a schema version of 0 or 1 if oldSchemaVersion &lt; 2 { newObject![\"email\"] = \"\" } } }) // Realm will automatically perform the migration and opening the Realm will succeed let realm = try! Realm() H3 Realm数据变化通知结果或列表是通过调用addnotificationblock方法在其数值发生变化的时候给予通知这是可能的。每一次写事务提交时，在其他线程上的其他线程发送通知到其他实例： // 注册通知 let token = realm.addNotificationBlock { notification, realm in viewController.updateUI() } // 稍后 token.stop() 当然你也可以注册某一范围的数值发生变化的时候，进行给予通知 // 大于5岁的人年纪发生变化的时候进行统治 let token = realm.objects(Person).filter(\"age > 5\").addNotificationBlock { results, error in // results 就已经是 `realm.objects(Person).filter(\"age > 5\")`的结果集了 viewController.updateUI() } // 稍后 token.stop() 其它更详细的文档请访问 Realm－Swift文档 realm-cocoa 学习.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"DB","slug":"DB","permalink":"http://blog.msiter.com/tags/DB/"},{"name":"realm","slug":"realm","permalink":"http://blog.msiter.com/tags/realm/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"IOS Tips 小集合","slug":"IOS Tips 小集合","date":"2015-08-10T20:53:35.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"IOS Tips xjh,g-20150810.html","link":"","permalink":"http://blog.msiter.com/IOS Tips xjh,g-20150810.html","excerpt":"IOS技巧，在工作学习中遇到的一些有点意思的小技巧，记录在在这里","text":"听说人在死前的一秒钟，他的一生会闪过眼前。 IOS技巧，在工作学习中遇到的一些有点意思的小技巧，记录在在这里 H2 代码记录H3 获取状态栏 ///获取状态栏 private func JZStatusBar() -> UIView?{ var object = UIApplication.sharedApplication(),statusBar:UIView? if object.respondsToSelector(NSSelectorFromString(\"statusBar\")) { statusBar = object.valueForKey(\"statusBar\") as? UIView } return statusBar } H3 动态显示视图///按钮扩展类 @IBDesignable class borderImageView:UIButton{ /// 设置边框宽度 @IBInspectable var borderWidth:CGFloat = 0 { didSet{ self.layer.borderWidth = borderWidth } } /// 设置边框颜色 @IBInspectable var borderColor:UIColor = UIColor.blackColor() { didSet{ self.layer.borderColor = borderColor.CGColor } } /// 设置圆形弧度 @IBInspectable var cornerRadius:CGFloat = 0{ didSet{ self.layer.cornerRadius = cornerRadius } } } H3 检测键盘弹起隐藏func resignNotification(){ NSNotificationCenter.defaultCenter().addObserver(self, selector: \"keyboardShow:\", name: UIKeyboardWillShowNotification, object: nil) NSNotificationCenter.defaultCenter().addObserver(self, selector: \"keyboardHide:\", name: UIKeyboardWillHideNotification, object: nil) } //通知中心通知键盘要出现了！ 😳 全员戒备！ func keyboardShow(note:NSNotification){ if let info = note.userInfo { let keyboardFrame:CGRect = (info[UIKeyboardFrameEndUserInfoKey] as! NSValue).CGRectValue() let deltay:CGFloat = keyboardFrame.size.height as CGFloat self.InputBackViewBottomSpaceConstraint.constant = deltay self.view.layoutIfNeeded() } } //通知中心通知键盘要消失了 😄 解散~ 庆功宴~~ func keyboardHide(note:NSNotification){ self.InputBackViewBottomSpaceConstraint.constant = 0 self.view.layoutIfNeeded() } H3 单例模式 /// 获取单例模式下的UIStoryBoard对象 class var shareWelComeStoryBoard:UIStoryboard!{ get{ struct backTaskLeton{ static var predicate:dispatch_once_t = 0 static var bgTask:UIStoryboard? = nil } dispatch_once(&amp;backTaskLeton.predicate, { () -> Void in backTaskLeton.bgTask = UIStoryboard(name: \"WelCome\", bundle: NSBundle.mainBundle()) }) return backTaskLeton.bgTask } } H3 获取当前显示的UIViewControllerextension UIViewController{ class func getCurrentViewController() -> UIViewController?{ if let rootViewController = UIApplication.sharedApplication().keyWindow?.rootViewController{ var topViewController = rootViewController while let present = topViewController.presentedViewController{ topViewController = present } return topViewController } return nil } } /// 调用方法如下 if let currentViewController = UIViewController.getCurrentViewController(){ //// 略 } H3 判断是否在前台 /// 处于前台 if application.applicationState == UIApplicationState.Active{ /// 处于后台 }else if application.applicationState == UIApplicationState.Inactive{ } H3 一下子dismiss 两个ViewControllerself.presentingViewController!.presentingViewController?.dismissViewControllerAnimated(true, completion: { () -> Void in }) H2 第三方导入库H3 下拉刷新BreakOutToRefresh 一个下拉刷新打砖块的swift库SDRefreshView 简单易用的上拉和下拉刷新ZLSwiftRefresh - 下拉刷新/上拉加载更多，支持自定义动画，集成简单GearRefreshControl - 一个非常精细的下拉刷新 做的很细心refresher - 简洁清爽的下拉刷新PullToBounce - 弹性动画 非常炫酷的下拉刷新RCTRefreshControl qq的橡皮糖下拉刷新PullToRefresh 刷新动画可定制的下拉数据请求更新组件MLSwiftBasic 集合自定义导航栏、下拉刷新/上拉加载更多、视觉效果、好用分类等等一系列，却耦合性很低的Swift库! H3 图片选择、浏览 (这部分swift库真少呀 欢迎知道的补充)PhotoBrowser-swift 图片浏览PhotoPicker swift图片选择BSImagePicker 这个图片选择 不错，oc和swift都有 真贴心呀KYElegantPhotoGallery - 一个优雅的图片浏览库(可惜OC写的呀。。。。)CocoaPicker - 仿 QQ 图片选择器（非swift）。 H3 网络部分Alamofire 著名的 AFNetworking 络基础库 Swift 语言版AlamofireImage 基于 Alamofire 的网络图片组件库Reachability.swift Reachability Swift 版本Ji Swift 版 HTML/XML 解析器CoreStore 提供高可读性，一致性及安全性的 Core Data 管理类库SwiftyJSON GitHub 上最为开发者认可的 JSON 解析类 H3 图片Kingfisher onevcat 大神开发的处理网络图片及缓存的库ImageScout 最小网络代价获得图片大小及类型Nuke 完整、强大、实用的图片管理类库HanekeSwift 轻量带缓存高性能图片加载组件UIImageColors 获取图片张的主色调和其相对应的对比色，背景色之类的框架，可以去看一下，感觉用到的地方还是会很多的 H3 界面效果,动画等awesome-ios-animation 收集了iOS平台下比较主流炫酷的几款动画框架（这上面有很多，孙然不是全部用swift写的。但是还是可以鉴赏下）LiquidFloatingActionButton 可定制水滴型浮动动态按钮组件及演示PNChart-Swift 带动画效果的图表控件库HamburgerButton - Menu/Close 无论设计还是代码，都进行了精雕细琢HamburgerButton - Check Hamburger 风格按钮动画图标（单选）组件entotsu/TKSubmitTransition 登录加载、返回按钮转场动画组件SweetAlert-iOS 带动画效果弹窗封装类Dodo 一款轻量地可定制信息栏小组件AnimatedTabBar 灵动的动画tabbarKYCircularProgress 简单、实用路径可定进程条ParkedTextField 带固定文本的输入组件optonaut/ActiveLabel.swift 扩展实现 UILabel 触控事件针对 “#, @, 链接” 响应GMStepper 带动画效果、支持手势滑动操作的步进标签KSTokenView 带搜索、快捷输入、分段显示关键词输入组件QRCodeReader QR 二维码阅读组件及示例EasyTipView 弹出提示框类及演示示例Popover 泡泡风格弹出视图封装类库TimingFunctionEditor - TimingFunctionEditor用swift编写， 贝塞尔曲线编辑器，编辑后可以预览或拷贝代码片段直接使用。P.S. 该项目采用更简单的依赖管理器Carthage ，而非常用的 CocoaPods。Carthage介绍中文。AAFaceDetection - AAFaceDetection–swift，简单、实用的面部识别封装库。虽然该技术从 iOS 5 发展，不过真正有趣的应用还不多。。Concorde - swift, Concorde, 一个可用于下载和解码渐进式 JPEG 的库, 可用来改善应用的用户体验。ZoomTransition - swift, 通过手势操控图片的放大、缩小、旋转等自由变化效果的组件及示例。AFImageHelper - swift,一套针对 UIImage 和 UIImageView 的实用扩展库，功能包含填色和渐变、裁剪、缩放以及具有缓存机制的在线图片获取PinterestSwift - swift,Pinterest 风格图片缩放、切换示例。NVActivityIndicatorView 等待指示器 真心多。UIViewXXYBoom 模拟MIUI卸载软甲的时候动画TisprCardStack 一款UICollection切换动画LTMorphingLabel 超级炫酷的Label切换文字的动画框架XLPagerTabStrip 多页UIViewControll框架 H3 约束AutolayoutSnapKit 我就用这一个 H3 数据库方面 realm-cocoa 经测试，表示比苹果自带的CoreData 速度更加的快，文档详细。版本迁移方便。 CoreStore 一款CoreData的第三方帮助库，使用CoreData更方面，包括版本迁移。 H3 相机KYShutterButton 模拟系统相机按钮…………TOCropViewController 模拟系统相册剪切图片时的界面MHVideoPhotoGallery 一款可以让你学习到很多知识的demo H3 其他方面ExSwift 一款Extension集合的框架，省着造轮子了JSQMessagesViewController 聊天页面的搭建，不用愁了～ 但是需要自己去实现一些，例如播放视频之类的东西，它本身只实现了文字和图片STClock 完全模仿锤子时钟，可以当作一个学习的案例 IOS Tips 小集合.md","categories":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}],"tags":[{"name":"ios","slug":"ios","permalink":"http://blog.msiter.com/tags/ios/"},{"name":"技巧","slug":"技巧","permalink":"http://blog.msiter.com/tags/技巧/"},{"name":"swift","slug":"swift","permalink":"http://blog.msiter.com/tags/swift/"}],"keywords":[{"name":"IOS","slug":"IOS","permalink":"http://blog.msiter.com/categories/IOS/"}]},{"title":"Swagger 初级学习","slug":"swagger 学习","date":"2015-07-13T18:41:43.000Z","updated":"2018-08-29T10:33:16.502Z","comments":true,"path":"swagger xx-20150713.html","link":"","permalink":"http://blog.msiter.com/swagger xx-20150713.html","excerpt":"最开始只是想找一个制作api的工具而已，然后再某一个帖子中发现了这个家伙。他不只是可以让你可以展示服务器的API接口。你甚至可以让客户端受益，生成客户端代码，让客户端开发者直接调用生成代码，使用生成的代码，访问你的接口并且完成数据的获取。So Coll Swagge is a simple yet powerful representation of your RESTful API","text":"突然想到你，笑了笑自己。 最开始只是想找一个制作api的工具而已，然后再某一个帖子中发现了这个家伙。他不只是可以让你可以展示服务器的API接口。你甚至可以让客户端受益，生成客户端代码，让客户端开发者直接调用生成代码，使用生成的代码，访问你的接口并且完成数据的获取。So Coll Swagge is a simple yet powerful representation of your RESTful API swagger的意思是 狂妄自大。但是等我介绍完毕之后你会的觉的他的狂妄绝对是有道理的，没有浮夸。具体来说他是什么呢，正如他自己的介绍，是一个简单而又强大的api发布工具，强大是毋庸置疑的，我现在知道也只是他的几个组件中的几个而已，还有更多的作用的，当然就是这几个作用我就已经获益匪浅了。废话不多说。 本文将从这几个步骤展开讲述： 作为服务器，我们应该如何向后端展示API介绍页面呢 在哪里编写呢？ 怎么编写？ 如何展示？ 仅限NodJs 作为客户端，我们如何获取数据根据Swagger的方式 如何获取? 怎么使用? 仅限swift H3 在哪里编写呢？两种是，一种是网络编辑器，第二种本地编辑器。如果你哪里的网络没有很差的话，比较推荐使用第一种方式。毕竟简单才是王道 点击这里进入 首先需要你拥有 nodejs 环境，然后执行以下语句 git clone https://github.com/swagger-api/swagger-editor.git cd swagger-editor npm start 其实这两种方式完成之后都会看到编辑页面。当然第一种会简单的很多。打开页面之后你要看看上面的导航栏哦 file自然就是文件的一些操作了，比如新建啊，打开自己的，或者打开魔板啊，之类的。、 Preferences 基本的一些配置，譬如说： 字体大小啊之类的饿，当然也会有其他的设置，但是如果你不是强迫症或者有自己的独特的准则的人，那么这个东西你可以无视 Generate Server 看他的意思也很明白了，生成服务器代码至于你生成什么语言的服务器就看你自己了。 Generate Client 生成客户端代码。很明显啦~ 哇哈哈哈 help - can l help you? 界面H3 怎么编写呢这个就要说起来话就多了，但是我就挑一些重要的吧。毕竟我懒…这里的编辑需要一种模板语言的基础。````yamlH6 使用请打开 【http://editor.swagger.io/#/】 或者 ################################################################################ H1 swagger################################################################################ #这个是必须的swagger: ‘2.0’ ################################################################################ H1 info################################################################################ #文档信息info: title: 遇见 Api description: 遇见 web Service Api 接口。该接口文档用于开发者更好的根据数据，用于遇见用户的记录和遇见用户动态的整合。 version: “1.0.0” termsOfService: Copyright [2015] [一匡天下] license:#可有可无 name: Apache 2.0 url: http://www.apache.org/licenses/LICENSE-2.0.html contact: name: 荆文征 url: msiter.com email: msiter@qq.com H1 API地址host: api.msiter.com H1 请求方式schemes: httpH1 这个字段会添加到所有的API前面，当做版本控制字段还是不错的#basePath: /v1 #MIME类型的api可以产生的列表。这是可以覆盖全球所有API,但在特定的API调用。值必须是所述 http://http://swagger.io/specification/#mimeTypesconsumes: application/json #MIME类型的api可以产生的列表。这是可以覆盖全球所有API,但在特定的API调用。值必须是所述 http://http://swagger.io/specification/#mimeTypesproduces: application/json################################################################################H1 Tags#################################################################################标签，如果你不写的话，他会自动帮你生成的。如果你自己写的话…请注意到咱们的民族。大中国语言毕竟有些不被世界接受，所以难免不好看。还是希望使用英文吧。tags: name: 用户description: | 有关于用户的接口API: 关于注册 关于获取 name: 动态description: | 有关于动态的接口API: 关于创建 关于获取 name: 辅助标签description: | 单纯的为了好看################################################################################ H1 paths#################################################################################接下里就是API主题了paths:/users/registered:post: summary: 注册用户 description: 根据用户传入的新浪微博参数,返回数据库里的用户信息. parameters: name: sourcerequired: truein: querytype: stringformat: stringdescription: 新浪微博 App Id name: access_tokenrequired: truein: querytype: stringformat: stringdescription: 新浪微博 认证口令 name: uidrequired: truein: querytype: stringformat: stringdescription: 新浪微博 用户ID.tags: 用户responses:200:description: 请求完成，获取用户成功schema: $ref: ‘#/definitions/User’400:description: 请求失败schema: $ref: ‘#/definitions/Error’ /users/obtainbyid:get: summary: 根据用户id获取用户信息 description: 根据用户传入的用户id获取用户的信息. parameters: name: masteridrequired: truein: querytype: stringformat: stringdescription: 主人id name: otheridrequired: falsein: querytype: stringformat: stringdescription: 要查询的用户id,如果不传递则查询主人idtags: 用户responses:200:description: 请求完成，获取用户成功schema: $ref: ‘#/definitions/User’400:description: 请求失败schema: $ref: ‘#/definitions/Error’/users/obtainallmeetuser:get:summary: get User By Iddescription: 根据用户id获取用户所有的遇见的人信息.这个接口其实就是获取用户的好友。parameters: name: useridrequired: truein: querytype: stringformat: stringdescription: 用户idtags: 用户responses:200:description: 请求完成，获取用户成功schema: type: array items: $ref: ‘#/definitions/User’400:description: 请求失败schema: $ref: ‘#/definitions/Error’################################################################################H1 Definitions#################################################################################API所需要的模块。definitions:User:description: 用户对象type: objectproperties:_id:type: stringdescription: 用户id.sinaId:type: stringdescription: 新浪微博唯一标示.name:type: stringdescription: 用户名称.gender:type: stringdescription: 用户性别 m：男、f：女、n：未知.commGround:type: stringdescription: 用户常出没地.signature:type: stringdescription: 用户的个性签名.headPhotoKey:type: stringdescription: 七牛的文件访问标示.createDateTime:type: stringformat: date-timedescription: 用户注册时间.userLabels:type: arrayitems:$ref: ‘#/definitions/UserLabel’userBacks:type: arrayitems:$ref: ‘#/definitions/UserBack’UserBack:description: 用户背景对象type: objectproperties:index:type: numberdescription: 用户背景的排序表示.identifier:type: stringdescription: 用户背景的唯一标示.imageKey:type: stringdescription: 七牛的文件访问标示.UserLabel:description: 用户个性签名对象type: objectproperties:content:type: stringdescription: 用户背景的排序表示.identifier:type: stringdescription: 用户背景的唯一标示.createDateTime:type: stringformat: date-timedescription: 七牛的文件访问标示.Error:description: 错误信息properties:error:type: stringdescription: 错误信息. 这个我真的不知道怎么说了，代码复制一下，复制到编辑器内。看看效果对照着来，我相信很快就会学会的。当然人家也是提供了一些示例代码了的，你也可以不看我的这个的。 ### 怎么展示 那就`so Easy`啦，去导航下载你索对应的服务器语言就OK，找不到？ 那么我推荐你使用`NODEJS`。 比如我就是下载的nodejs代码，解压后 cd nodejs-servernpm installnode index.js 然后[点击](http://localhost:8080/docs)不出现什么重大意外，你现在已经处于api页面了。 ### 如何获取? 点击导航内，并下载你所对应的语言 ### 怎么使用? - `swift` 我只知道swift的oc 的类似，其他的语言小弟不曾涉猎。抱歉。 下载完成后，解压后进入后： 1. 如果你使用的`cocopod`,只需要把 文件夹内的`SwaggerClient`文件夹一股脑的拽进你的项目就OK，当然你需要查看一下 `Carfile`文件看看需要引入那些第三方，pod install就可以了。 2. `Carthage`是一个第三方加载组件。我之前因为不知道，直接使用`cocopod`也可以,所以尝试了一番，故记下： - 安装 `Carthage` - 使用 `brew install Carthage` 2. 安装完成后，进入文件目录，`Carthage update` 3. 打开项目，在项目的某个Target -> Build Phases -> Link Library with Libraries，将Carthage/Build目录中希望导入的Framework库拖拽进去。 4. 添加脚本，添加Input Files - 添加脚本 ```/usr/local/bin/carthage copy-frameworks - 添加Input Files ```$(SRCROOT)/Carthage/Build/iOS/你所需要的.framework``` swagger 学习.md","categories":[{"name":"开发帮助","slug":"开发帮助","permalink":"http://blog.msiter.com/categories/开发帮助/"}],"tags":[{"name":"swagger","slug":"swagger","permalink":"http://blog.msiter.com/tags/swagger/"},{"name":"api","slug":"api","permalink":"http://blog.msiter.com/tags/api/"}],"keywords":[{"name":"开发帮助","slug":"开发帮助","permalink":"http://blog.msiter.com/categories/开发帮助/"}]},{"title":"Mongoose 学习","slug":"Mongoose 学习","date":"2015-07-11T20:53:35.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Mongoose xx-20150711.html","link":"","permalink":"http://blog.msiter.com/Mongoose xx-20150711.html","excerpt":"Mongoose is a MongoDB object modeling tool designed to work in an asynchronous environment. 关于mongodb的优势之类的话，我也就不说什么，因为你既然使用这个数据库的话，我相信你已经对他的基本信息很了解了。另外本篇文章没有基本的操作。主要是针对，子表和关联表的操作。因为我觉的基本的操作，不是很麻烦，而遍地都是文档，我感觉没什么必要再叨唠一遍了","text":"醉后不知天在水，满船清梦压星河。 Mongoose is a MongoDB object modeling tool designed to work in an asynchronous environment. 关于mongodb的优势之类的话，我也就不说什么，因为你既然使用这个数据库的话，我相信你已经对他的基本信息很了解了。另外本篇文章没有基本的操作。主要是针对，子表和关联表的操作。因为我觉的基本的操作，不是很麻烦，而遍地都是文档，我感觉没什么必要再叨唠一遍了 H2 MongoDB 简介MongoDB 是一个基于分布式文件存储的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。 H2 数据库操作H3 连接数据库，创建一个表。///获取Mongoose组件 var mongoose = require('mongoose'); ///链接至数据库，Meet则为数据库名称 mongoose.connect('mongodb://localhost/Meet'); 既然已经连接上的话，那么接下来就该是如何创建表了。 var mongoose = require('mongoose'); var UserSchema = new mongoose.Schema({ sinaId: String, name: String, gender: String,//性别，m：男、f：女、n：未知 commGround: String, signature: String, headPhotoKey: String, userBacks: [{ identifier: String, index: Number, imageKey: String }], userLabels: [{ content: String, identifier: String, createDateTime: {type: Date, default: Date.now} }], createDateTime: {type: Date, default: Date.now} }, {collection: \"User\"});///User就是表名了 /** 中间写其他的一些方法 */ var User = mongoose.model('User', UserSchema); 至此 一个表已经创建完成了，可能你会诧异为什么你启动了服务器并且也连接到了数据库却没有创建表，不要着急，你没有数据的时候，数据库是不会显示的。 H2 子表如何操作大家看我接下来的一张表 var UserSchema = new mongoose.Schema({ sinaId: String,//新浪微博ID name: String,//用户名称 gender: String,//性别，m：男、f：女、n：未知 commGround: String,//唱出没地 signature: String,//个性签名 headPhotoKey: String,//头像地址 userLabels: [{//用户个人标签集合 content: String,//内容 identifier: String,//唯一标示 createDateTime: {type: Date, default: Date.now}//创建时间 }], createDateTime: {type: Date, default: Date.now},//用户注册时间 isDelete: {type: Boolean, default: false}//是否删除 }, {collection: \"MeetUser\"}); 这是一个基本的用户数据类型。接下来让我们来看看如何操作这个类型那个吧。 H3 子表新增数据 //创建用户标签方法 UserSchema.statics.createUserLabel = function (userid, identifier, content, createtime, callBack) { //首先查看数据库中该用户是否存在这个个人标签，方法会在下面列出 this.findUserLabel(userid, identifier, function (err, result) { if (result) { if (callBack)return callBack(err, result); return; } //如果并没有该对象，那么久创建一个新德对象 var b = { identifier: identifier, content: content, createDateTime: createtime } //这里就是重点，使用findOneAndUpdate找到高用户，之后使用 $push 新增一个用户个人标签，并且执行 User.findOneAndUpdate({\"_id\": mongoose.Types.ObjectId(userid)}, {'$push': {\"userLabels\": b}}).exec(function (err, result) { ///接口需要所以要在增加完成之后，获取这个用户并且返回 User.findOne({\"_id\": mongoose.Types.ObjectId(userid)}, function (err, result) { callBack(err, result); }); }); }); }; H3 子表查找数据///该方法就是上面方法中调用的查找方法 UserSchema.statics.findUserLabel = function (userid, identifier, callBack) { this.findOne({ \"_id\": mongoose.Types.ObjectId(userid), \"userLabels.identifier\": identifier }, function (err, result) { if (callBack)return callBack(err, result); }) }; H3 子表删除数据由于业务上的需要，所以接下来方法是清空该用户所有的个人标签 UserSchema.statics.cleanUserLabels = function (userid, callBack) { ///先找到该用户 this.findOne({\"_id\": mongoose.Types.ObjectId(userid)}, function (err, result) { ///循环遍历用户的个人标签，async 会在另一篇博客中详细讲解 async.map(result.userLabels, function (item, callback) { // 之后使用 $pull 删除用户的个人标签 User.update({\"_id\": mongoose.Types.ObjectId(userid)}, {'$pull': {\"userLabels\": {\"identifier\": item.identifier}}}, function (err, numberUpdated) { callback(null, true) }); }, function (err, results) { if (callBack)return callBack(results.length); }); }); }; H3 子表修改数据UserSchema.statics.modifysUserLabel = function (userid, identifier,content, callBack) { this.update({ \"_id\": mongoose.Types.ObjectId(userid), \"userLabels.identifier\": identifier }, {'$set': {\"userLabels.$.content\": content}}, function (err, numberUpdated) { User.findById(userid, function (err, data) { if(callBack)callBack(err, data); }); }); }; 以上就是子类的增删改查。希望对你有些许帮助。基本的增删改查，我这里就不多多解释了。 ##关联表如何操作 在mongodb中并没有关联表这么一说，这也是因为mongodb本身就是非关系型数据库，但是mongoose中的populate方法在一定程度上解决了关联问题 首先来查看一些数据库的设计吧。 H3 关联表设计//用户表 var UserSchema = new mongoose.Schema({ name: String }, {collection: \"MeetUser\"}); //加入数据库 var User = mongoose.model('User', UserSchema); //分组表 var GroupSchema = new mongoose.Schema({ name:String, //此时的ref字段要和加入数据库中的model方法内的字段吻合，并且记住一定要写字符串 users:[{type:mongoose.Schema.ObjectId,ref:'User'}] },{collection:\"MeetGroup\"}); var Group = mongoose.model('Group',GroupSchema); H3 关联表查询方法 GroupSchema.statics.loadGroup = function(callBack){ Group.find().populate('users').exec(callBack); }; 以上是比较基础的查询，但是我们开发的时候遇到的往往没有那么简单，如果我想对字表进行排序或者筛选再或者我只想要子表里的其中一些字段该怎么办呢 H3 关联表准确查询GroupSchema.statics.loadGroup = function(callBack){ var populateQuery = {path:'users',select:'name',match:{ 'name':'Msiter' },options:{ limit:20 },sort:{'_id':1}}; Group.findOne({name:\"Test\"}).select('name users').populate(populateQuery).exec(callBack); }; 其中 Path字段是指要查询的 哪一个 关联表，select 则是需要字表的那些字段 ，如果需要多个 中间一个 空格分隔即可，_id字段是默认被需要的。match就是对关联表的这些筛选的，options就可以使用分页参数 Skip和limit了 当然也有一些常见的查询参数譬如Sort等； H3 关联表的增加呢？///这里的Userid时mongoose.Schema.ObjectId，即你要关联的对象的Id GroupSchema.statics.createGroup = function(groupname,userId,callBack){ var group = new Group({name:groupname}); group.users.push(userId); group.save(callBack); }; H3 关联表的删除///这里的Userid时mongoose.Schema.ObjectId，即你要关联的对象的Id GroupSchema.statics.createGroup = function(groupname,userId,callBack){ var group = new Group({name:groupname}); group.users.pull(userId); group.save(callBack); }; Mongoose 学习.md","categories":[{"name":"服务器","slug":"服务器","permalink":"http://blog.msiter.com/categories/服务器/"}],"tags":[{"name":"mongodb","slug":"mongodb","permalink":"http://blog.msiter.com/tags/mongodb/"},{"name":"mongoose","slug":"mongoose","permalink":"http://blog.msiter.com/tags/mongoose/"},{"name":"nodejs","slug":"nodejs","permalink":"http://blog.msiter.com/tags/nodejs/"}],"keywords":[{"name":"服务器","slug":"服务器","permalink":"http://blog.msiter.com/categories/服务器/"}]},{"title":"Nodejs Async 学习","slug":"Nodejs Async 学习","date":"2015-07-06T18:41:43.000Z","updated":"2018-08-29T10:33:16.498Z","comments":true,"path":"Nodejs Async xx-20150706.html","link":"","permalink":"http://blog.msiter.com/Nodejs Async xx-20150706.html","excerpt":"本文整理于bsspirit的博文和代码示例 Async是一个流程控制工具包，提供了直接而强大的异步功能。基于Javascript为Node.js设计，同时也可以直接在浏览器中使用。Async提供了大约20个函数，包括常用的map,reduce, filter, forEach 等，异步流程控制模式包括，串行(series)，并行(parallel)，瀑布(waterfall)等。","text":"让你难过的事情，有一天，你一定会笑着说出来。 本文整理于bsspirit的博文和代码示例 Async是一个流程控制工具包，提供了直接而强大的异步功能。基于Javascript为Node.js设计，同时也可以直接在浏览器中使用。Async提供了大约20个函数，包括常用的map,reduce, filter, forEach 等，异步流程控制模式包括，串行(series)，并行(parallel)，瀑布(waterfall)等。 H2 项目简介Async For Async v1.5.x documentation, go HERE Async is a utility module which provides straight-forward, powerful functionsfor working with asynchronous JavaScript. Although originally designed foruse with Node.js and installable via npm install --save async,it can also be used directly in the browser. Async is also installable via: bower: bower install async component: component install caolan/async jam: jam install async Async provides around 70 functions that include the usual ‘functional’suspects (map, reduce, filter, each…) as well as some common patternsfor asynchronous control flow (parallel, series, waterfall…). All thesefunctions assume you follow the Node.js convention of providing a singlecallback as the last argument of your asynchronous function – a callback which expects an Error as its first argument – and calling the callback once. H2 功能简介 H3 集合:Collections each: 如果想对同一个集合中的所有元素都执行同一个异步操作。 map: 对集合中的每一个元素，执行某个异步操作，得到结果。所有的结果将汇总到最终的callback里。与each的区别是，each只关心操作不管最后的值，而map关心的最后产生的值。 filter: 使用异步操作对集合中的元素进行筛选, 需要注意的是，iterator的callback只有一个参数，只能接收true或false。 reject: reject跟filter正好相反，当测试为true时则抛弃 reduce: 可以让我们给定一个初始值，用它与集合中的每一个元素做运算，最后得到一个值。reduce从左向右来遍历元素，如果想从右向左，可使用reduceRight。 detect: 用于取得集合中满足条件的第一个元素。 sortBy: 对集合内的元素进行排序，依据每个元素进行某异步操作后产生的值，从小到大排序。 some: 当集合中是否有至少一个元素满足条件时，最终callback得到的值为true，否则为false. every: 如果集合里每一个元素都满足条件，则传给最终回调的result为true，否则为false concat: 将多个异步操作的结果合并为一个数组。 H3 流程控制: Control Flow concat: 串行执行，一个函数数组中的每个函数，每一个函数执行完成之后才能执行下一个函数。 parallel: 并行执行多个函数，每个函数都是立即执行，不需要等待其它函数先执行。传给最终callback的数组中的数据按照tasks中声明的顺序，而不是执行完成的顺序。 whilst: 相当于while，但其中的异步调用将在完成后才会进行下一次循环。 doWhilst: 相当于do…while, doWhilst交换了fn,test的参数位置，先执行一次循环，再做test判断。 until: until与whilst正好相反，当test为false时循环，与true时跳出。其它特性一致。 doUntil: doUntil与doWhilst正好相反，当test为false时循环，与true时跳出。其它特性一致。 forever: 无论条件循环执行，如果不出错，callback永远不被执行。 waterfall: 按顺序依次执行一组函数。每个函数产生的值，都将传给下一个。 compose: 创建一个包括一组异步函数的函数集合，每个函数会消费上一次函数的返回值。把f(),g(),h()异步函数，组合成f(g(h()))的形式，通过callback得到返回值。 applyEach: 实现给一数组中每个函数传相同参数，通过callback返回。如果只传第一个参数，将返回一个函数对象，我可以传参调用。 queue: 是一个串行的消息队列，通过限制了worker数量，不再一次性全部执行。当worker数量不够用时，新加入的任务将会排队等候，直到有新的worker可用。 cargo: 一个串行的消息队列，类似于queue，通过限制了worker数量，不再一次性全部执行。不同之处在于，cargo每次会加载满额的任务做为任务单元，只有任务单元中全部执行完成后，才会加载新的任务单元。 auto: 用来处理有依赖关系的多个任务的执行。 iterator: 将一组函数包装成为一个iterator，初次调用此iterator时，会执行定义中的第一个函数并返回第二个函数以供调用。 apply: 可以让我们给一个函数预绑定多个参数并生成一个可直接调用的新函数，简化代码。 nextTick: 与nodejs的nextTick一样，再最后调用函数。 times: 异步运行,times可以指定调用几次，并把结果合并到数组中返回 timesSeries: 与time类似，唯一不同的是同步执行 H3 工具类: Utils memoize: 让某一个函数在内存中缓存它的计算结果。对于相同的参数，只计算一次，下次就直接拿到之前算好的结果。 unmemoize: 让已经被缓存的函数，返回不缓存的函数引用。 log: 执行某异步函数，并记录它的返回值，日志输出。 dir: 与log类似，不同之处在于，会调用浏览器的console.dir()函数，显示为DOM视图。 noConflict: 如果之前已经在全局域中定义了async变量，当导入本async.js时，会先把之前的async变量保存起来，然后覆盖它。仅仅用于浏览器端，在nodejs中没用，这里无法演示。 H2 代码演示 H3 apply代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * apply是一个非常好用的函数，可以让我们给一个函数预绑定多个参数并生成一个可直接调用的新函数，简化代码。 * * function(callback) { t.inc(3, callback); } * 等价于： * async.apply(t.inc, 3); */ // apply(function, arguments..) /** * 通过名字绑定函数t.inc, t.fire，作为新函数给parallel调用 */ //1.1 async.parallel([ async.apply(t.inc, 3), async.apply(t.fire, 100) ], function (err, results) { log('1.1 err: ', err); log('1.1 results: ', results); }); //58.605> 1.1 err: null //58.613> 1.1 results: [ 4, 100 ] /** * 构造一个加法函数，通过apply简化代码 */ //1.2 function inc(a,b,callback,timeout){ var timeout = timeout || 200; t.wait(200); setTimeout(function() { callback(null, a+b); }, timeout); } var fn = async.apply(inc, 1, 2); fn(function(err, n){ log('1.2 inc: ' + n); }); //58.616> 1.2 inc: 3 H3 applyEach代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * applyEach，可以实现给一数组中每个函数传相同参数，通过callback返回。 * 如果只传第一个参数，将返回一个函数对象，我可以传参调用。 */ // applyEach(fns, args..., callback) /** * 异步执行，给数组中的函数，他们有相同的参数。 */ //1.1 async.applyEach([ function (name,cb) { setTimeout(function () { log(\"1.1 handler: \" + name + \" A\"); cb(null, name); }, 500); }, function (name,cb) { setTimeout(function () { log(\"1.1 handler: \" + name + \" B\"); cb(null, name); }, 150); } ], 'Hello', function (err) { log('1.1 err: ', err); }); //06.739> 1.1 handler: Hello B //07.079> 1.1 handler: Hello A //07.080> 1.1 err: null /** * 异步执行，当只设置第一参数后，得到函数对象，再传参调用这个函数。 */ //1.2 var fn = async.applyEach([ function (name,cb) { setTimeout(function () { log(\"1.2 handler: \" + name + \" A\"); }, 500); }, function (name,cb) { setTimeout(function () { log(\"1.2 handler: \" + name + \" B\"); }, 150); } ]); fn(\"simgle\",function(err){ log('err: ',err); }); //29.351> 1.2 handler: simgle B //29.688> 1.2 handler: simgle A /** * applyEachSeries与applyEach唯一不同的是，数组的函数同步执行。 */ //applyEachSeries(arr, args..., callback) //1.3 async.applyEachSeries([ function (name,cb) { setTimeout(function () { log(\"1.3 handler: \" + name + \" A\"); cb(null, name); }, 500); }, function (name,cb) { setTimeout(function () { log(\"1.3 handler: \" + name + \" B\"); cb(null, name); }, 150); } ], \"aaa\", function (err) { log('1.3 err: ', err); }); //10.669> 1.3 handler: aaa A //10.831> 1.3 handler: aaa B //10.834> 1.3 err: null H3 auto代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * auto用来处理有依赖关系的多个任务的执行。 * * 比如某些任务之间彼此独立，可以并行执行；但某些任务依赖于其它某些任务，只能等那些任务完成后才能执行。 * 虽然我们可以使用parallel和series结合起来实现该功能，但如果任务之间关系复杂，则代码会相当复杂，以后如果想添加一个新任务，也会很麻烦。 * 这时使用auto，则会事半功倍。 * * 如果有任务中途出错，则会把该错误传给最终callback，所有任务（包括已经执行完的）产生的数据将被忽略。 * 如果不关心错误和最终数据，可以不用写最后那个callback。 */ // async.auto(tasks, [callback]) /** * 我要写一个程序，它要完成以下几件事： * 1. 从某处取得数据 * 2. 在硬盘上建立一个新的目录 * 3. 将数据写入到目录下某文件 * 4. 发送邮件，将文件以附件形式发送给其它人。 * * 分析该任务，可以知道1与2可以并行执行，3需要等1和2完成，4要等3完成。 * 可以按以下方式来使用auto函数。 */ // 1.1 async.auto({ getData: function (callback) { setTimeout(function(){ console.log('1.1: got data'); callback(null, 'mydata'); }, 300); }, makeFolder: function (callback) { setTimeout(function(){ console.log('1.1: made folder'); callback(null, 'myfolder'); }, 200); }, writeFile: ['getData', 'makeFolder', function(callback) { setTimeout(function(){ console.log('1.1: wrote file'); callback(null, 'myfile'); }, 300); }], emailFiles: ['writeFile', function(callback, results) { log('1.1: emailed file: ', results.writeFile); callback(null, results.writeFile); }] }, function(err, results) { log('1.1: err: ', err); log('1.1: results: ', results); }); //1.1: made folder //1.1: got data //1.1: wrote file //20.120> 1.1: emailed file: myfile //20.125> 1.1: err: null //20.127> 1.1: results: { makeFolder: 'myfolder', // getData: 'mydata', // writeFile: 'myfile', // emailFiles: 'myfile' } /** * 如果中途出错，则会把错误交给最终callback，执行完任务的传给最终callback。未执行完成的函数值被忽略 */ // 1.2 async.auto({ getData: function (callback) { setTimeout(function(){ console.log('1.2: got data'); callback(null, 'mydata'); }, 300); }, makeFolder: function (callback) { setTimeout(function(){ console.log('1.2: made folder'); callback(null, 'myfolder'); }, 200); }, writeFile: ['getData', 'makeFolder', function(callback, results) { setTimeout(function(){ console.log('1.2: wrote file'); callback('myerr'); }, 300); }], emailFiles: ['writeFile', function(callback, results) { console.log('1.2: emailed file: ' + results.writeFile); callback('err sending email', results.writeFile); }] }, function(err, results) { log('1.2 err: ', err); log('1.2 results: ', results); }); //1.2: made folder //1.2: got data //1.2: wrote file //51.399> 1.2 err: myerr //51.401> 1.2 results: { makeFolder: 'myfolder', // getData: 'mydata', // writeFile: undefined } H3 cargo代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * cargo也是一个串行的消息队列，类似于queue，通过限制了worker数量，不再一次性全部执行。 * 当worker数量不够用时，新加入的任务将会排队等候，直到有新的worker可用。 * * cargo的不同之处在于，cargo每次会加载满额的任务做为任务单元，只有任务单元中全部执行完成后，才会加载新的任务单元。 */ // cargo(worker, [payload]) /** * 创建cargo实例 */ var cargo = async.cargo(function (tasks, callback) { for(var i=0; i&lt;tasks.length; i++){ log('start ' + tasks[i].name); } callback(); }, 2); /** * 监听：如果某次push操作后，任务数将达到或超过worker数量时，将调用该函数 */ cargo.saturated = function() { log('all workers to be used'); } /** * 监听：当最后一个任务交给worker时，将调用该函数 */ cargo.empty = function() { log('no more tasks wating'); } /** * 监听：当所有任务都执行完以后，将调用该函数 */ cargo.drain = function() { log('all tasks have been processed'); } /** * 增加新任务 */ cargo.push({name: 'A'}, function (err) { t.wait(300); log('finished processing A'); }); cargo.push({name: 'B'}, function (err) { t.wait(600); log('finished processing B'); }); cargo.push({name: 'C'}, function (err) { t.wait(500); log('finished processing C'); }); cargo.push({name: 'D'}, function (err) { t.wait(100); log('finished processing D'); }); cargo.push({name: 'E'}, function (err) { t.wait(200); log('finished processing E'); }); //40.016> all workers to be used //40.020> no more tasks wating //40.020> start A //40.020> start B //40.322> finished processing A //40.923> finished processing B //40.923> no more tasks wating //40.924> start C //40.924> start D //41.425> finished processing C //41.526> finished processing D //41.526> no more tasks wating //41.527> start E //41.728> finished processing E //41.728> all tasks have been processed //41.729> all tasks have been processed //41.729> all tasks have been processed //41.729> all tasks have been processed //41.730> all tasks have been processed H3 compose代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 创建一个包括一组异步函数的函数集合，每个函数会消费上一次函数的返回值。 * 把f(),g(),h()异步函数，组合成f(g(h()))的形式，通过callback得到返回值。 */ // compose(fn1, fn2...) /** * 通过compose组合，f(g(h()))的形式，从内层到外层的执行的顺序。 */ //1.1 function f(n,callback){ log('1.1.f enter: ',n); setTimeout(function () { callback(null, n + 1); }, 10); } function g(n, callback) { log('1.1.g enter: ',n); setTimeout(function () { callback(null, n * 2); }, 10); } function h(n, callback) { log('1.1.h enter: ',n); setTimeout(function () { callback(null, n - 10); }, 10); } var fgh = async.compose(f,g,h); fgh(4,function(err,result){ log('1.1 err: ', err); log('1.1 result: ', result); }); //05.307> 1.1.h enter: 4 //05.329> 1.1.g enter: -6 //05.341> 1.1.f enter: -12 //05.361> 1.1 err: null //05.362> 1.1 result: -11 H3 concat代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 将多个异步操作的结果合并为一个数组。 */ // concat(arr, iterator(item,callback(err,result)), callback(err,result)) var data = { aaa: [11,22,33], bbb: [44,55], ccc: 66 }; var keys = [ {name: 'aaa', delay: 300}, {name: 'bbb', delay: 100}, {name: 'ccc', delay: 200} ]; /** * 以并行方式对集合中各元素进行异步操作，然后把得到的结果合并为一个数组，传给最后的callback。 */ // 1.1 async.concat(keys, function(key,callback) { setTimeout(function() { callback(null, data[key.name]); }, key.delay); }, function(err, values) { log('1.1 err: ', err); log('1.1 values: ', values); }); // 13.539> 1.1 err: // 13.539> 1.1 values: [ 44, 55, 66, 11, 22, 33 ] /** * 如果中途出错，则把错误以及已经完成的操作的结果交给最后callback。未执行完的则忽略。 */ // 1.2 async.concat(keys, function(key,callback) { setTimeout(function() { if(key.name==='ccc') callback('myerr'); else callback(null, data[key.name]); }, key.delay); }, function(err, values) { log('1.2 err: ', err); log('1.2 values: ', values); }); // 13.439> 1.2 err: myerr // 13.439> 1.2 values: [ 44, 55 ] /** * 按数组中的元素顺序来执行异步操作，一个完成后才对下一个进行操作。所有结果会汇集成一个数组交给最后的callback。 */ // concatSeries(arr, iterator, callback) // 1.3 async.concatSeries(keys, function(key,callback) { setTimeout(function() { callback(null, data[key.name]); }, key.delay); }, function(err, values) { log('1.3 err: ', err); log('1.3 values: ', values); }); // 13.859> 1.3 err: // 13.859> 1.3 values: [ 11, 22, 33, 44, 55, 66 ] H3 detect代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 用于取得集合中满足条件的第一个元素。 * 它分为并行与顺序执行两种方式，分别对应函数detect和detectSeries。 */ // detect(array, iterator(item,callback(test)), callback(result) var arr = [ {value:1,delay:500}, {value:2,delay:200}, {value:3,delay:300} ]; /** * 并行执行，通过t.inc做一个累加器，得到第一个满足条件的结果对象 */ async.detect(arr, function(item,callback){ log('1.1 enter: ', item.value); t.inc(item.value, function(err,n) { log('1.1 handle: ', item.value); callback(n%2===0); }, item.delay); }, function(result) { log('1.1 result: ', result); }); // 09.928> 1.1 enter: 1 // 09.928> 1.1 enter: 2 // 09.928> 1.1 enter: 3 // 10.138> 1.1 handle: 2 // 10.228> 1.1 handle: 3 // 10.228> 1.1 result: { value: 3, delay: 300 } // 10.438> 1.1 handle: 1 // 10.438> 1.1 handle: 1 /** * 串行执行，通过t.inc做一个累加器，得到第一个满足条件的结果对象 */ async.detectSeries(arr, function(item,callback) { log('1.2 enter: ', item.value); t.inc(item.value, function(err,n) { log('1.1 handle: ', item.value); callback(n%2===0); }, item.delay); }, function(result) { log('1.2 result: ', result); }); // 09.928> 1.2 enter: 1 // 10.438> 1.2 result: { value: 1, delay: 500 } H3 each代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 如果想对同一个集合中的所有元素都执行同一个异步操作，可以利用each函数。 * * async提供了三种方式： * 1. 集合中所有元素并行执行 * 2. 一个一个顺序执行 * 3. 分批执行，同一批内并行，批与批之间按顺序 * * 如果中途出错，则错误将上传给最终的callback处理。其它已经启动的任务继续执行，未启动的忽略。 */ // each(arr, iterator(item, callback), callback(err)) var arr = [{name:'Jack', delay: 200}, {name:'Mike', delay: 100}, {name:'Freewind', delay: 300}]; /** * 所有操作并发执行，且全部未出错，最终得到的err为undefined。注意最终callback只有一个参数err。 */ // 1.1 async.each(arr, function(item, callback) { log('1.1 enter: ' + item.name); setTimeout(function(){ log('1.1 handle: ' + item.name); callback(null, item.name); }, item.delay); }, function(err) { log('1.1 err: ' + err); }); // 输出如下： // 42.244> 1.1 enter: Jack // 42.245> 1.1 enter: Mike // 42.245> 1.1 enter: Freewind // 42.350> 1.1 handle: Mike // 42.445> 1.1 handle: Jack // 42.554> 1.1 handle: Freewind // 42.554> 1.1 err: undefined /** * 如果中途出错，则出错后马上调用最终的callback。其它未执行完的任务继续执行。 */ async.each(arr,function(item, callback) { log('1.2 enter: ' +item.name); setTimeout(function() { log('1.2 handle: ' + item.name); if(item.name==='Jack') { callback('myerr'); } }, item.delay); }, function(err) { log('1.2 err: ' + err); }); // 输出如下： // 42.246> 1.2 enter: Jack // 42.246> 1.2 enter: Mike // 42.246> 1.2 enter: Freewind // 42.350> 1.2 handle: Mike // 42.445> 1.2 handle: Jack // 42.446> 1.2 err: myerr // 42.555> 1.2 handle: Freewind /** * 与each相似，但不是并行执行。而是一个个按顺序执行。 */ async.eachSeries(arr, function(item, callback) { log('1.3 enter: ' + item.name); setTimeout(function(){ log('1.3 handle: ' + item.name); callback(null, item.name); }, item.delay); }, function(err) { log('1.3 err: ' + err); }); // 42.247> 1.3 enter: Jack // 42.459> 1.3 handle: Jack // 42.459> 1.3 enter: Mike // 42.569> 1.3 handle: Mike // 42.569> 1.3 enter: Freewind // 42.883> 1.3 handle: Freewind // 42.883> 1.3 err: undefined /** * 如果中途出错，则马上把错误传给最终的callback，还未执行的不再执行。 */ async.eachSeries(arr,function(item, callback) { log('1.4 enter: ' +item.name); setTimeout(function() { log('1.4 handle: ' + item.name); if(item.name==='Jack') { callback('myerr'); } }, item.delay); }, function(err) { log('1.4 err: ' + err); }); // 42.247> 1.4 enter: Jack // 42.460> 1.4 handle: Jack // 42.460> 1.4 err: myerr /** * 分批执行，第二个参数是每一批的个数。每一批内并行执行，但批与批之间按顺序执行。 */ async.eachLimit(arr, 2, function(item, callback) { log('1.5 enter: ' + item.name); setTimeout(function(){ log('1.5 handle: ' + item.name); callback(null, item.name); }, item.delay); }, function(err) { log('1.5 err: ' + err); }); // 42.247> 1.5 enter: Jack // 42.248> 1.5 enter: Mike // 42.351> 1.5 handle: Mike // 42.352> 1.5 enter: Freewind // 42.461> 1.5 handle: Jack // 42.664> 1.5 handle: Freewind // 42.664> 1.5 err: undefined /** * 如果中途出错，错误将马上传给最终的callback。同一批中的未执行完的任务还将继续执行，但下一批及以后的不再执行。 */ async.eachLimit(arr,2,function(item, callback) { log('1.6 enter: ' +item.name); setTimeout(function() { log('1.6 handle: ' + item.name); if(item.name==='Jack') { callback('myerr'); } }, item.delay); }, function(err) { log('1.6 err: ' + err); }); // 42.248> 1.6 enter: Jack // 42.248> 1.6 enter: Mike // 42.352> 1.6 handle: Mike // 42.462> 1.6 handle: Jack // 42.462> 1.6 err: myerr H3 every代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 如果集合里每一个元素都满足条件，则传给最终回调的result为true，否则为false */ // every(arr, iterator(item,callback), callback(result)) //alias: all var arr = [1,2,3,6]; /** * 串行执行，集合中所有的元素都&lt;=10，所以为true */ async.every(arr, function(item,callback){ log('1.1 enter: ',item); setTimeout(function(){ log('1.1 handle: ',item); callback(item&lt;=10); },100); }, function(result) { log('1.1 result: ', result); }); // 32.113> 1.1 enter: 1 // 32.123> 1.1 enter: 2 // 32.123> 1.1 enter: 3 // 32.123> 1.1 enter: 6 // 32.233> 1.1 handle: 1 // 32.233> 1.1 handle: 2 // 32.233> 1.1 handle: 3 // 32.233> 1.1 handle: 6 // 32.233> 1.1 result: true /** * 串行执行，集合中至少有一个元素不大于2，所以为false */ async.every(arr, function(item,callback){ log('1.2 enter: ',item); setTimeout(function(){ log('1.2 handle: ',item); callback(item>2); },100); }, function(result) { log('1.2 result: ', result); }); // 32.123> 1.2 enter: 1 // 32.123> 1.2 enter: 2 // 32.123> 1.2 enter: 3 // 32.123> 1.2 enter: 6 // 32.233> 1.2 handle: 1 // 32.233> 1.2 result: false // 32.233> 1.2 handle: 2 // 32.233> 1.2 handle: 3 // 32.233> 1.2 handle: 6 filter 和 reject代码演示 var async = require('async'); var t = require('./t'); var log = t.log; /** * 使用异步操作对集合中的元素进行筛选。需要注意的是，iterator的callback只有一个参数，只能接收true或false。 * * 对于出错，该函数没有做出任何处理，直接由nodejs抛出。所以需要注意对Error的处理。 * * async提供了两种方式： * 1. 并行执行：filter * 2. 顺序执行：filterSereis */ // filter(arr, iterator(item, callback(test)), callback(results)) var arr = [1,2,3,4,5]; /** * 并行执行，对arr进行筛选。 */ async.filter(arr, function(item, callback) { log('1.1 enter: ' + item); setTimeout(function() { log('1.1 test: ' + item); callback(item>=3); }, 200); }, function(results) { log('1.1 results: ', results); }); //16.739> 1.1 enter: 1 //16.749> 1.1 enter: 2 //16.749> 1.1 enter: 3 //16.749> 1.1 enter: 4 //16.749> 1.1 enter: 5 //16.749> 1.3 enter: 1 //16.949> 1.1 test: 1 //16.949> 1.1 test: 2 //16.949> 1.1 test: 3 //16.949> 1.1 test: 4 //16.949> 1.1 test: 5 //16.949> 1.1 results: [ 3, 4, 5 ] /** * 如果出错，将会由nodejs抛出，导致出错。为保证其它代码正常运行，注释掉该测试。 * * try..catch：抓不到这个错误 */ /* async.filter(arr, function(item, callback) { log('1.2 enter: ' + item); setTimeout(function() { log('1.2 handle: ' + item); if(item===2) { throw new Error('myerr'); } callback(item>=3); }, 100); }, function(results) { log('1.2 results: ', results); }); */ /** * 串行执行，对arr进行筛选。 */ // 1.3 async.filterSeries(arr, function(item, callback) { log('1.3 enter: ' + item); setTimeout(function() { log('1.3 handle: ' + item); callback(item>=3); }, 200); }, function(results) { log('1.3 results: ', results); }); // 16.749> 1.3 enter: 1 // 16.949> 1.3 handle: 1 // 16.949> 1.3 enter: 2 // 17.149> 1.3 handle: 2 // 17.149> 1.3 enter: 3 // 17.369> 1.3 handle: 3 // 17.369> 1.3 enter: 4 // 17.589> 1.3 handle: 4 // 17.589> 1.3 enter: 5 // 17.789> 1.3 handle: 5 // 17.789> 1.3 results: [ 3, 4, 5 ] /* * reject跟filter正好相反，当测试为true时，抛弃之 */ // reject(arr, iterator(item, callback(test)), callback(results) async.reject(arr, function(item, callback) { log('1.4 enter: ' + item); setTimeout(function() { log('1.4 test: ' + item); callback(item>=3); }, 200); }, function(results) { log('1.4 results: ', results); }); // 31.359> 1.4 enter: 1 // 31.359> 1.4 enter: 2 // 31.359> 1.4 enter: 3 // 31.359> 1.4 enter: 4 // 31.359> 1.4 enter: 5 // 31.559> 1.4 test: 1 // 31.559> 1.4 test: 2 // 31.559> 1.4 test: 3 // 31.559> 1.4 test: 4 // 31.559> 1.4 test: 5 // 31.569> 1.4 results: [ 1, 2 ] /** * 串行执行，对arr进行筛选。 */ // 1.3 async.rejectSeries(arr, function(item, callback) { log('1.5 enter: ' + item); setTimeout(function() { log('1.5 handle: ' + item); callback(item>=3); }, 200); }, function(results) { log('1.5 results: ', results); }); //43.592> 1.5 enter: 1 //43.799> 1.5 handle: 1 //43.800> 1.5 enter: 2 //44.004> 1.5 handle: 2 //44.007> 1.5 enter: 3 //44.210> 1.5 handle: 3 //44.211> 1.5 enter: 4 //44.412> 1.5 handle: 4 //44.413> 1.5 enter: 5 //44.614> 1.5 handle: 5 //44.616> 1.5 results: [ 1, 2 ] H3 iterator代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 将一组函数包装成为一个iterator，初次调用此iterator时，会执行定义中的第一个函数并返回第二个函数以供调用。 * 也可通过手动调用 next() 得到以下一个函数为起点的新的iterator。 * 该函数通常由async在内部使用，但如果需要时，也可在我们的代码中使用它。 */ // async.iterator(tasks) var iter = async.iterator([ function () {log('I am 111')}, function () {log('I am 222')}, function () {log('I am 333')} ]); /** * 直接调用()，会执行当前函数，并返回一个由下个函数为起点的新的iterator */ //1.1 log('1.1 iter()'); var it1 = iter(); it1(); it1(); //28.368> 1.1 iter() //28.371> I am 111 //28.372> I am 222 //28.372> I am 222 /** * 通过iter()来调用下一个函数 */ log('1.2 iter()'); var it2 = iter(); var it3 = it2(); var it4 = it3(); //it4(); // 这句代码执行会报错 log(it4); // => 'null' //32.449> 1.2 iter() //32.452> I am 111 //32.452> I am 222 //32.453> I am 333 //32.454> null /** * 调用next()，不会执行当前函数，直接返回由下个函数为起点的新iterator * 对于同一个iterator，多次调用next()，不会影响自己 */ //1.3 log('1.3 iter()'); var it5 = iter.next(); it5(); var it6 = iter.next().next(); it6(); iter(); //39.895> 1.3 iter() //39.898> I am 222 //39.899> I am 333 //39.899> I am 111 H3 map代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 对集合中的每一个元素，执行某个异步操作，得到结果。所有的结果将汇总到最终的callback里。与each的区别是，each只关心操作不管最后的值，而map关心的最后产生的值。 * * 提供了两种方式： * 1. 并行执行。同时对集合中所有元素进行操作，结果汇总到最终callback里。如果出错，则立刻返回错误以及已经执行完的任务的结果，未执行完的占个空位 * 2. 顺序执行。对集合中的元素一个一个执行操作，结果汇总到最终callback里。如果出错，则立刻返回错误以及已经执行完的结果，未执行的被忽略。 */ // map(arr, iterator(item, callback), callback(err, results)) var arr = [{name:'Jack', delay:200}, {name:'Mike', delay: 100}, {name:'Freewind', delay:300}, {name:'Test', delay: 50}]; /** * 所有操作均正确执行，未出错。所有结果按元素顺序汇总给最终的callback。 */ // 1.1 async.map(arr, function(item, callback) { log('1.1 enter: ' + item.name); setTimeout(function() { log('1.1 handle: ' + item.name); callback(null, item.name + '!!!'); }, item.delay); }, function(err,results) { log('1.1 err: ', err); log('1.1 results: ', results); }); // 54.569> 1.1 enter: Jack // 54.569> 1.1 enter: Mike // 54.569> 1.1 enter: Freewind // 54.569> 1.1 enter: Test // 54.629> 1.1 handle: Test // 54.679> 1.1 handle: Mike // 54.789> 1.1 handle: Jack // 54.879> 1.1 handle: Freewind // 54.879> 1.1 err: // 54.879> 1.1 results: [ 'Jack!!!', 'Mike!!!', 'Freewind!!!', 'Test!!!' ] /** * 如果中途出错，立刻将错误、以及已经执行完成的结果汇总给最终callback。未执行完的将会在结果数组中用占个空位。 */ async.map(arr, function(item, callback) { log('1.2 enter: ' + item.name); setTimeout(function() { log('1.2 handle: ' + item.name); if(item.name==='Jack') callback('myerr'); else callback(null, item.name+'!!!'); }, item.delay); }, function(err, results) { log('1.2 err: ', err); log('1.2 results: ', results); }); // 54.569> 1.2 enter: Jack // 54.569> 1.2 enter: Mike // 54.569> 1.2 enter: Freewind // 54.569> 1.2 enter: Test // 54.629> 1.2 handle: Test // 54.679> 1.2 handle: Mike // 54.789> 1.2 handle: Jack // 54.789> 1.2 err: myerr // 54.789> 1.2 results: [ undefined, 'Mike!!!', , 'Test!!!' ] // 54.879> 1.2 handle: Freewind /** * 顺序执行，一个完了才执行下一个。 */ async.mapSeries(arr, function(item, callback) { log('1.3 enter: ' + item.name); setTimeout(function() { log('1.3 handle: ' + item.name); callback(null, item.name+'!!!'); }, item.delay); }, function(err,results) { log('1.3 err: ', err); log('1.3 results: ', results); }); // 54.569> 1.3 enter: Jack // 54.789> 1.3 handle: Jack // 54.789> 1.3 enter: Mike // 54.899> 1.3 handle: Mike // 54.899> 1.3 enter: Freewind // 55.209> 1.3 handle: Freewind // 55.209> 1.3 enter: Test // 55.269> 1.3 handle: Test // 55.269> 1.3 err: // 55.269> 1.3 results: [ 'Jack!!!', 'Mike!!!', 'Freewind!!!', 'Test!!!' ] /** * 顺序执行过程中出错，只把错误以及执行完的传给最终callback，未执行的忽略。 */ async.mapSeries(arr, function(item, callback) { log('1.4 enter: ' + item.name); setTimeout(function() { log('1.4 handle: ' + item.name); if(item.name==='Mike') callback('myerr'); else callback(null, item.name+'!!!'); }, item.delay); }, function(err, results) { log('1.4 err: ', err); log('1.4 results: ', results); }); // 47.616> 1.4 enter: Jack // 47.821> 1.4 handle: Jack // 47.821> 1.4 enter: Mike // 47.931> 1.4 handle: Mike // 47.931> 1.4 err: myerr // 47.932> 1.4 results: [ 'Jack!!!', undefined ] /** * 并行执行，同时最多2个函数并行，传给最终callback。 */ //1.5 async.mapLimit(arr,2, function(item, callback) { log('1.5 enter: ' + item.name); setTimeout(function() { log('1.5 handle: ' + item.name); if(item.name==='Jack') callback('myerr'); else callback(null, item.name+'!!!'); }, item.delay); }, function(err, results) { log('1.5 err: ', err); log('1.5 results: ', results); }); //57.797> 1.5 enter: Jack //57.800> 1.5 enter: Mike //57.900> 1.5 handle: Mike //57.900> 1.5 enter: Freewind //58.008> 1.5 handle: Jack //58.009> 1.5 err: myerr //58.009> 1.5 results: [ undefined, 'Mike!!!' ] //58.208> 1.5 handle: Freewind //58.208> 1.5 enter: Test //58.273> 1.5 handle: Test H3 nextTick代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * nextTick的作用与nodejs的nextTick一样，再最后调用函数。 * 但在浏览器端，只能使用setTimeout(callback,0)，但这个方法有时候会让其它高优先级的任务插到前面去。 * 所以提供了这个nextTick，让同样的代码在服务器端和浏览器端表现一致。 */ // nextTick(callback) var calls = []; async.nextTick(function() { calls.push('two'); }); async.nextTick(function() { log('1.1',calls); }); calls.push('one'); log('1.2',calls); async.nextTick(function() { log('1.3',calls); }); //09.838> 1.2[ 'one' ] //09.842> 1.1[ 'one', 'two' ] //09.843> 1.3[ 'one', 'two' ] H3 parallel代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 并行执行多个函数，每个函数都是立即执行，不需要等待其它函数先执行。传给最终callback的数组中的数据按照tasks中声明的顺序，而不是执行完成的顺序。 * * 如果某个函数出错，则立刻将err和已经执行完的函数的结果值传给parallel最终的callback。其它未执行完的函数的值不会传到最终数据，但要占个位置。 * 同时支持json形式的tasks，其最终callback的结果也为json形式。 */ // parallel(tasks, [callback]) /** * 并行执行多个函数，每个函数的值将按函数声明的先后顺序汇成一个数组，传给最终callback。 */ // 1.1 async.parallel([ function(cb) { t.fire('a400', cb, 400) }, function(cb) { t.fire('a200', cb, 200) }, function(cb) { t.fire('a300', cb, 300) } ], function (err, results) { log('1.1 err: ', err); log('1.1 results: ', results); }); //36.929> 1.1 err: null //36.930> 1.1 results: [ 'a400', 'a200', 'a300' ] /** * 如果中途有个函数出错，则将该err和已经完成的函数值汇成一个数组，传给最终的callback。还没有执行完的函数的值将被忽略，但要在最终数组中占个位置 */ // 1.2 async.parallel([ function(cb) { log('1.2.1: ', 'start'); t.fire('a400', cb, 400) }, // 该函数的值不会传给最终callback，但要占个位置 function(cb) { log('1.2.2: ', 'start'); t.err('e200', cb, 200) }, function(cb) { log('1.2.3: ', 'start'); t.fire('a100', cb, 100) } ], function(err, results) { log('1.2 err: ', err); log('1.2 results: ', results); }); //36.537> 1.2.1: start //36.540> 1.2.2: start //36.541> 1.2.3: start //36.741> 1.2 err: e200 //36.744> 1.2 results: [ , undefined, 'a100' ] /** * 以json形式传入tasks，最终results也为json */ // 1.3 async.parallel({ a: function(cb) { t.fire('a400', cb, 400) }, b: function(cb) { t.fire('c300', cb, 300) } }, function(err, results) { log('1.3 err: ', err); log('1.3 results: ', results); }); //36.943> 1.3 err: null //36.944> 1.3 results: { b: 'c300', a: 'a400' } /** * 如果中途出错，会将err与已经完成的函数值（汇成一个json）传给最终callback。未执行完成的函数值被忽略，不会出现在最终json中。 */ // 1.4 async.parallel({ a: function(cb) { t.fire('a400', cb, 400) }, // 该函数的值不会传给最终的callback b: function(cb) { t.err('e300', cb, 300) }, c: function(cb) { t.fire('c200', cb, 200) } }, function(err, results) { log('1.4 err: ', err); log('1.4 results: ', results); }); //36.853> 1.4 err: e300 //36.854> 1.4 results: { c: 'c200', b: undefined } /** * 并行执行，同时最多2个函数并行，传给最终callback。 */ //1.5 async.parallelLimit({ a:function(cb) { log('a start'); t.fire('a400', cb, 200) }, b:function(cb) { log('b start'); t.fire('b200', cb, 200) }, c:function(cb) { log('c start'); t.fire('c100', cb, 100) }, d:function(cb) { log('d start'); t.fire('d600', cb, 600) }, e:function(cb) { log('e start'); t.fire('e300', cb, 300) } },2, function(err, results) { log('1.5 err: ', err); log('1.5 results: ', results); }); //26.993> a start //26.996> b start //27.200> c start //27.202> d start //27.313> e start //27.809> 1.5 err: //27.810> 1.5 results: { a: 'a400', b: 'b200', c: 'c100', e: 'e300', d: 'd600' } H3 queue代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * queue是一个串行的消息队列，通过限制了worker数量，不再一次性全部执行。 * 当worker数量不够用时，新加入的任务将会排队等候，直到有新的worker可用。 * * 该函数有多个点可供回调，如worker用完时、无等候任务时、全部执行完时等。 */ // queue(worker, concurrency) /** * 定义一个queue，设worker数量为2 */ var q = async.queue(function(task, callback) { log('worker is processing task: ', task.name); task.run(callback); }, 2); /** * 监听：如果某次push操作后，任务数将达到或超过worker数量时，将调用该函数 */ q.saturated = function() { log('all workers to be used'); } /** * 监听：当最后一个任务交给worker时，将调用该函数 */ q.empty = function() { log('no more tasks wating'); } /** * 监听：当所有任务都执行完以后，将调用该函数 */ q.drain = function() { log('all tasks have been processed'); } /** * 独立加入2个任务 */ q.push({name:'t1', run: function(cb){ log('t1 is running, waiting tasks: ', q.length()); t.fire('t1', cb, 400); // 400ms后执行 }}, function(err) { log('t1 executed'); }); log('pushed t1, waiting tasks: ', q.length()); q.push({name:'t2',run: function(cb){ log('t2 is running, waiting tasks: ', q.length()); t.fire('t2', cb, 200); // 200ms后执行 }}, function(err) { log('t2 executed'); }); log('pushed t2, waiting tasks: ', q.length()); //54.448> pushed t1, waiting tasks: 1 //54.451> all workers to be used //54.452> pushed t2, waiting tasks: 2 //54.452> worker is processing task: t1 //54.453> t1 is running, waiting tasks: 1 //54.455> no more tasks wating //54.455> worker is processing task: t2 //54.455> t2 is running, waiting tasks: 0 //54.656> t2 executed //54.867> t1 executed //54.868> all tasks have been processed // 同时加入多个任务 q.push([ { name:'t3', run: function(cb){ log('t3 is running, waiting tasks: ', q.length()); t.fire('t3', cb, 300); // 300ms后执行 } },{ name:'t4', run: function(cb){ log('t4 is running, waiting tasks: ', q.length()); t.fire('t4', cb, 500); // 500ms后执行 } },{ name:'t5', run: function(cb){ log('t5 is running, waiting tasks: ', q.length()); t.fire('t5', cb, 100); // 100ms后执行 } },{ name:'t6', run: function(cb){ log('t6 is running, waiting tasks: ', q.length()); t.fire('t6', cb, 400); // 400ms后执行 } } ], function(err) { log('err: ',err); }); log('pushed t3,t4,t5,t6 into queue, waiting tasks: ', q.length()); //53.755> all workers to be used //53.758> pushed t3,t4,t5,t6 into queue, waiting tasks: 4 //53.759> worker is processing task: t3 //53.760> t3 is running, waiting tasks: 3 //53.762> worker is processing task: t4 //53.762> t4 is running, waiting tasks: 2 //54.073> err: null //54.074> worker is processing task: t5 //54.076> t5 is running, waiting tasks: 1 //54.183> err: null //54.184> no more tasks wating //54.185> worker is processing task: t6 //54.186> t6 is running, waiting tasks: 0 //54.265> err: null //54.588> err: null //54.589> all tasks have been processed H3 Reduce代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * Reduce可以让我们给定一个初始值，用它与集合中的每一个元素做运算，最后得到一个值。reduce从左向右来遍历元素，如果想从右向左，可使用reduceRight。 */ //reduce(arr, memo, iterator(memo,item,callback), callback(err,result)) //alias: inject, foldl var arr = [1,3,5]; /** * 顺序执行 */ async.reduce(arr, 100, function(memo, item, callback) { log('1.1 enter: ' + memo +', ' + item); setTimeout(function() { callback(null, memo+item); }, 100); },function(err, result) { log('1.1 err: ', err); log('1.1 result: ', result); }); // 28.789> 1.1 enter: 100, 1 // 28.889> 1.1 enter: 101, 3 // 28.999> 1.1 enter: 104, 5 // 29.109> 1.1 err: // 29.109> 1.1 result: 109 /** * 顺序执行过程中出错，只把错误传给最终callback，结果是null */ async.reduce(arr, 100, function(memo, item, callback) { log('1.2 enter: ' + memo +', ' + item); setTimeout(function() { if(item===3) callback('myerr'); else callback(null, memo+item); }, 100); },function(err, result) { log('1.2 err: ', err); log('1.2 result: ', result); }); // 05.541> 1.2 enter: 100, 1 // 05.649> 1.2 enter: 101, 3 // 05.760> 1.2 err: myerr // 05.760> 1.2 result: /** * 顺序执行从右向左 * * alias: foldr */ async.reduceRight(arr, 100, function(memo, item, callback) { log('1.3 enter: ' + memo +', ' + item); setTimeout(function() { callback(null, memo+item); }, 100); },function(err, result) { log('1.3 err: ', err); log('1.3 result: ', result); }); // 28.789> 1.3 enter: 100, 5 // 28.889> 1.3 enter: 105, 3 // 28.999> 1.3 enter: 108, 1 // 29.109> 1.3 err: // 29.109> 1.3 result: 109 /** * 通过t.inc做一个累加器，参与reduce的计算 */ async.reduce(arr, 100, function(memo,item,callback) { log('1.4 enter: '+memo+','+item); t.inc(item, function(err,n) { log('1.4 handle: ',n); callback(null, memo+n); }); }, function(err,result) { log('1.4 err: ', err); log('1.4 result: ', result); }); // 28.789> 1.4 enter: 100,1 // 28.999> 1.4 handle: 2 // 28.999> 1.4 enter: 102,3 // 29.209> 1.4 handle: 4 // 29.209> 1.4 enter: 106,5 // 29.409> 1.4 handle: 6 // 29.409> 1.4 err: // 29.409> 1.4 result: 112 // --> spent 0.62s /** * 通过t.inc做一个累加器，并实现对map的结果集做reduce */ async.map(arr, function(item, callback) { log('1.5 enter: ', item); t.inc(item, function(err,n){ log('1.5 handle: ', n); callback(null,n); }); },function(err, results) { log('1.5 err: ', err); log('1.5 results: ', results); var sum = results.reduce(function(memo, item) { return memo + item; }, 100); log('1.5 sum: ', sum); }); // 28.789> 1.5 enter: 1 // 28.789> 1.5 enter: 3 // 28.789> 1.5 enter: 5 // 28.999> 1.5 handle: 2 // 28.999> 1.5 handle: 4 // 28.999> 1.5 handle: 6 // 28.999> 1.5 err: // 28.999> 1.5 results: [ 2, 4, 6 ] // 28.999> 1.5 sum: 112 // --> spent 0.21 H3 series代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 串行执行，一个函数数组中的每个函数，每一个函数执行完成之后才能执行下一个函数。 * * 如果任何一个函数向它的回调函数中传了一个error，则后面的函数都不会被执行，并且会立刻将该error以及已经执行了的函数的结果，传给series中最后那个callback。 * 当所有的函数执行完后（没有出错），则会把每个函数传给其回调函数的结果合并为一个数组，传给series最后的那个callback。 * 还可以json的形式来提供tasks。每一个属性都会被当作函数来执行，并且结果也会以json形式传给series最后的那个callback。这种方式可读性更高一些。 */ // series(tasks, [callback]) /** * 全部函数都正常执行。每个函数产生的值将按顺序合并为一个数组，传给最终的callback。 */ // 1.1 async.series([ function(cb) { t.inc(3, cb); }, function(cb) { t.inc(8, cb); }, function(cb) { t.inc(2, cb); } ], function(err, results) { log('1.1 err: ', err); log('1.1 results: ', results); }); //05.155> 1.1 err: null //05.156> 1.1 results: [ 4, 9, 3 ] /** * 中间有函数出错。出错之后的函数不会执行，错误及之前正常执行的函数结果将传给最终的callback。 */ // 1.2 async.series([ function(cb) { t.inc(3, cb); }, function(cb) { t.err('test_err', cb); }, function(cb) { t.inc(8, cb); } ], function (err, results) { log('1.2 err: ', err); log('1.2 results: ', results); }); //04.964> 1.2 err: test_err //04.973> 1.2 results: [ 4, undefined ] /** * 如果某个函数传的数据是undefined, null, {}, []等，它们会原样传给最终callback。 */ // 1.3 async.series([ function(cb) { t.fire(3, cb);}, function(cb) { t.fire(undefined, cb); }, function(cb) { t.fire(null, cb); }, function(cb) { t.fire({}, cb); }, function(cb) { t.fire([], cb); }, function(cb) { t.fire('abc', cb) } ], function(err, results) { log('1.3 err: ', err); log('1.3 results: ', results); }); //05.794> 1.3 err: null //05.795> 1.3 results: [ 3, undefined, null, {}, [], 'abc' ] /** * 以json形式传入tasks。其结果也将以json形式传给最终callback。 */ async.series({ a: function(cb) { t.inc(3, cb); }, b: function(cb) { t.fire(undefined, cb); }, c: function (cb) { t.err('myerr', cb); }, d: function (cb) { t.inc(8, cb); } }, function (err, results) { log('1.4 err: ', err); log('1.4 results: ', results); }); //05.178> 1.4 err: myerr //05.179> 1.4 results: { a: 4, b: undefined, c: undefined } H3 some代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 当集合中是否有至少一个元素满足条件时，最终callback得到的值为true，否则为false. */ // some(arr, iterator(item,callback(test)), callback(result)) //alias: any var arr = [1,2,3,6]; /** * 串行执行，集合中至少有一个元素&lt;=3，所以结果为true */ // 1.1 async.some(arr, function(item,callback){ log('1.1 enter: ',item); setTimeout(function(){ log('1.1 handle: ',item); callback(item&lt;=3); },100); }, function(result) { log('1.1 result: ', result); }); // 36.165> 1.1 enter: 1 // 36.165> 1.1 enter: 2 // 36.165> 1.1 enter: 3 // 36.165> 1.1 enter: 6 // 36.275> 1.1 handle: 1 // 36.275> 1.1 result: true // 36.275> 1.1 handle: 2 // 36.275> 1.1 handle: 3 // 36.275> 1.1 handle: 6 /** * 串行执行，集合中没有一个元素>10，所以结果为false */ async.some(arr, function(item,callback){ log('1.2 enter: ',item); setTimeout(function(){ log('1.2 handle: ',item); callback(item>10); },100); }, function(result) { log('1.2 result: ', result); }); // 36.165> 1.2 enter: 1 // 36.165> 1.2 enter: 2 // 36.165> 1.2 enter: 3 // 36.165> 1.2 enter: 6 // 36.275> 1.2 handle: 1 // 36.275> 1.2 handle: 2 // 36.275> 1.2 handle: 3 // 36.275> 1.2 handle: 6 // 36.275> 1.2 result: false H3 sortBy代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 对集合内的元素进行排序，依据每个元素进行某异步操作后产生的值，从小到大排序。 */ // sortBy(array, iterator(item,callback(err,result)), callback(err,results)) var arr = [3,6,1]; /** * 通过异步迭代器，对集合进行排序 */ async.sortBy(arr, function(item, callback) { setTimeout(function() { callback(null,item); }, 200); }, function(err,results) { log('1.1 err: ', err); log('1.1 results: ', results); }); // 26.562> 1.1 err: null // 26.562> 1.1 results: [ 1, 3, 6 ] /** * 迭代出错，callback返回err，没有results */ async.sortBy(arr, function(item, callback) { setTimeout(function() { if(item===6) callback('myerr'); else callback(null,item); }, 200); }, function(err,results) { log('1.2 err: ', err); log('1.2 results: ', results); }); // 26.572> 1.2 err: myerr // 26.572> 1.2 results: H3 t.js代码演示// 其实这个文件名的't'我不是很明白原作者freewind的意思，我觉得叫做'lib.js'或者 // 'helper.js'比较合适，因为这里面都是些辅助函数。 var moment = require('moment'); exports.inc = function(n, callback, timeout) { //将参数n自增1之后的结果返回给async timeout = timeout || 200; setTimeout(function() { callback(null, n+1); }, timeout); }; exports.fire = function(obj, callback, timeout) { //直接将obj的内容返回给async timeout = timeout || 200; setTimeout(function() { callback(null, obj); }, timeout); }; exports.err = function(errMsg, callback, timeout) { //模拟一个错误的产生，让async各个函数末尾的callback接收到。 timeout = timeout || 200; setTimeout(function() { callback(errMsg); }, timeout); }; // utils exports.log = function(msg, obj) { //对console.log进行了封装。主要是增加了秒钟的输出，通过秒数的差值方便大家对async的理解。 process.stdout.write(moment().format('ss.SSS')+'> '); if(obj!==undefined) { process.stdout.write(msg); console.log(obj); } else { console.log(msg); } }; exports.wait = function(mils) { //刻意等待mils的时间，mils的单位是毫秒。 var now = new Date; while(new Date - now &lt;= mils); } H3 times timesSeries代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 异步运行,times可以指定调用几次，并把结果合并到数组中返回 */ // times(n, callback) function delay(n){return (n+12) % 7 *100;} var createUser = function(id, callback) { callback(null, { id: 'user' + id, delay:delay(id) }) } /** * 异步执行，调用3次createUser函数，结果被合并到数组返回 */ //1.1 async.times(3, function(n, callback){ log(\"1.1 enter: \"+ n); setTimeout(function(){ log('1.1 handler: ',n); createUser(n, function(err, user) { callback(err, user) }) },delay(n)); }, function(err, users) { log('1.1 err: ',err); log('1.1 result: ',users); }); //07.397> 1.1 enter: 0 //07.400> 1.1 enter: 1 //07.401> 1.1 enter: 2 //07.412> 1.1 handler: 2 //07.912> 1.1 handler: 0 //08.009> 1.1 handler: 1 //08.010> 1.1 err: null //08.011> 1.1 result: [ { id: 'user0', delay: 500 }, // { id: 'user1', delay: 600 }, // { id: 'user2', delay: 0 } ] /** * timesSeries与time唯一不同的是，同步执行 */ //timesSeries(n, callback) /** * 同步执行，调用3次createUser函数，结果被合并到数组返回 */ //1.2 async.timesSeries(3, function(n, callback){ log(\"1.2 enter: \"+ n); setTimeout(function(){ log('1.2 handler: ',n); createUser(n, function(err, user) { callback(err, user) }) },delay(n)); }, function(err, users) { log('1.2 err: ',err); log('1.2 result: ',users); }); //16.642> 1.2 enter: 0 //17.159> 1.2 handler: 0 //17.162> 1.2 enter: 1 //17.763> 1.2 handler: 1 //17.767> 1.2 enter: 2 //17.778> 1.2 handler: 2 //17.779> 1.2 err: null //17.780> 1.2 result: [ { id: 'user0', delay: 500 }, // { id: 'user1', delay: 600 }, // { id: 'user2', delay: 0 } ] H3 unmemoize noConflict memoize log dir 代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 让某一个函数在内存中缓存它的计算结果。对于相同的参数，只计算一次，下次就直接拿到之前算好的结果。 * hasher可以让我们自定义如何根据参数来判断它是否已经在缓存中了。 */ // memoize(fn, [hasher]) //1.1 var slow_fn = function(x, y, callback) { log('1.1 start working for: ' + x+','+y); t.wait(500); log('1.1 finished: ' + x+','+y); callback(null, x+','+y); }; var fn = async.memoize(slow_fn,function(x,y) { return x+y; }); fn('a','b', function(err, result) { log(\"1.1 first time: \"+result); }); fn('cc','d', function(err, result) { log(\"1.1 first time: \"+result); }); fn('a','b', function(err, result) { log(\"1.1 second time: \"+result); }); //15.416> 1.1 start working for: a,b //15.920> 1.1 finished: a,b //15.920> 1.1 first time: a,b //15.921> 1.1 start working for: cc,d //16.423> 1.1 finished: cc,d //16.423> 1.1 first time: cc,d //16.424> 1.1 second time: a,b /** * 让已经被缓存的函数，返回不缓存的函数引用。 */ // unmemoize(fn) //1.2 var slow_fn2 = function(x, y, callback) { log('1.2 start working for: ' + x+','+y); t.wait(500); log('1.2 finished: ' + x+','+y); callback(null, x+','+y); }; var fn2 = async.memoize(slow_fn2,function(x,y) { return x+y; }); fn2('a','b', function(err,result) { log(\"1.2 first time: \"+result); }); var unFn2 =async.unmemoize(fn2); log('1.2 unmemoized'); unFn2('a','b', function(err,result) { log(\"1.2 second time: \"+result); }); //16.424> 1.2 start working for: a,b //16.926> 1.2 finished: a,b //16.926> 1.2 first time: a,b //16.927> 1.2 unmemoized //16.927> 1.2 start working for: a,b //17.428> 1.2 finished: a,b //17.428> 1.2 second time: a,b /** * 执行某异步函数，并记录它的返回值。试验函数时很方便，不用写那些固定模式的代码。 * 如果该函数向回调中传入了多个参数，则每行记录一个。 */ // log(function, arguments) //1.3 var x = function() { this.name = 'bsspirit'; } var hello = function(name, callback) { setTimeout(function() { callback(null, 'first ' + name, 'second '+ name, x, {a:'123'} ); }, 200); }; log(\"1.3 handler\"); async.log(hello, 'time'); //37.620> 1.3 handler //first time //second time //[Function] //{ a: '123' } /** * dir与log都是打印出输，在nodejs环境中没有分别。 * dir的不同之处在于，会调用浏览器的console.dir()函数，显示为DOM视图。 * * http://stackoverflow.com/questions/10636866/whats-the-difference-between-async-log-and-async-dir */ //1.4 log(\"1.4 handler\"); async.dir(hello, 'world'); //37.620> 1.4 handler //first time //second time //[Function] //{ a: '123' } /** * noConflict()仅仅用于浏览器端，在nodejs中没用，这里无法演示。 * * 它的作用是：如果之前已经在全局域中定义了async变量，当导入本async.js时，会先把之前的async变量保存起来，然后覆盖它。 * 用完之后，调用noConflict()方法，就会归还该值。同时返回async本身供换名使用。 */ // noConflict() /* // global on the server, window in the browser var root = this, previous_async = root.async; if (typeof module !== 'undefined' &amp;&amp; module.exports) { module.exports = async; } else { root.async = async; } async.noConflict = function () { root.async = previous_async; return async; }; */ H3 waterfall代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 按顺序依次执行一组函数。每个函数产生的值，都将传给下一个。 * 如果中途出错，后面的函数将不会被执行。错误信息将传给waterfall最终的callback。之前产生的结果被丢弃。 * * 这个函数名为waterfall(瀑布)，可以想像瀑布从上到下，中途冲过一层层突起的石头。 * * 注意，该函数不支持json格式的tasks */ // async.waterfall(tasks, [callback]); /** * 所有函数正常执行，每个函数的结果都将变为下一个函数的参数。 * * 注意，所有的callback都必须形如callback(err, result)，但err参数在前面各函数中无需声明，它被自动处理。 */ // 1.1 async.waterfall([ function(cb) { log('1.1.1: ', 'start'); cb(null, 3); }, function(n, cb) { log('1.1.2: ',n); t.inc(n, cb); }, function(n, cb) { log('1.1.3: ',n); t.fire(n*n, cb); } ], function (err, result) { log('1.1 err: ', err); log('1.1 result: ', result); }); //31.749> 1.1.1: start //31.752> 1.1.2: 3 //31.953> 1.1.3: 4 //32.156> 1.1 err: null //32.159> 1.1 result: 16 /** * 中途有函数出错，其err直接传给最终callback，结果被丢弃，后面的函数不再执行。 */ // 1.2 async.waterfall([ function(cb) { log('1.2.1: ', 'start'); cb(null, 3); }, function(n, cb) { log('1.2.2: ', n); t.inc(n, cb); }, function(n, cb) { log('1.2.3: ', n); t.err('myerr', cb); }, function(n, cb) { log('1.2.4: ', n); t.fire(n, cb); } ], function (err, result) { log('1.2 err: ', err); log('1.2 result: ', result); }); //44.935> 1.2.1: start //44.939> 1.2.2: 3 //45.140> 1.2.3: 4 //45.344> 1.2 err: myerr //45.348> 1.2 result: /** * 注意： 以json形式传入tasks，将不会被执行!! */ async.waterfall({ a: function(cb) { log('1.3.1: ', 'start'); cb(null, 3); }, b: function(n, cb) { log('1.3.2: ', n); t.inc(n, cb); }, c: function(n, cb) { log('1.3.3: ', n); t.fire(n*n, cb); } }, function (err, result) { log('1.3 err: ', err); log('1.3 result: ', result); }); //49.222> 1.3 err: [Error: First argument to waterfall must be an array of functions] //49.228> 1.3 result: H3 whilst until doUntil forever和 doWhilst代码演示var async = require('async'); var t = require('./t'); var log = t.log; /** * 相当于while，但其中的异步调用将在完成后才会进行下一次循环。 * * 它相当于： * try { * whilst(test) { * fn(); * } * callback(); * } catch (err) { * callback(err); * } * * 该函数的功能比较简单，条件变量通常定义在外面，可供每个函数访问。在循环中，异步调用时产生的值实际上被丢弃了，因为最后那个callback只能传入错误信息。 * * 另外，第二个函数fn需要能接受一个函数cb，这个cb最终必须被执行，用于表示出错或正常结束。 */ // whilst(test, fn, callback) /** * 正常情况，没有出错。第二个函数虽然是异步调用，但被同步执行。所以第三个函数被调用时，已经过了3秒。 */ // 1.1 var count1 = 0; async.whilst( function() { return count1 &lt; 3 }, function(cb) { log('1.1 count: ', count1); count1++; setTimeout(cb, 1000); }, function(err) { // 3s have passed log('1.1 err: ', err); } ); //10.318> 1.1 count: 0 //11.330> 1.1 count: 1 //12.342> 1.1 count: 2 //13.356> 1.1 err: /** * 中途出错。出错后立刻调用第三个函数。 */ // 1.2 var count2 = 0; async.whilst( function() { return count2 &lt; 3 }, function(cb) { log('1.2 count: ', count2); if(count2===1) { t.err('myerr', cb, 200); } else { count2++; setTimeout(cb, 1000); } }, function(err) { // 2s have passed log('1.2 err: ', err); } ); //12.805> 1.2 count: 0 //13.824> 1.2 count: 1 //14.026> 1.2 err: myerr /** * 第二个函数即使产生值，也会被忽略。第三个函数只能得到err。 */ // 1.3 var count3 = 0; async.whilst( function() {return count3 &lt; 3 }, function(cb) { log('1.3 count: ', count3); t.inc(count3++, cb); }, function(err,result){ // result没有用 log('1.3 err: ', err); log('1.3 result: ', result); } ); //45.311> 1.3 count: 0 //45.514> 1.3 count: 1 //45.718> 1.3 count: 2 //45.920> 1.3 err: //45.923> 1.3 result: /** * doWhilst交换了fn,test的参数位置，先执行一次循环，再做test判断。 和javascript中do..while语法一致。 */ // doWhilst(fn, test, callback) //1.4 var count4 = 0; async.doWhilst( function(cb) { log('1.4 count: ', count4); t.inc(count4++, cb); }, function() { log(\"1.4 test\"); return count4 &lt; 3 }, function(err,result){ // result没有用 log('1.4 err: ', err); log('1.4 result: ', result); } ); //33.643> 1.4 count: 0 //33.848> 1.4 test //33.850> 1.4 count: 1 //34.054> 1.4 test //34.057> 1.4 count: 2 //34.269> 1.4 test //34.270> 1.4 err: //34.270> 1.4 result: /** * until与whilst正好相反，当test为false时循环，与true时跳出。其它特性一致。 */ // 1.5 var count5 = 0; async.until( function() { return count5>3 }, function(cb) { log('1.5 count: ', count5); count5++; setTimeout(cb, 200); }, function(err) { // 4s have passed log('1.5 err: ',err); } ); //42.498> 1.5 count: 0 //42.701> 1.5 count: 1 //42.905> 1.5 count: 2 //43.107> 1.5 count: 3 //43.313> 1.5 err: /** * doUntil与doWhilst正好相反，当test为false时循环，与true时跳出。其它特性一致。 */ // doUntil(fn, test, callback) // 1.6 var count6 = 0; async.doUntil( function(cb) { log('1.6 count: ', count6); count6++; setTimeout(cb, 200); }, function() { log('1.6 test');return count6>3 }, function(err) { // 4s have passed log('1.6 err: ',err); } ); //41.831> 1.6 count: 0 //42.035> 1.6 test //42.037> 1.6 count: 1 //42.241> 1.6 test //42.244> 1.6 count: 2 //42.456> 1.6 test //42.457> 1.6 count: 3 //42.660> 1.6 test //42.661> 1.6 err: /** * forever，无论条件循环执行，如果不出错，callback永远不被执行 */ //forever(fn, callback) //1.7 var count7 = 0; async.forever( function(cb) { log('1.7 count: ', count7); count7++; setTimeout(cb, 200); }, function(err) { log('1.7 err: ',err); } ); //52.770> 1.7 count: 0 //52.973> 1.7 count: 1 //53.175> 1.7 count: 2 //53.377> 1.7 count: 3 //53.583> 1.7 count: 4 //53.785> 1.7 count: 5 //53.987> 1.7 count: 6 //54.189> 1.7 count: 7 //54.391> 1.7 count: 8 //54.593> 1.7 count: 9 //54.795> 1.7 count: 10 //54.997> 1.7 count: 11 //55.199> 1.7 count: 12 Nodejs Async 学习.md","categories":[{"name":"服务器","slug":"服务器","permalink":"http://blog.msiter.com/categories/服务器/"}],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"http://blog.msiter.com/tags/nodejs/"},{"name":"async","slug":"async","permalink":"http://blog.msiter.com/tags/async/"}],"keywords":[{"name":"服务器","slug":"服务器","permalink":"http://blog.msiter.com/categories/服务器/"}]},{"title":"测试本博客 MarkDown 支持成都","slug":"测试","date":"2015-07-03T03:25:00.000Z","updated":"2018-08-29T10:33:16.506Z","comments":true,"path":"cs-20150703.html","link":"","permalink":"http://blog.msiter.com/cs-20150703.html","excerpt":"","text":"Advertisement :) pica - high quality and fast imageresize in browser. babelfish - developer friendlyi18n with plurals support and easy syntax. You will like those projects! H1 h1 Heading 8-)H2 h2 HeadingH3 h3 HeadingH4 h4 HeadingH5 h5 HeadingH6 h6 HeadingH2 Horizontal Rules H2 Typographic replacementsEnable typographer option to see result. (c) (C) (r) (R) (tm) (TM) (p) (P) +- test.. test… test….. test?….. test!…. !!!!!! ???? ,, – — “Smartypants, double quotes” and ‘single quotes’ H2 EmphasisThis is bold text This is bold text This is italic text This is italic text Strikethrough H2 Blockquotes Blockquotes can also be nested… …by using additional greater-than signs right next to each other… …or with spaces between arrows. H2 ListsUnordered Create a list by starting a line with +, -, or * Sub-lists are made by indenting 2 spaces: Marker character change forces new list start: Ac tristique libero volutpat at Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Very easy! Ordered Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa You can use sequential numbers… …or keep all the numbers as 1. Start numbering with offset: foo bar H2 CodeInline code Indented code // Some comments line 1 of code line 2 of code line 3 of code Block code “fences” Sample text here... Syntax highlighting var foo = function (bar) { return bar++; }; console.log(foo(5)); H2 Tables 我就一展示数据的表格 Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Right aligned columns 我就一展示数据的表格 Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. H2 Linkslink text link with title Autoconverted link https://github.com/nodeca/pica (enable linkify to see) H2 Images The Stormtroopocat Like links, Images also have a footnote style syntax The Dojocat With a reference later in the document defining the URL location: H2 PluginsThe killer feature of markdown-it is very effective support ofsyntax plugins. H3 Emojies Classic markup: :wink: :crush: :cry: :tear: :laughing: :yum: Shortcuts (emoticons): :-) :-( 8-) ;) see how to change output with twemoji. H3 Subscript / Superscript 19^th^ H~2~O H3 \\++Inserted text++ H3 \\==Marked text== H3 FootnotesFootnote 1 link[^first]. Footnote 2 link[^second]. Inline footnote^[Text of inline footnote] definition. Duplicated footnote reference[^second]. [^first]: Footnote can have markup and multiple paragraphs. [^second]: Footnote text. H3 Definition listsTerm 1 : Definition 1with lazy continuation. Term 2 with inline markup : Definition 2 { some code, part of Definition 2 } Third paragraph of definition 2. Compact style: Term 1 ~ Definition 1 Term 2 ~ Definition 2a ~ Definition 2b H3 AbbreviationsThis is HTML abbreviation example. It converts “HTML”, but keep intact partial entries like “xxxHTMLyyy” and so on. *[HTML]: Hyper Text Markup Language H3 Custom containers::: warninghere be dragons::: H2 MathH3 InLine你好{%raw%}$ \\begin{matrix}1 & x & x^2 \\\\1 & y & y^2 \\\\1 & z & z^2 \\\\\\end{matrix}${%endraw%}啊 你好$ \\begin{matrix}1 & x & x^2 \\\\1 & y & y^2 \\\\1 & z & z^2 \\\\\\end{matrix}$啊 H3 Block你好{%raw%}$$ \\begin{matrix}1 & x & x^2 \\\\1 & y & y^2 \\\\1 & z & z^2 \\\\\\end{matrix}$${%endraw%}啊 你好$$ \\begin{matrix}1 & x & x^2 \\\\1 & y & y^2 \\\\1 & z & z^2 \\\\\\end{matrix}$$啊 测试.md","categories":[{"name":"测试用例","slug":"测试用例","permalink":"http://blog.msiter.com/categories/测试用例/"}],"tags":[{"name":"测试","slug":"测试","permalink":"http://blog.msiter.com/tags/测试/"},{"name":"MARKDOWN","slug":"MARKDOWN","permalink":"http://blog.msiter.com/tags/MARKDOWN/"}],"keywords":[{"name":"测试用例","slug":"测试用例","permalink":"http://blog.msiter.com/categories/测试用例/"}]}]}